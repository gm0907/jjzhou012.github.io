---
layout: article
title: 图神经网络：An efficient end-to-end deep learning architecture for activity classification (DGCNN)
date: 2020-07-11 00:10:00 +0800
tags: [GNN, Graph, Graph Classification]
categories: blog
pageview: true
key: GNN-DGCNN
---

------

- Paper: [An efficient end-to-end deep learning architecture for activity classification](https://link.springer.com/article/10.1007/s10470-018-1306-2)

- Code
  - Pytorch: [https://github.com/muhanzhang/pytorch_DGCNN](https://github.com/muhanzhang/pytorch_DGCNN)
  - Matlab: [https://github.com/muhanzhang/DGCNN](https://github.com/muhanzhang/DGCNN)



## 概述

- 提出了一种新颖的用于图分类的端到端深度学习框架DGCNN。它直接接受图作为输入，不需要任何预处理；
- 提出了一种新的空域图卷积层来提取多尺度的节点特征，并与常用的图核模型进行了类比来解释其工作原理；
- 开发了一个新的sortPooling层来对节点特征进行排序，而不是将它们相加，这样可以保留更多的信息，从全局拓扑结构中学习特征。



## 框架

![ff5a1aaf48ddccb4ae12c0d6724ed34](https://raw.githubusercontent.com/jjzhou012/image/master/blogImg20200711155910.png)



DGCNN的三个阶段：

- 图卷积层：提取节点的局部子结构特征，并定义一致的节点排序；
- sortPooling: 按照预定义的顺序对节点特征进行排序，并统一输入大小；
- 传统的卷积层和全连接层：读取排序图的特征表示并做出预测。



### 图卷积层

层的公式化表示：

![image-20200711155859149](https://raw.githubusercontent.com/jjzhou012/image/master/blogImg20200711155859.png)

很容易理解，图卷积层的作用就是对节点的邻域信息进行聚合，也就是说，一个节点的信息由它自身信息和邻居节点信息聚合而成。

$$
(\tilde{\mathbf{A}} \mathbf{Y})_{i}=\sum_{j} \tilde{\mathbf{A}}_{i j} \mathbf{Y}_{j}=\mathbf{Y}_{i}+\sum_{j \in \Gamma(i)} \mathbf{Y}_{j}
$$

最终，图卷积对局部邻域节点信息进行聚合，实现局部子结构信息的抽取。

通过堆叠多层图卷积实现多尺度子结构特征提取：

$$
\mathbf{Z}^{t+1}=f\left(\tilde{\mathbf{D}}^{-1} \tilde{\mathbf{A}} \mathbf{Z}^{t} \mathbf{W}^{t}\right)
$$

堆叠完之后，再用一层来对所有的隐藏层输出$$\mathbf{Z}^{t}, t=1, \ldots, h$$进行拼接得到：$$\mathbf{Z}^{1: h} \in \mathbb{R}^{n \times \sum_{1}^{h} c_{t}}$$。拼接输出的每一行都可以看作一个节点的“特征描述符”，编码其多尺度局部子结构信息。



### SortPooling层

排序池层的主要功能是对特征描述符进行排序，每个特征描述符代表一个节点，在将它们放入传统的1-D卷积和全连接层之前，按照一致的顺序排序。在图里面，可以根据节点在图中的结构角色对其进行排序。

SortPooling层接受图卷积层的输出作为输入$$\mathbf{Z}^{1: h} \in \mathbb{R}^{n \times \sum_{1}^{h} c_{t}}$$，每一行是一个节点的特征描述符，每一列是一个特征通道。我们认为前面图卷积层输出的最后一层$$\mathbf{Z}^{h}$$是对节点最精细的特征描述，所以这里利用最后的$$\mathbf{Z}^{h}$$对节点进行排序。根据$$\mathbf{Z}^{h}$$的通道从后往前遍历，按降序对节点进行排序；如果该通道的值相同，则向前推进，比较前一个通道的值。如果$$\mathbf{Z}^{h}$$的所有通道值都相同，则比较$$\mathbf{Z}^{h-1}$$的通道。

除了按照一致的顺序对顶点特征排序之外，SortPooling的下一个功能是统一输出张量的大小。SortPooling的输出被限制为$$k \times \sum_{1}^{h} c_{t}$$，也就是说，排序后，将输出张量从$n$截断/扩展到$k$。这样做的目的是统一图的大小，使结点数不同的图的大小被统一到$k$。若$$n>k$$，删除排序后的后$$n-k$$层；若$$n<k$$，在最后添加$$k-n$$行0。



### 后续

SortPooling层的输出为$$\mathbf{Z}^{sp} \in \mathbb{R}^{k \times \sum_{1}^{h} c_{t}}$$，将其reshape成尺寸为$$k\left(\sum_{1}^{h} c_{t}\right) \times 1$$的向量。然后应用1-D卷积操作（滤波器大小为$$\sum_{1}^{h} c_{t}$$），以便于在节点的特征描述符上按顺序应用过滤器。

之后，再应用一些MaxPooling层和1-D卷积层，来提取节点序列的局部模型特征。最后接上全连接层和softmax层。


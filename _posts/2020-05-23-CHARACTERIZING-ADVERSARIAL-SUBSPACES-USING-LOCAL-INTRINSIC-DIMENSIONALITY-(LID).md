---
layout: article
title: 对抗样本检测：characterizing adversarial subspaces using local intrinsic dimensionality
date: 2020-05-23 00:10:00 +0800
tags: [DeepTest, Adversarial, CV]
categories: blog
pageview: true
key: CHARACTERIZING-ADVERSARIAL-SUBSPACES-USING-LOCAL-INTRINSIC-DIMENSIONALITY-(LID)
---

------

- Paper: [Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality](https://arxiv.org/abs/1801.02613)

- Code: [https://github.com/xingjunm/lid_adversarial_subspace_detection](https://github.com/xingjunm/lid_adversarial_subspace_detection)



## 概要

每个对抗样本都可以被一个域的连通区域(“对抗性区域”或“对抗性子空间”)所包围，在这个区域内所有的点都以类似的方式破坏分类器。对抗性区域不仅可以在输入空间中定义，还可以在不同DNN层的激活空间定义。

根据已有的研究，对抗子空间的性质有以下几点：

- 低概率区域，即非正常出现的；
- 张成一个多维连续区域；
- 接近但与数据子流形保持一定距离；
- 它们的类分布与最近的数据子流形不同；

在之前的研究中，核密度估计（Kernel Density (KD) estimation）可以用于确定对抗子空间。但作者认为KD指标不适用于一些攻击。其他的基于密度的指标，如$$k-$$平均距离。这些指标对对抗子空间的描述存在限制。例如下图中的正常样本和对抗样本，它们基于指标来检测时，KD和KM指标相同，无法区分。

![4a8e86acef7bff0444cf5aa48a7a966](https://raw.githubusercontent.com/jjzhou012/image/master/blogImg20200524085036.png)

作为密度度量的一种替代方法，图1引导我们考虑基于扩展的内在维度度量作为描述对抗样本的潜在有效方法。这种模型已经成功地应用于流形学习、降维、相似度搜索和异常检测等。尽管早期的扩展模型将固有维数描述为数据集的一种属性，但局部固有维数(LID)将这一概念完全概括为从参考点到邻近点的局部距离分布，即**通过累积分布函数的增长特性揭示了参考点附近局部数据子流形的维数**。

**该论文使用LID来描述对抗子空间的内在特征，并进一步测试LID的估计在多大程度上可以用来区分对抗样本。**同时LID的主要目标是描述对抗样本的性质，而非作为一种存粹的防御方法。在上图中，对抗样本的LID指标明显高于正常样本，一定程度上反映了LID能有效捕捉对抗样本的内在维度特性。

主要贡献：

- 提出用LID来刻画DNN的对抗子空间，并讨论了对抗扰动如何影响对抗区域，并通过实验证明了利用小批量训练数据就能有效的估计测试样本的特性。

- 实验表明，对抗样本的LID指标明显大于正常样本，并且这种差异在更深层次的DNNs中变得更加明显。
- 证明了不同攻击产生的对抗子空间具有相似的维度属性，简单攻击的LID特征可以潜在地用于检测其他更复杂的攻击。我们还证明了一个朴素的基于LID的检测器对基于CW的正常低置信优化攻击具有很强的鲁棒性。





## 局部内在维度（LID）

![32909ec001c2ff2d7f4ffcd800fd49a](https://raw.githubusercontent.com/jjzhou012/image/master/blogImg20200524111939.png)

使用洛必达法则得到等式。最终$$x$$处的局部内在维度用极限定义，当半径$$r$$趋向于0时：
$$
\mathrm{LID}_{F}=\lim _{r \rightarrow 0} \mathrm{LID}_{F}(r)
$$
$$\mathrm{LID}_{F}$$描述了累计概率分布$$F(r)$$随着距离$$r$$增大而增大的相对速率，并且可以用样本内$$x$$到$$k$$个最近邻的距离来估计。

在理想情况下，$$x$$附近的数据均匀分布在子流形内，$$\mathrm{LID}_{F}$$等于子流形的维数；然而，一般来说，这些分布并不理想，流形模型的数据并不完全适用，$$\mathrm{LID}_{F}$$不是一个整数。然而，局部固有维数确实给出了包含$$x$$的子流形的维数的粗略指示，该子流形最适合$$x$$附近的数据分布。



### 特征子空间的LID

对于一个位于数据子流形$$S$$的样本$$x\in X$$，$$X$$是从正常数据分布$$\mathcal{P}$$中随机采样得到的。利用对抗扰动生成的对抗样本$$x'$$和正常样本$$x$$的坐标有微小差别。假设$$x’$$是$$x$$的一个成功的对抗样本，那么$$x$$的LID理论值为$$S$$的维度，$$x'$$的理论值为对抗子空间的维度。

由于扰动设置一般允许修改所有数据坐标，因此它们利用了数据域的表示维所提供的完全自由度。相关研究表明，$$x'$$位于$$S$$外面，但是距离很近。在高维数据中，表示性的维度比任何数据子流形的内在维度要大得多，这意味着$$x'$$的LID理论值要比$$x$$大得多。

对于对抗子空间，出现在$$x'$$附近的样本可以期望从一个以上的流形中抽取。$$x'$$接近$$S$$意味着邻居可能包含躺在$$S$$中的邻居；然而，如果邻域主要是由来自$$S$$的样本组成的，这就不太可能是一个对抗样本。因此，$$x'$$的邻域合在一起很可能形成一个内在维度子空间，其固有维数要比单独考虑的任何子流形都要高得多，而对$$x'$$的LID估计可以揭示这一点。



### 使用LID表征对抗样本

接下来将描述LID估计值如何作为特征来训练检测器来区分对抗样本。注意，这里只训练了一个基线分类器来演示LID如何很好地描述对抗样本。

方法要求训练集由三种类型的例子组成:对抗样本、正常样本和噪声样本。加入噪声数据的原因是，DNNs需要对噪声输入鲁棒，且噪声数据不应该被识别为对抗样本。

分类器可以通过使用训练数据为每个样本构造特征来进行训练，这些特征基于跨不同层的小批样本中的LID，其中对抗样本的类标分配为正，而正常样本和噪声样本的类标分配为负。



![f729ebb40d8901af0c0e424b3c88f14](https://raw.githubusercontent.com/jjzhou012/image/master/blogImg20200524152802.png)

算法流程：

- LID特征提取

  - 对应每个batch的正常样本，生成对应batch的对抗样本和噪声样本；

  - 每个样本的LID特征计算，通过每个batch的$$k$$最近邻。

    对于DNN中的每个示例和每个转换层：

    - 距离函数使用给定层中的神经元的激活值作为输入；
    - 每个转换层计算一个LID，作为一个特征；

- 分类器在这些LID特征上训练
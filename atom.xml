<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Andy_z &#39;s Blog</title>
  
  <subtitle>Coding - Thinking - Sharing - Deep learning</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoururl.com/"/>
  <updated>2019-04-28T12:35:55.903Z</updated>
  <id>http://yoururl.com/</id>
  
  <author>
    <name>Andy_z</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>node2vec的实现与思考</title>
    <link href="http://yoururl.com/2019/04/26/node2vec%E7%9A%84%E5%AE%9E%E7%8E%B0%E4%B8%8E%E5%BA%94%E7%94%A8/"/>
    <id>http://yoururl.com/2019/04/26/node2vec的实现与应用/</id>
    <published>2019-04-25T16:08:00.000Z</published>
    <updated>2019-04-28T12:35:55.903Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Node2vec的实现与应用"><a href="#Node2vec的实现与应用" class="headerlink" title="Node2vec的实现与应用"></a>Node2vec的实现与应用</h1><h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>我们生活的世界中存在着各种各样的网络，从宏观角度的全球物流、通信、交通网络，到微观世界的蛋白质结构、化合物作用网络，从交织于现实与虚拟世界的社交网络，到学科领域的科学家合作网络。网络系统的存在是世界复杂性的体现，延伸出了一门新的交叉学科——网络科学。</p><p><img src="http://ww1.sinaimg.cn/large/005NduT8ly1g2imjgfj1fj30hu0amdqc.jpg" alt=""></p><p>网络科学是从交叉学科研究成长起来的一个新兴的学术领域。致力于研究复杂网络的性质，并且应用这些性质去研究一些具有网络特点的领域，比如信息技术网络，计算机网络，生物圈网络，学习和认知网络，社会关系网络以及经济和金融网络。这个领域以数学中的图论为理论基础，从物理中的统计力学，计算机科学中的数据挖掘和信息可视化，统计学中的推断建模，以及社会学和经济学中的社会结构理论等学科和分支中汲取方法论营养。</p><h2 id="一、研究背景"><a href="#一、研究背景" class="headerlink" title="一、研究背景"></a>一、研究背景</h2><h3 id="网络的发展"><a href="#网络的发展" class="headerlink" title="网络的发展"></a>网络的发展</h3><p>复杂网络本质上是基于数据的复杂系统，探索网络研究的先进方法论对于学科的进步尤为重要。目前计算机领域中最火热的当属人工智能，其包含的机器学习、深度学习模型与方法在大数据的支持下，摧枯拉朽般的实现了困扰人类多年的许多任务，使得许多机器辅助功能都变得可实现，这是传统统计学方法无法实现和超越的。</p><p>复杂网络早期的方法论主要是基于统计学和图论，同时结合交叉领域的专业信息，像社团检测任务中的<code>infomap</code>、<code>betweenness</code>、<code>label propagation algorithm</code>，链路预测中的节点相似性指标<code>CN</code>、<code>RA</code>、<code>LP</code>等，这些方法在早期的时候发光发热，直到现在，其中一些方法依然不乏较好的效果。但随着大数据时代的到来，网络的形式、规模也有了巨大的发展，从原本的稀疏网络到现在上亿节点和关系的巨型网络，从原本的静态时不变网络到如今的动态分层网络，从原本同构的节点属性单一的网络到如今知识图谱等的节点属性丰富关系复杂的异构网络。原本的统计学方法在面对复杂的、特征多样的网络系统，似乎力不从心，如何探索更适合的方法论已成为网络科学的研究热点。</p><h3 id="与AI结合前的思考"><a href="#与AI结合前的思考" class="headerlink" title="与AI结合前的思考"></a>与AI结合前的思考</h3><p>既然人工智能的热潮持续不衰，网络科学能否“蹭一波热度”，将形式多样、性能优良的机器学习、深度学习方法迁移到网络科学中呢，研究者就此开始了探索。</p><p>占据人工智能领域一大块的当属计算机视觉，也就是我们常说的图像识别。众所周知，图像由像素点构成，以2维的形式规则的排列，卷积核通过固定尺寸的窗口在图像上移动并提取特征。</p><p><img src="http://ww1.sinaimg.cn/mw690/005NduT8ly1g2dirwh8usj30k4066429.jpg" alt=""></p><p>自然语言处理针对文本数据，流行的 word2vec 模型利用 skip-gram 在文本上移动提取词组特征。</p><p><img src="http://ww1.sinaimg.cn/mw690/005NduT8ly1g2divubwtdj30fq08lq4g.jpg" alt=""></p><p>图像、文本数据中，我们可以很容易的定义数据元之间的距离，如像素之间的欧式距离，文本词汇之间的上下文关系等，通过距离的定义，我们可以进一步探索数据之间的相似性。以上我们可以称之为欧式数据，针对这些数据可以通过固定尺寸的核来提取特征用于训练。</p><p>在网络中呢？一般网络（图）在计算机中通常用一个邻接矩阵表示其结构信息（节点、连边），矩阵的行与列由网络节点构成，如果两个节点之间存在连边，那么矩阵对应坐标的元素设置为边权值（无权图设为1）。如果我们打乱节点顺序，重新构造邻接矩阵，新的邻接矩阵与原邻接矩阵等价，依然能反映网络的结构信息。</p><p><img src="http://ww1.sinaimg.cn/mw690/005NduT8ly1g2dkjzap4aj30if0e6gmc.jpg" alt=""></p><p>但是问题由此产生，原邻接矩阵若我们定义节点1，2之间的欧式距离 $d<em>{1,2}=1$，在新的邻接矩阵中，$d</em>{1,2}=4$，所以在网络中我们无法用欧式距离来定义节点之间的距离；此外若我们想用类似卷积核的核窗口来提取网络特征，可以发现：</p><ul><li>若中心节点为1，则<code>node1</code>的邻居节点有两个<code>node2</code>与<code>node4</code>;</li><li>若中心节点为3，则<code>node3</code>的邻居节点有三个<code>node2</code>、<code>node4</code>与<code>node5</code>;</li></ul><p>因为核窗口应该包含中心点和其邻域点，但因网络中不同节点的邻居节点数存在差异，所以无法确定核窗口的尺寸，来完美囊括每一个节点的邻域节点。</p><p>由此我们可以看出，网络与图像、文本等最大的差异在于顺序性，图像、语料等数据规则且具有一定顺序性，而网络没有。网络存在于非欧式空间，网络数据属于非欧式数据，无法直接应用机器学习、深度学习里的一些特征提取方法。</p><h3 id="突破"><a href="#突破" class="headerlink" title="突破"></a>突破</h3><p>研究者继续探索，既然网络没有顺序性，能否通过构造一定的顺序性，来反映网络的拓扑结构，继而衔接机器学习算法呢？由此，网络中的随机游走（random walk）概念被提出，继而引发了新的热潮。</p><p>什么是网络中的random walk？区别于全局优化中的random walk算法，网络中的random walk是一种采样策略，在RW的每一步采样中，从当前节点$v$的邻居节点中随机地选取一个节点$w$作为下一个待采样节点。从节点$v$随机游走到其邻居节点$w$的概率与当前节点$v$的度相关：</p><script type="math/tex; mode=display">P_{v, w}^{R W}=\left\{\begin{array}{c}{\frac{1}{d(v)}, \text { if } w \text { is a neighbor of } v} \\ {0, \text { otherwise }}\end{array}\right.</script><p>通过随机游走采样，我们可以获取到一系列的节点序列，这些节点序列是有顺序性的，我们可以把游走生成的序列类比成文本中的sentence，序列中的每一个节点看作句子中的word：</p><ul><li>节点序列 $\Longrightarrow$ sentence</li><li>node $\Longrightarrow$ word</li></ul><p><img src="http://ww1.sinaimg.cn/mw690/005NduT8ly1g2dogx8tv9j30gb081dh2.jpg" alt=""></p><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>既然可以通过random walk采样得到具有类文本性质的节点序列，那么我们是否可以利用nlp中的模型和算法来对网络进行研究呢？</p><p>研究者提出了Deepwalk模型，Deepwalk的思想非常简单，首先将网络结构通过随机游走采样的方式，转换为类似“sentence”的节点序列的形式，再通过word2vec中的Skip-gram模型或者CBOW模型，训练得到每个节点的向量表示形式，进而可以用余弦距离或者欧式距离来求得两个节点之间的相似度。</p><h2 id="二、Node2vec原理"><a href="#二、Node2vec原理" class="headerlink" title="二、Node2vec原理"></a>二、Node2vec原理</h2><p>整体上来看，Node2Vector在deepwalk的基础上改变了节点游走的方式，考虑了更多的信息。Deepwalk在下一个节点的选择上只是从当前节点的所有邻居节点中随机选择一个，而node2vec结合传统的BFS和DFS的两种搜索方法，提出了新的搜索策略。</p><h3 id="前提假设"><a href="#前提假设" class="headerlink" title="前提假设"></a>前提假设</h3><p>Node2vec将网络特征学习视为一个极大似然问题。对于一个给定的网络 $G=(V, E)​$ ，设计一个函数映射 $f : V-&gt;R^{d}​$ 将特征映射为 $d​$ 维向量。对于网络中的任一节点 $v \in V​$ ， 利用 采样策略 $s​$ 得到的节点 $v​$ 的邻域信息集合为 $N_{S}(u) \subset V​$ 。整个特征学习过程为一个极大似然优化问题：</p><script type="math/tex; mode=display">\max _{f} \sum_{u \in V} \log \operatorname{Pr}\left(N_{S}(u) | f(u)\right)</script><p>为了简化该优化过程，作者提出了两个前提假设：</p><ul><li><p>条件独立性假设：给定源节点的特征表示，观察到一个邻节点的似然，与观察到其它邻节点的似然是相互独立的；</p><script type="math/tex; mode=display">\operatorname{Pr}\left(N_{s}(u) | f(u)\right)=\prod_{n_{i} \in N_{S}(u)} \operatorname{Pr}\left(n_{i} | f(u)\right)</script></li><li><p>特征空间的对称性：源节点与邻域节点在特征空间上具有对称性；</p><script type="math/tex; mode=display">\operatorname{Pr}\left(n_{i} | f(u)\right)=\frac{\exp \left(f\left(n_{i}\right) \cdot f(u)\right)}{\sum_{v \in V} \exp (f(v) \cdot f(u))}</script></li></ul><p>基于以上两个假设，问题转化为</p><script type="math/tex; mode=display">\begin{array}{c}{\max _{f} \sum_{u \in V}\left[-\log Z_{u}+\sum_{n_{i} \in N_{S}(u)} f\left(n_{i}\right) \cdot f(u)\right]} \\ {Z_{u}=\sum_{v \in V} \exp (f(u) \cdot f(v))}\end{array}</script><h3 id="网络中的BFS与DFS"><a href="#网络中的BFS与DFS" class="headerlink" title="网络中的BFS与DFS"></a>网络中的BFS与DFS</h3><p><img src="http://ww1.sinaimg.cn/mw690/005NduT8ly1g2dribz0kgj30kg07zjte.jpg" alt=""></p><p>在网络中，图嵌入学习得到的向量，应该需要表示两种信息：</p><ul><li>结构相似性（结构等价）：若网络中两个节点（直接相连）共享许多邻居节点，那么这两个节点具有结构相似性；如上图中的$u$和$s_1$ ，它们共享相同的邻居节点$s_2$和$s_3$，它们具有结构相似性；</li><li>同质性（规则等价）：若网络中两个节点（不直接相连）在网络中扮演相似的角色，即它们所处的网络结构相似，那么这两个节点为规则等价；如上图中的$u$和$s_6$ ，它们所处的网络结构相似，都有四个邻居节点，且邻居节点之间也存在一定连接，它们具有同质性；</li></ul><p>传统的BFS和DFS在网络中的表现：</p><ul><li>广度优先搜索(BFS)：在节点周围搜索，探索局部的结构形态，邻域$N_s$仅限于源节点的近邻节点；善于发现节点之间的结构相似性；</li><li>深度优先搜索(DFS)：在更大的范围去搜索高阶的结构形态，邻域由距离源节点越来越远的顺序采样的节点组成；善于发现节点之间的规则相似性；</li></ul><h3 id="Random-Walks"><a href="#Random-Walks" class="headerlink" title="Random Walks"></a>Random Walks</h3><p>给定一个源节点$u$，我们模拟一个固定长度$l$的随机游走。让$c_i$表示游走中的第$i$个节点，从$c_0=u$ 开始 ，节点 $c_i$以如下概率分布生成：</p><script type="math/tex; mode=display">P\left(c_{i}=x | c_{i-1}=v\right)=\left\{\begin{array}{ll}{\frac{\pi_{v x}}{Z}} & {\text { if }(v, x) \in E} \\ {0} & {\text { otherwise }}\end{array}\right.</script><p>$\pi_{vx}$ 为节点$v$和$x$之间的非标准化转移概率，$Z$是标准化常数。</p><p>随机游走相比于BFD/DFS，有以下优势：</p><ul><li>时间复杂度：通过在样本生成过程中引入图的连通性，随机游走提供了一种机制，通过跨不同源节点重用样本来提高有效采样效率。</li></ul><p>最简单的随机游走方法就是让$ \pi<em>{vx} = w</em>{vx}​$，就是按边的权重分配等价的概率来选择下一个节点。但是这样的设置是无法较好的搜索节点的邻域信息的。</p><h3 id="Node2vec的搜索策略"><a href="#Node2vec的搜索策略" class="headerlink" title="Node2vec的搜索策略"></a>Node2vec的搜索策略</h3><p>Node2vec结合BFS和DFS的优势，改变了deepwalk中的random walk搜索策略，提出了二阶的随机游走策略，通过两个参数$p,q$来控制。</p><p><img src="http://ww1.sinaimg.cn/mw690/005NduT8ly1g2drx9rii3j30br08d75f.jpg" alt=""></p><p>考虑一个随机游走过程，它刚刚遍历了边 $(t, v)$，现在驻留在节点$v$(图)，游走策略需要确定下一个节点走哪里，这里设置未归一化转移概率为 $<br>\pi<em>{v x}=\alpha</em>{p q}(t, x) \cdot w_{v x}<br>$ ，其中收缩偏置$\alpha$定义如下：</p><script type="math/tex; mode=display">\alpha_{p q}(t, x)=\left\{\begin{array}{ll}{\frac{1}{p}} & {\text { if } d_{t x}=0} \\ {1} & {\text { if } d_{t x}=1} \\ {\frac{1}{q}} & {\text { if } d_{t x}=2}\end{array}\right.</script><p>$d<em>{tx}$ 代表了节点 $t$ 与 $x$ 之间的最短路径，$d</em>{tx} \in {0,1,2}$ </p><p>参数：</p><ul><li>Return parameter：参数$p$控制在游走过程中访问上一个节点的概率, $\frac{1}{p}$, 提高$p$值可以降低在两个采样过程中重新访问已经访问过的节点的概率, 避免2-hop冗余；</li><li>In-out parameter：参数$q$允许搜索区分”向内”和”向外”节点, $q&gt;1$, 搜索为BFS; $q&lt;1​$, 搜索为DFS；</li></ul><h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><p><img src="http://ww1.sinaimg.cn/mw690/005NduT8ly1g2dsml9u6mj30c00ba3zr.jpg" alt=""></p><p>Node2vec的三个主要阶段：</p><ul><li>转移概率初始化</li><li>模拟随机游走采样</li><li>基于word2vec的SGD优化</li></ul><p>过程具体说明如下：</p><ul><li><p><strong>转移概率初始化</strong>：采样是基于$\pi_{vx}$的转移概率，对于二阶马尔可夫链的转移概率需要预先计算。这里需要注意，转移概率有两部分：</p><ul><li><p><strong>节点的转移概率</strong>：节点的转移概率用于第一次游走，因为第一次游走采样之前只确定了序列初始节点，不存在边的信息，故无法利用前一次采样的边来执行二阶的搜索采样，所以第一次游走采样的节点需要通过节点之间的转移概率来确定。节点之间的转移概率基于边的权值，即令$ \pi<em>{vx} = w</em>{vx}$。</p><p><img src="http://ww1.sinaimg.cn/large/005NduT8ly1g2dtazaru9j30s5083aar.jpg" alt=""></p></li><li><p><strong>边的转移概率</strong>：后续的游走属于$p,q$控制的二阶搜索采样过程，使用边级别的转移概率。</p><p><img src="http://ww1.sinaimg.cn/large/005NduT8ly1g2dtbfc8e2j30ms0f93zu.jpg" alt=""></p></li></ul><blockquote><p>注意：初始化转移概率的过程其实是<a href="http://www.keithschwarz.com/darts-dice-coins/" target="_blank" rel="noopener">alias sample</a>的第一阶段，初始化alias table的过程。该过程时间复杂度为$O(n)$。</p><p>具体算法实现：</p><p><img src="http://ww1.sinaimg.cn/large/005NduT8ly1g2dtjxpy5qj30rh0nhmzg.jpg" alt=""></p></blockquote></li></ul><ul><li><p><strong>模拟随机游走采样</strong>：该过程属于alias sample(别名采样)的第二阶段，采样过程。该过程基于alias sample的第一阶段生成的alias table。</p><p>在随机游走过程中，由于起始节点的选择不同，会引入潜在偏差。由于我们需要学习所有节点的表示，我们通过模拟从每个节点开始的$r$个长度为$l​$的随机游走来抵消这个偏差。</p><p><img src="http://ww1.sinaimg.cn/large/005NduT8ly1g2dtn2ieg2j30sa0armxx.jpg" alt=""></p></li></ul><ul><li><p><strong>基于word2vec的SGD优化</strong>：该过程将采样得到的节点序列输入word2vec模型，使用随机梯度下降优化损失函数，得到节点的向量表示。</p><p><img src="http://ww1.sinaimg.cn/large/005NduT8ly1g2dtsz9tjqj30x207caah.jpg" alt=""></p></li></ul><p>最终，我们得到节点的向量表示，可以用于下游任务。</p><p><img src="http://ww1.sinaimg.cn/large/005NduT8ly1g2du8jinlcj30r603yjro.jpg" alt=""></p><h2 id="三、实验"><a href="#三、实验" class="headerlink" title="三、实验"></a>三、实验</h2><p>我们通过node2vec表征了网络节点，得到了每个结点的向量表示。至此，我们可以衔接机器学习算法，实现下游的任务。</p><p>我们设计了两个实验，分别为了说明不同的目的：</p><ul><li>社团检测</li><li>节点分类</li></ul><h3 id="社团检测"><a href="#社团检测" class="headerlink" title="社团检测"></a>社团检测</h3><h4 id="社团检测介绍"><a href="#社团检测介绍" class="headerlink" title="社团检测介绍"></a><strong>社团检测介绍</strong></h4><p>社团结构是除小世界、无标度特性外复杂网络研究领域的又一重大发现。所谓的社团结构，就是网络中紧密连接的子图，子图内部的连边密度高于子图之间的连边密度。网络中存在的社团结构可以揭示出一定的行为特点和功能，展示系统拓扑结构中蕴含的信息。社团检测算法的研究就是为了挖掘出网络中存在的社团结构。</p><p>而Node2vec等图嵌入算法的出现为解决社团检测问题提供了一个新思路。</p><h4 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h4><p>衡量社团检测算法检测到的社团结果质量也是该领域研究中的一个重点。该领域的研究者们先后提出了一些评价指标，主要分为真实社团划分结果未知和真实社团划分结果已知两种情况，前者包括模块度及其相关扩展，后者包括标准化互信息（Normalized Mutual Information, NMI），调整兰德指数（Adjusted Rand Index, ARI）等。</p><p>本文选择了标准化互信息NMI作为评价指标，它是一个基于信息论的评价指标，衡量了检测到的社团划分结果和真实划分结果之间的相似性。将检测到的社团划分结果和真实的划分结果分布用随机变量$X​$和$Y​$表示，$x_i​$表示检测到的划分结果中节点$i​$所属的社团标号，$y_i​$表示真实划分结果中节点$i​$所属的社团标号。随机变量$X​$和$Y​$的互信息定义为：</p><script type="math/tex; mode=display">I(X, Y)=\sum_{x y} P(x, y) \log \frac{P(x, y)}{P(x) P(y)}</script><p>其中，$P(x, y)=P(X=x, Y=y)=n<em>{x y} / n$为随机变量$X$和$Y$的联合分布，同样有$P(x)=P(X=x)=n</em>{x} / n$和$P(x)=P(X=x)=n_{y} / n$。</p><p>进一步将其归一化得到：</p><script type="math/tex; mode=display">I_{\text {norm}}(X, Y)=\frac{2 I(X, Y)}{H(X)+H(Y)}</script><p>其中，$H(x)=-\sum_{x} P(x) \log P(x)$为划分结果的信息熵，$H(Y)$同样。</p><h4 id="数据集说明"><a href="#数据集说明" class="headerlink" title="数据集说明"></a>数据集说明</h4><p>本章实验设计的过程中选取了四个常用于社团检测的数据集，包括空手道俱乐部网络、海豚社交网络、美国大学橄榄球联赛网络以及美国政治书网络，数据集基本信息如下表所示。</p><ul><li>空手道俱乐部网络：该网络是由Zachary历时两年观察一个空手道俱乐部中的日常所构建的社交网络，网络中的节点表示俱乐部中的成员，连边表示成员之间存在的朋友关系。后因为俱乐部的教练和管理者之间发生分歧，最终一分为二。</li><li>海豚社交网络：该网络是由Lusseau 通过对新西兰神奇湾的海豚长达7 年的观察构建而成。网络中的节点代表了海豚，连边代表两只海豚间具有频繁联系。该网络后因一只海豚的离去划分成了两个社团。</li><li>美国大学橄榄球联赛网络：该网络表示的是是 2000 赛季组比赛的赛事安排，网络中的节点表示各个大学代表队，连边表示两个队伍之间开展过常规赛。所有参赛队伍被划分到了12 个联盟。相较于隶属不同联盟的队伍，同属于一个联盟的队伍之间会有更频繁的赛事，使得该网络表现出一定的社团结构。</li><li>美国政治书网络：V.Krebs根据亚马逊网站上在 2004 年美国总统大选期间销售的与政治相关的书籍构建了美国政治书网络。其中节点表示亚马逊上销售的政治书，连边表示有读者同时购买了两本书籍。</li></ul><div class="table-container"><table><thead><tr><th>数据集</th><th>节点数</th><th>连边数</th><th>真实社团个数</th></tr></thead><tbody><tr><td>空手道俱乐部网络</td><td>34</td><td>78</td><td>2</td></tr><tr><td>海豚社交网络</td><td>62</td><td>159</td><td>2</td></tr><tr><td>美国大学橄榄球联赛网络</td><td>115</td><td>613</td><td>12</td></tr><tr><td>美国政治书网络</td><td>105</td><td>441</td><td>3</td></tr></tbody></table></div><h4 id="对比算法"><a href="#对比算法" class="headerlink" title="对比算法"></a>对比算法</h4><ul><li>标签传播算法 (LPA)：Raghavan等人提出的LPA算法的基本思想为，算法初始为每个节点各自分配一个标签，然后对节点的标签进行迭代更新，更新规则为将节点新的标签设定为其邻接节点标签中出现频率最高的一个，出现相同最大值是则进行随机选择，当没有节点的标签再发生变化时，算法终止。</li><li>Infomap算法(INF)：Rosvall等人提出的Infomap算法主要基于网络图和编码理论。它通过压缩网络中的信息流描述来检测社团。因为信息流在经过不同社团时会产生更大的编码长度，其关键就在于最小化平均描述长度L（M）。</li><li>Louvain算法 (LOU)：Blondel等人提出的Louvain算法将社团检测视为一个多级模块度优化问题，主要包括两个步骤。第一阶段它先从孤立的节点开始，重复将节点划分到一个社区，实现最大化模块度增益，直到无法实现进一步的改进。第二阶段它再将此前检测到的社团合并为超级节点构建新网络。重复执行两个阶段直到算法稳定。</li><li>Node2vec+K-Means：Node2vec的原理以及算法流程已经在第二章中详细介绍，这里主要介绍K-Means聚类算法。该算法的实现流程为先随机选取K个对象作为初始的聚类中心，然后计算每个对象和各聚类中心之间的距离，将其分配给与它最接近的聚类中心。完成一轮分配后重新计算聚类中心，重复上述流程直至满足某个终止条件，得到最后的聚类结果。</li></ul><h4 id="实验结果及分析"><a href="#实验结果及分析" class="headerlink" title="实验结果及分析"></a>实验结果及分析</h4><p>我们在4个数据集上均做了实验，对比了Node2vec+K-Means和其余3种传统的社团检测算法的效果，实验结果如下表所示，表中我们标出了每个数据集上性能最优的两个结果。可以看到，Node2vec+K-Means在这4个数据集上均表现出了较好的检测准确性。</p><div class="table-container"><table><thead><tr><th></th><th>Karate</th><th>Dolphins</th><th>Football</th><th>Polbooks</th></tr></thead><tbody><tr><td>LPA</td><td><strong>0.806</strong></td><td><strong>0.607</strong></td><td>0.888</td><td><strong>0.586</strong></td></tr><tr><td>Infomap</td><td>0.699</td><td>0.553</td><td><strong>0.924</strong></td><td>0.493</td></tr><tr><td>Louvain</td><td>0.587</td><td>0.511</td><td>0.890</td><td>0.512</td></tr><tr><td>Node2vec+K-Means</td><td><strong>0.951</strong></td><td><strong>0.889</strong></td><td><strong>0.922</strong></td><td><strong>0.564</strong></td></tr></tbody></table></div><p>Node2vec等图嵌入算法的提出，提供了将网络从非欧空间转移到向量空间的新思路，由此，针对网络的算法研究不再仅仅依赖于网络拓扑结构，表征后得到的节点向量可以反映网络中节点间的相关性，用于后续的机器学习算法，可以在下游任务中得到优于传统方法的效果。</p><h3 id="节点分类"><a href="#节点分类" class="headerlink" title="节点分类"></a>节点分类</h3><h4 id="评价指标-1"><a href="#评价指标-1" class="headerlink" title="评价指标"></a>评价指标</h4><p>分类是监督学习中的一个核心问题。为了评价一个分类器的分类性能优劣，需要引入一些评估指标，常用的一些指标有准确率（Accuracy）、精确率（Precision）、召回率（Recall）、F值等。</p><p>在二分类问题中，通常以关注的类为正类，其他类为负类，依据分类器在测试数据集上的预测正确与否，四种情况出现的总数分别记作：</p><ul><li>TP：将正类预测为正类的样本数；</li><li>FN：将正类预测为负类的样本数；</li><li>FP：将负类预测为正类的样本数；</li><li>TN：将负类预测为负类的样本数；</li></ul><p>其中，True、False表示分类正确与错误，Positive、Negative表示正、负样本。</p><p>微平均（Micro-averaging）是对数据集中的每一个示例不分类别进行统计建立全局混淆矩阵，然后计算相应的指标。其计算公式如下：</p><p>micro精度(precision)：</p><script type="math/tex; mode=display">P_{\text {micto}}=\frac{T \overline{P}}{T P+F \overline{P}}=\frac{\sum_{i=1}^{n} T P_{i}}{\sum_{i=1}^{n} T P_{i}+\sum_{i=1}^{n} F P_{i}}</script><p>micro召回(recall)：</p><script type="math/tex; mode=display">R_{\text {micro}}=\frac{T^{\overline{P}}}{T \overline{P}+F \overline{N}}=\frac{\sum_{i=1}^{n} T P_{i}}{\sum_{i=1}^{n} T P_{i}+\sum_{i=1}^{n} F N_{i}}</script><p>micro-F1：</p><script type="math/tex; mode=display">F_{\text {micro}}=\frac{2 \times P_{\text {micro}} \times R_{\text {micro}}}{P_{\text {micro}}+R_{\text {micro}}}</script><p>Micro-averaging赋予每个样本决策相同的权重，对于数据集中各个类的分布不平衡的问题，更建议使用mirco-F1，因为macro没有考虑到各个类别的样本大小。</p><h4 id="数据集说明-1"><a href="#数据集说明-1" class="headerlink" title="数据集说明"></a>数据集说明</h4><ul><li>BlogCatalog：BlogCatalog网站上列出的博主的社交关系网络。标签表示通过博主提供的元数据推断的博主兴趣。该网络有10,312个节点，333,983个边缘和39个不同的标签。</li><li>Wikipedia:  这是一个由出现在Wikipedia转储文件的前一百万字节中的单词组成的并发网络。标签表示使用Stanford post - tagger推断的词性(POS)标签。该网络有4777个节点、184812条边和40个不同的标签。</li></ul><h4 id="对比算法-1"><a href="#对比算法-1" class="headerlink" title="对比算法"></a>对比算法</h4><ul><li><p>Deepwalk: DeepWalk通过<strong>截断随机游走</strong>(truncated random walk)学习出一个网络的<strong>社会表示</strong>，其中的采样策略可以看作是node2vec的一个特例，p = 1, q = 1。</p></li><li><p>LINE：利用了网络的一阶和二阶相似性，能够保留局部和全局的网络结构。同时提出了边缘采样方法，解决了经典随机梯度下降的局限性，提高了算法的有效性和效率。能够适用于任意类型的网络。</p></li></ul><h4 id="实验结果与分析"><a href="#实验结果与分析" class="headerlink" title="实验结果与分析"></a>实验结果与分析</h4><p>我们在两个数据集上做了实验，对比了三种图嵌入算法在同一节点分类任务中的表征效果。我们按数据集的划分比例，从10%-90%，将数据集划分为训练集和测试集，每种划分方式进行5次实验取平均。实验结果如下图所示，node2vec和deepwalk在这两种数据集上的表征效果相近，但都优于LINE方法。LINE方法适用于大规模网络，在实验用的两个数据集上效果没有其他两种算法好。</p><p><img src="http://ww1.sinaimg.cn/large/005NduT8ly1g2ic19o6kej30y10eomzh.jpg" alt=""></p><p>不同的图嵌入方法，从不同角度对网络的拓扑结构进行表征，且适用于不同规模和类型的网络。</p><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>图嵌入算法的提出，将网络科学与机器学习联系起来，带来了新的思路。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Node2vec的实现与应用&quot;&gt;&lt;a href=&quot;#Node2vec的实现与应用&quot; class=&quot;headerlink&quot; title=&quot;Node2vec的实现与应用&quot;&gt;&lt;/a&gt;Node2vec的实现与应用&lt;/h1&gt;&lt;h2 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写
      
    
    </summary>
    
      <category term="图嵌入" scheme="http://yoururl.com/categories/%E5%9B%BE%E5%B5%8C%E5%85%A5/"/>
    
    
      <category term="network embedding" scheme="http://yoururl.com/tags/network-embedding/"/>
    
  </entry>
  
  <entry>
    <title>GAN Lab：交互式可视化GAN平台</title>
    <link href="http://yoururl.com/2019/03/05/GAN%20Lab/"/>
    <id>http://yoururl.com/2019/03/05/GAN Lab/</id>
    <published>2019-03-04T16:08:00.000Z</published>
    <updated>2019-03-21T04:47:55.064Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GAN-Lab"><a href="#GAN-Lab" class="headerlink" title="GAN Lab"></a>GAN Lab</h1><p>GAN Lab 是一个最新的交互式可视化工具，使用 <a href="https://js.tensorflow.org/" target="_blank" rel="noopener"><code>Tensorflow.js</code></a> 构建。</p><p>由佐治亚理工学院 Minsuk Kahng、Polo Chau 和 Google Brain 的 Nikhil Thorat、Fernanda Viégas、Martin Wattenberg 合作开发了<a href="https://poloclub.github.io/ganlab/" target="_blank" rel="noopener">GAN Lab</a>。</p><p><code>Tensorflow.js</code> 是用于在浏览器和Node.js上训练和部署ML模型的JavaScript库。</p><p>GANs 是一类复杂的深度学习模型，GAN Lab 可用于交互式的训练针对2D数据分布的GAN模型，并可视化模型的内部工作机理。</p><h2 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h2><p>安装yarn</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g yarn</span><br></pre></td></tr></table></figure><p>若报错</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The engine &quot;node&quot; is incompatible with this module. Expected version &quot;&gt;=4 &lt;=9&quot;. Got &quot;10.8.0&quot;</span><br></pre></td></tr></table></figure><p>运行如下命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn install --ignore-engines</span><br></pre></td></tr></table></figure><p>安装ganlab</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https://github.com/poloclub/ganlab.git</span><br><span class="line">$ cd ganlab</span><br><span class="line">$ yarn prep</span><br></pre></td></tr></table></figure><h2 id="运行demo"><a href="#运行demo" class="headerlink" title="运行demo"></a>运行demo</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ ./scripts/watch-demo</span><br><span class="line"></span><br><span class="line">&gt;&gt; Waiting for initial compile...</span><br><span class="line">&gt;&gt; 3462522 bytes written to demo/bundle.js (2.17 seconds) at 00:00:00</span><br><span class="line">&gt;&gt; Starting up http-server, serving ./</span><br><span class="line">&gt;&gt; Available on:</span><br><span class="line">&gt;&gt;   http://127.0.0.1:8080</span><br><span class="line">&gt;&gt; Hit CTRL-C to stop the server</span><br></pre></td></tr></table></figure><p>访问 <code>http://localhost:8080/demo/</code></p><h2 id="工具模块解析"><a href="#工具模块解析" class="headerlink" title="工具模块解析"></a>工具模块解析</h2><h3 id="界面总览"><a href="#界面总览" class="headerlink" title="界面总览"></a>界面总览</h3><p><img src="https://s2.ax1x.com/2019/03/05/kjPDv8.png" alt="kjPDv8.png"></p><h3 id="模型界面"><a href="#模型界面" class="headerlink" title="模型界面"></a>模型界面</h3><h4 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h4><p><img src="https://s2.ax1x.com/2019/03/05/kjeupd.png" alt="kjeupd.png"></p><p>模型图上可以修改的超参数有：</p><ul><li>随机噪声类型（一维、二维；高斯、均匀）</li><li>优化器（SGD、Adam）</li><li>学习率</li><li>网络隐藏层数，神经元数</li><li>损失函数（Log、LeastSq）</li><li>参数更新速度</li></ul><h4 id="训练可视化"><a href="#训练可视化" class="headerlink" title="训练可视化"></a>训练可视化</h4><p><img src="https://s2.ax1x.com/2019/03/05/kjaH1I.png" alt="kjaH1I.png"></p><p>训练过程中，虚线将示意数据流动方向。运行按钮边上有一个慢动作按钮，点击后能放慢训练过程，可以更细致得查看模型内部的训练过程。</p><p>鼠标悬浮于生成网络，可以看到从随机噪声到生成样本的流形变换过程。</p><p><img src="https://s2.ax1x.com/2019/03/05/kjAby6.png" alt="kjAby6.png"></p><p>判别网络上，决策边界可视化为二维热图。绿色表示判别网络分类为真实样本，紫色表示判别网路分类为生成样本。<strong>颜色深浅编码了置信度</strong>，颜色越深，判别网络对自己的判断就越自信。</p><p>随着训练的进行，判别网络的热图总体趋近于灰色，意味着判别网络越来越难以分辨真实样本和虚假样本。</p><p>另外，判别网络的输出预测同样使用<strong>颜色深浅编码置信度</strong>。</p><p><img src="https://s2.ax1x.com/2019/03/05/kjaOnf.png" alt="kjaOnf.png"></p><p>右侧的数据分布视图用紫线可视化了生成网络的梯度。在训练中，梯度刺向背景热图的绿色区域，意味着生成网络正努力的欺骗判别网络。</p><p><img src="https://s2.ax1x.com/2019/03/05/kjajHS.png" alt="kjajHS.png"></p><h3 id="测度界面"><a href="#测度界面" class="headerlink" title="测度界面"></a>测度界面</h3><p><img src="https://s2.ax1x.com/2019/03/05/kjml8J.png" alt="kjml8J.png"></p><p>点击运行，开始训练后，可以看到右侧不断更新的测度，分别为：</p><ul><li>判别器loss</li><li>生成器loss</li><li>KL散度</li><li>JS 散度</li></ul><h3 id="数据分布视图"><a href="#数据分布视图" class="headerlink" title="数据分布视图"></a>数据分布视图</h3><p><a href="https://image-cdn.jqr.com/editor/203/904/2039045747-5b913b67a2794" target="_blank" rel="noopener">gif</a></p><p><img src="https://image-cdn.jqr.com/editor/203/904/2039045747-5b913b67a2794" alt="img"></p><p>绿点为真实样本，紫点为生成样本。训练过程中，生成样本的位置不断更新，最终趋向于和真实样本重叠。</p><h2 id="GAN的简单介绍"><a href="#GAN的简单介绍" class="headerlink" title="GAN的简单介绍"></a>GAN的简单介绍</h2><p>生成对抗网络（Generative Adversarial Nets）在 Ian Goodfellow 等人2014年的论文《Generative Adversarial Nets》中提出，是非监督学习的一种方法，通过让两个神经网络相互博弈的方式进行学习。</p><p>生成对抗网络由一个生成网络（Generator）与一个判别网络（Discriminator）组成。生成网络从潜在空间（latent space）中随机采样作为输入，其输出结果需要尽量<strong>模仿训练集中的真实样本的数据分布</strong>。判别网络的输入则为真实样本或生成网络的输出，其<strong>目的是将生成网络的输出从真实样本中尽可能分辨出来</strong>。而生成网络则要尽可能地欺骗判别网络。两个网络相互对抗、不断调整参数，<strong>最终目的是使判别网络无法判断生成网络的输出结果是否真实</strong>。生成对抗网络常用于生成以假乱真的图片。此外，该方法还被用于生成视频、三维物体模型等。</p><p>通过学习一类概率分布的数据，生成相似分布的数据。比如，模型通过学习一些人脸图片，然后自己来生成人脸图片。这样创造性的生成现实图片看似很神奇，但其实是有两个关键点：</p><ul><li>模型在高维空间上对数据的概率分布进行建模。因为我们需要模型了解哪些图像是人脸，哪些不是；</li><li>GAN由生成模型和判别模型构成，引入零和博弈的思想，生成器生成尽可能真实的图像，判别器努力将生成图像和真实图像区分开来，两个网络相互对抗，最终判别器无法准确分辨真实图像和生成图像。</li></ul><p>综上，GAN 通过从一个特定分布中采样生成数据，通过设置对抗网络来使得生成效果达到最优。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;GAN-Lab&quot;&gt;&lt;a href=&quot;#GAN-Lab&quot; class=&quot;headerlink&quot; title=&quot;GAN Lab&quot;&gt;&lt;/a&gt;GAN Lab&lt;/h1&gt;&lt;p&gt;GAN Lab 是一个最新的交互式可视化工具，使用 &lt;a href=&quot;https://js.tens
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoururl.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Tensorflow" scheme="http://yoururl.com/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>samba服务端与客户端安装配置</title>
    <link href="http://yoururl.com/2019/02/21/samba%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB%E9%85%8D%E7%BD%AE(1)/"/>
    <id>http://yoururl.com/2019/02/21/samba文件共享配置(1)/</id>
    <published>2019-02-20T16:07:00.000Z</published>
    <updated>2019-02-21T05:42:19.218Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Samba-文件共享配置"><a href="#Samba-文件共享配置" class="headerlink" title="Samba 文件共享配置"></a>Samba 文件共享配置</h1><h2 id="一、CentOS服务端—-Win客户端"><a href="#一、CentOS服务端—-Win客户端" class="headerlink" title="一、CentOS服务端—-Win客户端"></a>一、CentOS服务端—-Win客户端</h2><h3 id="1-1-安装samba组件"><a href="#1-1-安装samba组件" class="headerlink" title="1.1 安装samba组件"></a>1.1 安装samba组件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install samba samba-client samba-swat</span><br></pre></td></tr></table></figure><ul><li>查看安装情况：</li></ul><p><img src="https://s2.ax1x.com/2019/02/20/k2I95q.png" alt="k2I95q.png"></p><h3 id="1-2-配置samba"><a href="#1-2-配置samba" class="headerlink" title="1.2 配置samba"></a>1.2 配置samba</h3><ul><li>设置开机启动：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chkconfig smb on</span><br><span class="line">chkconfig nmb on</span><br></pre></td></tr></table></figure><ul><li>新建访问用户</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">useradd xxx       # 新建用户</span><br><span class="line">smbpasswd -a xxx  # 修改密码</span><br></pre></td></tr></table></figure><ul><li>创建共享文件夹</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir /root/root_share</span><br><span class="line"># 修改共享文件夹权限</span><br><span class="line">cd /</span><br><span class="line">chmod 777 /root</span><br><span class="line">chmod 777 /root/root_share</span><br></pre></td></tr></table></figure><ul><li>修改samba配置文件</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/samba/smb.conf</span><br></pre></td></tr></table></figure><p><img src="https://s2.ax1x.com/2019/02/20/k2ItZd.png" alt="k2ItZd.png"></p><ul><li>关闭防火墙</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chkconfig iptables off</span><br></pre></td></tr></table></figure><ul><li>关闭SELINUX</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/selinux/config</span><br></pre></td></tr></table></figure><p><img src="https://s2.ax1x.com/2019/02/20/k2IUII.png" alt="k2IUII.png"></p><ul><li>系统重启</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure><ul><li>查看samba启动状态</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service smb status</span><br></pre></td></tr></table></figure><p><img src="https://s2.ax1x.com/2019/02/20/k2IOF1.png" alt="k2IOF1.png"></p><ul><li>修改host allow</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/samba/smb.conf</span><br></pre></td></tr></table></figure><p><img src="https://s2.ax1x.com/2019/02/20/k2oCeH.png" alt="k2oCeH.png"></p><blockquote><p>注意不修改的话，windows无法访问</p></blockquote><h3 id="1-3-客户端连接共享文件夹"><a href="#1-3-客户端连接共享文件夹" class="headerlink" title="1.3 客户端连接共享文件夹"></a>1.3 客户端连接共享文件夹</h3><blockquote><p>客户端环境：windows10家庭版</p></blockquote><ul><li>开启SMB/CIFS支持</li></ul><p><img src="https://s2.ax1x.com/2019/02/20/k2o1kn.png" alt="k2o1kn.png"></p><ul><li>本地组策略编辑</li></ul><p>按住快捷键Win+R打开运行窗口，往运行里面输入<strong>gpedit.msc</strong> 打开的是组策略编辑器</p><p><img src="https://s2.ax1x.com/2019/02/20/k2oBkR.png" alt="k2oBkR.png"></p><blockquote><p>注意：有些用户想要打开组策略编辑器却遇到了gpedit.msc找不到的提示</p><p><img src="https://s2.ax1x.com/2019/02/20/k2oyp6.png" alt="k2oyp6.png"></p><p>解决方法：<a href="https://pan.baidu.com/s/1s9Il6ifEvXzGEUAiZ65GHg" target="_blank" rel="noopener">https://pan.baidu.com/s/1s9Il6ifEvXzGEUAiZ65GHg</a></p><p>下载上述文件，右键单击这个“win10添加策略组.cmd”文件，选择以<strong>管理员身份运行</strong>即可，运行完毕，系统成功加入策略组。</p></blockquote><ul><li>重启电脑</li></ul><ul><li><p>windows访问共享目录</p><p><img src="https://s2.ax1x.com/2019/02/20/k2TZNR.png" alt="k2TZNR.png"></p><p><img src="https://s2.ax1x.com/2019/02/20/k2TVE9.png" alt="k2TVE9.png"></p></li></ul><ul><li>访问成功</li></ul><h2 id="二、-—-Ubuntu客户端"><a href="#二、-—-Ubuntu客户端" class="headerlink" title="二、 — Ubuntu客户端"></a>二、 — Ubuntu客户端</h2><h3 id="2-1-安装samba客户端组件"><a href="#2-1-安装samba客户端组件" class="headerlink" title="2.1 安装samba客户端组件"></a>2.1 安装samba客户端组件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install smbclient</span><br></pre></td></tr></table></figure><h3 id="2-2-查看所以共享目录"><a href="#2-2-查看所以共享目录" class="headerlink" title="2.2 查看所以共享目录"></a>2.2 查看所以共享目录</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">smbclient -L server_ip</span><br></pre></td></tr></table></figure><blockquote><p>注：敲入上面命令后，在出现提示输入密码时，直接按Enter键（因为此处是匿名访问），结果会显示指定Samba服务器上当前全部的共享目录。</p></blockquote><h3 id="2-3-连接共享目录"><a href="#2-3-连接共享目录" class="headerlink" title="2.3 连接共享目录"></a>2.3 连接共享目录</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">smbclient //server_ip/root/root_share</span><br></pre></td></tr></table></figure><h3 id="2-4-挂载"><a href="#2-4-挂载" class="headerlink" title="2.4 挂载"></a>2.4 挂载</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mount -t cifs -o username=xxx,password=xxx //server_ip/root/root_share 本地挂载点</span><br></pre></td></tr></table></figure><h3 id="2-5-关于权限"><a href="#2-5-关于权限" class="headerlink" title="2.5 关于权限"></a>2.5 关于权限</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Samba-文件共享配置&quot;&gt;&lt;a href=&quot;#Samba-文件共享配置&quot; class=&quot;headerlink&quot; title=&quot;Samba 文件共享配置&quot;&gt;&lt;/a&gt;Samba 文件共享配置&lt;/h1&gt;&lt;h2 id=&quot;一、CentOS服务端—-Win客户端&quot;&gt;&lt;a h
      
    
    </summary>
    
      <category term="安装与配置" scheme="http://yoururl.com/categories/%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/"/>
    
    
      <category term="Install &amp; config" scheme="http://yoururl.com/tags/Install-config/"/>
    
  </entry>
  
  <entry>
    <title>NFS服务端与客户端安装配置</title>
    <link href="http://yoururl.com/2019/02/21/CentOS%206.9%20%E4%B8%8BNFS%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"/>
    <id>http://yoururl.com/2019/02/21/CentOS 6.9 下NFS安装配置/</id>
    <published>2019-02-20T16:07:00.000Z</published>
    <updated>2019-02-21T05:44:16.673Z</updated>
    
    <content type="html"><![CDATA[<h1 id="NFS安装配置"><a href="#NFS安装配置" class="headerlink" title="NFS安装配置"></a>NFS安装配置</h1><h2 id="一、服务器端配置"><a href="#一、服务器端配置" class="headerlink" title="一、服务器端配置"></a>一、服务器端配置</h2><h3 id="1-1-CentOS-服务器"><a href="#1-1-CentOS-服务器" class="headerlink" title="1.1 CentOS 服务器"></a>1.1 CentOS 服务器</h3><h4 id="1-1-1-确认软件是否安装，安装NFS服务相关软件"><a href="#1-1-1-确认软件是否安装，安装NFS服务相关软件" class="headerlink" title="1.1.1 确认软件是否安装，安装NFS服务相关软件"></a>1.1.1 确认软件是否安装，安装NFS服务相关软件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa|grep nfs</span><br><span class="line">rpm -qa|grep rpc</span><br></pre></td></tr></table></figure><p><img src="https://s2.ax1x.com/2019/02/19/kgasaR.png" alt="kgasaR.png"></p><h6 id="如查询结果如上，说明服务器自身已经安装了NFS，如果没有安装，则用yum命令来安装，并验证安装："><a href="#如查询结果如上，说明服务器自身已经安装了NFS，如果没有安装，则用yum命令来安装，并验证安装：" class="headerlink" title="如查询结果如上，说明服务器自身已经安装了NFS，如果没有安装，则用yum命令来安装，并验证安装："></a>如查询结果如上，说明服务器自身已经安装了NFS，如果没有安装，则用yum命令来安装，并验证安装：</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum -y install nfs-utils rpcbind</span><br><span class="line">rpm -qa nfs-utils rpcbind</span><br></pre></td></tr></table></figure><h4 id="1-1-2-编写nfs配置文件"><a href="#1-1-2-编写nfs配置文件" class="headerlink" title="1.1.2 编写nfs配置文件"></a>1.1.2 编写nfs配置文件</h4><p>nfs配置文件默认存在 /etc/exports</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/exports</span><br></pre></td></tr></table></figure><p><img src="https://s2.ax1x.com/2019/02/20/k2DXTg.png" alt="k2DXTg.png"></p><blockquote><p>/etc/exports 文件说明：</p><ul><li><p>/root/root_share    : — 指定共享目录信息</p></li><li><p>指定有访问权限的网段 </p><ul><li><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;     //NFS客户端地址：</span><br><span class="line">&gt;      指定IP: 192.168.0.1</span><br><span class="line">&gt;      指定子网所有主机: 192.168.0.0/24</span><br><span class="line">&gt;      指定域名的主机: test.com</span><br><span class="line">&gt;      指定域名所有主机: *.test.com</span><br><span class="line">&gt;      所有主机: *</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></li></ul></li></ul></blockquote><p>&gt;</p><blockquote><ul><li>其他设置<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; </span><br><span class="line">&gt; - （rw, sync, no_root_squash）    : -表示定义共享参数信息</span><br><span class="line">&gt; </span><br><span class="line">&gt;   - rw：表示读写； ro: 表示只读；</span><br><span class="line">&gt;   - sync : 同步， 数据会先写入到NFS服务器内存中，会立刻同步到磁盘里面==直接存储硬盘中；</span><br><span class="line">&gt;   - NFS 在预设的状况下会把 root 的 UID/GID (0/0) 对应到 nobody 去，这就是 root_squash。我们可以用 no_root_squash 关闭该功能。</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></li></ul></blockquote><h4 id="1-1-3-创建共享目录，进行权限设定"><a href="#1-1-3-创建共享目录，进行权限设定" class="headerlink" title="1.1.3 创建共享目录，进行权限设定"></a>1.1.3 创建共享目录，进行权限设定</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir /root/root_share -p</span><br><span class="line">chown -R nfsnobody.nfsnobody /root/root_share</span><br></pre></td></tr></table></figure><h4 id="1-1-4-启动服务"><a href="#1-1-4-启动服务" class="headerlink" title="1.1.4 启动服务"></a>1.1.4 启动服务</h4><h5 id="1-1-4-1-启动rpc服务"><a href="#1-1-4-1-启动rpc服务" class="headerlink" title="1.1.4.1 启动rpc服务"></a>1.1.4.1 启动rpc服务</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/rpcbind start</span><br></pre></td></tr></table></figure><h5 id="1-1-4-2-启动nfs服务"><a href="#1-1-4-2-启动nfs服务" class="headerlink" title="1.1.4.2 启动nfs服务"></a>1.1.4.2 启动nfs服务</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/nfs start</span><br></pre></td></tr></table></figure><blockquote><p>查看rpcbind 服务启动信息</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ps -ef|grep rpcbind</span><br><span class="line">netstat -lntup|grep 111</span><br><span class="line">rpcinfo -p localhost</span><br></pre></td></tr></table></figure><h4 id="1-1-5-服务器端部署完成"><a href="#1-1-5-服务器端部署完成" class="headerlink" title="1.1.5 服务器端部署完成"></a>1.1.5 服务器端部署完成</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">showmount -e 10.5.18.250</span><br></pre></td></tr></table></figure><blockquote><ul><li>-d：仅显示已被NFS客户端加载的目录；</li><li>-e：显示NFS服务器上所有的共享目录。</li></ul></blockquote><p>NFS服务开启后，默认的参数文件位置，注意：修改此文件，对nfs服务没有任何影响</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /var/lib/nfs/etab</span><br></pre></td></tr></table></figure><p><img src="https://s2.ax1x.com/2019/02/20/k2ru11.png" alt="k2ru11.png"></p><h4 id="1-1-6-设置NFS服务开机自启动"><a href="#1-1-6-设置NFS服务开机自启动" class="headerlink" title="1.1.6 设置NFS服务开机自启动"></a>1.1.6 设置NFS服务开机自启动</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chkconfig rpcbind on</span><br><span class="line">chkconfig nfs on</span><br></pre></td></tr></table></figure><blockquote><p>注意：</p><ul><li><p>关闭服务器防火墙</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;   # 永久关闭</span><br><span class="line">&gt;   chkconfig iptables off</span><br><span class="line">&gt;   # 临时关闭</span><br><span class="line">&gt;   service iptables stop</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></li></ul></blockquote><p>&gt;</p><blockquote><ul><li><p>root下共享文件夹权限开放</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;   chmod 777 root</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></li></ul></blockquote><p>&gt;</p><blockquote><ul><li><p>解决NFS版本问题</p><p>编辑 /etc/sysconfig/nfs文件，找到下面:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;   #Turn off v2 and v3 protocol support </span><br><span class="line">&gt;   #RPCNFSDARGS=&quot;-N 2 -N 3&quot; </span><br><span class="line">&gt;   #Turn off v4 protocol support </span><br><span class="line">&gt;   #RPCNFSDARGS=&quot;-N 4&quot;　　/*把这句前面的#号去掉*/</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></li></ul></blockquote><p>&gt;</p><blockquote><p>  最后保存，重启nfs服务，再尝试挂载；如果挂载不上，可尝试在后面加-o nolock参数。</p><ul><li><p>挂载成功</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;   mount -t nfs -o nolock server_ip:/root/root_share /home/zjj/root_share</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></li></ul></blockquote><h3 id="1-2-Ubuntu-服务器"><a href="#1-2-Ubuntu-服务器" class="headerlink" title="1.2. Ubuntu 服务器"></a>1.2. Ubuntu 服务器</h3><blockquote><p>Ubuntu 服务端配置好像没有遇到防火墙问题</p></blockquote><h4 id="1-2-1-安装组件"><a href="#1-2-1-安装组件" class="headerlink" title="1.2.1 安装组件"></a>1.2.1 安装组件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install nfs-kernel-server</span><br></pre></td></tr></table></figure><h4 id="1-2-2-创建共享文件夹"><a href="#1-2-2-创建共享文件夹" class="headerlink" title="1.2.2 创建共享文件夹"></a>1.2.2 创建共享文件夹</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir /home/nfs_share</span><br><span class="line"># 赋予访问权限</span><br><span class="line">sudo chmod -R go+rwx /home/nfs_share     # 不一定需要</span><br></pre></td></tr></table></figure><h4 id="1-2-3-配置nfs"><a href="#1-2-3-配置nfs" class="headerlink" title="1.2.3 配置nfs"></a>1.2.3 配置nfs</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/exports</span><br></pre></td></tr></table></figure><p>末尾添加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/home/nfs_share *(rw,sync,no_root_squash,no_subtree_check)</span><br></pre></td></tr></table></figure><p>保存退出</p><h4 id="1-2-4-启动rpc、nfs"><a href="#1-2-4-启动rpc、nfs" class="headerlink" title="1.2.4 启动rpc、nfs"></a>1.2.4 启动rpc、nfs</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo /etc/init.d/rpcbind restart</span><br><span class="line">sudo /etc/init.d/nfs-kernel-server restart</span><br></pre></td></tr></table></figure><blockquote><p>停止服务命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; service nfs-kernel-server stop</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><h2 id="二、-客户端挂载配置"><a href="#二、-客户端挂载配置" class="headerlink" title="二、 客户端挂载配置"></a>二、 客户端挂载配置</h2><h3 id="2-1-windows客户端"><a href="#2-1-windows客户端" class="headerlink" title="2.1 windows客户端"></a>2.1 windows客户端</h3><blockquote><p>win10家庭版没有NFS功能</p></blockquote><h3 id="2-2-centos客户端"><a href="#2-2-centos客户端" class="headerlink" title="2.2 centos客户端"></a>2.2 centos客户端</h3><h4 id="2-2-1-确认nfs、rpc软件安装"><a href="#2-2-1-确认nfs、rpc软件安装" class="headerlink" title="2.2.1 确认nfs、rpc软件安装"></a>2.2.1 确认nfs、rpc软件安装</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa|grep nfs</span><br><span class="line">rpm -qa|grep rpc</span><br><span class="line"># 若未安装，则运行已下命令安装</span><br><span class="line">yum -y install nfs-utils rpcbind</span><br><span class="line"># 确认安装</span><br><span class="line">rpm -qa nfs-utils rpcbind</span><br></pre></td></tr></table></figure><h4 id="2-2-2-查看服务器上的共享"><a href="#2-2-2-查看服务器上的共享" class="headerlink" title="2.2.2 查看服务器上的共享"></a>2.2.2 查看服务器上的共享</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">showmount -e server_ip</span><br></pre></td></tr></table></figure><h4 id="2-2-3-挂载"><a href="#2-2-3-挂载" class="headerlink" title="2.2.3 挂载"></a>2.2.3 挂载</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mount -t nfs -o nolock server_ip:/root/root_share /home/zjj/root_share</span><br></pre></td></tr></table></figure><blockquote><p>挂载路径自定义即可</p></blockquote><h3 id="2-3-ubuntu客户端"><a href="#2-3-ubuntu客户端" class="headerlink" title="2.3 ubuntu客户端"></a>2.3 ubuntu客户端</h3><h4 id="2-3-1-确认nfs、rpc软件安装"><a href="#2-3-1-确认nfs、rpc软件安装" class="headerlink" title="2.3.1 确认nfs、rpc软件安装"></a>2.3.1 确认nfs、rpc软件安装</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dpkg -l|grep nfs</span><br><span class="line">dpkg -l|grep rpc</span><br><span class="line"># 若未安装，则运行已下命令安装</span><br><span class="line">sudo apt-get install nfs-common</span><br></pre></td></tr></table></figure><h4 id="2-3-2-查看服务器上的共享"><a href="#2-3-2-查看服务器上的共享" class="headerlink" title="2.3.2 查看服务器上的共享"></a>2.3.2 查看服务器上的共享</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">showmount -e server_ip</span><br></pre></td></tr></table></figure><h4 id="2-3-3-挂载"><a href="#2-3-3-挂载" class="headerlink" title="2.3.3 挂载"></a>2.3.3 挂载</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mount -t nfs -o nolock server_ip:/root/root_share /home/zjj/root_share</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;NFS安装配置&quot;&gt;&lt;a href=&quot;#NFS安装配置&quot; class=&quot;headerlink&quot; title=&quot;NFS安装配置&quot;&gt;&lt;/a&gt;NFS安装配置&lt;/h1&gt;&lt;h2 id=&quot;一、服务器端配置&quot;&gt;&lt;a href=&quot;#一、服务器端配置&quot; class=&quot;headerli
      
    
    </summary>
    
      <category term="安装与配置" scheme="http://yoururl.com/categories/%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/"/>
    
    
      <category term="Install &amp; config" scheme="http://yoururl.com/tags/Install-config/"/>
    
  </entry>
  
  <entry>
    <title>FTP服务端与客户端安装配置</title>
    <link href="http://yoururl.com/2019/02/21/ftp%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%E9%85%8D%E7%BD%AE/"/>
    <id>http://yoururl.com/2019/02/21/ftp文件传输配置/</id>
    <published>2019-02-20T16:07:00.000Z</published>
    <updated>2019-02-22T09:26:39.626Z</updated>
    
    <content type="html"><![CDATA[<h1 id="FTP文件传输配置"><a href="#FTP文件传输配置" class="headerlink" title="FTP文件传输配置"></a>FTP文件传输配置</h1><h2 id="一、CentOS服务器端"><a href="#一、CentOS服务器端" class="headerlink" title="一、CentOS服务器端"></a>一、CentOS服务器端</h2><h3 id="1-安装vsftpd"><a href="#1-安装vsftpd" class="headerlink" title="1. 安装vsftpd"></a>1. 安装vsftpd</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install vsftpd</span><br></pre></td></tr></table></figure><h3 id="2-设置开机启动vsftpd-ftp服务"><a href="#2-设置开机启动vsftpd-ftp服务" class="headerlink" title="2.设置开机启动vsftpd ftp服务"></a>2.设置开机启动vsftpd ftp服务</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chkconfig vsftpd on</span><br></pre></td></tr></table></figure><h3 id="3-启动vsftpd服务"><a href="#3-启动vsftpd服务" class="headerlink" title="3.启动vsftpd服务"></a>3.启动vsftpd服务</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service vsftpd start</span><br></pre></td></tr></table></figure><h3 id="4-配置防火墙"><a href="#4-配置防火墙" class="headerlink" title="4.配置防火墙"></a>4.配置防火墙</h3><p>因为ftp默认的端口为21，而centos默认是没有开启的，所以要修改iptables文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/sysconfig/iptables</span><br></pre></td></tr></table></figure><p>在行上面有<code>22 -j ACCEPT</code> 下面另起一行输入 <strong>这行代码</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-A RH-Firewall-1-INPUT -m state --state NEW -m tcp -p tcp --dport 21 -j ACCEPT</span><br></pre></td></tr></table></figure><p>保存关闭，重启防火墙。</p><blockquote><p>我已经永久关闭防火墙了，所以也无需开启</p></blockquote><h3 id="5-配置vsftpd服务器"><a href="#5-配置vsftpd服务器" class="headerlink" title="5.配置vsftpd服务器"></a>5.配置vsftpd服务器</h3><p>打开配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/vsftpd/vsftpd.conf</span><br></pre></td></tr></table></figure><ul><li><p>把第一行的 <code>anonymous_enable=YES</code> ，改为<code>NO</code>，取消匿名登陆</p><blockquote><p>也可不取消</p></blockquote></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#chroot_list_enable=YES</span><br><span class="line"># (default follows)</span><br><span class="line">#chroot_list_file=/etc/vsftpd.chroot_list</span><br></pre></td></tr></table></figure><p>改为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chroot_list_enable=YES</span><br><span class="line"># (default follows)</span><br><span class="line">chroot_list_file=/etc/vsftpd/chroot_list</span><br></pre></td></tr></table></figure></li><li><p>修改权限，使用户能重命名或删除</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">anon_mkdir_write_enable=YES</span><br><span class="line">anon_other_write_enable=YES</span><br></pre></td></tr></table></figure></li><li><p>设置登陆默认路径（共享文件夹）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">local_root=/share</span><br></pre></td></tr></table></figure></li><li><p>其他设置</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">write_enables=YES</span><br></pre></td></tr></table></figure><p>保存关闭，重启 <code>vsftpd</code> 服务</p><h3 id="6-添加ftp用户"><a href="#6-添加ftp用户" class="headerlink" title="6. 添加ftp用户"></a>6. 添加ftp用户</h3><p>添加一个名为 ftpuser 的用户，所属 ftp 用户组，指向目录/share, 禁止登录：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">useradd -d /share -g ftp -s /sbin/nologin ftpuser</span><br></pre></td></tr></table></figure><p>设置ftpuser登陆密码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">passwd ftpuser</span><br></pre></td></tr></table></figure><p>添加FTP用户到 <code>user_list</code>文件夹中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 打开user_list文件</span><br><span class="line">vi /etc/vsftpd/user_list</span><br><span class="line"></span><br><span class="line"># 文件内文末添加</span><br><span class="line">ftpuser</span><br></pre></td></tr></table></figure><p>添加FTP用户到 <code>chroot_list</code> 文件夹：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 在/etc/vsftpd/ 目录下创建一个 chroot_list 文件：</span><br><span class="line">vi /etc/vsftpd/chroot_list</span><br><span class="line"></span><br><span class="line"># 文件内文末添加</span><br><span class="line">ftpuser</span><br></pre></td></tr></table></figure><blockquote><p>或者可以利用以有的用户</p></blockquote><h3 id="7-修改selinux"><a href="#7-修改selinux" class="headerlink" title="7.修改selinux"></a>7.修改selinux</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">setsebool -P allow_ftpd_full_access 1   </span><br><span class="line"></span><br><span class="line">setsebool -P ftp_home_dir off 1</span><br></pre></td></tr></table></figure><p>重启vsftpd</p><h2 id="二-Windows10客户端"><a href="#二-Windows10客户端" class="headerlink" title="二. Windows10客户端"></a>二. Windows10客户端</h2><h3 id="2-1-开启windows相关功能"><a href="#2-1-开启windows相关功能" class="headerlink" title="2.1 开启windows相关功能"></a>2.1 开启windows相关功能</h3><p><img src="https://s2.ax1x.com/2019/02/22/kfkc7Q.png" alt="kfkc7Q.png"></p><ul><li>开启后重启计算机</li></ul><h3 id="2-2-快速连接"><a href="#2-2-快速连接" class="headerlink" title="2.2 快速连接"></a>2.2 快速连接</h3><ul><li>在文件夹路径窗口输入 <code>ftp://10.5.18.250</code>，连接</li></ul><p><img src="https://s2.ax1x.com/2019/02/22/kfA0UJ.png" alt="kfA0UJ.png"></p><p>连接成功：</p><p><img src="https://s2.ax1x.com/2019/02/22/kfA6v6.png" alt="kfA6v6.png"></p><blockquote><p>到此结束也ok，若想要建立长久的本地驱动映射，继续</p></blockquote><h3 id="2-3-建立本地驱动映射"><a href="#2-3-建立本地驱动映射" class="headerlink" title="2.3 建立本地驱动映射"></a>2.3 建立本地驱动映射</h3><ul><li>打开 <code>此电脑--&gt;计算机--&gt;映射网络驱动器</code> :</li></ul><p><img src="https://s2.ax1x.com/2019/02/22/kfA9BD.png" alt="kfA9BD.png"></p><ul><li>选择 <code>连接到可用于存储文档和图片的网站</code></li></ul><p><img src="https://s2.ax1x.com/2019/02/22/kfk5cV.png" alt="kfk5cV.png"></p><ul><li><p><img src="https://s2.ax1x.com/2019/02/22/kfEGIH.png" alt="kfEGIH.png"></p></li></ul><ul><li><img src="https://s2.ax1x.com/2019/02/22/kfEfyV.png" alt="kfEfyV.png"></li><li>最后输入密码</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;FTP文件传输配置&quot;&gt;&lt;a href=&quot;#FTP文件传输配置&quot; class=&quot;headerlink&quot; title=&quot;FTP文件传输配置&quot;&gt;&lt;/a&gt;FTP文件传输配置&lt;/h1&gt;&lt;h2 id=&quot;一、CentOS服务器端&quot;&gt;&lt;a href=&quot;#一、CentOS服务器端&quot;
      
    
    </summary>
    
      <category term="安装与配置" scheme="http://yoururl.com/categories/%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/"/>
    
    
      <category term="Install &amp; config" scheme="http://yoururl.com/tags/Install-config/"/>
    
  </entry>
  
  <entry>
    <title>复杂网络：网络测度（二）</title>
    <link href="http://yoururl.com/2019/01/23/%E7%BD%91%E7%BB%9C%E6%B5%8B%E5%BA%A6%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <id>http://yoururl.com/2019/01/23/网络测度（二）/</id>
    <published>2019-01-22T16:01:00.000Z</published>
    <updated>2019-01-28T13:07:45.754Z</updated>
    
    <content type="html"><![CDATA[<h2 id="结点群组"><a href="#结点群组" class="headerlink" title="结点群组"></a>结点群组</h2><h3 id="团-clique"><a href="#团-clique" class="headerlink" title="团(clique)"></a>团(clique)</h3><ul><li><p>定义：指无向网络中的一个最大结点子集，在该子集中任何两个结点之间都有一条边直接相连。</p><blockquote><p>“最大”指在保证子集内每两个结点都直接相连的条件下，网络中其他结点无法再加入该子集中。</p><p>团的存在表明网络中存在一个联系紧密的子群。</p></blockquote></li></ul><h3 id="k-团-k-clique"><a href="#k-团-k-clique" class="headerlink" title="k-团(k-clique)"></a>k-团(k-clique)</h3><ul><li><p>定义：结点的一个最大子集，该子集中各个结点之间通过网络边的距离不超过$k$。</p><blockquote><p>当$k=1$时，该定义与团的原始定义一样；</p><p>但$k-团$的定义并不严谨，定义并不要求结点之间的路径全在子集中。若要求路径只能在子集中，得到的结果就是$k-党派$或$k-俱乐部$。两者的区别在于是否强制要求结点之间的路径只能在群组内部，或者是否先找到$k-团$，然后在此基础上删除那些有外部路径的团，这两种情况的最终结果可能不同。</p></blockquote></li></ul><h3 id="k-丛-k-plex"><a href="#k-丛-k-plex" class="headerlink" title="k-丛 (k-plex)"></a><strong>k-丛</strong> (k-plex)</h3><ul><li><p>定义：大小为$n$的$k-丛$是网络中结点数为$n$的最大子集，该子集的每个结点都至少和子集中另外$n-k$个结点相连。</p><blockquote><p>$k-丛$ 确定了网络的结点数$n$;</p><p>当$k=1$时，与最初定义的团相符，即$1-丛$就是通常意义上的团。</p><p>团思想的一般性表达：可以指定每一个结点与一定比例的其他成员有联系。</p></blockquote></li></ul><h3 id="k-核-k-core"><a href="#k-核-k-core" class="headerlink" title="k-核(k-core)"></a>k-核(k-core)</h3><ul><li><p>定义：$k-核$是网络结点的一个最大子集，该子集中每个结点至少与子集中$k$个其他结点相连。</p><blockquote><p>$k-核$不确定网络的结点数；</p><p>当子集结点数为$n$时，$k-核$与$(n-k)-丛$是相同的。</p><p>但给定$k$值的所有$k-核$的集合与$k-丛$的集合并不相等，因为不同的$k-核$的子集结点数$n$不同。</p><p>与$k-丛$不同，$k-核$彼此之间不能重合，根据定义，若两个$k-核$彼此共享同一个或多个结点，就可以合并生成一个更大的$k-核$。</p><p>寻找网络中的$k-核$的简单算法：从整个网络开始，将度数小于$k$的结点不断删除，此时会使网络中一些其他结点（即那些刚刚与删除结点相连的结点）度数减小。然后继续检查网络，删除度数小于$k$的结点，依次重复不断删除网络中度数小于$k$的结点，直到不存在这样的结点。此时剩下的网络就是一个$k-核$或$k-核$的集合。</p></blockquote></li></ul><h3 id="k-分支-k-component"><a href="#k-分支-k-component" class="headerlink" title="k-分支(k-component)"></a>k-分支(k-component)</h3><p>无向网络的分支是网络结点的一个最大子集，该子集中的结点彼此间通过特定路径相连。</p><ul><li><p>定义1：$k-分支$有时也称$k-连通分支$，是网络结点的一个最大子集，该子集中的结点彼此之间能够通过至少$k$条结点独立路径相连。</p><blockquote><p>若两条路径之间除了起点与终点之外，没有共享的结点，那么这两条路径是结点独立路径。</p><p>对于$k=2$或$k=3$的情况，分别称为<strong>二分支</strong>和<strong>三分支</strong>。</p></blockquote></li><li><p>定义2：$k-分支$是网络结点的一个最大子集，若将该子集中的任意两个结点之间的连接断开，至少需要删除$k$个结点。</p><blockquote><p>两个结点之间的节点独立路径数等于结点之间的结点割集大小，也就是将两个结点连接断开需要删除的结点数。</p></blockquote></li></ul><p>$k-分支$的思想与网络鲁棒性相关联。例如在一个Internet的数据网络中，两个结点之间的结点独立路径数同时也是这两个结点之间数据传输的独立路由数，它们之间割集的规模就是切断这两个终端之间数据传输时需要舍弃或去除的网络结点（路由器）数量。</p><blockquote><p>这样，由两条边独立路径相连的两个结点之间的连接不会因为单一的路由器故障而断开；由三条边独立路径相连的两个结点之间的连接不会因为任意两个路由器故障而断开。</p></blockquote><h2 id="传递性"><a href="#传递性" class="headerlink" title="传递性"></a>传递性</h2><p>网络传递性的数学表示为：若$a\circ b$和$b\circ c$，那么$a \circ c$。 在社会网络中的表述为：若$u$认识$v$，$v$认识$w$，那么在网络中存在一条由两条边构成的路径$uvw$。若$u$也认识$w$，则称该路径是闭合的，即该路径在网络中形成一个长度为3的循环，或称三角。三个结点形成一个<strong>闭合三元组</strong>。</p><h3 id="聚类系数"><a href="#聚类系数" class="headerlink" title="聚类系数"></a>聚类系数</h3><ul><li><p>定义1：网络中所有长度为2的路径中闭合路径所占的比例；</p><script type="math/tex; mode=display">C= \frac{(长度为2的路径中的闭合路径数)}{(长度为2的路径数)}</script><p>其取值范围在0到1之间。若$C=1$，则表明该网络具有完全传递性，网络中的所有分支都是团。</p><p>若$C=0$，则表明网络中没有闭合三元组，如树、正方形点阵。</p></li><li><p>定义2：考虑网络路径的方向性，经过相同结点但方向不同的两条路径需要分别统计。</p><script type="math/tex; mode=display">C= \frac{(三角形数)\times 6}{(长度为2的路径数)}</script></li><li><p>定义3：有公共邻居结点的两个结点，本身也互为邻居结点的平均概率。</p><script type="math/tex; mode=display">C=\frac{(三角形数)\times 3}{(连通三元组数)}</script><p>其中”连通三元组“是指在结点$uvw$三者之间存在边$(u,v)$和$(v,w)$，边$(u,w)$可以存在也可不存在。分子中的系数3指每个三角形中都包含3个连通三元组。</p></li></ul><h3 id="局部聚类"><a href="#局部聚类" class="headerlink" title="局部聚类"></a>局部聚类</h3><p>针对单个结点$i$的聚类系数：</p><ul><li><p>定义：</p><script type="math/tex; mode=display">C_i=\frac{（结点i的邻居结点中直接相连的结点对数）}{（结点i的邻居结点对总数）}</script><blockquote><p>结点$i$的邻居结点对总数为$\frac{1}{2} k_i(k_i-1)$, 其中$k_i$是结点$i$的度。</p><p>许多研究中发现，度较大的结点其局部聚类系数均较低。</p><p>局部聚类系数可以用于指示网络中是否存在所谓的<strong>结构洞</strong>。</p><p><img src="https://s2.ax1x.com/2019/01/26/kulc0P.png" alt="kulc0P.png"></p><p>如果关注网络中的信息或其他流量的有效传播，结构洞是有害的，因为他们会减少信息在网络中的路由数；</p><p>如果关注朋友之间的联系，结构洞对于结点$i$来说是有益的，因为结构洞使$i$在其邻居结点之间的信息流动中起到主导作用。因为如果$i$的两个朋友没有直接相连，那么他们彼此之间的信息流动就必须通过与双方都有联系的$i$，因此$i$就可以控制信息流动。</p><p>因此局部聚类系数也可以作为一种中心性测度，影响力越大的个体的局部聚类系数取值越小。</p></blockquote></li></ul><h3 id="冗余"><a href="#冗余" class="headerlink" title="冗余"></a>冗余</h3><ul><li><p>简化定义：结点$i$的冗余$R_i$是结点$i$的邻居结点之间直接连接数的平均值。</p><blockquote><p>结点冗余的最小值是0，最大值是 $k_i-1$ ；</p></blockquote><p>结点$i$ 的邻居结点之间的平均连接数为$R_i$，直接连接总数为$\frac{1}{2}k_i R_i$，邻居结点对的总数为$\frac{1}{2}k_i(k_i-1)$。 </p><p>局部聚类系数与冗余的关系：</p><script type="math/tex; mode=display">C_i= \frac{\frac{1}{2}k_iR_i}{\frac{1}{2}k_i(k_i-1)} = \frac{R_i}{k_i-1}</script><p>全局聚类系数：利用所有结点的局部聚类系数均值计算整个网络的聚类系数：</p><script type="math/tex; mode=display">C_{WS}= \frac{1}{n} \sum_{i=1}^n C_i</script></li></ul><h2 id="相互性"><a href="#相互性" class="headerlink" title="相互性"></a>相互性</h2><p>相互性度量了有向图中长度为2的闭合循环的频率，该频率描述了两个结点之间相互指向的概率。</p><blockquote><p>如果结点$v$和结点$u$相连接，$u$通过连接到$v$来表现出相互性。</p></blockquote><ul><li><p>定义：相互性$r$被定义为所有边中相互边所占的比例。</p><p>当且仅当结点$i$到$j$有双向边时，邻接矩阵中元素的乘积$A<em>{ij}A</em>{ji}$为1，否则为0。通过对所有结点对求和，得到相互性的计算表达：</p><script type="math/tex; mode=display">r = \frac{1}{m} \sum_{ij} A_{ij}A_{ji} = \frac{1}{m} {\bf Tr A^2}</script><p>其中，$m$为网络中有向边的总数。</p></li></ul><h2 id="有符号边和结构平衡"><a href="#有符号边和结构平衡" class="headerlink" title="有符号边和结构平衡"></a>有符号边和结构平衡</h2><p>可利用有向图来表示社交网络中各结点之间的关系，如朋友或敌对关系。每条边只有两种情况，+边代表朋友关系，-边代表敌对关系。这样的网络称为<strong>有符号网络</strong>，其边为<strong>有符号边</strong>。</p><p><img src="https://s2.ax1x.com/2019/01/27/kKeYfs.png" alt="kKeYfs.png"></p><p>上图两种稳定组合（a、b）与两种不稳定组合（c、d）的差别是，稳定组合的循环中有偶数个负号。</p><ul><li><p>推广：</p><ul><li><p>定义：网络若只包含带有偶数个负号的循环，则称其<strong>结构平衡</strong>。</p></li><li><p>推论：一个平衡网络能够被划分为若干个连通结点群组，且群组内结点之间的连接都是正的，而不同群组之间的连接都是负的。</p><blockquote><p>群组可由单个结点组成，也可由多个结点组成；群组可以是一个，也可以是多个；</p><p><img src="https://s2.ax1x.com/2019/01/27/kKnLef.png" alt="kKnLef.png"></p><p>能像上述划分成群组的网络被认为是<strong>可聚类的</strong>。 </p><p>网络中每个循环都包含偶数个负号。虚线表示将网络划分为不同的群组。</p><p>为网络中的结点涂色，结点的颜色只有两种情况，从任意一个结点开始，根据一下算法为结点涂色：</p><ol><li>如果结点$v$与$u$有一条正连接，且$u$已经涂上了颜色，那么$v$的颜色与$u$相同；</li><li>如果结点$v$与$u$有一条负连接，且$u$已经涂上了颜色，那么$v$的颜色与$u$相反；</li></ol><p>如果在为网络涂色时遇到一个已经涂上颜色的结点，说明在网络中一定还存在另一条从起点到达该结点的路径，因此在网络中至少存在一个或多个包含该结点的循环。如果网络是平衡的，该结点所属的每个循环就一定有偶数条负边。如果该结点的颜色与将要涂的颜色有冲突，那么网络必然是不平衡的。</p></blockquote></li></ul></li></ul><ul><li><p>注意：</p><blockquote><p>可聚类定理的逆定理并不成立，例如下面的网络：</p><p><img src="https://s2.ax1x.com/2019/01/27/kKuytg.png" alt="kKuytg.png"></p><p>上述网络有三个结点，三个结点之间彼此敌对，因此网络循环中有奇数条负边，但可以将该网络分为三个不同的群组，每个结点构成一个群组。该网络可聚类，但不平衡。</p></blockquote></li></ul><h2 id="相似性"><a href="#相似性" class="headerlink" title="相似性"></a>相似性</h2><p>考虑如何利用网络结构中包含的信息来确定网络中的结点之间的相似性。</p><p>构造网络相似性测度的两种基本方法：</p><ul><li>结构等价：<strong>两个结点间共有邻居结点的数量</strong>定义了两结点之间的相似程度；</li><li>规则等价：通过比较<strong>两个结点的邻居结点的相似程度</strong>来确定结点间的相似度，而不是通过共有的邻居结点来确定的；</li></ul><p><img src="https://s2.ax1x.com/2019/01/27/kKNn9P.png" alt="kKNn9P.png"></p><h3 id="结构等价"><a href="#结构等价" class="headerlink" title="结构等价"></a>结构等价</h3><h4 id="余弦相似性"><a href="#余弦相似性" class="headerlink" title="余弦相似性"></a>余弦相似性</h4><p>在<strong>无向网络</strong>中，结点$i$和$j$的共享邻居结点数表示为$n_{ij}$，则有</p><script type="math/tex; mode=display">n_{ij}=\sum_k A_{ik} A_{kj}</script><blockquote><p>考虑一种归一化的方法，来合理定义相似性：不仅需要考虑网络的结点总数，也要考虑目标结点的度。</p><p><strong>余弦相似性（Salton 余弦）</strong>: 将邻接矩阵的第$i$行和第$j​$行看成两个向量，将两个向量之间的夹角余弦值用于相似性度量。</p><p>无向网络中对应邻接矩阵中两行的点积就是 $\sum<em>k A</em>{ik} A_{kj}$ ；</p></blockquote><p>因此相似性测度是：</p><script type="math/tex; mode=display">\sigma_{ij} = \cos\theta = \frac{\sum_k A_{ik}A_{kj}}{\sqrt{\sum_k A_{ik}^2} \sqrt{\sum_k A_{jk}^2}}</script><p>假设网络是无权无向网络， 因此 $\forall i,j$ ,   有 $A<em>{ij}^2 = A</em>{ij}$ , 即 $\sum<em>k A</em>{ik}^2 = \sum<em>k A</em>{ik} =k_i$ ，其中 $k_i$ 是结点 $i$ 的度。</p><p>于是：</p><script type="math/tex; mode=display">\sigma_{ij} = \frac{\sum_k A_{ik} A_{kj}}{\sqrt{k_i k_j}} = \frac{n_{ij}}{\sqrt{k_i k_j}}</script><p>因此， 结点$i$和结点$j$的余弦相似性就是<strong>两个结点的共同邻居结点数与它们各自度的几何平均数的商</strong> 。</p><blockquote><p>严格来讲，若两个结点或其中一个结点的度为0，那么它们的余弦相似性就无定义， $\sigma_{ij} = 0$。</p></blockquote><h4 id="Jaccard-相似性"><a href="#Jaccard-相似性" class="headerlink" title="Jaccard 相似性"></a>Jaccard 相似性</h4><ul><li>定义：结点$i$和结点$j$ 的<strong>共同邻居结点数与它们所有邻居节点数的商</strong>。<script type="math/tex; mode=display">\sigma_{Jaccard}(i,j) = \frac{|N(i) \cap N(j)|}{|N(i) \cup N(j)|} = \frac{\sum_k A_{ik} A_{kj}}{k_i + k_j - \sum_k A_{ik} A_{kj}}</script></li></ul><h4 id="皮尔逊相关系数"><a href="#皮尔逊相关系数" class="headerlink" title="皮尔逊相关系数"></a>皮尔逊相关系数</h4><p>对共享邻居结点数进行归一化的另一种方法是：</p><p><strong>将其与一个期望值进行比较，该期望值是指网络中的结点随机选择邻居结点的条件下，共享邻居结点数的期望值。</strong></p><p>假设结点$i$和结点$j$各自的度是$k_i$和$k_j$，两个结点完全随机选取邻居结点。结点$i$从网络$n$个结点中（在不包含自环的网络中，是从$n-1$个结点中选取，但对于大规模网络而言，误差忽略不计）随机均匀选取$k_i$个结点作为邻居结点，每个结点成为结点$i$邻居结点的概率为 $k_i /n$ ，结点$j$有$k_j$个邻居结点，则结点$i$和结点$j$的共享邻居结点的期望值为 $k_i k_j /n$ 。</p><p>合理的归一化是用<strong>两个结点的实际共享邻居结点数减去随机选择邻居结点条件下两者共享邻居结点的期望值</strong>，即</p><script type="math/tex; mode=display">\sum_k A_{ik} A_{jk} - \frac{k_i k_j}{n} = \sum_k A_{ik} A_{jk} - n \frac{1}{n} \sum_k A_{ik} \frac{1}{n} \sum_l A_{jl} \\ = \sum_k A_{ik} A_{jk} - n\langle A_i \rangle \langle A_j \rangle \\ = \sum_k [A_{ik}A_{jk} - \langle A_i \rangle \langle A_j \rangle ] \\ = \sum_k [A_{ik} A_{jk} - \langle A_i \rangle \langle A_j \rangle - \langle A_i \rangle \langle A_j \rangle + \langle A_i \rangle \langle A_j \rangle]\\ =  \sum_k [A_{ik} A_{jk} - \langle A_{ik} \rangle \langle A_j \rangle - \langle A_i \rangle \langle A_{jk} \rangle + \langle A_i \rangle \langle A_j \rangle]\\ =\sum_k(A_{ik} - \langle A_i \rangle)(A_{jk} - \langle A_j \rangle)</script><p>其中， $\langle A<em>i \rangle = \frac{1}{n} \sum_k A</em>{ik}$  。 $\sum<em>k(A</em>{ik} - \langle A<em>i \rangle)(A</em>{jk} - \langle A_j \rangle)$ 项为$A_i$和$A_j$之间的协方差，对协方差进行归一化</p><script type="math/tex; mode=display">\sigma_{pearson}(i,j) = \frac{cov(A_{i},A_{j})}{\sigma_i \sigma_j} = \frac{\sum_k(A_{ik} - \langle A_i \rangle)(A_{jk} - \langle A_j \rangle)}{\sqrt{\sum_k(A_{ik} - \langle A_i \rangle)^2} \sqrt{\sum_k(A_{jk} - \langle A_j \rangle)^2} }</script><p>取值范围介于 $[-1,1]$ 之间，正值表示当结点$i$将结点$j$作为朋友时，结点$j$也可能将结点$i$当作朋友。负值相反，零值表示无线性关系。</p><h4 id="除以期望值"><a href="#除以期望值" class="headerlink" title="除以期望值"></a>除以期望值</h4><p>通过除以期望值来对两个结点的共享邻居结点数$n_{ij}$进行归一化，</p><script type="math/tex; mode=display">\frac{n_{ij}}{k_i k_j /n} = n \frac{\sum_k A_{ik} A_{jk}}{\sum_k A_{ik} \sum_k A_{jk}}</script><h4 id="欧几里得距离"><a href="#欧几里得距离" class="headerlink" title="欧几里得距离"></a>欧几里得距离</h4><ul><li>定义：两个结点之间邻居结点数的差值。<script type="math/tex; mode=display">d_{ij} = \sum_k (A_{ik} -A_{jk})^2</script>归一化：<script type="math/tex; mode=display">\frac{\sum_k (A_{ik} -A_{jk})^2}{k_i +k_j} = \frac{\sum_k (A_{ik} +A_{jk} -2A_{ik}A_{jk})}{k_i +k_j} = 1-2 \frac{n_{ij}}{k_i +k_j}</script></li></ul><h3 id="规则等价"><a href="#规则等价" class="headerlink" title="规则等价"></a>规则等价</h3><p>基本思想是：若结点$i$和结点$j$各自的邻居结点$k$和$l$本身具有较高的相似性，则$i$和$j$的相似性也较高。</p><p><img src="https://s2.ax1x.com/2019/01/28/kKXsZ6.png" alt="kKXsZ6.png"></p><ul><li><p>原始式： 结点$i$和结点$j$各自的邻居结点$k$和$l$本身具有较高的相似性，则$i$和$j$的相似性也较高。</p><script type="math/tex; mode=display">\sigma_{ij} = \alpha \sum_{kl} A_{ik} A_{jl} \sigma_{kl}   \\ \Longleftrightarrow \\{\bf σ = \alpha A σ  A}</script><p>赋予结点“自相似性”，引入对角元项：</p><script type="math/tex; mode=display">\sigma_{ij} = \alpha \sum_{kl} A_{ik} A_{jl} \sigma_{kl} + \delta_{ij}  \\ \Longleftrightarrow \\{\bf σ = \alpha A σ  A + I}</script><blockquote><p>存在问题：</p><p>假设可通过重复迭代求解，首先确定初始值 ${\bf σ^{(0)}=0}$，迭代结果为：</p><script type="math/tex; mode=display">{\bf σ^{(1)} = I}  \\{\bf σ^{(2)} = \alpha A^2 + I}  \\{\bf σ^{(3)} = \alpha^2 A^4 + \alpha A^2 +I}  \\</script><p>多次迭代取极限后，得到的邻接矩阵的偶数次幂的总和。因此该相似性测度本质上式结点之间偶数长度的路径数的加权和。</p></blockquote></li></ul><ul><li><p>放宽式： 如果结点$i$的邻居结点$k$与结点$j$相似，那么$i$与$j$相似。</p><p>同时再次考虑“自相似性”：</p><script type="math/tex; mode=display">\sigma_{ij} = \alpha \sum_k A_{ik} \sigma_{kj} + \delta_{ij}  \\  \Longleftrightarrow{\bf σ=\alpha A σ + I}</script></li></ul><blockquote><p>利用反复迭代的方法进行求解得：</p><script type="math/tex; mode=display">{\bf σ^{(1)} = I}  \\{\bf σ^{(2)} = \alpha A + I}  \\{\bf σ^{(3)} = \alpha^2 A^2 + \alpha A +I}  \\</script><p>当迭代次数无穷大时，得到</p><script type="math/tex; mode=display">{\bf σ = \sum_{m=0}^{\infty} (\alpha A)^m = (I-\alpha A)^{-1}}</script><p>至此，相似性测度包括了所有长度的路径数，实际上，该相似性公式计算结点$i$和$j$之间的所有路径加权数值，长度为$r$的路径权重为$\alpha^r$。 由于$\alpha &lt;1$，因此路径越长权重越小。</p></blockquote><p>  上述相似性测度倾向于赋予那些度较大的结点以较高的相似性，但这存在以下问题：</p><blockquote><ol><li>相比于朋友较少的人，朋友更多的人被认为与其他人更相似；（度较大）</li><li>两个没有朋友的隐士在某种程度上也有一定相似性；（度较少）</li></ol></blockquote><p>  因此，将相似性除以结点的度，来避免因偏向高度数结点而导致的偏差：</p><script type="math/tex; mode=display">  \sigma_{ij} = \frac{\alpha}{k_i} \sum_k A_{ik} \sigma_{kj} + \delta_{ij}   \\ \Longleftrightarrow \\  {\bf σ=\alpha D^{-1} A σ + I}</script><p>  其中， ${\bf D}$ 是元素为 $D_{ii} = k_i$ 的对角矩阵。</p><script type="math/tex; mode=display">  {\bf σ=(I-\alpha D^{-1} A)^{-1} = (D-\alpha A)^{-1} D}</script><h2 id="同质性和同配混合"><a href="#同质性和同配混合" class="headerlink" title="同质性和同配混合"></a>同质性和同配混合</h2><p>人们倾向于选择那些他们认为与其自身在某些方面相似的人作为朋友，这种倾向性称为<strong>同质性</strong>或者<strong>同配混合</strong></p><p>。</p><h3 id="依据离散特征的同配混合"><a href="#依据离散特征的同配混合" class="headerlink" title="依据离散特征的同配混合"></a>依据离散特征的同配混合</h3><p>网络结点根据某个特征分类，且该特征的取值是一个有限集合，且特征无序。</p><p>首先找出连接同类结点的边所占的比例，然后减去在不考虑结点类型时，随机连接的边中，连接两个同类结点的边所占比例的期望值。</p><p>令$c_i$表示结点$i$的类型，类型用整数值$1,…,n$表示，其中$n_c$是结点类型总数，那么同类结点之间的边数总和表示为</p><script type="math/tex; mode=display">\sum_{边(i,j)} \delta(c_i,c_j) = \frac{1}{2} \sum_{ij} A_{ij} \delta(c_i,c_j)</script><p>其中$\delta(m,n)$是克罗内克$\delta$函数，将系数设定为$\frac{1}{2}$，是因为结点$i,j$之间的边被计算了两次。</p><p>计算随机条件下同类结点之间边的期望值，考虑连接到结点$i$的一条特定边，该结点的度为$k_i$。根据定义，整个网络中有$2m$个边的端点，其中$m$是边总数，若所有连接都是随机的，特定边两端分别连接到度为$k_i$的结点$i$和度为 $k_j$ 的结点$j$的概率为$k_i k_j /{2m}$ 。进而同类结点之间的边期望值为：</p><script type="math/tex; mode=display">\frac{1}{2} \sum_{ij} \frac{k_i k_j}{2m} \delta (c_i, c_j)</script><p>网络中同类结点之间边的实际值与期望值之差为：</p><script type="math/tex; mode=display">\frac{1}{2} \sum_{ij} A_{ij} \delta(c_i,c_j) - \frac{1}{2}\sum_{ij} \frac{k_i k_j}{2m} \delta(c_i,c_j) = \frac{1}{2} \sum_{ij} (A_{ij} - \frac{k_i k_j}{2m}) \delta(c_i,c_j)</script><p> 计算比例：</p><script type="math/tex; mode=display">Q = \frac{1}{2m} \sum_{ij} (A_{ij} - \frac{k_i k_j}{2m}) \delta(c_i,c_j)</script><p>$Q$ <strong>为模块度，用来度量网络中同类结点之间的连接程度</strong> 。$Q$值为正说明网络是同配混合的，$Q$值为负说明网络是异配混合的。</p><p>式中变量 $B<em>{ij} = A</em>{ij} - \frac{k_i k_j}{2m}$ 可构造模块度矩阵$\bf B$。</p><blockquote><p>模块度$Q$值总小于1，根据网络中群组的规模和结点度数，$Q$的最大值可能会远小于1。需要对$Q$值进行归一化。</p></blockquote><p>在全同配混合网络中，边所连接的结点都是同类结点，因此若$A_{ij}=1$，则$\delta (c_i,c_j)=1$。 意味着式(28)第一项和为$2m$，全同配混合网络模块度值为</p><script type="math/tex; mode=display">Q_{max} = \frac{1}{2m} (2m - \sum_{ij} \frac{k_i k_j}{2m} \delta(c_i,c_j))</script><p>模块度归一化值为：</p><script type="math/tex; mode=display">\frac{Q}{Q_{max}} = \frac{\sum_{ij} (A_{ij} - k_i k_j /2m) \delta(c_i,c_j)}{2m - \sum_{ij}(k_i k_j /2m)\delta(c_i,c_j)}</script><p>该变量有时称为同配系数，对于全同配混合网络，该变量取最大值为1。</p><ul><li><p>模块度的另一种形式：</p><ul><li><p>连接类型$r$和类型$s$的结点的边所占的比例：</p><script type="math/tex; mode=display">e_{rs} = \frac{1}{2m} \sum_{ij} A_{ij} \delta(c_i,r) \delta(c_j,s)</script></li><li><p>连接到类型$r$的结点的边所占的比例：</p><script type="math/tex; mode=display">\delta(c_i,c_j) = \sum_r \delta(c_i,r) \delta(c_j, r)</script></li><li></li></ul><script type="math/tex; mode=display">\delta (c_i,c_j) = \sum_r \delta(c_i,r) \delta(c_j, r)</script><p>推导得</p><script type="math/tex; mode=display">Q = \frac{1}{2m} \sum_{ij} (A_{ij}-\frac{k_i k_j}{2m}) \sum_r \delta(c_i,r) \delta(c_j,r) \\ = \sum_r [\frac{1}{2m} \sum_{ij} A_{ij} \delta(c_i,r) \delta(c_j,r) - \frac{1}{2m} \sum_i k_i \delta(c_i,r) \frac{1}{2m} \sum_j k_j \delta(c_j, r)] \\= \sum_r (e_{rr} - a_r^2)</script><blockquote><p>这种模块度形式适用于 当网络数据包括边列表和边端点所对应的结点类型，但不包含结点度的确切信息的情况。</p></blockquote></li></ul><h3 id="依据标量特征的同配混合"><a href="#依据标量特征的同配混合" class="headerlink" title="依据标量特征的同配混合"></a>依据标量特征的同配混合</h3><p>标量特征具有确定的顺序，根据标量的数值，可以指出两个结点在什么情况下是完全相同的，也可指出在什么情况下是近似相同的。若网络中的结点在有某种标量特征的值相似时连接在一起，而当值不同时则较少连接在一起，那么认为该网络是依据该标量特征同配混合的。也可以称该网络是依据该标量特征<strong>分层</strong>的。</p><p>利用协方差：</p><ul><li>$x_i$ : 结点$i$的标量值；</li><li><p>$(x_i,x_j)$：网络中每条边$(i,j)​$的两个端点值；</p></li><li><p>$\mu$：某条边的端点值$x_i​$的均值；</p></li></ul><script type="math/tex; mode=display">\mu = \frac{\sum_{ij} A_{ij}x_i}{\sum_{ij}A_{ij}} = \frac{\sum_i k_i x_i}{\sum_i k_i} = \frac{1}{2m} \sum_i k_ix_i</script><p>该均值对所有边取平均。$x_i$与$x_j$对所有边的协方差为;</p><script type="math/tex; mode=display">cov(x_i,x_j) = \frac{\sum_{ij} A_{ij}(x_i -\mu)(x_j -\mu)}{\sum_{ij} A_{ij}} \\ = \frac{1}{2m} \sum_{ij} A_{ij} (x_ix_j - \mu x_i - \mu x_j + \mu^2) \\= \frac{1}{2m} \sum_{ij} A_{ij}x_ix_j - \mu^2 \\= \frac{1}{2m} \sum_{ij} A_{ij}x_ix_j - \frac{1}{(2m)^2} \sum_{ij} k_i k_j x_i x_j \\= \frac{1}{2m} \sum_{ij} (A_{ij} - \frac{k_ik_j}{2m}) x_ix_j</script><p>当一条边的两个端点$x_i,x_j$同时为大或同时为小时，协方差为正；一大一小时协方差为负。即，当同配混合时协方差为正，异配混合时协方差为负。</p><p>归一化可以使网络全同配混合时网络测度为1，所谓全同配混合是指网络中所有边都位于值为$x_i$的结点之间。令$x_j=x_i$，给出全同配混合网络的协方差值为：</p><script type="math/tex; mode=display">\frac{1}{2m} \sum_{ij} (A_{ij}x_i^2 - \frac{k_ik_j}{2m}x_ix_j) = \frac{1}{2m} \sum_{ij} (k_i \delta_{ij} - \frac{k_ik_j}{2m})x_ix_j</script><p>归一化：</p><script type="math/tex; mode=display">r= \frac{\sum_{ij} (A_{ij}-k_ik_j/2m)x_ix_j}{\sum_{ij} (k_i \delta_{ij} - k_ik_j/2m)x_ix_j}</script><h3 id="依据度的同配混合"><a href="#依据度的同配混合" class="headerlink" title="依据度的同配混合"></a>依据度的同配混合</h3><p>依据度的同配混合是依据标量特征的同配混合的一个特例，且受到特别关注。</p><p>依据度的同配混合网络中，高度数的结点倾向于与其他高度数结点相连；低度数的结点倾向于与其他低度数结点相连。</p><p>同配网络中，度数大的结点倾向于聚集在一起的网络中，我们希望得到网络中这些度数大的结点构成的结点块或核，他们周围是一些度小的结点构成的低密度<strong>边缘</strong>。这种<strong>核心/边缘结构</strong>是社会网络的普遍特征。</p><p>异配网络中，度数大的结点倾心于与度数小的结点连接，由此在网络中形成明显的星形结构特征。异配网络通常不具有核心/边缘特征，但结点分布更均匀。</p><p>依据度的同配混合同样可以通过标量特征方法进行度量。</p><script type="math/tex; mode=display">cov(k_i,k_j) = \frac{1}{2m} \sum_{ij} (A_{ij} - \frac{k_ik_j}{2m}) k_ik_j</script><p>利用协方差最大值进行归一化，</p><script type="math/tex; mode=display">r= \frac{\sum_{ij} (A_{ij}-k_ik_j/2m)k_i k_j}{\sum_{ij} (k_i \delta_{ij} - k_ik_j/2m)k_i k_j}</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;结点群组&quot;&gt;&lt;a href=&quot;#结点群组&quot; class=&quot;headerlink&quot; title=&quot;结点群组&quot;&gt;&lt;/a&gt;结点群组&lt;/h2&gt;&lt;h3 id=&quot;团-clique&quot;&gt;&lt;a href=&quot;#团-clique&quot; class=&quot;headerlink&quot; title=&quot;团
      
    
    </summary>
    
      <category term="复杂网络" scheme="http://yoururl.com/categories/%E5%A4%8D%E6%9D%82%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Networks" scheme="http://yoururl.com/tags/Networks/"/>
    
  </entry>
  
  <entry>
    <title>知识图谱：知识表示之Transparse模型</title>
    <link href="http://yoururl.com/2019/01/20/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA%E4%B9%8BTransparse/"/>
    <id>http://yoururl.com/2019/01/20/知识表示之Transparse/</id>
    <published>2019-01-19T16:09:00.000Z</published>
    <updated>2019-03-05T03:08:55.371Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Transparse"><a href="#Transparse" class="headerlink" title="Transparse"></a>Transparse</h1><p>论文地址：<a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11982/11693" target="_blank" rel="noopener">http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11982/11693</a></p><h2 id="模型改进"><a href="#模型改进" class="headerlink" title="模型改进"></a>模型改进</h2><p>KG中面临的两个主要问题，分别是 <strong>Heterogeneity（异构性）</strong>和 <strong>Imbalance（不平衡性）</strong>：</p><ul><li>Heterogeneity： 知识图谱中不同关系连接的实体（节点）数量不同；</li><li>Imbalance：同一关系连接的头尾实体（节点）数量不同；</li></ul><p><img src="https://s2.ax1x.com/2019/03/05/kXgFhT.png" alt="kXgFhT.png"></p><blockquote><p>上图展示了子图FB15k的数据结构，可以看出：</p><ul><li>不同关系的复杂性差异很大；</li><li>不平衡关系在知识图谱中占了很大比例；</li></ul><p>早期模型未关注这两个问题，用同样的方法构建关系。</p><p><strong>异构性可能导致简单或复杂关系的过拟合；关系的不平衡性表明平等的对待头尾实体是不合理的；</strong></p></blockquote><p>因此提出了两种模型来解决这两个问题：</p><p>为克服异质性，我们提出了一种<strong>TranSparse(share)</strong>模型，其中转移矩阵的稀疏程度由关系所链接的实体对的数量决定，关系的两边共享相同的转移矩阵。其中，复杂关系的转移矩阵要比简单关系的转移矩阵稀疏。</p><p>为克服不平衡性，对TranSparse(share)模型修改，提出了<strong>TranSparse(separate)</strong>模型，该模型中每个关系有两个分离稀疏转移矩阵，一个对头部实体一个对尾部实体，稀疏程度由关系连接的实体数量决定。</p><blockquote><p><strong>Sparse Matrix</strong>：稀疏矩阵中大多数元素为0，0元素占总元素的比例称为稀疏程度（$\theta$）,用$M(\theta)$表示稀疏程度为 $\theta​$ 的矩阵，稀疏矩阵更容易压缩，需要更少的存储空间，且只有非零元参与计算，减少计算复杂度。下图展示了结构化和非结构化数据：</p><p><img src="https://s2.ax1x.com/2019/03/05/kXgVc4.png" alt="kXgVc4.png"></p><p>结构化模式有助于向量矩阵运算，而非结构化模式则不是。因此，结构化模式可以使我们的模型更容易地扩展到大型知识图，而非结构化模式更多的用在其他文献中，有更好的实验结果。</p><p><strong>稀疏矩阵 VS 低秩矩阵</strong></p><p>我们需要分别使用自由度高和自由度低的矩阵来学习复杂关系和简单关系。权重矩阵的自由度是指独立变量的个数。对于权矩阵M，低秩和稀疏都可以降低自由度，因为它们都是对M的约束。具体来说，低秩强制一些变量满足特定的约束，使得M中的变量不能被自由分配。这样，自由度就降低了。对于稀疏矩阵，我们让一些元素为零，在训练过程中不改变它们的值，另一些元素为自由变量，可以通过训练来学习。因此，自由度就是通过训练学会的变量的数量。但是稀疏矩阵更适合我们的任务有两个原因：</p><ul><li>稀疏矩阵比低秩矩阵更灵活，假设 $M \in {\Bbb R^{m<em>n} }$,  $rank(M) \leq \min (m,n)$ 。 因为秩能控制自由度（$m</em>n$矩阵秩为$k$，有自由度 $k(m+n)-k^2$ ），如果用低秩去控制自由度，只能获得 $\min (m,n)$个低秩矩阵；若用稀疏矩阵去控制自由度，能获得 $m*n$ 个稀疏矩阵；</li><li>稀疏矩阵比低秩矩阵更高效。稀疏矩阵中仅非零元参与计算，减少了计算复杂度。而且稀疏矩阵更容易迁移到大型知识图谱上； </li></ul></blockquote><h3 id="TranSparse"><a href="#TranSparse" class="headerlink" title="TranSparse"></a>TranSparse</h3><h4 id="TranSparse-share"><a href="#TranSparse-share" class="headerlink" title="TranSparse(share)"></a>TranSparse(share)</h4><ul><li><p>$M_r(\theta_r)$：转移矩阵；</p></li><li><p>$\bf r$：每个关系$r$的转移向量；</p></li><li><p>$N_r$：关系$r$连接的实体对数量；</p></li><li><p>$N_{r^*}$：$N_r$中最大的数量；</p></li><li><p>$\theta<em>{min}$：$M</em>{r^*}$的最小稀疏度，为一个超平面，$0 \leq \theta_{min} \leq 1$;</p><p>转移矩阵的稀疏度被定义为：</p><script type="math/tex; mode=display">\theta_r = 1-(1-\theta_{min})N_r/N_{r^*}</script><p>投影向量：</p><script type="math/tex; mode=display">{\bf h}_p = {\bf M}_r(\theta_r){\bf h} \\{\bf t}_p = {\bf M}_r(\theta_r){\bf t}</script><p>其中：$M_r(\theta_r) \in {\Bbb R^{m*n} }$, ${\bf h,t} \in {\Bbb R^n}$, ${\Bbb h}_p, {\Bbb t}_p \in {\Bbb R^m}$.</p></li></ul><h4 id="TranSparse-separate"><a href="#TranSparse-separate" class="headerlink" title="TranSparse(separate)"></a>TranSparse(separate)</h4><ul><li><p>$M_r^h(\theta_r^h), M_r^t(\theta_r^t)$：头尾实体转移矩阵；</p></li><li><p>$N_r^l (l=h,t)$：关系$r$下$l$对应实体的数量；</p></li><li><p>$N_{r^<em>}^{l^</em>}$ : $N_r^l$ 中最大数量；</p></li><li><p>$\theta<em>{min}$ : $M</em>{r^<em>}^{l^</em>}$ 的最小稀疏度，$0 \leq \theta_{min} \leq 1$;</p><p>转移矩阵的稀疏度被定义为：</p></li></ul><script type="math/tex; mode=display">\theta_r^l = 1-(1-\theta_{min})N_r^l/N_{r^*}^{l^*}   ; (l=h,t)</script><p>​    投影向量：</p><script type="math/tex; mode=display">{\bf h}_p = {\bf M}_r^h(\theta_r^h){\bf h} \\{\bf t}_p = {\bf M}_r^t(\theta_r^t){\bf t}</script><p>​    其中：$M_r^h(\theta_r^h), M_r^t(\theta_r^t)\in \Bbb R^{m*n}$  .</p><p>以上两种模型的得分函数是：</p><script type="math/tex; mode=display">f_r({\bf h,t})= ||{\bf h_p+ r -t_p}||_{l_{1/2} }^2</script><p>​    其中 ${\bf r} \in {\Bbb R^m}$。</p><h2 id="训练对象"><a href="#训练对象" class="headerlink" title="训练对象"></a>训练对象</h2><p>用 $(h_i,r_i,t_i) (i=1,2,…)$ 表示第 $i$ 个三元组，标签 $y_i$ 代表了三元组的正负情况， 正样本和负样本分别表示为 $\Delta ={(h_i, r_i,t_i) | y_i=1}$ 和  $\Delta’ ={(h_i, r_i,t_i) | y_i=0}$, 知识图谱仅编码正样本。因此将负样本集合构建为 </p><script type="math/tex; mode=display">\Delta' = \{(h_i',r_i,t_i)|h_i' \neq h_i \wedge y_i = 1\} \cup \{(h_i,r_i,t_i')|t_i' \neq t_i \wedge y_i = 1 \}</script><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><script type="math/tex; mode=display">L =\sum_{(h,r,t)\in\Delta} \sum_{(h',r,t')\in\Delta'} [\gamma+f_r({\bf h,t})-f_r(\bf h',t')]_+</script><p>​    约束限制： $||{\bf h}||_2 \leq 1, ||{\bf r}||_2 \leq 1, ||{\bf t}||_2 \leq 1, ||{\bf h}_p||_2 \leq 1, ||{\bf t}_p||_2 \leq 1$</p><h2 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h2><p>对于转移矩阵 ${\bf M(\theta)} \in {\Bbb R}^{n \times n}$ , 有 $nz=[\theta \times n \times n]$ 个非零元素 </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Transparse&quot;&gt;&lt;a href=&quot;#Transparse&quot; class=&quot;headerlink&quot; title=&quot;Transparse&quot;&gt;&lt;/a&gt;Transparse&lt;/h1&gt;&lt;p&gt;论文地址：&lt;a href=&quot;http://www.aaai.org/ocs/
      
    
    </summary>
    
      <category term="知识图谱" scheme="http://yoururl.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="Knowledge graph" scheme="http://yoururl.com/tags/Knowledge-graph/"/>
    
  </entry>
  
  <entry>
    <title>知识图谱：知识表示之HyTE模型</title>
    <link href="http://yoururl.com/2019/01/20/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA%E4%B9%8BHyTE/"/>
    <id>http://yoururl.com/2019/01/20/知识表示之HyTE/</id>
    <published>2019-01-19T16:08:00.000Z</published>
    <updated>2019-05-18T07:30:20.945Z</updated>
    
    <content type="html"><![CDATA[<h1 id="HyTE"><a href="#HyTE" class="headerlink" title="HyTE"></a>HyTE</h1><p>Hyperplane-based Temporally aware KG Embedding</p><p>论文地址：<a href="http://talukdar.net/papers/emnlp2018_HyTE.pdf" target="_blank" rel="noopener">http://talukdar.net/papers/emnlp2018_HyTE.pdf</a></p><h2 id="模型改进"><a href="#模型改进" class="headerlink" title="模型改进"></a>模型改进</h2><p>现有的 KG embedding方法很少考虑到<strong>时间</strong>维度，因为它们假设所有的三元组总是永远正确的，可是现实中很多情况下不是这样。</p><blockquote><p> For example, (Bill Clinton, presidentOf, USA) was true only from 1993 to 2001;</p></blockquote><p>考虑到三元组<strong>时效性</strong>问题，提出了 HyTE 模型，定义了三元组有效成立时间段为 <strong>temporal scopes</strong> ，这些temporal scopes随着时间的推移对许多数据集会产生影响（比如YAGO，Wikidata），可以用于：</p><ul><li>利用<strong>时间导向</strong>进行知识图谱图推理；</li><li>为缺失时间注释的事实预测 temporal scopes； </li></ul><p>考虑一个四元组 $(h,r,t,[τ_s, τ_e])$，这里的 $τ_s$ 和 $τ_e$ 分别定义了三元组成立时间段的<strong>起始</strong>与<strong>截止</strong>。TransE模型将实体和关系考虑到相同的语义空间，但是在不同的时间段，实体与关系组成的 $(h，r)$ 可能会对应到不同的尾实体  $t$ ，所以在本文的模型中，希望<strong>实体能够随不同的时间点有着不同的表示</strong>。为了达到这一目的，文中将时间表示成超平面,模型示意图如下：</p><p><img src="http://ww1.sinaimg.cn/large/005NduT8ly1g35i5vr9vwj30ng0hb0xa.jpg" alt=""></p><blockquote><p>$e_h，e_t，e_r$，分别表示三元组中头实体，尾实体以及关系所对应的向量表示;</p><p>$τ_1$ 和 $τ_2$ 分别表示此三元组有效成立时间段的<strong>起始时间</strong>与<strong>截止时间</strong>;</p><p>$e_h(τ_1)$, $e_r(τ_1)$ 以及表示各向量在时间超平面 $τ_1$上的投影;</p><p>最终，模型通过最小化 translational distance 来完成结合时间的实体与关系的embedding学习过程。</p></blockquote><p>给定时间戳，可以将图分解为几个静态图，其中包含在各个时间步骤中有效的三元组，如：</p><p>知识图 $G$ 能被表示为 ${\Bbb {G=G<em>{τ_1} \cup G</em>{τ<em>2} \cup … \cup  G</em>{τ_T} } }$ , 其中 $τ_i, i \in 1,2,…,T$ 是离散时间点。</p><p>构建时间组成图 ${\Bbb G<em>τ}$ 时，对于一个四元组 $(h,r,t,[τ_s,τ_e])$ ，考虑每个在 $τ_s , τ_e$ 之间的时间点，该四元组为正样本。$τ$ 时刻正样本集合定义为 ${\scr D</em>τ^+}$ 。</p><p>对于 $T$ 个时间点的 KG，将会有 $T$ 个用不同法向量（$w<em>{t_1}, w</em>{t<em>2}, …, w</em>{t<em>T}$）表示的超平面，在超平面的帮助下将空间隔离成不同时间域。在时间 $τ$ 下有效的三元组被投影到特殊超平面 $w</em>τ$，在超平面上平移距离被最小化。</p><p>计算在 $w<em>τ$ 上的投影表示，其中 $||w</em>τ||_2=1$ ：</p><script type="math/tex; mode=display">P_τ(e_h)=e_h - (w_τ^Te_h)w_τ  \\P_τ(e_t)=e_t - (w_τ^Te_t)w_τ  \\P_τ(e_r)=e_r - (w_τ^Te_r)w_τ  \\</script><blockquote><p>向量投影</p></blockquote><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><h3 id="得分函数"><a href="#得分函数" class="headerlink" title="得分函数"></a>得分函数</h3><p>对于在时间 $τ$ 有效的正样本，希望映射满足这样的关系 ：$P<em>τ(e_h)=P</em>τ(e<em>r) \approx P</em>τ(e_t)$, 因而使用以下的得分函数：</p><script type="math/tex; mode=display">f_τ(h,r,t)=||P_τ(e_h)+P_τ(e_r)-P_τ(e_t)||_{l1/l2}</script><p>在实体和关系嵌入过程中，对每个时间戳 $τ$ , 学习对应法向量 ${w<em>τ}</em>{τ=1}^T$  。</p><p>通过将三元组投影到时间超平面，我们可以将时间信息融入关系实体嵌入，利用相同的分布式表示在不同的时间点呈现不同的表达。</p><h3 id="loss函数"><a href="#loss函数" class="headerlink" title="loss函数"></a>loss函数</h3><script type="math/tex; mode=display">{\cal L} = \sum_{\tau \in [T]} \sum_{\tau \in \scr D_τ^+} \sum_{τ \in \scr D_τ^-} \max(0,f_τ(x)-f_τ(y)+\gamma)</script><ul><li>$\scr D_τ^+$: 有效三元组集合，即正样本集合；</li><li>$\scr D_τ^-$: 负样本集合；</li><li>实体约束： $||e_p||_2 \leq 1, \forall p \in {\varepsilon}$              实体向量的$L_2$正则化</li><li>法向量约束：$||w_{\tau}||_2=1,\forall \tau \in [T]$      法向量归一化                </li></ul><h3 id="负样本构造"><a href="#负样本构造" class="headerlink" title="负样本构造"></a>负样本构造</h3><p>考虑了两种负样本：</p><ul><li><p><strong>Time agnostic negative sampling(TANS)</strong> </p><p><strong>与时间无关的负采样</strong>：忽略时间戳，考虑不属于KG的负样本，在时间 $τ$ 采样该负样本:</p><script type="math/tex; mode=display">\scr D_τ^- = \{(h',r,t,\tau)|h' \in \scr {\varepsilon}, (h',r,t) \notin \scr D^+ \} \cup \{(h,r,t',\tau)|t' \in \scr {\varepsilon} , (h,r,t') \notin \scr D^+ \}</script></li><li><p><strong>Time dependent negative sampling(TDNS)</strong></p><p><strong>与时间相关的负采样</strong>： 考虑时间戳，考虑属于KG，但不属于特定时间戳 $\tau$ 的负样本：</p><script type="math/tex; mode=display">\scr D_τ^- = \{(h',r,t,\tau)|h' \in \scr {\varepsilon}, (h',r,t) \in \scr D^+，(h',r,t,\tau) \notin \scr D_{\tau}^+ \} \cup \\\{(h,r,t',\tau)|t' \in \scr {\varepsilon} , (h,r,t') \in \scr D^+, (h,r,t',\tau) \notin \scr D_{\tau}^+ \}</script></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;HyTE&quot;&gt;&lt;a href=&quot;#HyTE&quot; class=&quot;headerlink&quot; title=&quot;HyTE&quot;&gt;&lt;/a&gt;HyTE&lt;/h1&gt;&lt;p&gt;Hyperplane-based Temporally aware KG Embedding&lt;/p&gt;
&lt;p&gt;论文地址：&lt;a 
      
    
    </summary>
    
      <category term="知识图谱" scheme="http://yoururl.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="Knowledge graph" scheme="http://yoururl.com/tags/Knowledge-graph/"/>
    
  </entry>
  
  <entry>
    <title>知识图谱：知识表示之TransG模型</title>
    <link href="http://yoururl.com/2019/01/20/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA%E4%B9%8BTransG/"/>
    <id>http://yoururl.com/2019/01/20/知识表示之TransG/</id>
    <published>2019-01-19T16:07:00.000Z</published>
    <updated>2019-10-26T14:21:56.250Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TransG"><a href="#TransG" class="headerlink" title="TransG"></a>TransG</h1><p>论文地址： <a href="https://arxiv.org/pdf/1509.05488.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1509.05488.pdf</a></p><h2 id="模型改进"><a href="#模型改进" class="headerlink" title="模型改进"></a>模型改进</h2><p>针对一种关系存在的多语义问题：</p><p><img src="https://s2.ax1x.com/2019/03/05/kXcqtf.png" alt="kXcqtf.png"></p><p>由上图，嵌入向量的可视化结果所示表明，一个特定的关系存在不同的簇，不同的簇表示不同的潜语义。</p><blockquote><p>例如，关系HasPart至少有两个潜在的语义:与合成相关的as(Table、HasPart、Leg)和与位置相关的as (Atlantics、HasPart、NewYorkBay)。</p><p>再例如，Freebase中，(Jon Snow, birth place, Winter Fall)和(George R. R. Martin, birth place, U.S.)分别映射到模式 ：/fictional_universe/fictional_character/place of birth  和 /people/person/place of birth，表明出生地有不同的含义。</p></blockquote><p>多关系语义的可视化</p><p><img src="https://s2.ax1x.com/2019/03/05/kXcj1g.png" alt="kXcj1g.png"></p><blockquote><p>点是正确的三元组，属于HasPart关系，而圆是不正确的。</p><p>点坐标是头部和尾部实体之间的差向量，应该靠近中心。</p><p>(a)正确的三元组很难与错误的三元组区分开来；</p><p>(b)通过应用多个语义分量，TransG 可以区分正确的三元组和错误的三元组</p></blockquote><h3 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h3><ul><li><p>提出了一种关系会因为实体对的差异存在多重语义的问题，相当于对关系进行了细化；</p></li><li><p>提出了一种新的<strong>贝叶斯非参数无限混合嵌入模型TransG</strong>。该模型可以自动发现关系的语义集群，并利用多个关系分量的混合来转换实体对;</p></li></ul><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>模型生成过程：</p><ul><li><p>对一个实体 $e \in E$ :</p><p>(a)  从标准正态分布中提取每个嵌入的平均向量作为先验： ${\bf u_e} \sim  {\cal N}(0,1)$.</p></li><li><p>对于一个三元组 $(h,r,t) {\in \Delta}$ ： </p><p>(a)    通过$CRP$过程对一种关系构造语义成分， $\pi _{r,m} \sim CRP(\beta)$；</p><p>(b)    用正态分布构造头实体嵌入向量，${\bf h} \sim  {\cal N}({\bf u_h}, \sigma_h^2 {\bf E})$.</p><p>(c)    用正态分布构造尾实体嵌入向量，${\bf t} \sim  {\cal N}({\bf u_t}, \sigma_t^2 {\bf E})$.</p><p>(d)    对该语义构造一个关系嵌入向量，${\bf u_{r,m} }= {\bf {t-h} } \sim \cal N ({\bf {u_t-u_h, (\sigma_h^2+\sigma_t^2)E} })$ .</p></li></ul><p>其中：</p><ul><li>${\bf u_h}$ 和 ${\bf u_t}$ 代表头尾实体的平均嵌入向量，</li><li>$\sigma _h$ 和 $\sigma _t$  代表对应实体分布的方差；</li><li><p>${\bf u_{r,m} }$ 代表关系 $r$ 的第 $m$ 个 成分转移向量</p></li><li><p><a href="https://segmentfault.com/a/1190000010694630" target="_blank" rel="noopener">$CRP$</a> 过程是一个 Dirichlet 过程，它能自动检测语义成分。</p></li></ul><p>得分函数：</p><script type="math/tex; mode=display">{\Bbb P \{(h,r,t)\} }  \propto  \sum_{m=1}^{M_r} \pi_{r,m} \Bbb P({\bf u_{r,m} } | h,t)=\sum_{m=1}^{M_r} \pi_{r,m} e^{-\frac{||{\bf u_h+u_r}, \bf m-u_t||_2^2}{\sigma_h^2+\sigma_t^2} }</script><ul><li>$\pi_{r,m}$ : 混合系数，代表第$i$个语义成分的权重；</li><li>$M_r$ : 关系$r$的语义成分数量， 通过$CRP$自动的从数据中学习得到；</li></ul><p>TransG利用了特定关系的关系分量向量的组合。每个成分代表一个特定的潜在含义。通过这种方法，TransG可以区分多个关系语义。值得注意的是，CRP可以生成多个语义分量，并从数据中自适应地学习关系语义分量数$M_r$。</p><h3 id="几何解释"><a href="#几何解释" class="headerlink" title="几何解释"></a>几何解释</h3><p>TransG 推广：</p><script type="math/tex; mode=display">m_{h,r,t}^* = {\arg\min}_{m=1,...,M_r} \left(  \pi_{r,m} e^{-\frac{||{\bf u_h+u_r,m-u_t}||_2^2}{\sigma_h^2+\sigma_t^2} }     \right)</script><script type="math/tex; mode=display">{\bf h} + \bf u_{ {r,m}_{(\bf h,r,t)}^*} \approx \bf t</script><ul><li>$m_{h,r,t}^*$ : 主分量，虽然所有分量都对模型有贡献，但是由于指数效应，主分量贡献最大；</li><li>给定一个三元组，TransG计算出主分量，然后用主转换向量将头实体转化为尾实体；</li><li>对于大多数三元组而言，应该只有一个分量有明显的非零值 $ \left(  \pi_{r,m} e^{-\frac{||{\bf u_h+u_r, m-u_t}||_2^2}{\sigma_h^2+\sigma_t^2} }     \right)$， 而其他分量由于指数衰减应该足够小，所有TransG中所有分量都有贡献，但主分量贡献最少；</li><li>该性质有效的减少了来自其他语义分量的噪声，更好的描述了多种语义关系；</li><li>在TransG中， ${\bf t-h}$ 近乎只有一个转换向量 ${\bf u<em>{r,m}</em>{(h,r,t)}^<em>}$ ，当 $m \neq m_{(h,r,t)}^</em>$ 时，$\frac{||{\bf u_h+u_r, m-u_t}||_2^2}{ {\sigma}_h^2+{\sigma}_t^2}$ 很大，经过指数操作后值很小，故其他分量可以忽略；</li></ul><h2 id="训练算法"><a href="#训练算法" class="headerlink" title="训练算法"></a>训练算法</h2><p>训练中运用了最大数据似然原理。对于无参数部分，$\pi _{r,m}$ 通过 Gibbs 采样 从 CRP 生成。从三元组采样新的分量可利用以下概率：</p><script type="math/tex; mode=display">\Bbb P (m_{r.new}) = \frac{\beta e^{-\frac{||{\bf h-t}||_2^2}{\sigma_h^2 + \sigma_t^2 +2} } }{\beta e^{-\frac{||{\bf h-t}||_2^2}{\sigma_h^2 + \sigma_t^2 +2} }+ \Bbb P\{(h,r,t)\} }</script><ul><li>$\Bbb P{(h,r,t)}$ : 当前后验概率</li></ul><h3 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h3><p>其他部分，为了更好地区分正样本和负样本，将正样本和负样本的可能性比最大化。值得注意的是，嵌入向量是由(Glorot and Bengio, 2010)初始化的。将所有其他约束组合在一起，得到最终目标函数，如下所示:</p><script type="math/tex; mode=display">\min_{\bf u_h,u_r,m,u_t}  {\cal L}    \\{\cal L} = -\sum_{(h,r,t)\in \Delta} ln \left(\sum_{m=1}^{M_r} \pi_{r,m} e^{-\frac{||{\bf u_h+u_r, m-u_t}||_2^2}{\sigma_h^2+\sigma_t^2} } \right)  \\ +  \sum_{(h',r',t')\in \Delta'} ln \left(\sum_{m=1}^{M_r} \pi_{r',m} e^{-\frac{||{\bf u_{h'}+u_{r'} ,m-u_{t'}}||_2^2}{\sigma_{h'}^2+\sigma_{t'}^2} } \right) + C\left(\sum_{r\in R} \sum_{m=1}^{M_r} ||{\bf u_{r,m} }||_2^2 + \sum_{e\in E}||{\bf u_e}||_2^2 \right)</script><blockquote><p>此外还应用了一个技巧来控制训练过程中的参数更新过程。对于那些非常不可能的三元组，将跳过更新过程。因此，引入了与TransE 相似的条件: 训练算法只在满足以下条件时更新嵌入向量:</p><script type="math/tex; mode=display">\frac{\Bbb P\{(h,r,t)\} }{\Bbb P\{(h',r',t')\} }= \frac{\sum_{m=1}^{M_r} \pi_{r,m} e^{-\frac{||{\bf u_h+u_r, m-u_t}||_2^2}{\sigma_h^2+\sigma_t^2} } }{\sum_{m=1}^{M_{r'} } \pi_{r',m} e^{-\frac{||{\bf u_{h'}+u_{r'} , m-u_{t'}}||_2^2}{\sigma_{h'}^2+\sigma_{t'}^2} } }  \leq M_r e^{\gamma}</script><ul><li>$\gamma$ : 控制更新条件</li></ul></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TransG&quot;&gt;&lt;a href=&quot;#TransG&quot; class=&quot;headerlink&quot; title=&quot;TransG&quot;&gt;&lt;/a&gt;TransG&lt;/h1&gt;&lt;p&gt;论文地址： &lt;a href=&quot;https://arxiv.org/pdf/1509.05488.pdf&quot; t
      
    
    </summary>
    
      <category term="知识图谱" scheme="http://yoururl.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="Knowledge graph" scheme="http://yoururl.com/tags/Knowledge-graph/"/>
    
  </entry>
  
  <entry>
    <title>知识图谱：知识表示之TransA模型</title>
    <link href="http://yoururl.com/2019/01/20/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA%E4%B9%8BTransA/"/>
    <id>http://yoururl.com/2019/01/20/知识表示之TransA/</id>
    <published>2019-01-19T16:05:00.000Z</published>
    <updated>2019-10-26T08:09:46.143Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TransA"><a href="#TransA" class="headerlink" title="TransA"></a>TransA</h1><p>论文地址: <a href="https://arxiv.org/pdf/1509.05490.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1509.05490.pdf</a></p><h2 id="模型改进"><a href="#模型改进" class="headerlink" title="模型改进"></a>模型改进</h2><h3 id="缺陷"><a href="#缺陷" class="headerlink" title="缺陷"></a>缺陷</h3><p><img src="https://s2.ax1x.com/2019/03/05/kXcy01.png" alt="kXcy01.png"></p><p>TransE模型本质上是一种欧式距离的计算，对应一个等势超球面。</p><blockquote><p> 上图中蓝色部分为正例，红色部分为负例，TransE模型错误划分7个点；利用本文提出的基于马氏距离的TransA模型，其PCA降维图对应一个椭圆，该模型只错误划分三个点。</p></blockquote><ul><li><p>目前基于转移的方法构造了等式超球面，不容易划分匹配与不匹配的尾部实体；而且等式超球面形状固定、不够灵活；</p><blockquote><p>疑问：“等式超球面在等式面上权重处处相等，且等势面广，容易将不匹配的实体包含进来？？？</p></blockquote></li><li><p>权重的问题：损失函数过于简单，向量的每一维度等价考虑，无法突出维度的重要性差异；</p></li></ul><p><img src="https://s2.ax1x.com/2019/03/05/kXc6Tx.png" alt="kXc6Tx.png"></p><blockquote><p>上图所示，对于关系 has-part 而言，TransE模型根据欧式距离计算生成了像 ”Room-has-Goniff“这样的三元组。而正确的结果是”Room-has-Wall“。</p><p>对x,y轴进行分解，发现Room在x轴上距离Wall更近，因此可以认为该图在x轴维度上更重要。TransA模型通过引入加权矩阵，对每一个维度赋予不同权重。</p><p>轴分量损失： $loss_x = (h_x+r_x-t_x)$ ,  $loss_y=(h_y+r_y-t_y)$</p></blockquote><h2 id="Adaptive-Metric-Approach"><a href="#Adaptive-Metric-Approach" class="headerlink" title="Adaptive Metric Approach"></a>Adaptive Metric Approach</h2><ul><li>TransA利用椭圆表面，而不是球面，这样可以更好的表示由复杂关系引起的复杂的嵌入拓扑；</li><li>根据自适应度量方法，TransA可以自动从数据中学习权重，加权变换特征维度；</li></ul><p>得分函数：</p><script type="math/tex; mode=display">f_r(h,t)=(|{\bf h+r-t}|)^T {\bf W}_r(|{\bf h+r-t}|)</script><ul><li>$|{\bf h+r-t} |  \doteq (|h_1+r_1-t_1|,|h_1+r_1-t_1|,…,|h_n+r_n-t_n|)$</li><li>${\bf w}_r$ 是与自适应度相关的对称非负权重矩阵；</li><li>采用绝对值运算能很好的定义得分函数，保证${\bf w}_r$是非负的；</li></ul><p>将得分函数扩展为一个诱导范数:</p><script type="math/tex; mode=display">N_r({\bf e})=\sqrt{f_r(h,t)}</script><ul><li><p>${\bf e} \doteq {\bf h+r-t}$  </p></li><li><p>$N_r$ 是非负的，单位的，绝对齐次的。</p><script type="math/tex; mode=display">N_r({\bf e}_1+{\bf e}_2)=\sqrt{|{\bf e_1}+{\bf e_2}|^T{\bf W_r} |{\bf e_1}+{\bf e_2} |} \leq  \sqrt{|{\bf e_1}|^T {\bf W_r} |{\bf e_1}|} + \sqrt{|{\bf e_2}|^T {\bf W_r} |{\bf e_2}|} = N_r({\bf e}_1) + N_r({\bf e}_2)</script></li></ul><script type="math/tex; mode=display">{\bf W_r}={\bf L_r}^T{\bf D_r L_r}</script><script type="math/tex; mode=display">f_r=({\bf L_r}|{\bf h+r-t}|)^T {\bf D_r} ({\bf L_r}|{\bf h+r-t}|)</script><ul><li>${\bf D_r}$ : 对角矩阵$diag (w_1, w_2,…, w_n)$，对角元素代表向量每一维度$i$以权重$w_i$嵌入 ;</li></ul><h4 id="等势面"><a href="#等势面" class="headerlink" title="等势面"></a>等势面</h4><p>其他基于平移的方法：</p><ul><li>欧式距离定义等势面<script type="math/tex; mode=display">||({\bf t-h-r})||_2^2={\cal C}</script></li></ul><p>TransA方法：</p><ul><li><p><a href="https://www.cnblogs.com/likai198981/p/3167928.html" target="_blank" rel="noopener">马氏距离</a>定义等势面</p><script type="math/tex; mode=display">|{\bf t-h-r}|^T {\bf W_r} |{\bf t-h-r}|= {\cal C}</script></li></ul><blockquote><p>马氏距离利用协方差，有效计算样本各特性之间的联系，与尺度无关。</p><p>从而可以看出，TransA利用马氏距离，可以更好的应对1-N关系，由于矩阵对称，反过来对于N-1关系也有效；N-N关系可以看成多个1-N关系；因此TransA对于复杂关系的处理很有效。</p></blockquote><h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><script type="math/tex; mode=display">\left( \sum_{e \in E}||{\bf e}||_2^2 + \sum_{r \in R}||{\bf r}||_2^2 \right)</script><script type="math/tex; mode=display">{\cal L}=\sum_{(h,r,t) \in \Delta} \sum_{(h',r',t') \in \Delta'} [\gamma + f_r(h, t)-f_{r'}(h', t')]_+ + C \left (\sum_{e \in E}||{\bf e}||_2^2 + \sum_{r \in R}||{\bf r}||_2^2 \right) + \lambda \left (\sum_{r \in R}||{\bf W_r}||_F^2 \right)</script><ul><li>$\lambda$ : 正则化自适应权重矩阵</li><li><p>$C$ : 控制缩放比例</p></li><li><p>${\bf [W<em>r]}</em>{ij} \geq 0$ :  在每轮的训练中，${\bf W_r}$ 可以通过将推导值设为零直接计算出来。为保证${\bf W_r}$的非负，将${\bf W_r}$的所有负项都设为零。</p><script type="math/tex; mode=display">\bf W_r = -\sum_{(h,r,t)\in \Delta} \left(|{\bf h+r-t}||{\bf h+r-t}|^T \right) + \sum_{(h',r',t')\in \Delta'} \left(|{\bf h'+r'-t'}||{\bf h'+r'-t'}|^T \right)</script></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TransA&quot;&gt;&lt;a href=&quot;#TransA&quot; class=&quot;headerlink&quot; title=&quot;TransA&quot;&gt;&lt;/a&gt;TransA&lt;/h1&gt;&lt;p&gt;论文地址: &lt;a href=&quot;https://arxiv.org/pdf/1509.05490.pdf&quot; t
      
    
    </summary>
    
      <category term="知识图谱" scheme="http://yoururl.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="Knowledge graph" scheme="http://yoururl.com/tags/Knowledge-graph/"/>
    
  </entry>
  
  <entry>
    <title>知识图谱：知识表示之TransR模型</title>
    <link href="http://yoururl.com/2019/01/20/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA%E4%B9%8BTransR/"/>
    <id>http://yoururl.com/2019/01/20/知识表示之TransR/</id>
    <published>2019-01-19T16:03:00.000Z</published>
    <updated>2019-10-27T06:11:04.591Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TransR"><a href="#TransR" class="headerlink" title="TransR"></a>TransR</h1><p>论文地址: <a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/download/9571/9523/" target="_blank" rel="noopener">http://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/download/9571/9523/</a></p><h2 id="模型改进"><a href="#模型改进" class="headerlink" title="模型改进"></a>模型改进</h2><p>TransE 和 TransH 都假设实体和关系嵌入在相同的空间中。然而，一个实体是多种属性的综合体，不同关系对应实体的不同属性，即头尾节点和关系可能不在一个向量空间中，在公共语义空间中不能表示它们。</p><p><img src="https://s2.ax1x.com/2019/03/05/kXcAOA.png" alt="kXcAOA.png" style="zoom:67%;"></p><ul><li>对每个三元组，实体空间中的实体首先通过运算 $M_r$ 映射到与它相关的 $r$ 关系空间, 保证 ${\bf h}_r + r \approx {\bf t}_r$ , 关系特定投影可以使实际持有该关系(表示为彩色圆圈)的头/尾实体彼此靠近，也可以使不持有该关系(表示为彩色三角形)的头/尾实体远离。</li><li>TransR对每个关系$r$都分配了一个空间${\bf M}_r \in R^{k \times d}$。</li><li>特定关系下，头尾实体会表现不同的模式；</li></ul><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>提出了一种新的方法，<strong>在不同的空间中建模实体和关系</strong>，即，<strong>实体空间</strong>和<strong>关系空间</strong>，并在关系空间中进行转换，因此命名为TransR。</p><h3 id="TransR-1"><a href="#TransR-1" class="headerlink" title="TransR"></a>TransR</h3><p>TransR 模型中，对每一个三元组，实体嵌入 ${\bf h,t} \in {\Bbb R}^k$ , 关系嵌入 ${ {\bf r} \in {\Bbb R}^d}$, 两个空间的维度不一定相同（属于不同空间）。  </p><ul><li>对每一个关系$r$，定义一个投影矩阵 ${\bf M}_r \in {\Bbb R}^{k \times d}$, 将实体从实体空间投影到关系空间：</li></ul><script type="math/tex; mode=display">{ {\bf h_r} = {\bf hM}_r}</script><script type="math/tex; mode=display">{ {\bf t_r} = {\bf tM}_r}</script><ul><li><p>得分函数：</p><script type="math/tex; mode=display">f_r(h,t)=||{ {\bf h}_r} + {\bf r} - {\bf t}_r||_2^2</script></li><li><p>实体和关系嵌入的范数约束  </p><script type="math/tex; mode=display">||{\bf h}||_2 \leq 1, ||{\bf t}||_2 \leq 1,||{\bf r}||_2 \leq 1, ||{\bf hM}_r||_2 \leq 1, ||{\bf tM}_r||_2 \leq 1</script></li></ul><h3 id="Cluster-based-TransR-CTransR"><a href="#Cluster-based-TransR-CTransR" class="headerlink" title="Cluster-based TransR (CTransR)"></a>Cluster-based TransR (CTransR)</h3><p>上述模型包括TransE, TransH和TransR，仅仅通过单个的关系向量还不足以建立从头实体到尾实体的所有转移，<strong>即对于同一条关系$r$  来讲，$r$ 具有多种语义上的表示</strong>。为了更好地建模这些关系，引入了<strong>分段线性回归</strong>的思想来扩展TransR。</p><ul><li><p>对于一个特定的关系$r$，把训练数据中的所有实体对 $(h, t)$ 聚类到多个组中，每个组中的实体对都期望表现出相似的$r$关系。其中所有实体对$(h,t)$通过的向量偏移$(h−t)$来聚类；</p><blockquote><p>为什么根据$(h-t)$(也就是$r$)就能聚类:</p><p> CTransR考虑的问题是对一个关系只用一个表示无法体现这一种关系的多义性，比如关系（location location contains）其实包含country-city、country-university、continent-country等多种含义。</p><p><img src="https://s2.ax1x.com/2019/03/05/kXc1yj.png" alt="kXc1yj.png"></p><p>原文提到，这里的$h,t$是经过TRansE模型预训练得到的: </p><p><img src="https://s2.ax1x.com/2019/03/05/kXcJwq.png" alt="kXcJwq.png"></p><hr><p><img src="https://s2.ax1x.com/2019/03/05/kXcNkV.png" alt="kXcNkV.png"></p><p> 而TransE模型的映射是唯一（one to one）的，大关系下的不同子关系通过映射后其实是不同的向量表示，那么$(h-t)$的结果也不相同，根据不同的结果可以用来进行聚类。</p></blockquote></li><li><p>对每一个簇, 学习一个<strong>分离关系向量</strong> ${\bf r}_c$ ，对每种关系，学习投影矩阵 ${\bf M}_r$</p></li><li><p>定义实体和关系的投影向量为：</p></li></ul><script type="math/tex; mode=display">{ {\bf h}_{r,c} = {\bf hM}_r}</script><script type="math/tex; mode=display">{ {\bf t}_{r,c} = {\bf tM}_r}</script><ul><li>得分函数：</li></ul><script type="math/tex; mode=display">f_r(h,t)=||{ {\bf h}_{r,c}} + {\bf r}_c - {\bf t}_{r,c}||_2^2 + \alpha ||{\bf r}_c - {\bf r}||_2^2</script><p>$||{\bf r}_c - {\bf r}||_2^2$ 这一项确保群特异性关系向量 ${\bf r}_c$ 距离原始关系向量 ${\bf r}$ 不太远， $\alpha$ 控制约束效果</p><ul><li>实体和关系嵌入的范数约束  </li></ul><script type="math/tex; mode=display">||{\bf h}||_2 \leq 1, ||{\bf t}||_2 \leq 1,||{\bf r}||_2 \leq 1, ||{\bf hM}_r||_2 \leq 1, ||{\bf tM}_r||_2 \leq 1</script><h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p>损失函数：</p><script type="math/tex; mode=display">{\cal L}=\sum_{(h,r,t)\in \Delta} \sum_{(h',r,t')\in \Delta'} max (0, \gamma + f_r(h, t)-f_{r}(h', t') )</script><h3 id="负样本生成"><a href="#负样本生成" class="headerlink" title="负样本生成"></a>负样本生成</h3><p>为首尾实体替换分配不同的概率。对于那些1- n、n -1和n -n关系，给“one”设置更高的概率，产生假阴性样本的机会将会减少 </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TransR&quot;&gt;&lt;a href=&quot;#TransR&quot; class=&quot;headerlink&quot; title=&quot;TransR&quot;&gt;&lt;/a&gt;TransR&lt;/h1&gt;&lt;p&gt;论文地址: &lt;a href=&quot;http://www.aaai.org/ocs/index.php/AAAI/
      
    
    </summary>
    
      <category term="知识图谱" scheme="http://yoururl.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="Knowledge graph" scheme="http://yoururl.com/tags/Knowledge-graph/"/>
    
  </entry>
  
  <entry>
    <title>知识图谱：知识表示之TransH模型</title>
    <link href="http://yoururl.com/2019/01/20/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA%E4%B9%8BTransH/"/>
    <id>http://yoururl.com/2019/01/20/知识表示之TransH/</id>
    <published>2019-01-19T16:02:00.000Z</published>
    <updated>2019-03-05T03:04:12.008Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TransH"><a href="#TransH" class="headerlink" title="TransH"></a>TransH</h1><p>论文地址：<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/viewFile/8531/8546" target="_blank" rel="noopener">https://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/viewFile/8531/8546</a></p><h2 id="模型改进"><a href="#模型改进" class="headerlink" title="模型改进"></a>模型改进</h2><p><img src="https://s2.ax1x.com/2019/03/05/kX6zo6.png" alt="kX6zo6.png"></p><p>将特定关系的转移向量 $d_r$ 放置于特定关系的超平面 $w_r$ ,而不是映射到相同的实体嵌入空间；  </p><p>对于三元组 $(h,r,t)$，嵌入向量 ${\bf h}$ 和 ${\bf t}$ 投影到超平面 ${\bf {w<em>r}}$ , 投影被表示为 ${\bf h</em>{\bot}}$ 和 ${\bf t<em>{\bot}}$ 。投影 ${h</em>{\bot}}$ 和 ${t_{\bot}}$ 能被转移向量 ${\bf d_r}$ 连接， 当三元组为正样本时有更低的错误率，为负样本时错误率上升；   </p><blockquote><p>TransH将一个关系$r$表示成两个向量：超平面法向量${\bf W}_r$和超平面内的关系向量${\bf d_r}$表示；</p><p>该关系连接的不同实体对在超平面上的投影只对应一个向量表示： ${\bf h<em>{\bot}}$ 和 ${\bf t</em>{\bot}}$，</p><p>也就是，唯一的${\bf W}_r$和${\bf d_r}$ 确定了该关系在空间中的唯一超平面；</p></blockquote><ul><li><p>定义一个得分函数,衡量三元组的合理性：</p><script type="math/tex; mode=display">||{\bf h_{\bot} } + {\bf d_r} - {\bf t_{\bot} }||_2^2</script></li><li><p>超平面法向量限制为 $||{\bf w}_r ||_2 = 1$, 超平面投影的表示为</p></li></ul><script type="math/tex; mode=display">{\bf h_{\bot} } = {\bf h} - {\bf w}_r^T {\bf h}{\bf w}_r</script><script type="math/tex; mode=display">{\bf t_{\bot} } = {\bf t} - {\bf w}_r^T {\bf h}{\bf w}_r</script><blockquote><p>推导： 嵌入向量在超平面法向量上的投影长度，再乘上法向量方向向量：<br>$d=\frac{ | {\bf w}_r^T h| }{| |{\bf w}| |} \cdot \frac{ {\bf w}_r}{| |{\bf w}| |}=\frac{ {\bf w}_r^T {\bf h}{\bf w}_r}{| |{\bf w}^2| |}={\bf w}_r^T {\bf h}{\bf w}_r$</p></blockquote><p>最终得分函数：</p><script type="math/tex; mode=display">f_r({\bf h},{\bf t}) = | |({\bf h} - {\bf w}_r^T {\bf h} {\bf w}_r) + {\bf d}_r -({\bf t} - {\bf w}_r^T {\bf h} {\bf w}_r)| |_2^2</script><p>模型参数：</p><ul><li>所有实体的嵌入向量  ${ {\bf e<em>i}}</em>{r=1}^{ |E| }$ ; </li><li>所有关系超平面和转移向量  ${ ( {\bf w<em>r, d_r})}</em>{r=1}^{ |R| }$  ;</li></ul><p>在TransH中，通过引入投射到特定关系超平面上的机制，使实体在不同的关系/三元组中扮演不同的角色。</p><h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><script type="math/tex; mode=display">{\cal L}=\sum_{(h,r,t)\in \Delta} \sum_{(h',r',t')\in \Delta'_{(h,r, t)} } [\gamma + f_r({\bf h}, {\bf t})-f_{r'}({\bf h'}, {\bf t'}) ]_+</script><ul><li>$\Delta$: 正确三元组集合</li><li>$\Delta’$: 错误三元组集合</li><li>$\gamma$: margin 距离超参数，表示正负样本之间的距离</li><li>$[x]_+$: $max(0,x)$</li></ul><p>训练的限制条件：</p><ul><li>$\forall e\in E, ||{\bf e}||_2 \leq 1$ ,   # 控制实体嵌入大小</li><li>$\forall r \in R, \frac{|{\bf w}_t^T {\bf d}_r|}{||{\bf d}_r||_2} \leq \epsilon$ , # 正交，控制转移向量落在超平面</li><li>$\forall r \in R. ||{\bf w}_r||_2=1$ , # 单位法向量</li></ul><p>软约束：</p><script type="math/tex; mode=display">{\cal L}=\sum_{(h,r,t)\in \Delta} \sum_{(h',r',t')\in \Delta'_{(h,r, t)} } [\gamma + f_r({\bf h}, {\bf t})-f_{r'}({\bf h'}, {\bf t'}) ]_+ + C\left\{\sum_{e\in E}[||{\bf e}||_2^2 -1]_+ + \sum_{r \in R}\left[\frac{({\bf w}_t^T {\bf d}_r)^2}{||{\bf d}_r||_2^2} - \epsilon ^2\right]_+ \right\}</script><ul><li>C是软约束的超参数权重</li><li>注意到约束3不在loss公式里，在访问每一个mini-batch时将每一个${\bf w}_r$投影到单位  <a href="https://blog.csdn.net/zouxy09/article/details/24971995" target="_blank" rel="noopener">$L_2- \bf {ball}$</a> </li><li>随机梯度下降，正样本的集合被随机遍历多次，当访问一个正样本时，一个负样本被随机构造。</li></ul><h3 id="负样本构造"><a href="#负样本构造" class="headerlink" title="负样本构造"></a>负样本构造</h3><p>相对于TransE模型的随机采样生成负样本，TransH模型的创新点：<br><strong>赋予头尾实体采样概率</strong>   </p><ul><li>处理1-N关系时，赋予头部实体更高的采样概率；</li><li>处理N-1关系时，赋予尾部实体更高的采样概率；  </li></ul><p>在所有关系r的三元组中，首先获取两个数据：</p><ul><li>$tph$: 每一个头部实体对应的平均尾部实体;</li><li>$hpt$: 每一个尾部实体对应的平均头部实体;</li></ul><p>针对这两个数据进行映射的分类：</p><script type="math/tex; mode=display">\left \{ \begin{array}{rcl}1-1    & \mbox{for} & tph_r<1.5,hpt_r <1.5 \\ N-N    & \mbox{for} & tph_r \geq 1.5,hpt_r \geq 1.5 \\1-N    & \mbox{for} & tph_r \geq 1.5,hpt_r < 1.5 \\N-1    & \mbox{for} & tph_r < 1.5,hpt_r \geq 1.5 \\\end{array}\right.</script><p>定义一个伯努利分布进行采样：</p><ul><li>$\frac{tph}{tph+hpt}$: 采样头部实体的概率;</li><li>$\frac{hpt}{tph+hpt}$: 采样尾部实体的概率;</li></ul><h2 id="实验部分-未完待补充"><a href="#实验部分-未完待补充" class="headerlink" title="实验部分(未完待补充)"></a>实验部分(未完待补充)</h2><p>在三个任务上研究评估模型：从不同视角和应用层面，评估对陌生三元组的预测精度</p><ul><li>link prediction</li><li>triplets classification</li><li>relational fact extraction</li></ul><p>实验数据使用：<br><img src="http://p5bxip6n0.bkt.clouddn.com/18-11-1/13704280.jpg" alt=""></p><h4 id="link-prediction"><a href="#link-prediction" class="headerlink" title="link prediction"></a>link prediction</h4><p><strong>任务</strong>：三元组的头部或者尾部实体缺失，给定 $(h,r)$ 预测 $t$ 或者给定 $(r,t)$ 预测 $h$ , 返回预测的候选排名；<br><strong>评估协议</strong>： 对于给定的三元组，用每个实体 $e$ 取代尾部实体 $t$ ，并计算损坏样本的差异性分数，升序排列获取原始三元组的排名；<br><strong>过滤</strong>： 生成的损坏三元组可能原本就存在于知识图谱中，需要删去；<br><strong>报告指标</strong>：  </p><ul><li>Mean:平均排名:</li><li>$Hits@10$: 排名不超过10的比例</li></ul><h4 id="triplets-classification"><a href="#triplets-classification" class="headerlink" title="triplets classification"></a>triplets classification</h4><p><strong>任务</strong>: 对给定三元组进行二分类判断正负样本；</p><h4 id="relational-fact-extraction"><a href="#relational-fact-extraction" class="headerlink" title="relational fact extraction"></a>relational fact extraction</h4><p>(待补充)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TransH&quot;&gt;&lt;a href=&quot;#TransH&quot; class=&quot;headerlink&quot; title=&quot;TransH&quot;&gt;&lt;/a&gt;TransH&lt;/h1&gt;&lt;p&gt;论文地址：&lt;a href=&quot;https://www.aaai.org/ocs/index.php/AAAI/
      
    
    </summary>
    
      <category term="知识图谱" scheme="http://yoururl.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="Knowledge graph" scheme="http://yoururl.com/tags/Knowledge-graph/"/>
    
  </entry>
  
  <entry>
    <title>知识图谱：知识表示之TransE模型</title>
    <link href="http://yoururl.com/2019/01/20/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA%E4%B9%8BTransE/"/>
    <id>http://yoururl.com/2019/01/20/知识表示之TransE/</id>
    <published>2019-01-19T16:01:00.000Z</published>
    <updated>2019-10-27T05:33:14.484Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TransE"><a href="#TransE" class="headerlink" title="TransE"></a>TransE</h1><p>论文地址：<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/viewFile/8531/8546" target="_blank" rel="noopener">https://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/viewFile/8531/8546</a>  </p><h2 id="模型概述"><a href="#模型概述" class="headerlink" title="模型概述"></a>模型概述</h2><ul><li>三元组：   $(h,{\scr l},t)$      </li><li>embedding之后， 头部实体嵌入向量加上关系嵌入向量，更接近与尾部实体嵌入向量</li><li>依赖于简化的参数集，只学习每个实体和每个关系的一个<strong>低维向量</strong>表示</li></ul><p><img src="https://s2.ax1x.com/2019/03/05/kXcCWD.png" alt="kXcCWD.png"></p><p>细节：</p><ul><li>训练集 $S$: 包含三元组 $(h,{\scr l},t)$， 实体 $h,t\in E(实体集)$, 关系 ${\scr l} \in L(关系集)$；</li><li>embeddings 在 $\Bbb R^k$ 中取值</li><li>${\bf h}+{\scr l}\approx {\bf t}$ , ${\bf t}$ 应该为 ${\bf h}+{\scr l}$ 的最邻近， 然后 ${\bf h}+{\scr l}$ 与其他的 $t$ 尽可能远；  这里的“接近”程度可以用 $L_1$或$L_2$范数衡量；<br>理想状态下一个正确的三元组的embedding 之间存在 ${\bf h}+{\scr l}={\bf t}$ 的关系，错误的三元组没有；</li><li>利用基于能量的框架，三元组的势能表示为 $d(h, {\scr l}, t)=||h+{\scr l}-t||_2$ ， 正确的三元组势能越低越好，错误的三元组势能越高越好；</li></ul><h2 id="损失函数："><a href="#损失函数：" class="headerlink" title="损失函数："></a>损失函数：</h2><h3 id="带negative-sample的max-margin损失函数"><a href="#带negative-sample的max-margin损失函数" class="headerlink" title="带negative sample的max margin损失函数"></a>带negative sample的max margin损失函数</h3><p>训练方法：margin-based ranking criterion</p><script type="math/tex; mode=display">{\cal L}=\sum_{(h,{\scr l},t)\in S} \sum_{(h',{\scr l},t')\in S'_{(h,{\scr l}, t)} } [\gamma + d(h+{\scr l}, t)-d(h'+{\scr l}, t') ]_+</script><script type="math/tex; mode=display">d(h, {\scr l}, t)=||h+{\scr l}-t||_2</script><ul><li>$S$: 正确三元组集合</li><li>$S’$: 错误三元组集合</li><li>$\gamma$: margin 距离超参数，表示正负样本之间的距离，常数;</li><li>$[x]_+$: $max(0,x)$</li></ul><blockquote><p>最小化loss可以使正样本势能越低，负样本势能越高，但两者的能量差距达到一定程度 $\gamma$ 就足够了， 再大loss也只是0；</p></blockquote><h3 id="负样本生成"><a href="#负样本生成" class="headerlink" title="负样本生成"></a>负样本生成</h3><script type="math/tex; mode=display">S'_{(h,{\scr l},t)} = \{(h',{\scr l},t)|h'\in E\}\bigcup \{(h,{\scr l},t')|t' \in E\}</script><ul><li>对于三元组 $(h,{\scr l},t)$， 随机使用知识库中的某个实体 $h’$ 替换 $h$，或用某个实体 $t’$ 替换 $t$, 得到两个负样本 $(h’,{\scr l},t)$ 和 $(h,{\scr l},t’)$;  </li><li>对生成的负样本进行筛选过滤，若该负样本原本存在于知识库，则重新生成；  </li><li>然后，有人认为，生成负样本时不应该完全随机，而是应该选择与被替换实体类型相似的实体来进行替换；</li></ul><h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-11-1/93529922.jpg" alt=""></p><h2 id="TransE局限性"><a href="#TransE局限性" class="headerlink" title="TransE局限性"></a>TransE局限性</h2><p>考虑在没有错误embedding的情况下，$h+{\scr l}=t$  当 $(h,{\scr l},t) \in \Delta$ 时，我们可以从TransE模型中看出：</p><ul><li>若 $(h,{\scr l},t) \in \Delta$ 且 $(t,{\scr l},h) \in \Delta$, $r$是一个自反映射， 因此 $r=0$ 且 $h=t$;</li><li>若 $\forall i \in {0,…,m},(h_i,r,t)\in \Delta$ , $r$是一个N-1映射，且 $h_0=…=h_m$;<br>类似的，$\forall i \in {0,…,m},(h,r,t_i)\in \Delta$ , $r$是一个1-N映射，且 $t_0=…=t_m$;  </li></ul><p>当涉及相同关系时，忽略了实体的分布式表示，导致实体呈现相同的嵌入表示。</p><blockquote><p>例如，假如知识库中有两个三元组，分别是(美国, 总统, 奥巴马)和(美国, 总统, 布什)。这里的关系“总统”是典型的 1-N 的复杂关系。如果用 TransE 从这两个三元组学习知识表示，将会使奥巴马和布什的向量变得相同。<br>因而，TransE 模型在处理 1-N、N-1、N-N 复杂关系时存在局限性。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TransE&quot;&gt;&lt;a href=&quot;#TransE&quot; class=&quot;headerlink&quot; title=&quot;TransE&quot;&gt;&lt;/a&gt;TransE&lt;/h1&gt;&lt;p&gt;论文地址：&lt;a href=&quot;https://www.aaai.org/ocs/index.php/AAAI/
      
    
    </summary>
    
      <category term="知识图谱" scheme="http://yoururl.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="Knowledge graph" scheme="http://yoururl.com/tags/Knowledge-graph/"/>
    
  </entry>
  
  <entry>
    <title>知识图谱：知识表示之TransD模型</title>
    <link href="http://yoururl.com/2019/01/20/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA%E4%B9%8BTransD/"/>
    <id>http://yoururl.com/2019/01/20/知识表示之TransD/</id>
    <published>2019-01-19T16:01:00.000Z</published>
    <updated>2019-10-27T06:16:26.442Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TransD"><a href="#TransD" class="headerlink" title="TransD"></a>TransD</h1><p>论文地址: <a href="http://www.aclweb.org/anthology/P15-1067" target="_blank" rel="noopener">http://www.aclweb.org/anthology/P15-1067</a></p><p>TransR /CTransR模型存在的问题：</p><ul><li>对于一种关系，所有实体共享一样的映射矩阵${\bf M}_r$。然而被同一个关系链接的实体拥有不同的类型和属性，这些差异需要用不同的映射来体现；</li><li>实体与关系间的映射是可逆的，没有理由只通过关系来构建映射矩阵；</li><li>矩阵向量乘法运算，参数多，模型运算量大；</li></ul><p>创新点：</p><ul><li>TransD可以说是TransR/CTransR的简化版本，它同时考虑了实体和关系之间的多样性，用两个向量来动态重构mapping矩阵；</li><li>相比TransR/CTransR有更小的计算量，且没有矩阵运算，可以在大规模KG上应用；</li></ul><p><strong>实体关系的多语义表示</strong>：</p><p><img src="https://s2.ax1x.com/2019/03/05/kXcDX9.png" alt="kXcDX9.png"></p><h2 id="模型改进"><a href="#模型改进" class="headerlink" title="模型改进"></a>模型改进</h2><p>TransD 模型同 CTransR 模型一样，都是为了解决关系的多种语义表示。相比较 CTransR 采用聚类的方式，TransD 提出一种<strong>动态变化矩阵</strong>的方法。</p><p><img src="https://s2.ax1x.com/2019/03/05/kXc0l4.png" alt="kXc0l4.png"></p><p>每一个命名对象（实体关系）用两个向量表示：</p><ul><li>$(h,r,t)$ :  自身的关系（语义）表示；</li><li>$(h_p, r_p, t_p)$ :  实体空间中的投影，用于构建映射矩阵的表示；</li></ul><p>具体公式如下图所示：</p><script type="math/tex; mode=display">{\bf M}_{rh} = {\bf r}_p{\bf h}_p^T + {\bf I}^{m \times n}</script><script type="math/tex; mode=display">{\bf M}_{rt} = {\bf r}_p{\bf t}_p^T + {\bf I}^{m \times n}</script><ul><li>下标$p$表示投影向量， ${\bf h} , {\bf h}_p, {\bf t} , {\bf t}_p \in {\Bbb R}^n$ ,  ${\bf r}, {\bf r}_p \in {\Bbb R}^m$</li><li>映射矩阵的每一个元素都包含了实体和关系信息；</li><li>通过向量相乘生成的矩阵对单位矩阵（代表不做变换）进行调整；</li></ul><p>定义向量在关系空间的投影：</p><script type="math/tex; mode=display">{\bf h_{\perp} }={\bf M}_{rh} {\bf h}</script><script type="math/tex; mode=display">{\bf t_{\perp} }={\bf M}_{rt} {\bf t}</script><p>得分函数：</p><script type="math/tex; mode=display">f_r({\bf h,t})= -|| {\bf h_\perp} + {\bf {r-t}_\perp}||_2^2</script><ul><li>限制条件：  </li></ul><script type="math/tex; mode=display">||{\bf h}||_2 \leq 1, ||{\bf t}||_2 \leq 1,     ||{\bf r}||_2 \leq 1, ||{\bf h_\perp}||_2 \leq 1, ||{\bf t_\perp}||_2 \leq 1</script><h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p>假设训练集中有$n_t$个三元组，用$(h_i,r_i,t_i)(i=1,2,…,n_t)$表示第$i$个三元组。</p><p>每个三元组有标签$y_i$表示三元组的正负性质：</p><script type="math/tex; mode=display">\Delta = \{(h_j,r_j,t_j)|y_j=1\}</script><script type="math/tex; mode=display">\Delta' = \{(h_j,r_j,t_j)|y_j=0\}</script><h3 id="负样本生成"><a href="#负样本生成" class="headerlink" title="负样本生成"></a>负样本生成</h3><script type="math/tex; mode=display">\Delta' = \{(h_l,r_k,t_k)|h_l\neq h_k \wedge y_k=1\} \cup \{(h_k,r_k,t_l)|t_l\neq t_k \wedge y_k=1\}</script><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><script type="math/tex; mode=display">{\cal L}=\sum_{\xi \in \Delta} \sum_{\xi' \in \Delta' } [\gamma + f_r(\xi')-f_{r}(\xi) ]_+</script><ul><li>$\xi$ : 正样本， $\xi’$ : 负样本</li></ul><p>为加快收敛和避免过拟合：</p><ul><li><p>利用TransE模型初始化实体和关系嵌入向量；</p></li><li><p>用单位矩阵初始化转移矩阵；   </p></li></ul><h2 id="和其他模型的联系"><a href="#和其他模型的联系" class="headerlink" title="和其他模型的联系"></a>和其他模型的联系</h2><h3 id="TransE"><a href="#TransE" class="headerlink" title="TransE"></a>TransE</h3><p>当向量维度满足$m=n$，且所有用于构建映射矩阵的投影向量都为0时，TransE是TransD的一种特殊情况。</p><h3 id="TransH"><a href="#TransH" class="headerlink" title="TransH"></a>TransH</h3><p>当向量维度满足$m=n$时，实体的投影向量能被表示为：</p><script type="math/tex; mode=display">{\bf h_{\perp} }={\bf M}_{rh} {\bf h} = {\bf h}+{\bf h}_p^T {\bf h} {\bf r}_p</script><script type="math/tex; mode=display">{\bf t_{\perp} }={\bf M}_{rt} {\bf t} = {\bf t}+{\bf t}_p^T {\bf t} {\bf r}_p</script><p>此时，投影向量仅由关系表示。</p><h3 id="TransR-CTransR"><a href="#TransR-CTransR" class="headerlink" title="TransR/CTransR"></a>TransR/CTransR</h3><p>相比TransR对每个关系直接定义一个映射矩阵，TransD通过为每个实体关系对设置一个投影向量，来为三元组动态的构造映射矩阵。</p><p>另外，TransD没有矩阵向量乘法操作，可以用向量运算代替：</p><p>假设$m \geq n$，投影向量能按以下方式计算：</p><script type="math/tex; mode=display">{\bf h_{\perp} }={\bf M}_{rh} {\bf h} = {\bf h}_p^T {\bf h} {\bf r}_p + [{\bf h}^T, {\bf 0}^T]^T</script><script type="math/tex; mode=display">{\bf t_{\perp} }={\bf M}_{rt} {\bf t} = {\bf t}_p^T {\bf t} {\bf r}_p + [{\bf t}^T, {\bf 0}^T]^T</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TransD&quot;&gt;&lt;a href=&quot;#TransD&quot; class=&quot;headerlink&quot; title=&quot;TransD&quot;&gt;&lt;/a&gt;TransD&lt;/h1&gt;&lt;p&gt;论文地址: &lt;a href=&quot;http://www.aclweb.org/anthology/P15-106
      
    
    </summary>
    
      <category term="知识图谱" scheme="http://yoururl.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="Knowledge graph" scheme="http://yoururl.com/tags/Knowledge-graph/"/>
    
  </entry>
  
  <entry>
    <title>复杂网络：网络测度之中心性</title>
    <link href="http://yoururl.com/2019/01/20/%E7%BD%91%E7%BB%9C%E6%B5%8B%E5%BA%A6%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%BA%A6%E4%B8%8E%E4%B8%AD%E5%BF%83%E6%80%A7/"/>
    <id>http://yoururl.com/2019/01/20/网络测度（一）：度与中心性/</id>
    <published>2019-01-19T16:01:00.000Z</published>
    <updated>2019-01-26T15:28:24.221Z</updated>
    
    <content type="html"><![CDATA[<h2 id="度"><a href="#度" class="headerlink" title="度"></a>度</h2><ul><li><p>定义：<strong>与结点直接相连的边数目</strong></p></li><li><p>对于无向图：</p><ul><li><p>结点 $i$ 的度 可用邻接矩阵表示为  $k<em>i=\sum</em>{j=1}^n A_{ij}$  ;</p></li><li><p>无向图中，若边数量为 $m$ , 则边端点为 $2m$ , <strong>边的端点数与所有顶点度总和相等</strong> ， $2m=\sum_{i=1}^n k_i$  或</p><script type="math/tex; mode=display">m = \frac{1}{2} \sum_{i=1}^n k_i = \frac{1}{2} \sum_{ij} A_{ij}</script></li><li><p>顶点度均值 $c = \frac{1}{n} \sum_{i=1}^n k_i$ ;</p><script type="math/tex; mode=display">c=\frac{2m}{n}</script><blockquote><p>$cn=2m$ : 顶点度总和 == 无向边端点数</p></blockquote></li></ul></li><li><blockquote><p>简单图（无重边和自边）中，可能最大边数为 $\frac{1}{2}n(n-1)$ 个。</p><p><strong>连通度</strong>或<strong>密度</strong> $\rho$ : 图中实际出现的边数与边最大值的比值</p><script type="math/tex; mode=display">\rho = \frac{实际边数}{边最大值} = \frac{m}{\frac{n(n-1)}{2} } = \frac{c}{n-1}</script><p><em>网络规模足够大， 连通度可近似表示   $\rho=c\n$ </em> </p></blockquote></li></ul><ul><li><blockquote><p>根据 $\rho$  定义的网络疏密：</p><p>当 $n \rightarrow \infty $ 时：</p><ul><li><p>$\rho$ 趋于常数， 即度均值 $c\rightarrow \infty$ ，网络为密集的；</p><p>此类网络当网络规模扩大时，邻接矩阵中非零元的比例会保持常数；</p></li><li><p>$\rho \rightarrow 0$， 网络为稀疏的；</p><p>此类网络当网络规模扩大时，邻接矩阵中非零元的比例趋于零； </p></li></ul></blockquote></li><li><blockquote><p><strong>正则图</strong>： 所有结点的度相同；</p><p>$k-正则图$： 所有结点的度为$k$;</p></blockquote></li><li><p>对于有向图：</p><ul><li><p>每个结点有两个度:       考虑从结点$j$到$i$有一条边：</p><ul><li>入度：连接到该结点的入边数；   $k<em>i^{in}=\sum</em>{j=1}^n A_{ij}$ </li><li>出度：连接到该结点的出边数；   $k<em>j^{out}=\sum</em>{i=1}^n A_{ij}$ </li></ul></li><li><p>有向图中，边数目 $m$ 等于<strong>入边端点数总和</strong>，也等于<strong>出边端点数总和</strong>，有</p><script type="math/tex; mode=display">m = \sum_{i=1}^n k_i^{in} = \sum_{j=1}^n k_{j}^{out} = \sum_{ij} A_{ij}</script></li><li><p>有向图的入度均值 $c<em>{in}$ 等于出度均值 $c</em>{out}$ ,即</p><script type="math/tex; mode=display">c_{in} = \frac{1}{n}\sum_{i=1}^n k_i^{in} = \frac{1}{n}\sum_{j=1}^n k_j^{out} = c_{out}</script><script type="math/tex; mode=display">c=c_{in}=c_{out}=\frac{m}{n}</script></li></ul></li></ul><h2 id="中心性"><a href="#中心性" class="headerlink" title="中心性"></a>中心性</h2><p>中心性(Centrality)是社交网络分析中用以表达社交网络中结点在整个网络中所在中心的程度。</p><h3 id="度中心性"><a href="#度中心性" class="headerlink" title="度中心性"></a>度中心性</h3><ul><li>定义： 刻画结点中心性的连接中心度， 一个结点与其他点直接链接的总和（度$d$）；</li><li>无向图的结点$v_i$中心性 $C_d$ ： $C_d(v_i) = d_i$ ;                            </li><li>有向图的结点度中心性：<ul><li>入度： 刻画结点受欢迎程度，表示结点的突出性(prominence)或声望(prestige),   $C_d(v_i) = d_i^{in} （声望）$</li><li>出度：表示结点的合群性(gregariousness), $C_d(v_i) = d_i^{out} （合群性）$</li><li>结合入度出度： $C_d(v_i)=d_i^{in} + d_i^{out}$ ;</li></ul></li></ul><blockquote><p>度中心性度量方法不能用于比较不同网络中的中心性值，需要归一化；</p></blockquote><h3 id="度中心性的归一化"><a href="#度中心性的归一化" class="headerlink" title="度中心性的归一化"></a>度中心性的归一化</h3><ul><li>使用最大可能度数：<script type="math/tex; mode=display">C_d^{norm}(v_i)=\frac{度中心度}{最大可能度数}=\frac{d_i}{n-1}</script></li></ul><ul><li>使用最大度数：<script type="math/tex; mode=display">C_d^{max}(v_i) = \frac{度中心度}{最大度数} = \frac{d_i}{\max_jd_j}</script></li></ul><ul><li>使用度数和：<script type="math/tex; mode=display">C_d^{sum}(v_i)=\frac{度中心度}{度数和}=\frac{d_i}{\sum_jd_j} = \frac{d_i}{2m}</script></li></ul><h3 id="特征向量中心性"><a href="#特征向量中心性" class="headerlink" title="特征向量中心性"></a>特征向量中心性</h3><p>在度中心性度量中，认为具有较多连接的结点更为重要。但在社交网络中，拥有更多的邻居结点并不能确保该结点就是重要的，拥有更多重要的邻居结点才能提供更有力的信息。因为很多情况下，一个结点会由于连接到一些很重要的结点从而使得自身的重要性得到提升。</p><p>特征向量中心性通过结合<strong>无向图的邻居节点</strong>（或<strong>有向图的输入邻居结点</strong>）的重要性来概括度中心性。</p><p>对于每个结点$i$,令其的中心性为$x_i$。 计算$i$的所有邻居结点的中心性之和： </p><script type="math/tex; mode=display">x_i' = \sum_i A_{ij} x_j   \\     \Longrightarrow   \\  \bf x' = Ax    (矩阵形式)</script><p>重复估算过程，得到中心性计算公式：</p><script type="math/tex; mode=display">\bf x(t) = A^tx(0)</script><blockquote><p>$\bf x(0)$  为邻接矩阵特征向量$\bf v_i$的线性组合， 即  $\bf x(0) = \sum_i c_i v_i$ ;</p><p>根据特征值的定义： $Av_i = \lambda v_i$ </p></blockquote><p>最终得：</p><script type="math/tex; mode=display">\bf x{(t)} = A^t\sum_i c_i v_i = \sum_i c_i\lambda_i^tv_i = \lambda_1^t \sum_i c_i[\frac{\lambda_i}{\lambda_1}]^t v_i</script><p>其中， $\lambda_i$ 为 $\bf A$ 的 特征值， $\lambda_1$ 为其中最大的特征值。</p><blockquote><p>当 $i\neq 1$ 时，对于所有 $i$ ，$\frac{\lambda_i}{\lambda_1}&lt;1$ 。当 $t$ 增大时， 除第一项外其他项都呈指数级下降，当$t \rightarrow \infty$ 时， $\bf x(t) \rightarrow c_1\lambda_1^t v_t$  。<strong>中心性向量的极限与邻接矩阵中的主特征向量成正比</strong>， 因此可等价认为中心性$\bf x$满足: $\bf Ax=\lambda_1 x$</p></blockquote><p>由此可得出，<strong>结点$i$的中心性与该结点邻居节点的中心性之和成正比</strong> ： </p><script type="math/tex; mode=display">x_i = \frac{1}{\lambda_i} \sum_j A_{ij} x_j</script><blockquote><p>该公式赋予特征向量中心性的性质：使得它的值会随两方面因素变大：</p><ul><li>该结点具有多个邻居结点；</li><li>该结点的邻居节点中有重要的结点；</li></ul></blockquote><h4 id="Perron-Frobenius-Theorem"><a href="#Perron-Frobenius-Theorem" class="headerlink" title="Perron-Frobenius Theorem:"></a>Perron-Frobenius Theorem:</h4><p>假设$A\in \Bbb R^{n \times n}$ 时[强]连通图的邻接矩阵，或者 $A:A<em>{i,j} &gt;0$ （即一个正的$n\times n$的矩阵）。 存在一个正实数（Perron-Frobenius特征值）$\lambda</em>{max}$，满足$\lambda<em>{max}$ 是矩阵$\bf A$的特征值，并且$\bf A $的其余特征值均严格小于$\lambda</em>{max}$。 $\lambda_{max}$ 所对应的特征向量为$v=(v_1,v_2,v_3,…,v_n)$，满足$\forall v_i&gt;0$ 。</p><p>根据该定理，我们可以<strong>通过求解矩阵$A$ 的特征值得到正的中心性值，选取其中最大的特征值 $\lambda_{max}$ ,其对应特征向量为 $x_i$，该特征向量的所有部分均为正值，并且其分量对应于各结点的特征向量中心性，其中特征向量中最大分量对应的结点考虑为最中心的结点</strong></p><blockquote><p>寻找最中心结点：</p><ul><li>计算邻接矩阵的特征值；</li><li>选择最大的特征值，计算对应的特征向量；</li><li>特征向量最大分量对应的结点有最大的特征向量中心性，考虑为最中心的结点。</li></ul></blockquote><p>理论上讲，特征向量中心性对于有向和无向网络都适用，但在有向网络中存在一些问题。</p><ul><li><p>有向网络对应的邻接矩阵通常非对称，意味着有两类特征向量，即左特征向量和右特征向量。左特征向量对应该结点指向的结点（出），右特征向量对应指向该结点的结点（入）。中心性主要由指向该结点的结点赋予，因此选择<strong>右特征向量</strong>。</p><p>在有向网络中结点$i$的特征中心性的正确定义为：<strong>结点的特征向量中心性与指向该结点的所有结点的中心性之和成正比。</strong></p></li><li><p>如果有向网络中结点$B$的所有入边都来源于特征向量中心性为0的邻居结点，则结点$B$的特征向量中心性也为0。</p></li></ul><h3 id="Katz中心性"><a href="#Katz中心性" class="headerlink" title="Katz中心性"></a>Katz中心性</h3><p>Katz中心性是特征向量中心性的变体，解决上述有向网络中零特征向量中心性传递带来的问题。</p><ul><li><p>定义：为网络中的每个结点赋予少量的中心性，不考虑该结点在网络中的具体位置或者其邻居节点的中心性。</p><script type="math/tex; mode=display">x_i = \alpha \sum_i A_{ij} x_j + \beta</script><p>偏差项$\beta$ 用来解决中心性值为0 的问题；</p><p>矩阵表示上述公式，$\beta$ 作为整体因子其取值并不重要，通常设定为1：</p><script type="math/tex; mode=display">\bf x=\alpha Ax+\beta 1  \\ \Longrightarrow  \beta=1 \Longrightarrow \\x=(I-\alpha A)^{-1} 1</script></li><li><p>自由参数$\alpha$ 负责调节特征向量与常数项之间的平衡。</p><ul><li><p>当$\alpha=0$ 时， 式（14）只剩下常数项，所有结点赋予相同的中心性$\beta$;</p></li><li><p>当$\alpha$ 变大时，中心性不断提高，$\beta$ 的影响将减小，最终达到一个点，在该点中心性发散。该情况出现在$\bf det(A-\alpha^{-1}I)=0$ 的那一点；</p><blockquote><p>该公式为特征方程，当$\alpha =\lambda_{max}^{-1}$时，行列式第一次经过零点；因此应选择一个小于该值的$\alpha$ 值，保证中心性收敛。</p><p>很多研究中，将$\alpha$ 设为稍小于最大值$\lambda_{max}^{-1}$的值，这样可以使公式中特征向量项权值最大，而使常数项权值最小。</p></blockquote></li></ul></li></ul><h4 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h4><p>对于增加的常数项，根据结点的不同赋予不同的值，可以定义一种更加通用的中心性：</p><script type="math/tex; mode=display">x_i = \alpha \sum_j A_{ij} x_j + \beta_i</script><p>其中$\beta_i$是每一个结点与网络无关的固有中心性。因此中心性向量$\bf x$可描述为</p><script type="math/tex; mode=display">\bf x=(I-\alpha A)^{-1} \beta</script><h3 id="PageRank"><a href="#PageRank" class="headerlink" title="PageRank"></a>PageRank</h3><p>Katz中心性的不足之处在于，Katz中心性较高的结点会向它指向的结点传递其高中心性，这是不可取的，因为该高中心性结点指向的结点数量可能很大，但并不是每一个被指向的结点都具有很高的中心性。因此，<strong>被有重要影响的结点指向的结点，其从重要节点获得的中心性会因为与其他结点共享而被稀释。</strong></p><ul><li>定义：从网络邻居结点获得的中心性与邻居结点的中心性除以它们的出度成正比。</li></ul><script type="math/tex; mode=display">x_i = \alpha \sum_i A_{ij} \frac{x_j}{k_j^{out} } + \beta</script><blockquote><p>对于网络中出度$k<em>j^{out}=0$的结点 ，会产生0/0的结果（因为对于所有$i$，$A</em>{ij}=0$）。</p><p>解决此问题： 没有出度的结点对其他结点的中心性贡献为0，因此将这些结点的出度设定为1；实际可将$k_j^{out}$ 设定为任何一个非零值。</p></blockquote><p>​    表示为矩阵形式，同样将$\beta$设定为1</p><script type="math/tex; mode=display">\bf x=\alpha AD^{-1}x+\beta1    \\  \Longrightarrow \beta=1 \Longrightarrow \\  x=(I-\alpha AD^{-1})^{-1} 1=D(D-\alpha A)^{-1} 1</script><p>​    其中， $\bf D$ 为对角矩阵，其元素为 $D_{ii}=\max(k_i^{out},1)$</p><blockquote><p>与katz中心性类似，$\alpha$ 的值应小于$AD^{-1}$的最大特征值的倒数，即$\frac{1}{\lambda_{max} }$ ;</p><p>对于无向网络，其最大特征值为1，因此 $\alpha$ 应选择小于1的值；</p><p>对于有向网络，通常主特征值实际取值近似1；</p></blockquote><h4 id="拓展-1"><a href="#拓展-1" class="headerlink" title="拓展"></a>拓展</h4><p>PageRank推广，使得常数项$\beta$ 对不同顶点取不同的值：</p><script type="math/tex; mode=display">x_i = \alpha \sum_i A_{ij} \frac{x_j}{k_j^{out} } + \beta_i</script><p>矩阵形式为：</p><script type="math/tex; mode=display">\bf x=D(D-\alpha A)^{-1} \beta</script><blockquote><p>利用该公式对网页进行排序时，其中$\beta_i$的值可以基于网页与查询条件的文本相似性给出。</p><h4 id="四种中心性测度"><a href="#四种中心性测度" class="headerlink" title="四种中心性测度"></a>四种中心性测度</h4><div class="table-container"><table><thead><tr><th></th><th>带常数项</th><th>不带常数项</th></tr></thead><tbody><tr><td>除以出度</td><td>$\bf x=D(D-\alpha A)^{-1}1$       RageRank</td><td>$\bf x = AD^{-1}x$     度中心性</td></tr><tr><td>不做任何除法</td><td>$\bf x=(I-\alpha A)^{-1} 1$             Katz中心性</td><td>$\bf x=\lambda_1^{-1}Ax$      特征向量中心性</td></tr></tbody></table></div></blockquote><h3 id="针对引文网络的中心性"><a href="#针对引文网络的中心性" class="headerlink" title="针对引文网络的中心性"></a>针对引文网络的中心性</h3><h4 id="核心结点与权威结点"><a href="#核心结点与权威结点" class="headerlink" title="核心结点与权威结点"></a>核心结点与权威结点</h4><ul><li>权威结点（authority）: 包含所关注主题有用的信息的结点；</li><li>核心结点（hub)：指向权威结点的结点，说明到哪能找到最合适的权威结点；</li></ul><p>核心结点与权威结点只存在于有向网络中，在有向网络中可以定义两种中心性，</p><ul><li><p>权威中心性</p><p>与指向该结点的核心中心性之和成正比；</p><script type="math/tex; mode=display">x_i=\alpha \sum_j A_{ij}y_j</script></li><li><p>核心中心性</p><p>与该结点指向的结点的权威中心性之和成正比；</p><script type="math/tex; mode=display">y_i =\beta \sum_j A_{ji}x_j</script><p>矩阵表示：</p><script type="math/tex; mode=display">\bf x=\alpha Ay  ,    y=\beta A^Tx    \\ \LongrightarrowAA^Tx=\lambda x,   A^TAy=\lambda y</script><p>其中，$\lambda=(\alpha \beta)^{-1}$</p><blockquote><p>权威中心性与核心中心性分别由具有相同特征值的矩阵$AA^T$和$A^TA$对应的特征向量决定。</p><p>因此矩阵$AA^T$和$A^TA$ 有相同的主特征值$\lambda$ ：</p><p>若 $\bf AA^Tx=\lambda x$ , 公式两边都乘以 $A^T$ , 可以得到 $\bf A^TA(A^Tx)=\lambda(A^Tx)$。因此$A^Tx$ 也是矩阵$A^TA$ 的特征值为$\lambda$ 的特征向量， 即$\bf y=A^Tx$ 。 </p><ul><li>$AA^T$ 是共引矩阵，权威中心性可以粗略的认为是共引网络的特征向量中心性；</li><li>$A^TA$ 是文献耦合矩阵，核心中心性就是文献耦合网络的特征向量中心性；</li></ul></blockquote></li></ul><h3 id="接近度中心性"><a href="#接近度中心性" class="headerlink" title="接近度中心性"></a>接近度中心性</h3><p>接近中心性不同于其他中心性测度，度量了一个结点到其他结点的平均距离。接近中心性的思想是结点越趋于中心，越能快速到达其他结点。形象化的描述为，这些结点满足与其他结点之间有最小平均最短路径。</p><ul><li>定义：平均测地距离的倒数<script type="math/tex; mode=display">C_i=\frac{1}{\ell_i}    \\\ell_i = \frac{1}{n}\sum_j d_{ij}    \\  or \\\ell_i = \frac{1}{n-1} \sum_{j(\neq i)} d_{ij}</script></li></ul><blockquote><ul><li><p>问题1：接近中心性最大最小值之间的动态变化范围很小。大部分网络中，顶点之间的测地距离$d_{ij}$ 一般很小，随网络规模增长呈对数级速度增长。而且最短测地距离与最长测地距离确定了平均距离$\ell_i$的上下限，因此$\ell_i$和$C_i$的取值范围都较小。结点接近中心性的密集意味着网络结构的微小变化就会引起接近度中心性值排序的显著变化。</p></li><li><p>问题2：若将不同分支中的结点间的测地距离定义为无穷大，那么假设任何一个多于一个分支的网络中所有结点$i$的$\ell_i$ 都为无穷大，则$C_i$ 为零。</p></li><li>解决方法之一是<strong>只计算在同一分支内部的结点的平均测地距离</strong>，但仍然存在固有缺陷：小规模分支内部结点间的距离普遍偏小，与大规模分支中的结点相比，其$\ell_i$较小，$C_i$更大。产生不理想的结果：<strong>大多数情况下，小规模分支中结点之间的连通程度比大规模分支中要低，因此应赋予较低的中心性</strong>。</li></ul></blockquote><p>重定义接近中心性，使用结点之间的<strong>调和平均测地距离</strong>：</p><script type="math/tex; mode=display">C_i'= \frac{1}{n-1}\sum_{j(\neq i)} \frac{1}{d_{ij} }</script><ul><li><p>网络平均测地距离：</p><ul><li>对于只有一个分支的网络，所有结点对之间的平均距离为</li></ul><script type="math/tex; mode=display">\ell = \frac{1}{n^2}\sum_{ij}d_{ij} = \frac{1}{n}\sum_i \ell_i</script><p>​    即所有结点的平均测地距离$\ell_i$的平均值。</p><ul><li><p>对于多分支网络，<em>只计算同一分支内部结点之间路径的平均长度</em>。令${ {\scr C}_m }$表示网络中分支的集合，定义：</p><script type="math/tex; mode=display">\ell = \frac{\sum_m \sum_{ij\in {\scr C}_m} d_{ij} }{\sum_m n_m^2}</script><p>其中，$n_m$为分支$\scr C_m$中的结点数。</p><p>另一中定义方式为定义一个调和平均距离$\ell ’$ ：</p><script type="math/tex; mode=display">\frac{1}{\ell '} = \frac{1}{n(n-1)} \sum_{i \neq j} \frac{1}{d_{ij} }=\frac{1}{n}\sum_i C_i'    \\  \Longleftrightarrow \\\ell ' = \frac{n}{\sum_i C_i'}</script></li></ul></li></ul><h3 id="介数中心性"><a href="#介数中心性" class="headerlink" title="介数中心性"></a>介数中心性</h3><p>考虑结点在连接其他结点时表现的”中介“次数，即其他结点间通过结点$v_i$的最短路径的数目。</p><p><strong>介数中心性衡量某个结点对其他结点对之间信息流动的影响力。</strong> </p><ul><li><p>定义：</p><script type="math/tex; mode=display">C_b(v_i) = \sum_{s \neq t \neq v_i} \frac{s到t经过v_i的最短路径数目}{s到t的最短路径数目} =\sum_{s \neq t \neq v_i} \frac{\sigma_{st}(v_i)}{\sigma_{st} }</script></li><li><p>归一化：</p><ul><li><p>最大值：当结点$v<em>i$出现在连接任意结点对$(s,t)$的所有最短路径中时，该结点的中间中心性对应最大值1，即$\forall (s,t), s \neq t \neq v_i , \frac{\sigma</em>{st} (v<em>i)}{\sigma</em>{st} } = 1$。 因此，最大值为：</p><script type="math/tex; mode=display">C_b(v_i)=\sum_{s \neq t \neq v_i} \frac{\sigma_{st}(v_i)}{\sigma_{st} }=\sum_{s \neq t \neq v_i} 1 = 2 \begin{pmatrix}n-1 \\2\\\end{pmatrix} = (n-1)(n-2)</script></li><li></li></ul><script type="math/tex; mode=display">C_b^{norm}(v_i) = \frac{C_b(v_i)}{2\begin{pmatrix}n-1 \\2\\\end{pmatrix} }</script></li></ul><h4 id="另一种表述"><a href="#另一种表述" class="headerlink" title="另一种表述"></a>另一种表述</h4><p>表示一般性网络的介数，定义$n<em>{st}^i$为从$s$到$t$经过$i$的测地路径数量，定义$g</em>{st}$为从$s$到$t$的测地路径总数。那么结点$i$的介数中心性可以表示为</p><script type="math/tex; mode=display">x_i = \sum_{st} \frac{n_{st}^i}{g_{st} }</script><p>介数中心性主要是度量一个结点“介于”其他结点的程度。</p><blockquote><p>一个结点的度可以很低，与其相连的结点的度也很低，与其他结点之间的平均距离很长，但仍有较高的介数。</p><p><a href="https://imgchr.com/i/kulBSH" target="_blank" rel="noopener"><img src="images/kulBSH.png" alt="kulBSH.png"></a></p><p>如图，结点A是网络中两个结点群组之间的桥梁，由于两个群组结点之间的任何最短路径都必须经过结点A，因此A获得了很高的介数。结点A对于其他结点间信息流动起到控制作用，此类结点在社会学文献中称为”<strong>中间人</strong>“。</p></blockquote><ul><li><p>归一化：（考虑自环）</p><ul><li>基于结点对：<script type="math/tex; mode=display">x_i= \frac{1}{n^2}\sum_{st} \frac{n_{st}^i}{g_{st} }</script></li></ul></li></ul><ul><li>基于介数最大可能值：<script type="math/tex; mode=display">x_i = \frac{1}{n^2-n+1} \sum_{st}\frac{n_{st}^i}{g_{st} }</script></li></ul><h3 id="群体中心性"><a href="#群体中心性" class="headerlink" title="群体中心性"></a>群体中心性</h3><p>考虑如何将度中心性、接近中心性以及中间中心性应用到一组结点上。</p><p>假设$S$表示需要求解群体中心性的结点集，$V-S$表示上述集合之外的结点集。</p><h4 id="群体度中心性"><a href="#群体度中心性" class="headerlink" title="群体度中心性"></a>群体度中心性</h4><p>群体度中心性是群体外部结点连接到群体内部结点的数目。形式化的定义为：</p><script type="math/tex; mode=display">C_d^{group}(S)=|\{v_i \in V-S| v_i连接到v_j \in S\}|</script><p>与度中心性相似，可以利用有向图中的入度或出度。同时该值可以进行归一化。</p><p>最理想的情况为，群体中的结点均连接到群体外的所有结点上，此时$C_d^{group}(S)$的最大值为$V-S$。使用群体度中心性除以$|V-S|$进行归一化处理。</p><h4 id="群体介数中心性"><a href="#群体介数中心性" class="headerlink" title="群体介数中心性"></a>群体介数中心性</h4><p>群体介数中心性被定义为：</p><script type="math/tex; mode=display">C_b^{group}(S) = \sum_{s\neq t, s\notin S, t \notin S}  \frac{\sigma_{st}(S)}{\sigma_{st} }</script><p>其中，$\sigma_{st}(S)$ 表示从$s$到$t$经过集合$S$中元素的最短路径的数目。</p><p>最理想的情况下，从$s$到$t$的所有的最短路径均经过集合$S$中的元素，因此，$C_b^{group}(S)$的最大值为${2\begin{pmatrix}  |V-S| \ 2\  \end{pmatrix} }$。</p><p>和介数中心性相似，使用介数中心性除以最大值进行归一化处理。</p><h4 id="群体接近中心性"><a href="#群体接近中心性" class="headerlink" title="群体接近中心性"></a>群体接近中心性</h4><p>群体接近中心性被定义为：</p><script type="math/tex; mode=display">C_c^{group}(S)=\frac{1}{\bar l_S^{group} }</script><p>其中，$\bar l <em>S^{group} = \frac{1}{|V-S|}\sum</em>{v<em>j \notin S} l</em>{S,v<em>j}$，$l</em>{S,v_j}$是群体$S$与群体之外的元素$v_j \in V-S$的最短路径的长度。该长度可以以多种方式定义，一种方法是寻找$S$中距离$v_j$最近的成员元素：</p><script type="math/tex; mode=display">l_{S,v_j} = \min_{v_i \in S}l_{v_i,v_j}</script><p>另一种是使用最大距离或者平均距离。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;度&quot;&gt;&lt;a href=&quot;#度&quot; class=&quot;headerlink&quot; title=&quot;度&quot;&gt;&lt;/a&gt;度&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;定义：&lt;strong&gt;与结点直接相连的边数目&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;对于无向图：&lt;/p&gt;
&lt;ul&gt;

      
    
    </summary>
    
      <category term="复杂网络" scheme="http://yoururl.com/categories/%E5%A4%8D%E6%9D%82%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Networks" scheme="http://yoururl.com/tags/Networks/"/>
    
  </entry>
  
  <entry>
    <title>R安装与关联jupyter</title>
    <link href="http://yoururl.com/2018/12/14/R%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E5%88%B0jupyter/"/>
    <id>http://yoururl.com/2018/12/14/R安装配置到jupyter/</id>
    <published>2018-12-13T16:01:00.000Z</published>
    <updated>2019-01-26T14:57:23.797Z</updated>
    
    <content type="html"><![CDATA[<h2 id="R安装并配置到jupyter"><a href="#R安装并配置到jupyter" class="headerlink" title="R安装并配置到jupyter"></a>R安装并配置到jupyter</h2><ul><li><p>安装R</p><p>版本：<a href="https://mran.revolutionanalytics.com/download" target="_blank" rel="noopener">Microsoft R Open 3.5.1</a></p></li><li><p>cmd进入R会话</p></li></ul><ul><li><p>输入如下配置命令;</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">install.packages(<span class="string">"devtools"</span>)</span><br><span class="line">devtools::install_github(<span class="string">"IRkernel/IRkernel"</span>)</span><br><span class="line">IRkernel::installspec()</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;R安装并配置到jupyter&quot;&gt;&lt;a href=&quot;#R安装并配置到jupyter&quot; class=&quot;headerlink&quot; title=&quot;R安装并配置到jupyter&quot;&gt;&lt;/a&gt;R安装并配置到jupyter&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;安装R&lt;/p&gt;
&lt;p&gt;版本
      
    
    </summary>
    
      <category term="安装与配置" scheme="http://yoururl.com/categories/%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/"/>
    
    
      <category term="Install &amp; config" scheme="http://yoururl.com/tags/Install-config/"/>
    
  </entry>
  
  <entry>
    <title>jupyterLab安装与配置</title>
    <link href="http://yoururl.com/2018/12/01/%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AEjupyterLab/"/>
    <id>http://yoururl.com/2018/12/01/安装与配置jupyterLab/</id>
    <published>2018-11-30T16:01:00.000Z</published>
    <updated>2019-01-26T14:41:16.205Z</updated>
    
    <content type="html"><![CDATA[<h2 id="安装与更新-jupyterLab"><a href="#安装与更新-jupyterLab" class="headerlink" title="安装与更新 jupyterLab"></a>安装与更新 jupyterLab</h2><ul><li>安装jupyterLab</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install -c conda-forge jupyterlab</span><br></pre></td></tr></table></figure><ul><li>更新jupyterlab</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U jupyterlab</span><br></pre></td></tr></table></figure><h2 id="安装nodejs"><a href="#安装nodejs" class="headerlink" title="安装nodejs"></a>安装nodejs</h2><ul><li>安装nodejs</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install -c conda-forge nodejs</span><br></pre></td></tr></table></figure><ul><li>安装扩展</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension install my-extension</span><br></pre></td></tr></table></figure><ul><li>列出扩展</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension list</span><br></pre></td></tr></table></figure><ul><li>卸载扩展</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension uninstall my-extension</span><br></pre></td></tr></table></figure><ul><li>启用扩展</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension enable my-extension</span><br></pre></td></tr></table></figure><ul><li>禁用扩展</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension disable my-extension</span><br></pre></td></tr></table></figure><h2 id="插件"><a href="#插件" class="headerlink" title="插件"></a>插件</h2><ul><li>目录</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension install @jupyterlab/toc</span><br></pre></td></tr></table></figure><ul><li>tensorboard</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension install jupyterlab_tensorboard</span><br></pre></td></tr></table></figure><ul><li>html</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension install @mflevine/jupyterlab_html</span><br></pre></td></tr></table></figure><ul><li>latex</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension install @jupyterlab/latex</span><br></pre></td></tr></table></figure><ul><li>go-to-definition</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension install @krassowski/jupyterlab_go_to_definition</span><br></pre></td></tr></table></figure><ul><li>voyager</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension install jupyterlab_voyager</span><br></pre></td></tr></table></figure><ul><li>statusbar</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension install @jupyterlab/statusbar</span><br></pre></td></tr></table></figure><ul><li>celltags</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension install @jupyterlab/celltags</span><br></pre></td></tr></table></figure><ul><li>drawio</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension install jupyterlab-drawio</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;安装与更新-jupyterLab&quot;&gt;&lt;a href=&quot;#安装与更新-jupyterLab&quot; class=&quot;headerlink&quot; title=&quot;安装与更新 jupyterLab&quot;&gt;&lt;/a&gt;安装与更新 jupyterLab&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;安装jupyte
      
    
    </summary>
    
      <category term="安装与配置" scheme="http://yoururl.com/categories/%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/"/>
    
    
      <category term="Install &amp; config" scheme="http://yoururl.com/tags/Install-config/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow环境 人脸识别 FaceNet 应用（一）:FaceNet安装与验证测试集</title>
    <link href="http://yoururl.com/2018/07/15/windows%E4%B8%8Bpython3.5%E5%AE%89%E8%A3%85facenet/"/>
    <id>http://yoururl.com/2018/07/15/windows下python3.5安装facenet/</id>
    <published>2018-07-15T02:15:33.025Z</published>
    <updated>2018-03-20T08:07:06.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>作者：Andy_z<br>文献：<a href="https://arxiv.org/abs/1503.03832" target="_blank" rel="noopener">FaceNet: A Unified Embedding for Face Recognition and Clustering</a><br><a href="https://pan.baidu.com/s/1R70SWpSmF7SoZB5vkHdfpw" target="_blank" rel="noopener">数据集及模型下载通道</a>：(密码：3wty)</p></blockquote><h2 id="一、前提条件"><a href="#一、前提条件" class="headerlink" title="一、前提条件"></a>一、前提条件</h2><h3 id="1-emsp-已安装Tensorflow"><a href="#1-emsp-已安装Tensorflow" class="headerlink" title="1.&emsp;已安装Tensorflow"></a>1.&emsp;已安装Tensorflow</h3><h3 id="2-emsp-已在安装下列包-二选一"><a href="#2-emsp-已在安装下列包-二选一" class="headerlink" title="2.&emsp;已在安装下列包(二选一):"></a>2.&emsp;已在安装下列包(二选一):</h3><p>&emsp;&emsp;a.&emsp;python下安装scipy, scikit-learn, opencv-python, h5py, matplotlib, Pillow, requests, psutil</p><p>&emsp;&emsp;b.&emsp;安装Anaconda集成环境</p><h3 id="3-emsp-已更新Sklearn至最新版本-二选一"><a href="#3-emsp-已更新Sklearn至最新版本-二选一" class="headerlink" title="3.&emsp;已更新Sklearn至最新版本(二选一):"></a>3.&emsp;已更新Sklearn至最新版本(二选一):</h3><p>&emsp;&emsp;a.&emsp;可在propmt下”conda update conda “</p><p>&emsp;&emsp;b.&emsp;直接在cmd命令行下”pip install -U scikit-learn”</p><h3 id="4-emsp-已安装git"><a href="#4-emsp-已安装git" class="headerlink" title="4.&emsp;已安装git"></a>4.&emsp;已安装git</h3><blockquote><p>备注:如果没有完成以上的第3点,之后执行align时,可能会出现”no module named facenet”,”no module named align”,”no module named scikit-learn”等情况</p></blockquote><h2 id="二、安装和配置FaceNet"><a href="#二、安装和配置FaceNet" class="headerlink" title="二、安装和配置FaceNet"></a>二、安装和配置FaceNet</h2><p>&emsp;&emsp;1.&emsp;在cmd命令行，定位到自己想下载的文件夹,用git下载FaceNet源代码工程:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone --recursive https://github.com/davidsandberg/facenet.git</span><br></pre></td></tr></table></figure><blockquote><p>建议：最好定位在&emsp;&emsp;Anaconda3\Lib\site-packages&emsp;&emsp;下安装。因为FaceNet也相当于一个python库。</p></blockquote><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-15/23373226.jpg" alt=""></p><p>&emsp;&emsp;2.&emsp;下载数据集LFW。LFW数据集是由美国马萨诸塞大学阿姆斯特分校计算机视觉实验室整理的。下载地址：<a href="http://vis-www.cs.umass.edu/lfw/lfw.tgz" target="_blank" rel="noopener">http://vis-www.cs.umass.edu/lfw/lfw.tgz</a>, 下载完成后，把数据解压到目录 ..facenet\data\lfw\raw  下面,新建一个空文件夹命名为”lfw_160”。可以看到数据集中每张图像的分辩率是250*250。</p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-15/8023931.jpg" alt=""></p><p>&emsp;&emsp;3.&emsp;设置环境变量,以下方法二选一:</p><p>&emsp;&emsp;a.&emsp;在cmd命令行键入：set PYTHONPATH=…\facenet\src, 例如笔者的是:set PYTHONPATH=D:\Anaconda2\envs\py3.6\Lib\site-packages\facenet\src</p><p>&emsp;&emsp;b.&emsp;在 计算机—&gt;属性—&gt;高级系统设置—&gt;环境变量中,新建PYTHONPATH,键入 D:\Anaconda2\envs\py3.6\Lib\site-packages\facenet\src</p><p>检验:在cmd命令行下面，键入set，查看设置情况</p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-15/66907272.jpg" alt=""></p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-15/56240084.jpg" alt=""></p><h2 id="三、图像数据预处理"><a href="#三、图像数据预处理" class="headerlink" title="三、图像数据预处理"></a>三、图像数据预处理</h2><blockquote><p>也可直接使用下载的已处理数据集</p></blockquote><p>&emsp;&emsp;我们需要将待检测所使用的数据集校准为和预训练模型所使用的数据集大小一致。</p><p>&emsp;&emsp;1.&emsp;使用&emsp;facenet\src\align\align_dataset_mtcnn.py&emsp;进行校准,校准后的图片存在&emsp;..facenet\data\lfw\lfw_160&emsp;下面。在cmd命令行 或者 对应语言版本的propmt下，定位到facenet所在位置，键入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python src\align\align_dataset_mtcnn.py data/lfw/raw data/lfw/lfw_160</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;官方Wiki说明</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python src/align/align_dataset_mtcnn.py ~/datasets/casia/CASIA-maxpy-clean/ ~/datasets/casia/casia_maxpy_mtcnnpy_182 --image_size 182 --margin 44</span><br></pre></td></tr></table></figure><blockquote><p>上述命令生成的脸部缩略图是182x182像素。</p></blockquote><p>&emsp;&emsp;2.&emsp;校准后发现图像大小变了</p><h2 id="四、评估谷歌预训练模型在数据集的准确率"><a href="#四、评估谷歌预训练模型在数据集的准确率" class="headerlink" title="四、评估谷歌预训练模型在数据集的准确率"></a>四、评估谷歌预训练模型在数据集的准确率</h2><p>&emsp;&emsp;1.&emsp;下载预训练的模型。把下载的文件解压到src\models\目录下面。</p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-15/34564036.jpg" alt=""></p><p>&emsp;&emsp;2.&emsp;程序下载好了,测试数据集LFW也有了,模型也有了,接下来就可以评估模型在数据集的准确率了。在cmd命令行或者propmt下定位到facenet文件夹下，输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python src\validate_on_lfw.py data\lfw\lfw_160 src\models\20170512-110547</span><br></pre></td></tr></table></figure><p>紧接着,预测中,结果如图：</p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-15/47530520.jpg" alt=""></p><h2 id="五、其他"><a href="#五、其他" class="headerlink" title="五、其他"></a>五、其他</h2><h3 id="5-1-对比"><a href="#5-1-对比" class="headerlink" title="5.1 对比"></a>5.1 对比</h3><p>&emsp;&emsp;facenet可以直接比对两个人脸经过它的网络映射之后的欧氏距离，运行程序为facenet-master\src\compare.py。<br>-1、在compare.py所在目录下放入要比对的文件1.jpg和2.jpg，打开cmd命令行窗口<br>-2、cd到compare.py所在路径<br>-3、输入 python compare.py models/20170512-110547 1.png 2.png</p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-16/42045957.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;作者：Andy_z&lt;br&gt;文献：&lt;a href=&quot;https://arxiv.org/abs/1503.03832&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;FaceNet: A Unified Embedding for F
      
    
    </summary>
    
      <category term="人脸识别" scheme="http://yoururl.com/categories/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/"/>
    
    
      <category term="Summary" scheme="http://yoururl.com/tags/Summary/"/>
    
      <category term="facenet" scheme="http://yoururl.com/tags/facenet/"/>
    
      <category term="face recognition" scheme="http://yoururl.com/tags/face-recognition/"/>
    
  </entry>
  
  <entry>
    <title>Jupyter notebook: How to create a slideshow</title>
    <link href="http://yoururl.com/2018/07/15/Jupyter%20notebook%EF%BC%9AHow%20to%20create%20a%20slideshow/"/>
    <id>http://yoururl.com/2018/07/15/Jupyter notebook：How to create a slideshow/</id>
    <published>2018-07-15T02:15:32.933Z</published>
    <updated>2018-04-25T17:54:21.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="利用Jupyter-notebook-制作PPT"><a href="#利用Jupyter-notebook-制作PPT" class="headerlink" title="利用Jupyter notebook 制作PPT"></a>利用Jupyter notebook 制作PPT</h1><p>使用 Jupyter notebook 作为 slide 主要优点：  </p><ul><li>运行 notebook 可以播放幻灯片  </li><li>导出 slides.html 格式的幻灯片，方便在浏览器打开播放</li></ul><h2 id="工具依赖"><a href="#工具依赖" class="headerlink" title="工具依赖"></a>工具依赖</h2><ul><li>RISE</li><li>reveal.js </li></ul><h3 id="RISE"><a href="#RISE" class="headerlink" title="RISE"></a>RISE</h3><p>RISE allows you to instantly turn your Jupyter Notebooks into a slideshow. No out-of-band conversion is needed, switch from jupyter notebook to a live reveal.js-based slideshow in a single keystroke, and back.</p><h4 id="Install-RISE"><a href="#Install-RISE" class="headerlink" title="Install RISE"></a>Install RISE</h4><h4 id="Option-1-Using-conda"><a href="#Option-1-Using-conda" class="headerlink" title="Option 1 - Using conda :"></a>Option 1 - Using conda :</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install -c damianavila82 rise</span><br></pre></td></tr></table></figure><h4 id="Option-2-Using-pip"><a href="#Option-2-Using-pip" class="headerlink" title="Option 2 - Using pip::"></a>Option 2 - Using pip::</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install RISE</span><br></pre></td></tr></table></figure><p>and then two more steps to install the JS and CSS in the proper places:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter-nbextension install rise --py --sys-prefix</span><br></pre></td></tr></table></figure><p>and enable the nbextension:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter-nbextension enable rise --py --sys-prefix</span><br></pre></td></tr></table></figure><h3 id="reveal-js"><a href="#reveal-js" class="headerlink" title="reveal.js"></a>reveal.js</h3><p>A framework for easily creating beautiful presentations using HTML. <a href="https://revealjs.com/#/" target="_blank" rel="noopener">Check out the live demo.</a></p><p>reveal.js comes with a broad range of features including nested slides, Markdown contents, PDF export, speaker notes and a JavaScript API. There’s also a fully featured visual editor and platform for sharing reveal.js presentations at slides.com.  </p><p>Reveal.js 是一个使用 HTML 语言制作演示文稿的 Web 框架，支持插入多种格式的内容，并以类似 PPT 的形式呈现。  </p><p>Reveal.js 具有许多优势：</p><ul><li>制作灵活、不限应用，只需修改 HTML 文件</li><li>发布灵活、不限平台，只需打开 HTML 文件</li><li>丰富的特性，支持过渡动画、代码高亮、视频背景、Markdown 语法、导出 PDF 等</li><li>极度轻量，占用空间和内存少</li></ul><p>配置流程：  </p><ul><li>在 notebook 文件目录（包含 .ipnb 文件）下， clone <a href="https://github.com/hakimel/reveal.js.git" target="_blank" rel="noopener">reveal.js</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/hakimel/reveal.js.git</span><br></pre></td></tr></table></figure><h2 id="slide-设置"><a href="#slide-设置" class="headerlink" title="slide 设置"></a>slide 设置</h2><p>这里有一个幻灯片<a href="http://www.slideviper.oquanta.info/tutorial/slideshow_tutorial_slides.html#/" target="_blank" rel="noopener">示例</a>供参考，其制作风格简洁明晰。</p><p>那么如何用 Jupyter Notebook 制作幻灯片呢？<br>首先在 notebook 的菜单栏选择 View &gt; Cell Toolbar &gt; Slideshow，这时在文档的每个单元右上角显示了 Slide Type 的选项。通过设置不同的类型，来控制幻灯片的格式。有如下5中类型：</p><ul><li>Slide：主页面，通过按左右方向键进行切换。</li><li>Sub-Slide：副页面，通过按上下方向键进行切换。</li><li>Fragment：一开始是隐藏的，按空格键或方向键后显示，实现动态效果。</li><li>Skip：在幻灯片中不显示的单元。</li><li>Notes：作为演讲者的备忘笔记，也不在幻灯片中显示。</li></ul><h2 id="生成幻灯片"><a href="#生成幻灯片" class="headerlink" title="生成幻灯片"></a>生成幻灯片</h2><p>在notebook中设置cell 的slide属性，确认后保存，例如 notebook.ipynb<br>使用nbconvert 来将notebook文件转换为HTML  </p><pre><code class="lang-python">jupyter nbconvert --to slides notebook.ipynb --reveal-prefix=reveal.js</code></pre><p>生成文件： notebook.slides.html , 直接用浏览器打开即可播放幻灯片</p><p>有时候不想要input cell显示在slide上面，这个时候可以使用下面的设置：  </p><pre><code class="lang-python">jupyter nbconvert RainStromNetworkAnalysis.ipynb --to slides --TemplateExporter.exclude_input=True</code></pre><p>同样的使用下面的命令虽然可以隐藏input cell但是不能生成slide只能生成html文件：  </p><pre><code class="lang-python">jupyter nbconvert --template=nbextensions --to=slides RainStromNetworkAnalysis.ipynb</code></pre><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>Reveal.js 支持 Markdown 语法，我们得以直接在 Markdown 编辑器里做 PPT。以上只是制作了最简单的 PPT，我们后续还可以添加各种动画效果、背景、图表等内容。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;利用Jupyter-notebook-制作PPT&quot;&gt;&lt;a href=&quot;#利用Jupyter-notebook-制作PPT&quot; class=&quot;headerlink&quot; title=&quot;利用Jupyter notebook 制作PPT&quot;&gt;&lt;/a&gt;利用Jupyter note
      
    
    </summary>
    
      <category term="Jupyter" scheme="http://yoururl.com/categories/Jupyter/"/>
    
    
      <category term="Jupyter" scheme="http://yoururl.com/tags/Jupyter/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow环境 人脸识别 FaceNet 应用（二）:FaceNet官方WiKi解读</title>
    <link href="http://yoururl.com/2018/07/15/FaceNet%20%E5%AE%98%E6%96%B9WiKi%E8%A7%A3%E8%AF%BB/"/>
    <id>http://yoururl.com/2018/07/15/FaceNet 官方WiKi解读/</id>
    <published>2018-07-15T02:15:32.918Z</published>
    <updated>2018-03-23T08:27:53.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>作者：Andy_z<br>文献：<a href="https://github.com/davidsandberg/facenet/wiki" target="_blank" rel="noopener">官方WiKi</a></p></blockquote><h2 id="一、分类器训练"><a href="#一、分类器训练" class="headerlink" title="一、分类器训练"></a>一、分类器训练</h2><h3 id="1-1-运行-train-softmax-py-文件训练"><a href="#1-1-运行-train-softmax-py-文件训练" class="headerlink" title="1.1 运行 train_softmax.py 文件训练"></a>1.1 运行 train_softmax.py 文件训练</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">python src/train_softmax.py</span><br><span class="line">--logs_base_dir ~/logs/facenet/</span><br><span class="line">--models_base_dir ~/models/facenet/</span><br><span class="line">--data_dir ~/datasets/casia/casia_maxpy_mtcnnalign_182</span><br><span class="line">--image_size 160</span><br><span class="line">--model_def models.inception_resnet_v1</span><br><span class="line">--lfw_dir /home/david/datasets/lfw/lfw_mtcnnalign_160</span><br><span class="line">--optimizer RMSPROP</span><br><span class="line">--learning_rate -1</span><br><span class="line">--max_nrof_epochs 80</span><br><span class="line">--keep_probability 0.8</span><br><span class="line">--random_crop</span><br><span class="line">--random_flip</span><br><span class="line">--learning_rate_schedule_file data/learning_rate_schedule_classifier_casia.txt</span><br><span class="line">--weight_decay 5e-5</span><br><span class="line">--center_loss_factor 1e-2</span><br><span class="line">--center_loss_alfa 0.9</span><br></pre></td></tr></table></figure><ul><li><strong>log_base_dir</strong>:<br><strong>models_base_dir</strong>:<br>训练开始时，以数据/时间训练开始的训练会话的子目录以yyyymmdd-hhmm的格式在以上两个目录中创建。  </li><li><strong>data_dir</strong>：  用于指出训练数据集的位置，可以通过用冒号分隔路径来使用几个数据集的联合。<br>model_def： 给出推理网络的描述符，上述样例中  models.inception_resnet_v1 指向models包中的<br>inception_resnet_v1模块。 该模块定义一个函数 inference(images, …)，images是输入图像的占位符(Inception-ResNet-v1的尺寸&lt;?, 160,160,3&gt;),并返回一个embeddings变量的引用。  </li><li><strong>lfw_dir</strong>：如果将参数lfw_dir设置为指向LFW数据集的基本目录，那么每1000个批次将在LFW上对该模型进行评估。有关如何在LFW上评估现有模型的信息，请参阅 Validate-on-LFW 页面。 如果在训练期间不需要对LFW进行评估，则可以将lfw_dir参数留空。 但请注意，此处使用的LFW数据集应与训练数据集一致。  </li><li><strong>max_nrof_epochs</strong>：最大训练周期。  </li><li><strong>learning_rate_schedule_file</strong>：为了改善最终模型的性能，当训练开始收敛时，学习速率降低10倍。 这是通过在参数learning_rate_schedule_file指向的文本文件中定义的学习速率时间表来完成的，同时还将参数learning_rate设置为负值。 为了简单起见，本例中data / learning_rate_schedule_classifier_casia.txt中使用的学习率也包括在库中。</li></ul><blockquote><p>注：train_tripletloss.py和train_softmax.py的区别：这是作者对论文做出的一个延伸，除了使用facenet里提到的train_tripletloss三元组损失函数来训练，还实现了用softmax的训练方法来训练。当然，在样本量很小的情况下，用softmax训练会更容易收敛。但是，当训练集中包含大量的不同个体(超过10万)时，最后一层的softmax输出数量就会变得非常大，但是使用train_tripletloss的训练仍然可以正常工作。</p></blockquote><h3 id="1-2-运行-train-softmax-py-文件训练"><a href="#1-2-运行-train-softmax-py-文件训练" class="headerlink" title="1.2 运行 train_softmax.py 文件训练"></a>1.2 运行 train_softmax.py 文件训练</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">python src/train_tripletloss.py</span><br><span class="line">--logs_base_dir ~/logs/facenet/</span><br><span class="line">--models_base_dir ~/models/facenet/</span><br><span class="line">--data_dir ~/datasets/casia/casia_maxpy_mtcnnalign_182_160</span><br><span class="line">--image_size 160</span><br><span class="line">--model_def models.inception_resnet_v1</span><br><span class="line">--lfw_dir ~/datasets/lfw/lfw_mtcnnalign_160</span><br><span class="line">--optimizer RMSPROP</span><br><span class="line">--learning_rate 0.01</span><br><span class="line">--weight_decay 1e-4</span><br><span class="line">--max_nrof_epochs 500</span><br></pre></td></tr></table></figure><h2 id="二、可视化TensorBoard"><a href="#二、可视化TensorBoard" class="headerlink" title="二、可视化TensorBoard"></a>二、可视化TensorBoard</h2><p>&emsp;&emsp;监视训练过程，使用TensorBoard:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=~/logs/facenet --port 6006</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;打开浏览器：<a href="http://localhost:6006/" target="_blank" rel="noopener">http://localhost:6006/</a></p><h2 id="三、用自己的图像训练分类器"><a href="#三、用自己的图像训练分类器" class="headerlink" title="三、用自己的图像训练分类器"></a>三、用自己的图像训练分类器</h2><h3 id="3-1-在LFW上训练分类器"><a href="#3-1-在LFW上训练分类器" class="headerlink" title="3.1 在LFW上训练分类器"></a>3.1 在LFW上训练分类器</h3><p>&emsp;&emsp;对于这个实验，我们使用LFW图像的子集来训练分类器。 LFW数据集分为训练和测试集。 然后加载预训练模型，然后使用此模型为选定图像生成特征。 预训练模型通常在更大的数据集上进行训练以提供良好的性能（本例中为MS-Celeb-1M数据集的一个子集）。</p><ul><li>将数据集分解为训练和测试集</li><li>加载预训练模型进行特征提取</li><li>计算数据集中图像的嵌入</li><li><p>模式= TRAIN：</p><ul><li>使用来自数据集的训练部分的嵌入来训练分类器  </li><li>将训练好的分类模型保存为python pickle</li></ul></li><li><p>模式= CLASSIFY：</p><ul><li>加载分类模型</li><li>使用来自数据集测试部分的嵌入来测试分类器  </li></ul></li></ul><blockquote><p>classifier.py定义参数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">def parse_arguments(argv):</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line"></span><br><span class="line">    parser.add_argument(&apos;mode&apos;, type=str, choices=[&apos;TRAIN&apos;, &apos;CLASSIFY&apos;],</span><br><span class="line">        help=&apos;Indicates if a new classifier should be trained or a classification &apos; +</span><br><span class="line">        &apos;model should be used for classification&apos;, default=&apos;CLASSIFY&apos;)</span><br><span class="line">    parser.add_argument(&apos;data_dir&apos;, type=str,</span><br><span class="line">        help=&apos;Path to the data directory containing aligned LFW face patches.&apos;)</span><br><span class="line">    parser.add_argument(&apos;model&apos;, type=str,</span><br><span class="line">        help=&apos;Could be either a directory containing the meta_file and ckpt_file or a model protobuf (.pb) file&apos;)</span><br><span class="line">    parser.add_argument(&apos;classifier_filename&apos;,</span><br><span class="line">        help=&apos;Classifier model file name as a pickle (.pkl) file. &apos; +</span><br><span class="line">        &apos;For training this is the output and for classification this is an input.&apos;)</span><br><span class="line">    parser.add_argument(&apos;--use_split_dataset&apos;,</span><br><span class="line">        help=&apos;Indicates that the dataset specified by data_dir should be split into a training and test set. &apos; +  </span><br><span class="line">        &apos;Otherwise a separate test set can be specified using the test_data_dir option.&apos;, action=&apos;store_true&apos;)</span><br><span class="line">    parser.add_argument(&apos;--test_data_dir&apos;, type=str,</span><br><span class="line">        help=&apos;Path to the test data directory containing aligned images used for testing.&apos;)</span><br><span class="line">    parser.add_argument(&apos;--batch_size&apos;, type=int,</span><br><span class="line">        help=&apos;Number of images to process in a batch.&apos;, default=90)</span><br><span class="line">    parser.add_argument(&apos;--image_size&apos;, type=int,</span><br><span class="line">        help=&apos;Image size (height, width) in pixels.&apos;, default=160)</span><br><span class="line">    parser.add_argument(&apos;--seed&apos;, type=int,</span><br><span class="line">        help=&apos;Random seed.&apos;, default=666)</span><br><span class="line">    parser.add_argument(&apos;--min_nrof_images_per_class&apos;, type=int,</span><br><span class="line">        help=&apos;Only include classes with at least this number of images in the dataset&apos;, default=20)</span><br><span class="line">    parser.add_argument(&apos;--nrof_train_images_per_class&apos;, type=int,</span><br><span class="line">        help=&apos;Use this number of images from each class for training and the rest for testing&apos;, default=10)</span><br><span class="line"></span><br><span class="line">    return parser.parse_args(argv)</span><br></pre></td></tr></table></figure></p></blockquote><ul><li><strong>mode</strong>：  指示训练新分类器还是进行分类测试集。’TRAIN’,    ‘CLASSIFY’</li><li><strong>data_dir</strong>：  包含对齐的LFW面部补丁的数据目录路径。</li><li><strong>model</strong>：  可能是包含meta_file和ckpt_file或模型protobuf(.pb)文件的目录</li><li><strong>classifier_filename</strong>：  分类器模型文件名称作pickle（.pkl）文件，对于训练过程，这是输出；对于分类过程，这是输入。</li><li><strong>use_split_dataset</strong>：  指示由data_dir指定的数据集应该分为训练集和测试集。 否则可以使用test_data_dir选项指定单独的测试集。</li><li><strong>test_data_dir</strong>：  包含用于测试的对齐图像的测试数据目录的路径。</li><li><strong>batch_size</strong>：  一个批次的图像运行数量。</li><li><strong>image_size</strong> ：  图像的像素尺寸。</li><li><strong>seed</strong>:   随机seed。</li><li><strong>min_nrof_images_per_class</strong>：  仅包含数据集中至少包含这些数量的图像的类。</li><li><strong>nrof_train_images_per_class</strong>：  从每个类中使用这个数量的图像进行训练，其余的进行测试。</li></ul><p>&emsp;&emsp;在数据集的训练集部分训练分类器的步骤如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">python src/classifier.py</span><br><span class="line">TRAIN</span><br><span class="line">data/lfw/lfw_align_mtcnnpy_160/</span><br><span class="line">src/models/20170512-110547/20170512-110547.pb</span><br><span class="line">src/models/lfw_classifier.pkl</span><br><span class="line">--batch_size 1000</span><br><span class="line">--min_nrof_images_per_class 40</span><br><span class="line">--nrof_train_images_per_class 35</span><br><span class="line">--use_split_dataset</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python src/classifier.py TRAIN data/lfw/lfw_align_mtcnnpy_160/ src/models/20170512-110547/20170512-110547.pb src/models/lfw_classifier.pkl --batch_size 1000 --min_nrof_images_per_class 40 --nrof_train_images_per_class 35 --use_split_dataset</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;训练输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Number of classes: 19</span><br><span class="line">Number of images: 665</span><br><span class="line">Loading feature extraction model</span><br><span class="line">Model filename: src/models/20170512-110547/20170512-110547.pb</span><br><span class="line">Calculating features for images</span><br><span class="line">Training classifier</span><br><span class="line">Saved classifier model to file &quot;src/models/lfw_classifier.pkl&quot;</span><br></pre></td></tr></table></figure></p><p>&emsp;&emsp;训练好的分类器可以稍后用于使用测试集进行分类：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">python src/classifier.py</span><br><span class="line">CLASSIFY</span><br><span class="line">data/lfw/lfw_align_mtcnnpy_160/</span><br><span class="line">src/models/20170512-110547/20170512-110547.pb</span><br><span class="line">src/models/lfw_classifier.pkl</span><br><span class="line">--batch_size 1000</span><br><span class="line">--min_nrof_images_per_class 40</span><br><span class="line">--nrof_train_images_per_class 35</span><br><span class="line">--use_split_dataset</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python src/classifier.py CLASSIFY data/lfw/lfw_align_mtcnnpy_160/ src/models/20170512-110547/20170512-110547.pb src/models/lfw_classifier.pkl --batch_size 1000 --min_nrof_images_per_class 40 --nrof_train_images_per_class 35 --use_split_dataset</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;单独指定测试集</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python src/classifier.py CLASSIFY data/lfw/test_lfw src/models/20170512-110547/20170512-110547.pb src/models/lfw_classifier.pkl --batch_size 1000 --min_nrof_images_per_class 40 --nrof_train_images_per_class 35 --test_data_dir data/lfw/test_lfw</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;这里使用数据集的测试集部分进行分类，并显示分类结果和分类概率。 该子集的分类准确度为〜0.98。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Number of classes: 19</span><br><span class="line">Number of images: 1202</span><br><span class="line">Loading feature extraction model</span><br><span class="line">Model filename: src/models/20170512-110547/20170512-110547.pb</span><br><span class="line">Calculating features for images</span><br><span class="line">Testing classifier</span><br><span class="line">Loaded classifier model from file &quot;src/models/lfw_classifier.pkl&quot;</span><br><span class="line">   0  Ariel Sharon: 0.712</span><br><span class="line">   1  Ariel Sharon: 0.771</span><br><span class="line">   2  Ariel Sharon: 0.807</span><br><span class="line">   3  Ariel Sharon: 0.785</span><br><span class="line">   4  Ariel Sharon: 0.750</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">1197  Vladimir Putin: 0.536</span><br><span class="line">1198  Vladimir Putin: 0.723</span><br><span class="line">1199  Vladimir Putin: 0.715</span><br><span class="line">1200  Vladimir Putin: 0.663</span><br><span class="line">1201  Vladimir Putin: 0.732</span><br><span class="line">Accuracy: 0.999</span><br></pre></td></tr></table></figure></p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-21/53475149.jpg" alt=""></p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-21/76473615.jpg" alt=""></p><h2 id="四、基于mtcnn与facenet的人脸识别（单张图像识别分类）"><a href="#四、基于mtcnn与facenet的人脸识别（单张图像识别分类）" class="headerlink" title="四、基于mtcnn与facenet的人脸识别（单张图像识别分类）"></a>四、基于mtcnn与facenet的人脸识别（单张图像识别分类）</h2><p>&emsp;&emsp;代码：facenet/contributed/predict.py  </p><p>&emsp;&emsp;主要功能：</p><ul><li><p>① 使用mtcnn进行人脸检测并对齐与裁剪</p></li><li><p>② 对裁剪的人脸使用facenet进行embedding</p></li><li><p>③ 执行predict.py进行人脸识别（需要训练好的svm模型）</p></li></ul><p>&emsp;&emsp;参数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def parse_arguments(argv):</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(&apos;image_files&apos;, type=str, nargs=&apos;+&apos;, help=&apos;Path(s) of the image(s)&apos;)</span><br><span class="line">    parser.add_argument(&apos;model&apos;, type=str,</span><br><span class="line">        help=&apos;Could be either a directory containing the meta_file and ckpt_file or a model protobuf (.pb) file&apos;)</span><br><span class="line">    parser.add_argument(&apos;classifier_filename&apos;,</span><br><span class="line">        help=&apos;Classifier model file name as a pickle (.pkl) file. &apos; +</span><br><span class="line">        &apos;For training this is the output and for classification this is an input.&apos;)</span><br><span class="line">    parser.add_argument(&apos;--image_size&apos;, type=int,</span><br><span class="line">        help=&apos;Image size (height, width) in pixels.&apos;, default=160)</span><br><span class="line">    parser.add_argument(&apos;--seed&apos;, type=int,</span><br><span class="line">        help=&apos;Random seed.&apos;, default=666)</span><br><span class="line">    parser.add_argument(&apos;--margin&apos;, type=int,</span><br><span class="line">        help=&apos;Margin for the crop around the bounding box (height, width) in pixels.&apos;, default=44)</span><br><span class="line">    parser.add_argument(&apos;--gpu_memory_fraction&apos;, type=float,</span><br><span class="line">        help=&apos;Upper bound on the amount of GPU memory that will be used by the process.&apos;, default=1.0)</span><br><span class="line">    return parser.parse_args(argv)</span><br></pre></td></tr></table></figure></p><ul><li><strong>image_files</strong>： 被识别图像路径</li><li><strong>model</strong>：包含meta_file和ckpt_file或模型protobuf（.pb）文件的目录</li><li><strong>classifier_filename</strong>：分类器模型文件名称作为pickle（.pkl）文件</li></ul><p>&emsp;&emsp;测试：用三中生成的lfw_classifier.pkl作为分类器模型进行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python predict.py d:/Anaconda3/Lib/site-packages/facenet/data/images/3.png D:/Anaconda3/Lib/site-packages/facenet/src/models/20170512-110547 D:/Anaconda3/Lib/site-packages/facenet/src/models/lfw_classifier.pkl</span><br></pre></td></tr></table></figure><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-22/3119407.jpg" alt=""></p><p>python contributed/predict.py data/images/2.png src/models/20170512-110547 src/models/lfw_classifier_whole.pkl</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;作者：Andy_z&lt;br&gt;文献：&lt;a href=&quot;https://github.com/davidsandberg/facenet/wiki&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;官方WiKi&lt;/a&gt;&lt;/p&gt;
&lt;/bloc
      
    
    </summary>
    
      <category term="人脸识别" scheme="http://yoururl.com/categories/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/"/>
    
    
      <category term="Summary" scheme="http://yoururl.com/tags/Summary/"/>
    
      <category term="facenet" scheme="http://yoururl.com/tags/facenet/"/>
    
      <category term="face recognition" scheme="http://yoururl.com/tags/face-recognition/"/>
    
  </entry>
  
</feed>

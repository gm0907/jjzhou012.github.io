<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Andy_z &#39;s Blog</title>
  
  <subtitle>Coding - Thinking - Sharing - Deep learning</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoururl.com/"/>
  <updated>2019-03-05T15:04:36.411Z</updated>
  <id>http://yoururl.com/</id>
  
  <author>
    <name>Andy_z</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>GAN Lab：交互式可视化GAN平台</title>
    <link href="http://yoururl.com/2019/03/05/GAN%20Lab/"/>
    <id>http://yoururl.com/2019/03/05/GAN Lab/</id>
    <published>2019-03-04T16:08:00.000Z</published>
    <updated>2019-03-05T15:04:36.411Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GAN-Lab"><a href="#GAN-Lab" class="headerlink" title="GAN Lab"></a>GAN Lab</h1><p>GAN Lab 是一个最新的交互式可视化工具，使用 <a href="https://js.tensorflow.org/" target="_blank" rel="noopener"><code>Tensorflow.js</code></a> 构建。</p><p>由佐治亚理工学院 Minsuk Kahng、Polo Chau 和 Google Brain 的 Nikhil Thorat、Fernanda Viégas、Martin Wattenberg 合作开发了<a href="https://poloclub.github.io/ganlab/" target="_blank" rel="noopener">GAN Lab</a>。</p><p><code>Tensorflow.js</code> 是用于在浏览器和Node.js上训练和部署ML模型的JavaScript库。</p><p>GANs 是一类复杂的深度学习模型，GAN Lab 可用于交互式的训练针对2D数据分布的GAN模型，并可视化模型的内部工作机理。</p><h2 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h2><blockquote><p>安装yarn:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; npm install -g yarn</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><p>&gt;</p><blockquote><p>若报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; The engine &quot;node&quot; is incompatible with this module. Expected version &quot;&gt;=4 &lt;=9&quot;. Got &quot;10.8.0&quot;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><p>&gt;</p><blockquote><p>运行如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; yarn install --ignore-engines</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https://github.com/poloclub/ganlab.git</span><br><span class="line">$ cd ganlab</span><br><span class="line">$ yarn prep</span><br></pre></td></tr></table></figure><h2 id="运行demo"><a href="#运行demo" class="headerlink" title="运行demo"></a>运行demo</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ ./scripts/watch-demo</span><br><span class="line"></span><br><span class="line">&gt;&gt; Waiting for initial compile...</span><br><span class="line">&gt;&gt; 3462522 bytes written to demo/bundle.js (2.17 seconds) at 00:00:00</span><br><span class="line">&gt;&gt; Starting up http-server, serving ./</span><br><span class="line">&gt;&gt; Available on:</span><br><span class="line">&gt;&gt;   http://127.0.0.1:8080</span><br><span class="line">&gt;&gt; Hit CTRL-C to stop the server</span><br></pre></td></tr></table></figure><p>访问 <code>http://localhost:8080/demo/</code></p><h2 id="工具模块解析"><a href="#工具模块解析" class="headerlink" title="工具模块解析"></a>工具模块解析</h2><h3 id="界面总览"><a href="#界面总览" class="headerlink" title="界面总览"></a>界面总览</h3><p><img src="https://s2.ax1x.com/2019/03/05/kjPDv8.png" alt="kjPDv8.png"></p><h3 id="模型界面"><a href="#模型界面" class="headerlink" title="模型界面"></a>模型界面</h3><h4 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h4><p><img src="https://s2.ax1x.com/2019/03/05/kjeupd.png" alt="kjeupd.png"></p><p>模型图上可以修改的超参数有：</p><ul><li>随机噪声类型（一维、二维；高斯、均匀）</li><li>优化器（SGD、Adam）</li><li>学习率</li><li>网络隐藏层数，神经元数</li><li>损失函数（Log、LeastSq）</li><li>参数更新速度</li></ul><h4 id="训练可视化"><a href="#训练可视化" class="headerlink" title="训练可视化"></a>训练可视化</h4><p><img src="https://www.jqr.com/editor/212/559/2125596163-5b913202c00ce" alt="æ¢å¨ä½æ¨¡å¼"></p><p>训练过程中，虚线将示意数据流动方向。运行按钮边上有一个慢动作按钮，点击后能放慢训练过程，可以更细致得查看模型内部的训练过程。</p><p>鼠标悬浮于生成网络，可以看到从随机噪声到生成样本的流形变换过程。</p><p><img src="https://s2.ax1x.com/2019/03/05/kjAby6.png" alt="kjAby6.png"></p><p>判别网络上，决策边界可视化为二维热图。绿色表示判别网络分类为真实样本，紫色表示判别网路分类为生成样本。<strong>颜色深浅编码了置信度</strong>，颜色越深，判别网络对自己的判断就越自信。</p><p>随着训练的进行，判别网络的热图总体趋近于灰色，意味着判别网络越来越难以分辨真实样本和虚假样本。</p><p>另外，判别网络的输出预测同样使用<strong>颜色深浅编码置信度</strong>。</p><p><img src="C:\Users\jjzhou\AppData\Roaming\Typora\typora-user-images\1551794572297.png" alt="1551794572297"></p><p>右侧的数据分布视图用紫线可视化了生成网络的梯度。在训练中，梯度刺向背景热图的绿色区域，意味着生成网络正努力的欺骗判别网络。</p><p><img src="C:\Users\jjzhou\AppData\Roaming\Typora\typora-user-images\1551785433674.png" alt="1551785433674"></p><h3 id="测度界面"><a href="#测度界面" class="headerlink" title="测度界面"></a>测度界面</h3><p><img src="https://s2.ax1x.com/2019/03/05/kjml8J.png" alt="kjml8J.png"></p><p>点击运行，开始训练后，可以看到右侧不断更新的测度，分别为：</p><ul><li>判别器loss</li><li>生成器loss</li><li>KL散度</li><li>JS 散度</li></ul><h3 id="数据分布视图"><a href="#数据分布视图" class="headerlink" title="数据分布视图"></a>数据分布视图</h3><p><img src="https://image-cdn.jqr.com/editor/203/904/2039045747-5b913b67a2794" alt="img"></p><p>绿点为真实样本，紫点为生成样本。训练过程中，生成样本的位置不断更新，最终趋向于和真实样本重叠。</p><h2 id="GAN的简单介绍"><a href="#GAN的简单介绍" class="headerlink" title="GAN的简单介绍"></a>GAN的简单介绍</h2><p>通过学习一类概率分布的数据，生成相似分布的数据。比如，模型通过学习一些人脸图片，然后自己来生成人脸图片。这样创造性的生成现实图片看似很神奇，但其实是有两个关键点：</p><ul><li>模型在高维空间上对数据的概率分布进行建模。因为我们需要模型了解哪些图像是人脸，哪些不是；</li><li>GAN由生成模型和判别模型构成，引入零和博弈的思想，生成器生成尽可能真实的图像，判别器努力将生成图像和真实图像区分开来，两个网络相互对抗，最终判别器无法准确分辨真实图像和生成图像。</li></ul><p>综上，GAN 通过从一个特定分布中采样生成数据，通过设置对抗网络来使得生成效果达到最优。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;GAN-Lab&quot;&gt;&lt;a href=&quot;#GAN-Lab&quot; class=&quot;headerlink&quot; title=&quot;GAN Lab&quot;&gt;&lt;/a&gt;GAN Lab&lt;/h1&gt;&lt;p&gt;GAN Lab 是一个最新的交互式可视化工具，使用 &lt;a href=&quot;https://js.tens
      
    
    </summary>
    
      <category term="深度学习" scheme="http://yoururl.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Tensorflow" scheme="http://yoururl.com/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>FTP服务端与客户端安装配置</title>
    <link href="http://yoururl.com/2019/02/21/ftp%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%E9%85%8D%E7%BD%AE/"/>
    <id>http://yoururl.com/2019/02/21/ftp文件传输配置/</id>
    <published>2019-02-20T16:07:00.000Z</published>
    <updated>2019-02-22T09:26:39.626Z</updated>
    
    <content type="html"><![CDATA[<h1 id="FTP文件传输配置"><a href="#FTP文件传输配置" class="headerlink" title="FTP文件传输配置"></a>FTP文件传输配置</h1><h2 id="一、CentOS服务器端"><a href="#一、CentOS服务器端" class="headerlink" title="一、CentOS服务器端"></a>一、CentOS服务器端</h2><h3 id="1-安装vsftpd"><a href="#1-安装vsftpd" class="headerlink" title="1. 安装vsftpd"></a>1. 安装vsftpd</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install vsftpd</span><br></pre></td></tr></table></figure><h3 id="2-设置开机启动vsftpd-ftp服务"><a href="#2-设置开机启动vsftpd-ftp服务" class="headerlink" title="2.设置开机启动vsftpd ftp服务"></a>2.设置开机启动vsftpd ftp服务</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chkconfig vsftpd on</span><br></pre></td></tr></table></figure><h3 id="3-启动vsftpd服务"><a href="#3-启动vsftpd服务" class="headerlink" title="3.启动vsftpd服务"></a>3.启动vsftpd服务</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service vsftpd start</span><br></pre></td></tr></table></figure><h3 id="4-配置防火墙"><a href="#4-配置防火墙" class="headerlink" title="4.配置防火墙"></a>4.配置防火墙</h3><p>因为ftp默认的端口为21，而centos默认是没有开启的，所以要修改iptables文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/sysconfig/iptables</span><br></pre></td></tr></table></figure><p>在行上面有<code>22 -j ACCEPT</code> 下面另起一行输入 <strong>这行代码</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-A RH-Firewall-1-INPUT -m state --state NEW -m tcp -p tcp --dport 21 -j ACCEPT</span><br></pre></td></tr></table></figure><p>保存关闭，重启防火墙。</p><blockquote><p>我已经永久关闭防火墙了，所以也无需开启</p></blockquote><h3 id="5-配置vsftpd服务器"><a href="#5-配置vsftpd服务器" class="headerlink" title="5.配置vsftpd服务器"></a>5.配置vsftpd服务器</h3><p>打开配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/vsftpd/vsftpd.conf</span><br></pre></td></tr></table></figure><ul><li><p>把第一行的 <code>anonymous_enable=YES</code> ，改为<code>NO</code>，取消匿名登陆</p><blockquote><p>也可不取消</p></blockquote></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#chroot_list_enable=YES</span><br><span class="line"># (default follows)</span><br><span class="line">#chroot_list_file=/etc/vsftpd.chroot_list</span><br></pre></td></tr></table></figure><p>改为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chroot_list_enable=YES</span><br><span class="line"># (default follows)</span><br><span class="line">chroot_list_file=/etc/vsftpd/chroot_list</span><br></pre></td></tr></table></figure></li><li><p>修改权限，使用户能重命名或删除</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">anon_mkdir_write_enable=YES</span><br><span class="line">anon_other_write_enable=YES</span><br></pre></td></tr></table></figure></li><li><p>设置登陆默认路径（共享文件夹）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">local_root=/share</span><br></pre></td></tr></table></figure></li><li><p>其他设置</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">write_enables=YES</span><br></pre></td></tr></table></figure><p>保存关闭，重启 <code>vsftpd</code> 服务</p><h3 id="6-添加ftp用户"><a href="#6-添加ftp用户" class="headerlink" title="6. 添加ftp用户"></a>6. 添加ftp用户</h3><p>添加一个名为 ftpuser 的用户，所属 ftp 用户组，指向目录/share, 禁止登录：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">useradd -d /share -g ftp -s /sbin/nologin ftpuser</span><br></pre></td></tr></table></figure><p>设置ftpuser登陆密码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">passwd ftpuser</span><br></pre></td></tr></table></figure><p>添加FTP用户到 <code>user_list</code>文件夹中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 打开user_list文件</span><br><span class="line">vi /etc/vsftpd/user_list</span><br><span class="line"></span><br><span class="line"># 文件内文末添加</span><br><span class="line">ftpuser</span><br></pre></td></tr></table></figure><p>添加FTP用户到 <code>chroot_list</code> 文件夹：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 在/etc/vsftpd/ 目录下创建一个 chroot_list 文件：</span><br><span class="line">vi /etc/vsftpd/chroot_list</span><br><span class="line"></span><br><span class="line"># 文件内文末添加</span><br><span class="line">ftpuser</span><br></pre></td></tr></table></figure><blockquote><p>或者可以利用以有的用户</p></blockquote><h3 id="7-修改selinux"><a href="#7-修改selinux" class="headerlink" title="7.修改selinux"></a>7.修改selinux</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">setsebool -P allow_ftpd_full_access 1   </span><br><span class="line"></span><br><span class="line">setsebool -P ftp_home_dir off 1</span><br></pre></td></tr></table></figure><p>重启vsftpd</p><h2 id="二-Windows10客户端"><a href="#二-Windows10客户端" class="headerlink" title="二. Windows10客户端"></a>二. Windows10客户端</h2><h3 id="2-1-开启windows相关功能"><a href="#2-1-开启windows相关功能" class="headerlink" title="2.1 开启windows相关功能"></a>2.1 开启windows相关功能</h3><p><img src="https://s2.ax1x.com/2019/02/22/kfkc7Q.png" alt="kfkc7Q.png"></p><ul><li>开启后重启计算机</li></ul><h3 id="2-2-快速连接"><a href="#2-2-快速连接" class="headerlink" title="2.2 快速连接"></a>2.2 快速连接</h3><ul><li>在文件夹路径窗口输入 <code>ftp://10.5.18.250</code>，连接</li></ul><p><img src="https://s2.ax1x.com/2019/02/22/kfA0UJ.png" alt="kfA0UJ.png"></p><p>连接成功：</p><p><img src="https://s2.ax1x.com/2019/02/22/kfA6v6.png" alt="kfA6v6.png"></p><blockquote><p>到此结束也ok，若想要建立长久的本地驱动映射，继续</p></blockquote><h3 id="2-3-建立本地驱动映射"><a href="#2-3-建立本地驱动映射" class="headerlink" title="2.3 建立本地驱动映射"></a>2.3 建立本地驱动映射</h3><ul><li>打开 <code>此电脑--&gt;计算机--&gt;映射网络驱动器</code> :</li></ul><p><img src="https://s2.ax1x.com/2019/02/22/kfA9BD.png" alt="kfA9BD.png"></p><ul><li>选择 <code>连接到可用于存储文档和图片的网站</code></li></ul><p><img src="https://s2.ax1x.com/2019/02/22/kfk5cV.png" alt="kfk5cV.png"></p><ul><li><p><img src="https://s2.ax1x.com/2019/02/22/kfEGIH.png" alt="kfEGIH.png"></p></li></ul><ul><li><img src="https://s2.ax1x.com/2019/02/22/kfEfyV.png" alt="kfEfyV.png"></li><li>最后输入密码</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;FTP文件传输配置&quot;&gt;&lt;a href=&quot;#FTP文件传输配置&quot; class=&quot;headerlink&quot; title=&quot;FTP文件传输配置&quot;&gt;&lt;/a&gt;FTP文件传输配置&lt;/h1&gt;&lt;h2 id=&quot;一、CentOS服务器端&quot;&gt;&lt;a href=&quot;#一、CentOS服务器端&quot;
      
    
    </summary>
    
      <category term="安装与配置" scheme="http://yoururl.com/categories/%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/"/>
    
    
      <category term="Install &amp; config" scheme="http://yoururl.com/tags/Install-config/"/>
    
  </entry>
  
  <entry>
    <title>samba服务端与客户端安装配置</title>
    <link href="http://yoururl.com/2019/02/21/samba%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB%E9%85%8D%E7%BD%AE(1)/"/>
    <id>http://yoururl.com/2019/02/21/samba文件共享配置(1)/</id>
    <published>2019-02-20T16:07:00.000Z</published>
    <updated>2019-02-21T05:42:19.218Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Samba-文件共享配置"><a href="#Samba-文件共享配置" class="headerlink" title="Samba 文件共享配置"></a>Samba 文件共享配置</h1><h2 id="一、CentOS服务端—Win客户端"><a href="#一、CentOS服务端—Win客户端" class="headerlink" title="一、CentOS服务端—Win客户端"></a>一、CentOS服务端—Win客户端</h2><h3 id="1-1-安装samba组件"><a href="#1-1-安装samba组件" class="headerlink" title="1.1 安装samba组件"></a>1.1 安装samba组件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install samba samba-client samba-swat</span><br></pre></td></tr></table></figure><ul><li>查看安装情况：</li></ul><p><img src="https://s2.ax1x.com/2019/02/20/k2I95q.png" alt="k2I95q.png"></p><h3 id="1-2-配置samba"><a href="#1-2-配置samba" class="headerlink" title="1.2 配置samba"></a>1.2 配置samba</h3><ul><li>设置开机启动：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chkconfig smb on</span><br><span class="line">chkconfig nmb on</span><br></pre></td></tr></table></figure><ul><li>新建访问用户</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">useradd xxx       # 新建用户</span><br><span class="line">smbpasswd -a xxx  # 修改密码</span><br></pre></td></tr></table></figure><ul><li>创建共享文件夹</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir /root/root_share</span><br><span class="line"># 修改共享文件夹权限</span><br><span class="line">cd /</span><br><span class="line">chmod 777 /root</span><br><span class="line">chmod 777 /root/root_share</span><br></pre></td></tr></table></figure><ul><li>修改samba配置文件</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/samba/smb.conf</span><br></pre></td></tr></table></figure><p><img src="https://s2.ax1x.com/2019/02/20/k2ItZd.png" alt="k2ItZd.png"></p><ul><li>关闭防火墙</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chkconfig iptables off</span><br></pre></td></tr></table></figure><ul><li>关闭SELINUX</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/selinux/config</span><br></pre></td></tr></table></figure><p><img src="https://s2.ax1x.com/2019/02/20/k2IUII.png" alt="k2IUII.png"></p><ul><li>系统重启</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure><ul><li>查看samba启动状态</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service smb status</span><br></pre></td></tr></table></figure><p><img src="https://s2.ax1x.com/2019/02/20/k2IOF1.png" alt="k2IOF1.png"></p><ul><li>修改host allow</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/samba/smb.conf</span><br></pre></td></tr></table></figure><p><img src="https://s2.ax1x.com/2019/02/20/k2oCeH.png" alt="k2oCeH.png"></p><blockquote><p>注意不修改的话，windows无法访问</p></blockquote><h3 id="1-3-客户端连接共享文件夹"><a href="#1-3-客户端连接共享文件夹" class="headerlink" title="1.3 客户端连接共享文件夹"></a>1.3 客户端连接共享文件夹</h3><blockquote><p>客户端环境：windows10家庭版</p></blockquote><ul><li>开启SMB/CIFS支持</li></ul><p><img src="https://s2.ax1x.com/2019/02/20/k2o1kn.png" alt="k2o1kn.png"></p><ul><li>本地组策略编辑</li></ul><p>按住快捷键Win+R打开运行窗口，往运行里面输入<strong>gpedit.msc</strong> 打开的是组策略编辑器</p><p><img src="https://s2.ax1x.com/2019/02/20/k2oBkR.png" alt="k2oBkR.png"></p><blockquote><p>注意：有些用户想要打开组策略编辑器却遇到了gpedit.msc找不到的提示</p><p><img src="https://s2.ax1x.com/2019/02/20/k2oyp6.png" alt="k2oyp6.png"></p><p>解决方法：<a href="https://pan.baidu.com/s/1s9Il6ifEvXzGEUAiZ65GHg" target="_blank" rel="noopener">https://pan.baidu.com/s/1s9Il6ifEvXzGEUAiZ65GHg</a></p><p>下载上述文件，右键单击这个“win10添加策略组.cmd”文件，选择以<strong>管理员身份运行</strong>即可，运行完毕，系统成功加入策略组。</p></blockquote><ul><li>重启电脑</li></ul><ul><li><p>windows访问共享目录</p><p><img src="https://s2.ax1x.com/2019/02/20/k2TZNR.png" alt="k2TZNR.png"></p><p><img src="https://s2.ax1x.com/2019/02/20/k2TVE9.png" alt="k2TVE9.png"></p></li></ul><ul><li>访问成功</li></ul><h2 id="二、-–-Ubuntu客户端"><a href="#二、-–-Ubuntu客户端" class="headerlink" title="二、 – Ubuntu客户端"></a>二、 – Ubuntu客户端</h2><h3 id="2-1-安装samba客户端组件"><a href="#2-1-安装samba客户端组件" class="headerlink" title="2.1 安装samba客户端组件"></a>2.1 安装samba客户端组件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install smbclient</span><br></pre></td></tr></table></figure><h3 id="2-2-查看所以共享目录"><a href="#2-2-查看所以共享目录" class="headerlink" title="2.2 查看所以共享目录"></a>2.2 查看所以共享目录</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">smbclient -L server_ip</span><br></pre></td></tr></table></figure><blockquote><p>注：敲入上面命令后，在出现提示输入密码时，直接按Enter键（因为此处是匿名访问），结果会显示指定Samba服务器上当前全部的共享目录。</p></blockquote><h3 id="2-3-连接共享目录"><a href="#2-3-连接共享目录" class="headerlink" title="2.3 连接共享目录"></a>2.3 连接共享目录</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">smbclient //server_ip/root/root_share</span><br></pre></td></tr></table></figure><h3 id="2-4-挂载"><a href="#2-4-挂载" class="headerlink" title="2.4 挂载"></a>2.4 挂载</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mount -t cifs -o username=xxx,password=xxx //server_ip/root/root_share 本地挂载点</span><br></pre></td></tr></table></figure><h3 id="2-5-关于权限"><a href="#2-5-关于权限" class="headerlink" title="2.5 关于权限"></a>2.5 关于权限</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Samba-文件共享配置&quot;&gt;&lt;a href=&quot;#Samba-文件共享配置&quot; class=&quot;headerlink&quot; title=&quot;Samba 文件共享配置&quot;&gt;&lt;/a&gt;Samba 文件共享配置&lt;/h1&gt;&lt;h2 id=&quot;一、CentOS服务端—Win客户端&quot;&gt;&lt;a hr
      
    
    </summary>
    
      <category term="安装与配置" scheme="http://yoururl.com/categories/%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/"/>
    
    
      <category term="Install &amp; config" scheme="http://yoururl.com/tags/Install-config/"/>
    
  </entry>
  
  <entry>
    <title>NFS服务端与客户端安装配置</title>
    <link href="http://yoururl.com/2019/02/21/CentOS%206.9%20%E4%B8%8BNFS%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"/>
    <id>http://yoururl.com/2019/02/21/CentOS 6.9 下NFS安装配置/</id>
    <published>2019-02-20T16:07:00.000Z</published>
    <updated>2019-02-21T05:44:16.673Z</updated>
    
    <content type="html"><![CDATA[<h1 id="NFS安装配置"><a href="#NFS安装配置" class="headerlink" title="NFS安装配置"></a>NFS安装配置</h1><h2 id="一、服务器端配置"><a href="#一、服务器端配置" class="headerlink" title="一、服务器端配置"></a>一、服务器端配置</h2><h3 id="1-1-CentOS-服务器"><a href="#1-1-CentOS-服务器" class="headerlink" title="1.1 CentOS 服务器"></a>1.1 CentOS 服务器</h3><h4 id="1-1-1-确认软件是否安装，安装NFS服务相关软件"><a href="#1-1-1-确认软件是否安装，安装NFS服务相关软件" class="headerlink" title="1.1.1 确认软件是否安装，安装NFS服务相关软件"></a>1.1.1 确认软件是否安装，安装NFS服务相关软件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa|grep nfs</span><br><span class="line">rpm -qa|grep rpc</span><br></pre></td></tr></table></figure><p><img src="https://s2.ax1x.com/2019/02/19/kgasaR.png" alt="kgasaR.png"></p><h6 id="如查询结果如上，说明服务器自身已经安装了NFS，如果没有安装，则用yum命令来安装，并验证安装："><a href="#如查询结果如上，说明服务器自身已经安装了NFS，如果没有安装，则用yum命令来安装，并验证安装：" class="headerlink" title="如查询结果如上，说明服务器自身已经安装了NFS，如果没有安装，则用yum命令来安装，并验证安装："></a>如查询结果如上，说明服务器自身已经安装了NFS，如果没有安装，则用yum命令来安装，并验证安装：</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum -y install nfs-utils rpcbind</span><br><span class="line">rpm -qa nfs-utils rpcbind</span><br></pre></td></tr></table></figure><h4 id="1-1-2-编写nfs配置文件"><a href="#1-1-2-编写nfs配置文件" class="headerlink" title="1.1.2 编写nfs配置文件"></a>1.1.2 编写nfs配置文件</h4><p>nfs配置文件默认存在 /etc/exports</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/exports</span><br></pre></td></tr></table></figure><p><img src="https://s2.ax1x.com/2019/02/20/k2DXTg.png" alt="k2DXTg.png"></p><blockquote><p>/etc/exports 文件说明：</p><ul><li><p>/root/root_share    : – 指定共享目录信息</p></li><li><p>指定有访问权限的网段 </p><ul><li><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;     //NFS客户端地址：</span><br><span class="line">&gt;      指定IP: 192.168.0.1</span><br><span class="line">&gt;      指定子网所有主机: 192.168.0.0/24</span><br><span class="line">&gt;      指定域名的主机: test.com</span><br><span class="line">&gt;      指定域名所有主机: *.test.com</span><br><span class="line">&gt;      所有主机: *</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></li></ul></li></ul></blockquote><blockquote><ul><li>其他设置<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; </span><br><span class="line">&gt; - （rw, sync, no_root_squash）    : -表示定义共享参数信息</span><br><span class="line">&gt; </span><br><span class="line">&gt;   - rw：表示读写； ro: 表示只读；</span><br><span class="line">&gt;   - sync : 同步， 数据会先写入到NFS服务器内存中，会立刻同步到磁盘里面==直接存储硬盘中；</span><br><span class="line">&gt;   - NFS 在预设的状况下会把 root 的 UID/GID (0/0) 对应到 nobody 去，这就是 root_squash。我们可以用 no_root_squash 关闭该功能。</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></li></ul></blockquote><h4 id="1-1-3-创建共享目录，进行权限设定"><a href="#1-1-3-创建共享目录，进行权限设定" class="headerlink" title="1.1.3 创建共享目录，进行权限设定"></a>1.1.3 创建共享目录，进行权限设定</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir /root/root_share -p</span><br><span class="line">chown -R nfsnobody.nfsnobody /root/root_share</span><br></pre></td></tr></table></figure><h4 id="1-1-4-启动服务"><a href="#1-1-4-启动服务" class="headerlink" title="1.1.4 启动服务"></a>1.1.4 启动服务</h4><h5 id="1-1-4-1-启动rpc服务"><a href="#1-1-4-1-启动rpc服务" class="headerlink" title="1.1.4.1 启动rpc服务"></a>1.1.4.1 启动rpc服务</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/rpcbind start</span><br></pre></td></tr></table></figure><h5 id="1-1-4-2-启动nfs服务"><a href="#1-1-4-2-启动nfs服务" class="headerlink" title="1.1.4.2 启动nfs服务"></a>1.1.4.2 启动nfs服务</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/nfs start</span><br></pre></td></tr></table></figure><blockquote><p>查看rpcbind 服务启动信息</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ps -ef|grep rpcbind</span><br><span class="line">netstat -lntup|grep 111</span><br><span class="line">rpcinfo -p localhost</span><br></pre></td></tr></table></figure><h4 id="1-1-5-服务器端部署完成"><a href="#1-1-5-服务器端部署完成" class="headerlink" title="1.1.5 服务器端部署完成"></a>1.1.5 服务器端部署完成</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">showmount -e 10.5.18.250</span><br></pre></td></tr></table></figure><blockquote><ul><li>-d：仅显示已被NFS客户端加载的目录；</li><li>-e：显示NFS服务器上所有的共享目录。</li></ul></blockquote><p>NFS服务开启后，默认的参数文件位置，注意：修改此文件，对nfs服务没有任何影响</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /var/lib/nfs/etab</span><br></pre></td></tr></table></figure><p><img src="https://s2.ax1x.com/2019/02/20/k2ru11.png" alt="k2ru11.png"></p><h4 id="1-1-6-设置NFS服务开机自启动"><a href="#1-1-6-设置NFS服务开机自启动" class="headerlink" title="1.1.6 设置NFS服务开机自启动"></a>1.1.6 设置NFS服务开机自启动</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chkconfig rpcbind on</span><br><span class="line">chkconfig nfs on</span><br></pre></td></tr></table></figure><blockquote><p>注意：</p><ul><li><p>关闭服务器防火墙</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;   # 永久关闭</span><br><span class="line">&gt;   chkconfig iptables off</span><br><span class="line">&gt;   # 临时关闭</span><br><span class="line">&gt;   service iptables stop</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></li></ul></blockquote><blockquote><ul><li><p>root下共享文件夹权限开放</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;   chmod 777 root</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></li></ul></blockquote><blockquote><ul><li><p>解决NFS版本问题</p><p>编辑 /etc/sysconfig/nfs文件，找到下面:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;   #Turn off v2 and v3 protocol support </span><br><span class="line">&gt;   #RPCNFSDARGS=&quot;-N 2 -N 3&quot; </span><br><span class="line">&gt;   #Turn off v4 protocol support </span><br><span class="line">&gt;   #RPCNFSDARGS=&quot;-N 4&quot;　　/*把这句前面的#号去掉*/</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></li></ul></blockquote><blockquote><p>  最后保存，重启nfs服务，再尝试挂载；如果挂载不上，可尝试在后面加-o nolock参数。</p><ul><li><p>挂载成功</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;   mount -t nfs -o nolock server_ip:/root/root_share /home/zjj/root_share</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></li></ul></blockquote><h3 id="1-2-Ubuntu-服务器"><a href="#1-2-Ubuntu-服务器" class="headerlink" title="1.2. Ubuntu 服务器"></a>1.2. Ubuntu 服务器</h3><blockquote><p>Ubuntu 服务端配置好像没有遇到防火墙问题</p></blockquote><h4 id="1-2-1-安装组件"><a href="#1-2-1-安装组件" class="headerlink" title="1.2.1 安装组件"></a>1.2.1 安装组件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install nfs-kernel-server</span><br></pre></td></tr></table></figure><h4 id="1-2-2-创建共享文件夹"><a href="#1-2-2-创建共享文件夹" class="headerlink" title="1.2.2 创建共享文件夹"></a>1.2.2 创建共享文件夹</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir /home/nfs_share</span><br><span class="line"># 赋予访问权限</span><br><span class="line">sudo chmod -R go+rwx /home/nfs_share     # 不一定需要</span><br></pre></td></tr></table></figure><h4 id="1-2-3-配置nfs"><a href="#1-2-3-配置nfs" class="headerlink" title="1.2.3 配置nfs"></a>1.2.3 配置nfs</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/exports</span><br></pre></td></tr></table></figure><p>末尾添加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/home/nfs_share *(rw,sync,no_root_squash,no_subtree_check)</span><br></pre></td></tr></table></figure><p>保存退出</p><h4 id="1-2-4-启动rpc、nfs"><a href="#1-2-4-启动rpc、nfs" class="headerlink" title="1.2.4 启动rpc、nfs"></a>1.2.4 启动rpc、nfs</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo /etc/init.d/rpcbind restart</span><br><span class="line">sudo /etc/init.d/nfs-kernel-server restart</span><br></pre></td></tr></table></figure><blockquote><p>停止服务命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; service nfs-kernel-server stop</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><h2 id="二、-客户端挂载配置"><a href="#二、-客户端挂载配置" class="headerlink" title="二、 客户端挂载配置"></a>二、 客户端挂载配置</h2><h3 id="2-1-windows客户端"><a href="#2-1-windows客户端" class="headerlink" title="2.1 windows客户端"></a>2.1 windows客户端</h3><blockquote><p>win10家庭版没有NFS功能</p></blockquote><h3 id="2-2-centos客户端"><a href="#2-2-centos客户端" class="headerlink" title="2.2 centos客户端"></a>2.2 centos客户端</h3><h4 id="2-2-1-确认nfs、rpc软件安装"><a href="#2-2-1-确认nfs、rpc软件安装" class="headerlink" title="2.2.1 确认nfs、rpc软件安装"></a>2.2.1 确认nfs、rpc软件安装</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa|grep nfs</span><br><span class="line">rpm -qa|grep rpc</span><br><span class="line"># 若未安装，则运行已下命令安装</span><br><span class="line">yum -y install nfs-utils rpcbind</span><br><span class="line"># 确认安装</span><br><span class="line">rpm -qa nfs-utils rpcbind</span><br></pre></td></tr></table></figure><h4 id="2-2-2-查看服务器上的共享"><a href="#2-2-2-查看服务器上的共享" class="headerlink" title="2.2.2 查看服务器上的共享"></a>2.2.2 查看服务器上的共享</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">showmount -e server_ip</span><br></pre></td></tr></table></figure><h4 id="2-2-3-挂载"><a href="#2-2-3-挂载" class="headerlink" title="2.2.3 挂载"></a>2.2.3 挂载</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mount -t nfs -o nolock server_ip:/root/root_share /home/zjj/root_share</span><br></pre></td></tr></table></figure><blockquote><p>挂载路径自定义即可</p></blockquote><h3 id="2-3-ubuntu客户端"><a href="#2-3-ubuntu客户端" class="headerlink" title="2.3 ubuntu客户端"></a>2.3 ubuntu客户端</h3><h4 id="2-3-1-确认nfs、rpc软件安装"><a href="#2-3-1-确认nfs、rpc软件安装" class="headerlink" title="2.3.1 确认nfs、rpc软件安装"></a>2.3.1 确认nfs、rpc软件安装</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dpkg -l|grep nfs</span><br><span class="line">dpkg -l|grep rpc</span><br><span class="line"># 若未安装，则运行已下命令安装</span><br><span class="line">sudo apt-get install nfs-common</span><br></pre></td></tr></table></figure><h4 id="2-3-2-查看服务器上的共享"><a href="#2-3-2-查看服务器上的共享" class="headerlink" title="2.3.2 查看服务器上的共享"></a>2.3.2 查看服务器上的共享</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">showmount -e server_ip</span><br></pre></td></tr></table></figure><h4 id="2-3-3-挂载"><a href="#2-3-3-挂载" class="headerlink" title="2.3.3 挂载"></a>2.3.3 挂载</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mount -t nfs -o nolock server_ip:/root/root_share /home/zjj/root_share</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;NFS安装配置&quot;&gt;&lt;a href=&quot;#NFS安装配置&quot; class=&quot;headerlink&quot; title=&quot;NFS安装配置&quot;&gt;&lt;/a&gt;NFS安装配置&lt;/h1&gt;&lt;h2 id=&quot;一、服务器端配置&quot;&gt;&lt;a href=&quot;#一、服务器端配置&quot; class=&quot;headerli
      
    
    </summary>
    
      <category term="安装与配置" scheme="http://yoururl.com/categories/%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/"/>
    
    
      <category term="Install &amp; config" scheme="http://yoururl.com/tags/Install-config/"/>
    
  </entry>
  
  <entry>
    <title>复杂网络：网络测度（二）</title>
    <link href="http://yoururl.com/2019/01/23/%E7%BD%91%E7%BB%9C%E6%B5%8B%E5%BA%A6%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <id>http://yoururl.com/2019/01/23/网络测度（二）/</id>
    <published>2019-01-22T16:01:00.000Z</published>
    <updated>2019-01-28T13:07:45.754Z</updated>
    
    <content type="html"><![CDATA[<h2 id="结点群组"><a href="#结点群组" class="headerlink" title="结点群组"></a>结点群组</h2><h3 id="团-clique"><a href="#团-clique" class="headerlink" title="团(clique)"></a>团(clique)</h3><ul><li><p>定义：指无向网络中的一个最大结点子集，在该子集中任何两个结点之间都有一条边直接相连。</p><blockquote><p>“最大”指在保证子集内每两个结点都直接相连的条件下，网络中其他结点无法再加入该子集中。</p><p>团的存在表明网络中存在一个联系紧密的子群。</p></blockquote></li></ul><h3 id="k-团-k-clique"><a href="#k-团-k-clique" class="headerlink" title="k-团(k-clique)"></a>k-团(k-clique)</h3><ul><li><p>定义：结点的一个最大子集，该子集中各个结点之间通过网络边的距离不超过$k$。</p><blockquote><p>当$k=1$时，该定义与团的原始定义一样；</p><p>但$k-团$的定义并不严谨，定义并不要求结点之间的路径全在子集中。若要求路径只能在子集中，得到的结果就是$k-党派$或$k-俱乐部$。两者的区别在于是否强制要求结点之间的路径只能在群组内部，或者是否先找到$k-团$，然后在此基础上删除那些有外部路径的团，这两种情况的最终结果可能不同。</p></blockquote></li></ul><h3 id="k-丛-k-plex"><a href="#k-丛-k-plex" class="headerlink" title="k-丛 (k-plex)"></a><strong>k-丛</strong> (k-plex)</h3><ul><li><p>定义：大小为$n$的$k-丛$是网络中结点数为$n$的最大子集，该子集的每个结点都至少和子集中另外$n-k$个结点相连。</p><blockquote><p>$k-丛$ 确定了网络的结点数$n$;</p><p>当$k=1$时，与最初定义的团相符，即$1-丛$就是通常意义上的团。</p><p>团思想的一般性表达：可以指定每一个结点与一定比例的其他成员有联系。</p></blockquote></li></ul><h3 id="k-核-k-core"><a href="#k-核-k-core" class="headerlink" title="k-核(k-core)"></a>k-核(k-core)</h3><ul><li><p>定义：$k-核$是网络结点的一个最大子集，该子集中每个结点至少与子集中$k$个其他结点相连。</p><blockquote><p>$k-核$不确定网络的结点数；</p><p>当子集结点数为$n$时，$k-核$与$(n-k)-丛$是相同的。</p><p>但给定$k$值的所有$k-核$的集合与$k-丛$的集合并不相等，因为不同的$k-核$的子集结点数$n$不同。</p><p>与$k-丛$不同，$k-核$彼此之间不能重合，根据定义，若两个$k-核$彼此共享同一个或多个结点，就可以合并生成一个更大的$k-核$。</p><p>寻找网络中的$k-核$的简单算法：从整个网络开始，将度数小于$k$的结点不断删除，此时会使网络中一些其他结点（即那些刚刚与删除结点相连的结点）度数减小。然后继续检查网络，删除度数小于$k$的结点，依次重复不断删除网络中度数小于$k$的结点，直到不存在这样的结点。此时剩下的网络就是一个$k-核$或$k-核$的集合。</p></blockquote></li></ul><h3 id="k-分支-k-component"><a href="#k-分支-k-component" class="headerlink" title="k-分支(k-component)"></a>k-分支(k-component)</h3><p>无向网络的分支是网络结点的一个最大子集，该子集中的结点彼此间通过特定路径相连。</p><ul><li><p>定义1：$k-分支$有时也称$k-连通分支$，是网络结点的一个最大子集，该子集中的结点彼此之间能够通过至少$k$条结点独立路径相连。</p><blockquote><p>若两条路径之间除了起点与终点之外，没有共享的结点，那么这两条路径是结点独立路径。</p><p>对于$k=2$或$k=3$的情况，分别称为<strong>二分支</strong>和<strong>三分支</strong>。</p></blockquote></li><li><p>定义2：$k-分支$是网络结点的一个最大子集，若将该子集中的任意两个结点之间的连接断开，至少需要删除$k$个结点。</p><blockquote><p>两个结点之间的节点独立路径数等于结点之间的结点割集大小，也就是将两个结点连接断开需要删除的结点数。</p></blockquote></li></ul><p>$k-分支$的思想与网络鲁棒性相关联。例如在一个Internet的数据网络中，两个结点之间的结点独立路径数同时也是这两个结点之间数据传输的独立路由数，它们之间割集的规模就是切断这两个终端之间数据传输时需要舍弃或去除的网络结点（路由器）数量。</p><blockquote><p>这样，由两条边独立路径相连的两个结点之间的连接不会因为单一的路由器故障而断开；由三条边独立路径相连的两个结点之间的连接不会因为任意两个路由器故障而断开。</p></blockquote><h2 id="传递性"><a href="#传递性" class="headerlink" title="传递性"></a>传递性</h2><p>网络传递性的数学表示为：若$a\circ b$和$b\circ c$，那么$a \circ c$。 在社会网络中的表述为：若$u$认识$v$，$v$认识$w$，那么在网络中存在一条由两条边构成的路径$uvw$。若$u$也认识$w$，则称该路径是闭合的，即该路径在网络中形成一个长度为3的循环，或称三角。三个结点形成一个<strong>闭合三元组</strong>。</p><h3 id="聚类系数"><a href="#聚类系数" class="headerlink" title="聚类系数"></a>聚类系数</h3><ul><li><p>定义1：网络中所有长度为2的路径中闭合路径所占的比例；</p><script type="math/tex; mode=display">C= \frac{(长度为2的路径中的闭合路径数)}{(长度为2的路径数)}</script><p>其取值范围在0到1之间。若$C=1$，则表明该网络具有完全传递性，网络中的所有分支都是团。</p><p>若$C=0$，则表明网络中没有闭合三元组，如树、正方形点阵。</p></li><li><p>定义2：考虑网络路径的方向性，经过相同结点但方向不同的两条路径需要分别统计。</p><script type="math/tex; mode=display">C= \frac{(三角形数)\times 6}{(长度为2的路径数)}</script></li><li><p>定义3：有公共邻居结点的两个结点，本身也互为邻居结点的平均概率。</p><script type="math/tex; mode=display">C=\frac{(三角形数)\times 3}{(连通三元组数)}</script><p>其中”连通三元组“是指在结点$uvw$三者之间存在边$(u,v)$和$(v,w)$，边$(u,w)$可以存在也可不存在。分子中的系数3指每个三角形中都包含3个连通三元组。</p></li></ul><h3 id="局部聚类"><a href="#局部聚类" class="headerlink" title="局部聚类"></a>局部聚类</h3><p>针对单个结点$i$的聚类系数：</p><ul><li><p>定义：</p><script type="math/tex; mode=display">C_i=\frac{（结点i的邻居结点中直接相连的结点对数）}{（结点i的邻居结点对总数）}</script><blockquote><p>结点$i$的邻居结点对总数为$\frac{1}{2} k_i(k_i-1)$, 其中$k_i$是结点$i$的度。</p><p>许多研究中发现，度较大的结点其局部聚类系数均较低。</p><p>局部聚类系数可以用于指示网络中是否存在所谓的<strong>结构洞</strong>。</p><p><img src="https://s2.ax1x.com/2019/01/26/kulc0P.png" alt="kulc0P.png"></p><p>如果关注网络中的信息或其他流量的有效传播，结构洞是有害的，因为他们会减少信息在网络中的路由数；</p><p>如果关注朋友之间的联系，结构洞对于结点$i$来说是有益的，因为结构洞使$i$在其邻居结点之间的信息流动中起到主导作用。因为如果$i$的两个朋友没有直接相连，那么他们彼此之间的信息流动就必须通过与双方都有联系的$i$，因此$i$就可以控制信息流动。</p><p>因此局部聚类系数也可以作为一种中心性测度，影响力越大的个体的局部聚类系数取值越小。</p></blockquote></li></ul><h3 id="冗余"><a href="#冗余" class="headerlink" title="冗余"></a>冗余</h3><ul><li><p>简化定义：结点$i$的冗余$R_i$是结点$i$的邻居结点之间直接连接数的平均值。</p><blockquote><p>结点冗余的最小值是0，最大值是 $k_i-1$ ；</p></blockquote><p>结点$i$ 的邻居结点之间的平均连接数为$R_i$，直接连接总数为$\frac{1}{2}k_i R_i$，邻居结点对的总数为$\frac{1}{2}k_i(k_i-1)$。 </p><p>局部聚类系数与冗余的关系：</p><script type="math/tex; mode=display">C_i= \frac{\frac{1}{2}k_iR_i}{\frac{1}{2}k_i(k_i-1)} = \frac{R_i}{k_i-1}</script><p>全局聚类系数：利用所有结点的局部聚类系数均值计算整个网络的聚类系数：</p><script type="math/tex; mode=display">C_{WS}= \frac{1}{n} \sum_{i=1}^n C_i</script></li></ul><h2 id="相互性"><a href="#相互性" class="headerlink" title="相互性"></a>相互性</h2><p>相互性度量了有向图中长度为2的闭合循环的频率，该频率描述了两个结点之间相互指向的概率。</p><blockquote><p>如果结点$v$和结点$u$相连接，$u$通过连接到$v$来表现出相互性。</p></blockquote><ul><li><p>定义：相互性$r$被定义为所有边中相互边所占的比例。</p><p>当且仅当结点$i$到$j$有双向边时，邻接矩阵中元素的乘积$A<em>{ij}A</em>{ji}$为1，否则为0。通过对所有结点对求和，得到相互性的计算表达：</p><script type="math/tex; mode=display">r = \frac{1}{m} \sum_{ij} A_{ij}A_{ji} = \frac{1}{m} {\bf Tr A^2}</script><p>其中，$m$为网络中有向边的总数。</p></li></ul><h2 id="有符号边和结构平衡"><a href="#有符号边和结构平衡" class="headerlink" title="有符号边和结构平衡"></a>有符号边和结构平衡</h2><p>可利用有向图来表示社交网络中各结点之间的关系，如朋友或敌对关系。每条边只有两种情况，+边代表朋友关系，-边代表敌对关系。这样的网络称为<strong>有符号网络</strong>，其边为<strong>有符号边</strong>。</p><p><img src="https://s2.ax1x.com/2019/01/27/kKeYfs.png" alt="kKeYfs.png"></p><p>上图两种稳定组合（a、b）与两种不稳定组合（c、d）的差别是，稳定组合的循环中有偶数个负号。</p><ul><li><p>推广：</p><ul><li><p>定义：网络若只包含带有偶数个负号的循环，则称其<strong>结构平衡</strong>。</p></li><li><p>推论：一个平衡网络能够被划分为若干个连通结点群组，且群组内结点之间的连接都是正的，而不同群组之间的连接都是负的。</p><blockquote><p>群组可由单个结点组成，也可由多个结点组成；群组可以是一个，也可以是多个；</p><p><img src="https://s2.ax1x.com/2019/01/27/kKnLef.png" alt="kKnLef.png"></p><p>能像上述划分成群组的网络被认为是<strong>可聚类的</strong>。 </p><p>网络中每个循环都包含偶数个负号。虚线表示将网络划分为不同的群组。</p><p>为网络中的结点涂色，结点的颜色只有两种情况，从任意一个结点开始，根据一下算法为结点涂色：</p><ol><li>如果结点$v$与$u$有一条正连接，且$u$已经涂上了颜色，那么$v$的颜色与$u$相同；</li><li>如果结点$v$与$u$有一条负连接，且$u$已经涂上了颜色，那么$v$的颜色与$u$相反；</li></ol><p>如果在为网络涂色时遇到一个已经涂上颜色的结点，说明在网络中一定还存在另一条从起点到达该结点的路径，因此在网络中至少存在一个或多个包含该结点的循环。如果网络是平衡的，该结点所属的每个循环就一定有偶数条负边。如果该结点的颜色与将要涂的颜色有冲突，那么网络必然是不平衡的。</p></blockquote></li></ul></li></ul><ul><li><p>注意：</p><blockquote><p>可聚类定理的逆定理并不成立，例如下面的网络：</p><p><img src="https://s2.ax1x.com/2019/01/27/kKuytg.png" alt="kKuytg.png"></p><p>上述网络有三个结点，三个结点之间彼此敌对，因此网络循环中有奇数条负边，但可以将该网络分为三个不同的群组，每个结点构成一个群组。该网络可聚类，但不平衡。</p></blockquote></li></ul><h2 id="相似性"><a href="#相似性" class="headerlink" title="相似性"></a>相似性</h2><p>考虑如何利用网络结构中包含的信息来确定网络中的结点之间的相似性。</p><p>构造网络相似性测度的两种基本方法：</p><ul><li>结构等价：<strong>两个结点间共有邻居结点的数量</strong>定义了两结点之间的相似程度；</li><li>规则等价：通过比较<strong>两个结点的邻居结点的相似程度</strong>来确定结点间的相似度，而不是通过共有的邻居结点来确定的；</li></ul><p><img src="https://s2.ax1x.com/2019/01/27/kKNn9P.png" alt="kKNn9P.png"></p><h3 id="结构等价"><a href="#结构等价" class="headerlink" title="结构等价"></a>结构等价</h3><h4 id="余弦相似性"><a href="#余弦相似性" class="headerlink" title="余弦相似性"></a>余弦相似性</h4><p>在<strong>无向网络</strong>中，结点$i$和$j$的共享邻居结点数表示为$n_{ij}$，则有</p><script type="math/tex; mode=display">n_{ij}=\sum_k A_{ik} A_{kj}</script><blockquote><p>考虑一种归一化的方法，来合理定义相似性：不仅需要考虑网络的结点总数，也要考虑目标结点的度。</p><p><strong>余弦相似性（Salton 余弦）</strong>: 将邻接矩阵的第$i$行和第$j​$行看成两个向量，将两个向量之间的夹角余弦值用于相似性度量。</p><p>无向网络中对应邻接矩阵中两行的点积就是 $\sum<em>k A</em>{ik} A_{kj}$ ；</p></blockquote><p>因此相似性测度是：</p><script type="math/tex; mode=display">\sigma_{ij} = \cos\theta = \frac{\sum_k A_{ik}A_{kj}}{\sqrt{\sum_k A_{ik}^2} \sqrt{\sum_k A_{jk}^2}}</script><p>假设网络是无权无向网络， 因此 $\forall i,j$ ,   有 $A<em>{ij}^2 = A</em>{ij}$ , 即 $\sum<em>k A</em>{ik}^2 = \sum<em>k A</em>{ik} =k_i$ ，其中 $k_i$ 是结点 $i$ 的度。</p><p>于是：</p><script type="math/tex; mode=display">\sigma_{ij} = \frac{\sum_k A_{ik} A_{kj}}{\sqrt{k_i k_j}} = \frac{n_{ij}}{\sqrt{k_i k_j}}</script><p>因此， 结点$i$和结点$j$的余弦相似性就是<strong>两个结点的共同邻居结点数与它们各自度的几何平均数的商</strong> 。</p><blockquote><p>严格来讲，若两个结点或其中一个结点的度为0，那么它们的余弦相似性就无定义， $\sigma_{ij} = 0$。</p></blockquote><h4 id="Jaccard-相似性"><a href="#Jaccard-相似性" class="headerlink" title="Jaccard 相似性"></a>Jaccard 相似性</h4><ul><li>定义：结点$i$和结点$j$ 的<strong>共同邻居结点数与它们所有邻居节点数的商</strong>。<script type="math/tex; mode=display">\sigma_{Jaccard}(i,j) = \frac{|N(i) \cap N(j)|}{|N(i) \cup N(j)|} = \frac{\sum_k A_{ik} A_{kj}}{k_i + k_j - \sum_k A_{ik} A_{kj}}</script></li></ul><h4 id="皮尔逊相关系数"><a href="#皮尔逊相关系数" class="headerlink" title="皮尔逊相关系数"></a>皮尔逊相关系数</h4><p>对共享邻居结点数进行归一化的另一种方法是：</p><p><strong>将其与一个期望值进行比较，该期望值是指网络中的结点随机选择邻居结点的条件下，共享邻居结点数的期望值。</strong></p><p>假设结点$i$和结点$j$各自的度是$k_i$和$k_j$，两个结点完全随机选取邻居结点。结点$i$从网络$n$个结点中（在不包含自环的网络中，是从$n-1$个结点中选取，但对于大规模网络而言，误差忽略不计）随机均匀选取$k_i$个结点作为邻居结点，每个结点成为结点$i$邻居结点的概率为 $k_i /n$ ，结点$j$有$k_j$个邻居结点，则结点$i$和结点$j$的共享邻居结点的期望值为 $k_i k_j /n$ 。</p><p>合理的归一化是用<strong>两个结点的实际共享邻居结点数减去随机选择邻居结点条件下两者共享邻居结点的期望值</strong>，即</p><script type="math/tex; mode=display">\sum_k A_{ik} A_{jk} - \frac{k_i k_j}{n} = \sum_k A_{ik} A_{jk} - n \frac{1}{n} \sum_k A_{ik} \frac{1}{n} \sum_l A_{jl} \\ = \sum_k A_{ik} A_{jk} - n\langle A_i \rangle \langle A_j \rangle \\ = \sum_k [A_{ik}A_{jk} - \langle A_i \rangle \langle A_j \rangle ] \\ = \sum_k [A_{ik} A_{jk} - \langle A_i \rangle \langle A_j \rangle - \langle A_i \rangle \langle A_j \rangle + \langle A_i \rangle \langle A_j \rangle]\\ =  \sum_k [A_{ik} A_{jk} - \langle A_{ik} \rangle \langle A_j \rangle - \langle A_i \rangle \langle A_{jk} \rangle + \langle A_i \rangle \langle A_j \rangle]\\ =\sum_k(A_{ik} - \langle A_i \rangle)(A_{jk} - \langle A_j \rangle)</script><p>其中， $\langle A<em>i \rangle = \frac{1}{n} \sum_k A</em>{ik}$  。 $\sum<em>k(A</em>{ik} - \langle A<em>i \rangle)(A</em>{jk} - \langle A_j \rangle)$ 项为$A_i$和$A_j$之间的协方差，对协方差进行归一化</p><script type="math/tex; mode=display">\sigma_{pearson}(i,j) = \frac{cov(A_{i},A_{j})}{\sigma_i \sigma_j} = \frac{\sum_k(A_{ik} - \langle A_i \rangle)(A_{jk} - \langle A_j \rangle)}{\sqrt{\sum_k(A_{ik} - \langle A_i \rangle)^2} \sqrt{\sum_k(A_{jk} - \langle A_j \rangle)^2} }</script><p>取值范围介于 $[-1,1]$ 之间，正值表示当结点$i$将结点$j$作为朋友时，结点$j$也可能将结点$i$当作朋友。负值相反，零值表示无线性关系。</p><h4 id="除以期望值"><a href="#除以期望值" class="headerlink" title="除以期望值"></a>除以期望值</h4><p>通过除以期望值来对两个结点的共享邻居结点数$n_{ij}$进行归一化，</p><script type="math/tex; mode=display">\frac{n_{ij}}{k_i k_j /n} = n \frac{\sum_k A_{ik} A_{jk}}{\sum_k A_{ik} \sum_k A_{jk}}</script><h4 id="欧几里得距离"><a href="#欧几里得距离" class="headerlink" title="欧几里得距离"></a>欧几里得距离</h4><ul><li>定义：两个结点之间邻居结点数的差值。<script type="math/tex; mode=display">d_{ij} = \sum_k (A_{ik} -A_{jk})^2</script>归一化：<script type="math/tex; mode=display">\frac{\sum_k (A_{ik} -A_{jk})^2}{k_i +k_j} = \frac{\sum_k (A_{ik} +A_{jk} -2A_{ik}A_{jk})}{k_i +k_j} = 1-2 \frac{n_{ij}}{k_i +k_j}</script></li></ul><h3 id="规则等价"><a href="#规则等价" class="headerlink" title="规则等价"></a>规则等价</h3><p>基本思想是：若结点$i$和结点$j$各自的邻居结点$k$和$l$本身具有较高的相似性，则$i$和$j$的相似性也较高。</p><p><img src="https://s2.ax1x.com/2019/01/28/kKXsZ6.png" alt="kKXsZ6.png"></p><ul><li><p>原始式： 结点$i$和结点$j$各自的邻居结点$k$和$l$本身具有较高的相似性，则$i$和$j$的相似性也较高。</p><script type="math/tex; mode=display">\sigma_{ij} = \alpha \sum_{kl} A_{ik} A_{jl} \sigma_{kl}   \\ \Longleftrightarrow \\{\bf σ = \alpha A σ  A}</script><p>赋予结点“自相似性”，引入对角元项：</p><script type="math/tex; mode=display">\sigma_{ij} = \alpha \sum_{kl} A_{ik} A_{jl} \sigma_{kl} + \delta_{ij}  \\ \Longleftrightarrow \\{\bf σ = \alpha A σ  A + I}</script><blockquote><p>存在问题：</p><p>假设可通过重复迭代求解，首先确定初始值 ${\bf σ^{(0)}=0}$，迭代结果为：</p><script type="math/tex; mode=display">{\bf σ^{(1)} = I}  \\{\bf σ^{(2)} = \alpha A^2 + I}  \\{\bf σ^{(3)} = \alpha^2 A^4 + \alpha A^2 +I}  \\</script><p>多次迭代取极限后，得到的邻接矩阵的偶数次幂的总和。因此该相似性测度本质上式结点之间偶数长度的路径数的加权和。</p></blockquote></li></ul><ul><li><p>放宽式： 如果结点$i$的邻居结点$k$与结点$j$相似，那么$i$与$j$相似。</p><p>同时再次考虑“自相似性”：</p><script type="math/tex; mode=display">\sigma_{ij} = \alpha \sum_k A_{ik} \sigma_{kj} + \delta_{ij}  \\  \Longleftrightarrow{\bf σ=\alpha A σ + I}</script></li></ul><blockquote><p>利用反复迭代的方法进行求解得：</p><script type="math/tex; mode=display">{\bf σ^{(1)} = I}  \\{\bf σ^{(2)} = \alpha A + I}  \\{\bf σ^{(3)} = \alpha^2 A^2 + \alpha A +I}  \\</script><p>当迭代次数无穷大时，得到</p><script type="math/tex; mode=display">{\bf σ = \sum_{m=0}^{\infty} (\alpha A)^m = (I-\alpha A)^{-1}}</script><p>至此，相似性测度包括了所有长度的路径数，实际上，该相似性公式计算结点$i$和$j$之间的所有路径加权数值，长度为$r$的路径权重为$\alpha^r$。 由于$\alpha &lt;1$，因此路径越长权重越小。</p></blockquote><p>  上述相似性测度倾向于赋予那些度较大的结点以较高的相似性，但这存在以下问题：</p><blockquote><ol><li>相比于朋友较少的人，朋友更多的人被认为与其他人更相似；（度较大）</li><li>两个没有朋友的隐士在某种程度上也有一定相似性；（度较少）</li></ol></blockquote><p>  因此，将相似性除以结点的度，来避免因偏向高度数结点而导致的偏差：</p><script type="math/tex; mode=display">  \sigma_{ij} = \frac{\alpha}{k_i} \sum_k A_{ik} \sigma_{kj} + \delta_{ij}   \\ \Longleftrightarrow \\  {\bf σ=\alpha D^{-1} A σ + I}</script><p>  其中， ${\bf D}$ 是元素为 $D_{ii} = k_i$ 的对角矩阵。</p><script type="math/tex; mode=display">  {\bf σ=(I-\alpha D^{-1} A)^{-1} = (D-\alpha A)^{-1} D}</script><h2 id="同质性和同配混合"><a href="#同质性和同配混合" class="headerlink" title="同质性和同配混合"></a>同质性和同配混合</h2><p>人们倾向于选择那些他们认为与其自身在某些方面相似的人作为朋友，这种倾向性称为<strong>同质性</strong>或者<strong>同配混合</strong></p><p>。</p><h3 id="依据离散特征的同配混合"><a href="#依据离散特征的同配混合" class="headerlink" title="依据离散特征的同配混合"></a>依据离散特征的同配混合</h3><p>网络结点根据某个特征分类，且该特征的取值是一个有限集合，且特征无序。</p><p>首先找出连接同类结点的边所占的比例，然后减去在不考虑结点类型时，随机连接的边中，连接两个同类结点的边所占比例的期望值。</p><p>令$c_i$表示结点$i$的类型，类型用整数值$1,…,n$表示，其中$n_c$是结点类型总数，那么同类结点之间的边数总和表示为</p><script type="math/tex; mode=display">\sum_{边(i,j)} \delta(c_i,c_j) = \frac{1}{2} \sum_{ij} A_{ij} \delta(c_i,c_j)</script><p>其中$\delta(m,n)$是克罗内克$\delta$函数，将系数设定为$\frac{1}{2}$，是因为结点$i,j$之间的边被计算了两次。</p><p>计算随机条件下同类结点之间边的期望值，考虑连接到结点$i$的一条特定边，该结点的度为$k_i$。根据定义，整个网络中有$2m$个边的端点，其中$m$是边总数，若所有连接都是随机的，特定边两端分别连接到度为$k_i$的结点$i$和度为 $k_j$ 的结点$j$的概率为$k_i k_j /{2m}$ 。进而同类结点之间的边期望值为：</p><script type="math/tex; mode=display">\frac{1}{2} \sum_{ij} \frac{k_i k_j}{2m} \delta (c_i, c_j)</script><p>网络中同类结点之间边的实际值与期望值之差为：</p><script type="math/tex; mode=display">\frac{1}{2} \sum_{ij} A_{ij} \delta(c_i,c_j) - \frac{1}{2}\sum_{ij} \frac{k_i k_j}{2m} \delta(c_i,c_j) = \frac{1}{2} \sum_{ij} (A_{ij} - \frac{k_i k_j}{2m}) \delta(c_i,c_j)</script><p> 计算比例：</p><script type="math/tex; mode=display">Q = \frac{1}{2m} \sum_{ij} (A_{ij} - \frac{k_i k_j}{2m}) \delta(c_i,c_j)</script><p>$Q$ <strong>为模块度，用来度量网络中同类结点之间的连接程度</strong> 。$Q$值为正说明网络是同配混合的，$Q$值为负说明网络是异配混合的。</p><p>式中变量 $B<em>{ij} = A</em>{ij} - \frac{k_i k_j}{2m}$ 可构造模块度矩阵$\bf B$。</p><blockquote><p>模块度$Q$值总小于1，根据网络中群组的规模和结点度数，$Q$的最大值可能会远小于1。需要对$Q$值进行归一化。</p></blockquote><p>在全同配混合网络中，边所连接的结点都是同类结点，因此若$A_{ij}=1$，则$\delta (c_i,c_j)=1$。 意味着式(28)第一项和为$2m$，全同配混合网络模块度值为</p><script type="math/tex; mode=display">Q_{max} = \frac{1}{2m} (2m - \sum_{ij} \frac{k_i k_j}{2m} \delta(c_i,c_j))</script><p>模块度归一化值为：</p><script type="math/tex; mode=display">\frac{Q}{Q_{max}} = \frac{\sum_{ij} (A_{ij} - k_i k_j /2m) \delta(c_i,c_j)}{2m - \sum_{ij}(k_i k_j /2m)\delta(c_i,c_j)}</script><p>该变量有时称为同配系数，对于全同配混合网络，该变量取最大值为1。</p><ul><li><p>模块度的另一种形式：</p><ul><li><p>连接类型$r$和类型$s$的结点的边所占的比例：</p><script type="math/tex; mode=display">e_{rs} = \frac{1}{2m} \sum_{ij} A_{ij} \delta(c_i,r) \delta(c_j,s)</script></li><li><p>连接到类型$r$的结点的边所占的比例：</p><script type="math/tex; mode=display">\delta(c_i,c_j) = \sum_r \delta(c_i,r) \delta(c_j, r)</script></li><li></li></ul><script type="math/tex; mode=display">\delta (c_i,c_j) = \sum_r \delta(c_i,r) \delta(c_j, r)</script><p>推导得</p><script type="math/tex; mode=display">Q = \frac{1}{2m} \sum_{ij} (A_{ij}-\frac{k_i k_j}{2m}) \sum_r \delta(c_i,r) \delta(c_j,r) \\ = \sum_r [\frac{1}{2m} \sum_{ij} A_{ij} \delta(c_i,r) \delta(c_j,r) - \frac{1}{2m} \sum_i k_i \delta(c_i,r) \frac{1}{2m} \sum_j k_j \delta(c_j, r)] \\= \sum_r (e_{rr} - a_r^2)</script><blockquote><p>这种模块度形式适用于 当网络数据包括边列表和边端点所对应的结点类型，但不包含结点度的确切信息的情况。</p></blockquote></li></ul><h3 id="依据标量特征的同配混合"><a href="#依据标量特征的同配混合" class="headerlink" title="依据标量特征的同配混合"></a>依据标量特征的同配混合</h3><p>标量特征具有确定的顺序，根据标量的数值，可以指出两个结点在什么情况下是完全相同的，也可指出在什么情况下是近似相同的。若网络中的结点在有某种标量特征的值相似时连接在一起，而当值不同时则较少连接在一起，那么认为该网络是依据该标量特征同配混合的。也可以称该网络是依据该标量特征<strong>分层</strong>的。</p><p>利用协方差：</p><ul><li>$x_i$ : 结点$i$的标量值；</li><li><p>$(x_i,x_j)$：网络中每条边$(i,j)​$的两个端点值；</p></li><li><p>$\mu$：某条边的端点值$x_i​$的均值；</p></li></ul><script type="math/tex; mode=display">\mu = \frac{\sum_{ij} A_{ij}x_i}{\sum_{ij}A_{ij}} = \frac{\sum_i k_i x_i}{\sum_i k_i} = \frac{1}{2m} \sum_i k_ix_i</script><p>该均值对所有边取平均。$x_i$与$x_j$对所有边的协方差为;</p><script type="math/tex; mode=display">cov(x_i,x_j) = \frac{\sum_{ij} A_{ij}(x_i -\mu)(x_j -\mu)}{\sum_{ij} A_{ij}} \\ = \frac{1}{2m} \sum_{ij} A_{ij} (x_ix_j - \mu x_i - \mu x_j + \mu^2) \\= \frac{1}{2m} \sum_{ij} A_{ij}x_ix_j - \mu^2 \\= \frac{1}{2m} \sum_{ij} A_{ij}x_ix_j - \frac{1}{(2m)^2} \sum_{ij} k_i k_j x_i x_j \\= \frac{1}{2m} \sum_{ij} (A_{ij} - \frac{k_ik_j}{2m}) x_ix_j</script><p>当一条边的两个端点$x_i,x_j$同时为大或同时为小时，协方差为正；一大一小时协方差为负。即，当同配混合时协方差为正，异配混合时协方差为负。</p><p>归一化可以使网络全同配混合时网络测度为1，所谓全同配混合是指网络中所有边都位于值为$x_i$的结点之间。令$x_j=x_i$，给出全同配混合网络的协方差值为：</p><script type="math/tex; mode=display">\frac{1}{2m} \sum_{ij} (A_{ij}x_i^2 - \frac{k_ik_j}{2m}x_ix_j) = \frac{1}{2m} \sum_{ij} (k_i \delta_{ij} - \frac{k_ik_j}{2m})x_ix_j</script><p>归一化：</p><script type="math/tex; mode=display">r= \frac{\sum_{ij} (A_{ij}-k_ik_j/2m)x_ix_j}{\sum_{ij} (k_i \delta_{ij} - k_ik_j/2m)x_ix_j}</script><h3 id="依据度的同配混合"><a href="#依据度的同配混合" class="headerlink" title="依据度的同配混合"></a>依据度的同配混合</h3><p>依据度的同配混合是依据标量特征的同配混合的一个特例，且受到特别关注。</p><p>依据度的同配混合网络中，高度数的结点倾向于与其他高度数结点相连；低度数的结点倾向于与其他低度数结点相连。</p><p>同配网络中，度数大的结点倾向于聚集在一起的网络中，我们希望得到网络中这些度数大的结点构成的结点块或核，他们周围是一些度小的结点构成的低密度<strong>边缘</strong>。这种<strong>核心/边缘结构</strong>是社会网络的普遍特征。</p><p>异配网络中，度数大的结点倾心于与度数小的结点连接，由此在网络中形成明显的星形结构特征。异配网络通常不具有核心/边缘特征，但结点分布更均匀。</p><p>依据度的同配混合同样可以通过标量特征方法进行度量。</p><script type="math/tex; mode=display">cov(k_i,k_j) = \frac{1}{2m} \sum_{ij} (A_{ij} - \frac{k_ik_j}{2m}) k_ik_j</script><p>利用协方差最大值进行归一化，</p><script type="math/tex; mode=display">r= \frac{\sum_{ij} (A_{ij}-k_ik_j/2m)k_i k_j}{\sum_{ij} (k_i \delta_{ij} - k_ik_j/2m)k_i k_j}</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;结点群组&quot;&gt;&lt;a href=&quot;#结点群组&quot; class=&quot;headerlink&quot; title=&quot;结点群组&quot;&gt;&lt;/a&gt;结点群组&lt;/h2&gt;&lt;h3 id=&quot;团-clique&quot;&gt;&lt;a href=&quot;#团-clique&quot; class=&quot;headerlink&quot; title=&quot;团
      
    
    </summary>
    
      <category term="复杂网络" scheme="http://yoururl.com/categories/%E5%A4%8D%E6%9D%82%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Networks" scheme="http://yoururl.com/tags/Networks/"/>
    
  </entry>
  
  <entry>
    <title>知识图谱：知识表示之Transparse模型</title>
    <link href="http://yoururl.com/2019/01/20/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA%E4%B9%8BTransparse/"/>
    <id>http://yoururl.com/2019/01/20/知识表示之Transparse/</id>
    <published>2019-01-19T16:09:00.000Z</published>
    <updated>2019-03-05T03:08:55.371Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Transparse"><a href="#Transparse" class="headerlink" title="Transparse"></a>Transparse</h1><p>论文地址：<a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11982/11693" target="_blank" rel="noopener">http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11982/11693</a></p><h2 id="模型改进"><a href="#模型改进" class="headerlink" title="模型改进"></a>模型改进</h2><p>KG中面临的两个主要问题，分别是 <strong>Heterogeneity（异构性）</strong>和 <strong>Imbalance（不平衡性）</strong>：</p><ul><li>Heterogeneity： 知识图谱中不同关系连接的实体（节点）数量不同；</li><li>Imbalance：同一关系连接的头尾实体（节点）数量不同；</li></ul><p><img src="https://s2.ax1x.com/2019/03/05/kXgFhT.png" alt="kXgFhT.png"></p><blockquote><p>上图展示了子图FB15k的数据结构，可以看出：</p><ul><li>不同关系的复杂性差异很大；</li><li>不平衡关系在知识图谱中占了很大比例；</li></ul><p>早期模型未关注这两个问题，用同样的方法构建关系。</p><p><strong>异构性可能导致简单或复杂关系的过拟合；关系的不平衡性表明平等的对待头尾实体是不合理的；</strong></p></blockquote><p>因此提出了两种模型来解决这两个问题：</p><p>为克服异质性，我们提出了一种<strong>TranSparse(share)</strong>模型，其中转移矩阵的稀疏程度由关系所链接的实体对的数量决定，关系的两边共享相同的转移矩阵。其中，复杂关系的转移矩阵要比简单关系的转移矩阵稀疏。</p><p>为克服不平衡性，对TranSparse(share)模型修改，提出了<strong>TranSparse(separate)</strong>模型，该模型中每个关系有两个分离稀疏转移矩阵，一个对头部实体一个对尾部实体，稀疏程度由关系连接的实体数量决定。</p><blockquote><p><strong>Sparse Matrix</strong>：稀疏矩阵中大多数元素为0，0元素占总元素的比例称为稀疏程度（$\theta$）,用$M(\theta)$表示稀疏程度为 $\theta​$ 的矩阵，稀疏矩阵更容易压缩，需要更少的存储空间，且只有非零元参与计算，减少计算复杂度。下图展示了结构化和非结构化数据：</p><p><img src="https://s2.ax1x.com/2019/03/05/kXgVc4.png" alt="kXgVc4.png"></p><p>结构化模式有助于向量矩阵运算，而非结构化模式则不是。因此，结构化模式可以使我们的模型更容易地扩展到大型知识图，而非结构化模式更多的用在其他文献中，有更好的实验结果。</p></blockquote><blockquote><p><strong>稀疏矩阵 VS 低秩矩阵</strong></p><p>我们需要分别使用自由度高和自由度低的矩阵来学习复杂关系和简单关系。权重矩阵的自由度是指独立变量的个数。对于权矩阵M，低秩和稀疏都可以降低自由度，因为它们都是对M的约束。具体来说，低秩强制一些变量满足特定的约束，使得M中的变量不能被自由分配。这样，自由度就降低了。对于稀疏矩阵，我们让一些元素为零，在训练过程中不改变它们的值，另一些元素为自由变量，可以通过训练来学习。因此，自由度就是通过训练学会的变量的数量。但是稀疏矩阵更适合我们的任务有两个原因：</p><ul><li>稀疏矩阵比低秩矩阵更灵活，假设 $M \in {\Bbb R^{m<em>n} }$,  $rank(M) \leq \min (m,n)$ 。 因为秩能控制自由度（$m</em>n$矩阵秩为$k$，有自由度 $k(m+n)-k^2$ ），如果用低秩去控制自由度，只能获得 $\min (m,n)$个低秩矩阵；若用稀疏矩阵去控制自由度，能获得 $m*n$ 个稀疏矩阵；</li><li>稀疏矩阵比低秩矩阵更高效。稀疏矩阵中仅非零元参与计算，减少了计算复杂度。而且稀疏矩阵更容易迁移到大型知识图谱上； </li></ul></blockquote><h3 id="TranSparse"><a href="#TranSparse" class="headerlink" title="TranSparse"></a>TranSparse</h3><h4 id="TranSparse-share"><a href="#TranSparse-share" class="headerlink" title="TranSparse(share)"></a>TranSparse(share)</h4><ul><li><p>$M_r(\theta_r)$：转移矩阵；</p></li><li><p>$\bf r$：每个关系$r$的转移向量；</p></li><li><p>$N_r$：关系$r$连接的实体对数量；</p></li><li><p>$N_{r^*}$：$N_r$中最大的数量；</p></li><li><p>$\theta_{min}$：$M_{r^*}$的最小稀疏度，为一个超平面，$0 \leq \theta_{min} \leq 1$;</p><p>转移矩阵的稀疏度被定义为：</p><p>$$<br>\theta_r = 1-(1-\theta_{min})N_r/N_{r^*}<br>$$</p><p>投影向量：</p><p>$$<br>{\bf h}_p = {\bf M}_r(\theta_r){\bf h} \<br>{\bf t}_p = {\bf M}_r(\theta_r){\bf t}<br>$$</p><p>其中：$M_r(\theta_r) \in {\Bbb R^{m*n} }$, ${\bf h,t} \in {\Bbb R^n}$, ${\Bbb h}_p, {\Bbb t}_p \in {\Bbb R^m}$.</p></li></ul><h4 id="TranSparse-separate"><a href="#TranSparse-separate" class="headerlink" title="TranSparse(separate)"></a>TranSparse(separate)</h4><ul><li><p>$M_r^h(\theta_r^h), M_r^t(\theta_r^t)$：头尾实体转移矩阵；</p></li><li><p>$N_r^l (l=h,t)$：关系$r$下$l$对应实体的数量；</p></li><li><p>$N_{r^<em>}^{l^</em>}$ : $N_r^l$ 中最大数量；</p></li><li><p>$\theta_{min}$ : $M_{r^<em>}^{l^</em>}$ 的最小稀疏度，$0 \leq \theta_{min} \leq 1$;</p><p>转移矩阵的稀疏度被定义为：</p></li></ul><p>$$<br>\theta_r^l = 1-(1-\theta_{min})N_r^l/N_{r^<em>}^{l^</em>}   ; (l=h,t)<br>$$</p><p>​    投影向量：<br>$$<br>{\bf h}_p = {\bf M}_r^h(\theta_r^h){\bf h} \<br>{\bf t}_p = {\bf M}_r^t(\theta_r^t){\bf t}<br>$$<br>​    其中：$M_r^h(\theta_r^h), M_r^t(\theta_r^t)\in \Bbb R^{m*n}$  .</p><p>以上两种模型的得分函数是：<br>$$<br>f_r({\bf h,t})= ||{\bf h_p+ r -t_p}||_{l_{1/2} }^2<br>$$<br>​    其中 ${\bf r} \in {\Bbb R^m}$。</p><h2 id="训练对象"><a href="#训练对象" class="headerlink" title="训练对象"></a>训练对象</h2><p>用 $(h_i,r_i,t_i) (i=1,2,…)$ 表示第 $i$ 个三元组，标签 $y_i$ 代表了三元组的正负情况， 正样本和负样本分别表示为 $\Delta ={(h_i, r_i,t_i) | y_i=1}$ 和  $\Delta’ ={(h_i, r_i,t_i) | y_i=0}$, 知识图谱仅编码正样本。因此将负样本集合构建为<br>$$<br>\Delta’ = {(h_i’,r_i,t_i)|h_i’ \neq h_i \wedge y_i = 1} \cup {(h_i,r_i,t_i’)|t_i’ \neq t_i \wedge y_i = 1 }<br>$$</p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>$$<br>L =\sum_{(h,r,t)\in\Delta} \sum_{(h’,r,t’)\in\Delta’} [\gamma+f_r({\bf h,t})-f_r(\bf h’,t’)]_+<br>$$</p><p>​    约束限制： $||{\bf h}||_2 \leq 1, ||{\bf r}||_2 \leq 1, ||{\bf t}||_2 \leq 1, ||{\bf h}_p||_2 \leq 1, ||{\bf t}_p||_2 \leq 1$</p><h2 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h2><p>对于转移矩阵 ${\bf M(\theta)} \in {\Bbb R}^{n \times n}$ , 有 $nz=[\theta \times n \times n]$ 个非零元素 </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Transparse&quot;&gt;&lt;a href=&quot;#Transparse&quot; class=&quot;headerlink&quot; title=&quot;Transparse&quot;&gt;&lt;/a&gt;Transparse&lt;/h1&gt;&lt;p&gt;论文地址：&lt;a href=&quot;http://www.aaai.org/ocs/
      
    
    </summary>
    
      <category term="知识图谱" scheme="http://yoururl.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="Knowledge graph" scheme="http://yoururl.com/tags/Knowledge-graph/"/>
    
  </entry>
  
  <entry>
    <title>知识图谱：知识表示之HyTE模型</title>
    <link href="http://yoururl.com/2019/01/20/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA%E4%B9%8BHyTE/"/>
    <id>http://yoururl.com/2019/01/20/知识表示之HyTE/</id>
    <published>2019-01-19T16:08:00.000Z</published>
    <updated>2019-03-05T03:08:20.063Z</updated>
    
    <content type="html"><![CDATA[<h1 id="HyTE"><a href="#HyTE" class="headerlink" title="HyTE"></a>HyTE</h1><p>Hyperplane-based Temporally aware KG Embedding</p><p>论文地址：<a href="http://talukdar.net/papers/emnlp2018_HyTE.pdf" target="_blank" rel="noopener">http://talukdar.net/papers/emnlp2018_HyTE.pdf</a></p><h2 id="模型改进"><a href="#模型改进" class="headerlink" title="模型改进"></a>模型改进</h2><p>现有的 KG embedding方法很少考虑到<strong>时间</strong>维度，因为它们假设所有的三元组总是永远正确的，可是现实中很多情况下不是这样。</p><blockquote><p> For example, (Bill Clinton, presidentOf, USA) was true only from 1993 to 2001;</p></blockquote><p>考虑到三元组<strong>时效性</strong>问题，提出了 HyTE 模型，定义了三元组有效成立时间段为 <strong>temporal scopes</strong> ，这些temporal scopes随着时间的推移对许多数据集会产生影响（比如YAGO，Wikidata），可以用于：</p><ul><li>利用<strong>时间导向</strong>进行知识图谱图推理；</li><li>为缺失时间注释的事实预测 temporal scopes； </li></ul><p>考虑一个四元组 $(h,r,t,[τ_s, τ_e])$，这里的 $τ_s$ 和 $τ_e$ 分别定义了三元组成立时间段的<strong>起始</strong>与<strong>截止</strong>。TransE模型将实体和关系考虑到相同的语义空间，但是在不同的时间段，实体与关系组成的 $(h，r)$ 可能会对应到不同的尾实体  $t$ ，所以在本文的模型中，希望<strong>实体能够随不同的时间点有着不同的表示</strong>。为了达到这一目的，文中将时间表示成超平面,模型示意图如下：</p><p><img src="https://s2.ax1x.com/2019/03/05/kXg97q.png" alt="kXg97q.png"></p><blockquote><p>$e_h，e_t，e_r$，分别表示三元组中头实体，尾实体以及关系所对应的向量表示;</p><p>$τ_1$ 和 $τ_2$ 分别表示此三元组有效成立时间段的<strong>起始时间</strong>与<strong>截止时间</strong>;</p><p>$e_h(τ_1)$, $e_r(τ_1)$ 以及表示各向量在时间超平面 $τ_1$上的投影;</p><p>最终，模型通过最小化 translational distance 来完成结合时间的实体与关系的embedding学习过程。</p></blockquote><p>给定时间戳，可以将图分解为几个静态图，其中包含在各个时间步骤中有效的三元组，如：</p><p>知识图 $G$ 能被表示为 ${\Bbb {G=G_{τ<em>1} \cup G</em>{τ<em>2} \cup … \cup  G</em>{τ_T} } }$ , 其中 $τ_i, i \in 1,2,…,T$ 是离散时间点。</p><p>构建时间组成图 ${\Bbb G_τ}$ 时，对于一个四元组 $(h,r,t,[τ_s,τ_e])$ ，考虑每个在 $τ_s , τ<em>e$ 之间的时间点，该四元组为正样本。$τ$ 时刻正样本集合定义为 ${\scr D</em>τ^+}$ 。</p><p>对于 $T$ 个时间点的 KG，将会有 $T$ 个用不同法向量（$w_{t_1}, w_{t_2}, …, w_{t_T}$）表示的超平面，在超平面的帮助下将空间隔离成不同时间域。在时间 $τ$ 下有效的三元组被投影到特殊超平面 $w_τ$，在超平面上平移距离被最小化。</p><p>计算在 $w_τ$ 上的投影表示，其中 $||w_τ||_2=1$ ：</p><p>$$<br>P_τ(e_h)=e_h - (w_τ^Te_h)w_τ  \<br>P_τ(e_t)=e_t - (w_τ^Te_t)w_τ  \<br>P_τ(e_r)=e_r - (w_τ^Te_r)w_τ  \<br>$$</p><blockquote><p>向量投影</p></blockquote><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><h3 id="得分函数"><a href="#得分函数" class="headerlink" title="得分函数"></a>得分函数</h3><p>对于在时间 $τ$ 有效的正样本，希望映射满足这样的关系 ：$P_τ(e_h)=P_τ(e_r) \approx P_τ(e_t)$, 因而使用以下的得分函数：</p><p>$$<br>f_τ(h,r,t)=||P_τ(e_h)+P_τ(e_r)-P_τ(e_t)||_{l1/l2}<br>$$</p><p>在实体和关系嵌入过程中，对每个时间戳 $τ$ , 学习对应法向量 ${w_τ}_{τ=1}^T$  。</p><p>通过将三元组投影到时间超平面，我们可以将时间信息融入关系实体嵌入，利用相同的分布式表示在不同的时间点呈现不同的表达。</p><h3 id="loss函数"><a href="#loss函数" class="headerlink" title="loss函数"></a>loss函数</h3><p>$$<br>{\cal L} = \sum_{\tau \in [T]} \sum_{\tau \in \scr D_τ^+} \sum_{τ \in \scr D_τ^-} \max(0,f_τ(x)-f_τ(y)+\gamma)<br>$$</p><ul><li>$\scr D_τ^+$: 有效三元组集合，即正样本集合；</li><li>$\scr D_τ^-$: 负样本集合；</li><li>实体约束： $||e_p||_2 \leq 1, \forall p \in {\varepsilon}$              实体向量的$L_2$正则化</li><li>法向量约束：$||w_{\tau}||_2=1,\forall \tau \in [T]$      法向量归一化                </li></ul><h3 id="负样本构造"><a href="#负样本构造" class="headerlink" title="负样本构造"></a>负样本构造</h3><p>考虑了两种负样本：</p><ul><li><p><strong>Time agnostic negative sampling(TANS)</strong> </p><p><strong>与时间无关的负采样</strong>：忽略时间戳，考虑不属于KG的负样本，在时间 $τ$ 采样该负样本:<br>$$<br>\scr D_τ^- = {(h’,r,t,\tau)|h’ \in \scr {\varepsilon}, (h’,r,t) \notin \scr D^+ } \cup {(h,r,t’,\tau)|t’ \in \scr {\varepsilon} , (h,r,t’) \notin \scr D^+ }<br>$$</p></li><li><p><strong>Time dependent negative sampling(TDNS)</strong></p><p><strong>与时间相关的负采样</strong>： 考虑时间戳，考虑属于KG，但不属于特定时间戳 $\tau$ 的负样本：<br>$$<br>\scr D_τ^- = {(h’,r,t,\tau)|h’ \in \scr {\varepsilon}, (h’,r,t) \in \scr D^+，(h’,r,t,\tau) \notin \scr D_{\tau}^+ } \cup \<br>{(h,r,t’,\tau)|t’ \in \scr {\varepsilon} , (h,r,t’) \in \scr D^+, (h,r,t’,\tau) \notin \scr D_{\tau}^+ }<br>$$</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;HyTE&quot;&gt;&lt;a href=&quot;#HyTE&quot; class=&quot;headerlink&quot; title=&quot;HyTE&quot;&gt;&lt;/a&gt;HyTE&lt;/h1&gt;&lt;p&gt;Hyperplane-based Temporally aware KG Embedding&lt;/p&gt;
&lt;p&gt;论文地址：&lt;a 
      
    
    </summary>
    
      <category term="知识图谱" scheme="http://yoururl.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="Knowledge graph" scheme="http://yoururl.com/tags/Knowledge-graph/"/>
    
  </entry>
  
  <entry>
    <title>知识图谱：知识表示之TransG模型</title>
    <link href="http://yoururl.com/2019/01/20/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA%E4%B9%8BTransG/"/>
    <id>http://yoururl.com/2019/01/20/知识表示之TransG/</id>
    <published>2019-01-19T16:07:00.000Z</published>
    <updated>2019-03-05T03:07:51.671Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TransG"><a href="#TransG" class="headerlink" title="TransG"></a>TransG</h1><p>论文地址： <a href="https://arxiv.org/pdf/1509.05488.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1509.05488.pdf</a></p><h2 id="模型改进"><a href="#模型改进" class="headerlink" title="模型改进"></a>模型改进</h2><p>针对一种关系存在的多语义问题：</p><p><img src="https://s2.ax1x.com/2019/03/05/kXcqtf.png" alt="kXcqtf.png"></p><p>由上图，嵌入向量的可视化结果所示表明，一个特定的关系存在不同的簇，不同的簇表示不同的潜语义。</p><blockquote><p>例如，关系HasPart至少有两个潜在的语义:与合成相关的as(Table、HasPart、Leg)和与位置相关的as (Atlantics、HasPart、NewYorkBay)。</p><p>再例如，Freebase中，(Jon Snow, birth place, Winter Fall)和(George R. R. Martin, birth place, U.S.)分别映射到模式 ：/fictional_universe/fictional_character/place of birth  和 /people/person/place of birth，表明出生地有不同的含义。</p></blockquote><p>多关系语义的可视化</p><p><img src="https://s2.ax1x.com/2019/03/05/kXcj1g.png" alt="kXcj1g.png"></p><blockquote><p>点是正确的三元组，属于HasPart关系，而圆是不正确的。</p><p>点坐标是头部和尾部实体之间的差向量，应该靠近中心。</p><p>(a)正确的三元组很难与错误的三元组区分开来；</p><p>(b)通过应用多个语义分量，TransG 可以区分正确的三元组和错误的三元组</p></blockquote><h3 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h3><ul><li><p>提出了一种关系会因为实体对的差异存在多重语义的问题，相当于对关系进行了细化；</p></li><li><p>提出了一种新的<strong>贝叶斯非参数无限混合嵌入模型TransG</strong>。该模型可以自动发现关系的语义集群，并利用多个关系分量的混合来转换实体对;</p></li></ul><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>模型生成过程：</p><ul><li><p>对一个实体 $e \in E$ :</p><p>(a)  从标准正态分布中提取每个嵌入的平均向量作为先验： ${\bf u_e} \sim  {\cal N}(0,1)$.</p></li><li><p>对于一个三元组 $(h,r,t) {\in \Delta}$ ： </p><p>(a)    通过$CRP$过程对一种关系构造语义成分， $\pi _{r,m} \sim CRP(\beta)$；</p><p>(b)    用正态分布构造头实体嵌入向量，${\bf h} \sim  {\cal N}({\bf u_h}, \sigma_h^2 {\bf E})$.</p><p>(c)    用正态分布构造尾实体嵌入向量，${\bf t} \sim  {\cal N}({\bf u_t}, \sigma_t^2 {\bf E})$.</p><p>(d)    对该语义构造一个关系嵌入向量，${\bf u_{r,m} }= {\bf {t-h} } \sim \cal N ({\bf {u_t-u_h, (\sigma_h^2+\sigma_t^2)E} })$ .</p></li></ul><p>其中：</p><ul><li>${\bf u_h}$ 和 ${\bf u_t}$ 代表头尾实体的平均嵌入向量，</li><li>$\sigma _h$ 和 $\sigma _t$  代表对应实体分布的方差；</li><li><p>${\bf u_{r,m} }$ 代表关系 $r$ 的第 $m$ 个 成分转移向量</p></li><li><p><a href="https://segmentfault.com/a/1190000010694630" target="_blank" rel="noopener">$CRP$</a> 过程是一个 Dirichlet 过程，它能自动检测语义成分。</p></li></ul><p>得分函数：<br>$$<br>{\Bbb P {(h,r,t)} }  \propto  \sum_{m=1}^{M_r} \pi_{r,m} \Bbb P({\bf u_{r,m} } | h,t)=\sum_{m=1}^{M_r} \pi_{r,m} e^{-\frac{||{\bf u_h+u_r}, \bf m-u_t||_2^2}{\sigma_h^2+\sigma_t^2} }<br>$$</p><ul><li>$\pi_{r,m}$ : 混合系数，代表第$i$个语义成分的权重；</li><li>$M_r$ : 关系$r$的语义成分数量， 通过$CRP$自动的从数据中学习得到；</li></ul><p>TransG利用了特定关系的关系分量向量的组合。每个成分代表一个特定的潜在含义。通过这种方法，TransG可以区分多个关系语义。值得注意的是，CRP可以生成多个语义分量，并从数据中自适应地学习关系语义分量数$M_r$。</p><h3 id="几何解释"><a href="#几何解释" class="headerlink" title="几何解释"></a>几何解释</h3><p>TransG 推广：<br>$$<br>m_{h,r,t}^* = {\arg\min}_{m=1,…,M_r} \left(  \pi_{r,m} e^{-\frac{||{\bf u_h+u_r,m-u_t}||_2^2}{\sigma_h^2+\sigma_t^2} }     \right)<br>$$</p><p>$$<br>{\bf h} + \bf u_{ {r,m}_{(\bf h,r,t)}^*} \approx \bf t<br>$$</p><ul><li>$m_{h,r,t}^*$ : 主分量，虽然所有分量都对模型有贡献，但是由于指数效应，主分量贡献最大；</li><li>给定一个三元组，TransG计算出主分量，然后用主转换向量将头实体转化为尾实体；</li><li>对于大多数三元组而言，应该只有一个分量有明显的非零值 $ \left(  \pi_{r,m} e^{-\frac{||{\bf u_h+u_r, m-u_t}||_2^2}{\sigma_h^2+\sigma_t^2} }     \right)$， 而其他分量由于指数衰减应该足够小，所有TransG中所有分量都有贡献，但主分量贡献最少；</li><li>该性质有效的减少了来自其他语义分量的噪声，更好的描述了多种语义关系；</li><li>在TransG中， ${\bf t-h}​$ 近乎只有一个转换向量 ${\bf u_{r,m}<em>{(h,r,t)}^*}​$ ，当 $m \neq m</em>{(h,r,t)}^*​$ 时，$\frac{||{\bf u_h+u_r, m-u_t}||_2^2}{ {\sigma}_h^2+{\sigma}_t^2}​$ 很大，经过指数操作后值很小，故其他分量可以忽略；</li></ul><h2 id="训练算法"><a href="#训练算法" class="headerlink" title="训练算法"></a>训练算法</h2><p>训练中运用了最大数据似然原理。对于无参数部分，$\pi _{r,m}$ 通过 Gibbs 采样 从 CRP 生成。从三元组采样新的分量可利用以下概率：</p><p>$$<br>\Bbb P (m_{r.new}) = \frac{\beta e^{-\frac{||{\bf h-t}||_2^2}{\sigma_h^2 + \sigma_t^2 +2} } }{\beta e^{-\frac{||{\bf h-t}||_2^2}{\sigma_h^2 + \sigma_t^2 +2} }+ \Bbb P{(h,r,t)} }<br>$$</p><ul><li>$\Bbb P{(h,r,t)}$ : 当前后验概率</li></ul><h3 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h3><p>其他部分，为了更好地区分正样本和负样本，将正样本和负样本的可能性比最大化。值得注意的是，嵌入向量是由(Glorot and Bengio, 2010)初始化的。将所有其他约束组合在一起，得到最终目标函数，如下所示:</p><p>$$<br>\min_{\bf u_h,u_r,m,u_t}  {\cal L}    \<br>{\cal L} = -\sum_{(h,r,t)\in \Delta} ln \left(\sum_{m=1}^{M_r} \pi_{r,m} e^{-\frac{||{\bf u_h+u_r, m-u_t}||_2^2}{\sigma_h^2+\sigma_t^2} } \right)  \ +  \sum_{(h’,r’,t’)\in \Delta’} ln \left(\sum_{m=1}^{M_r} \pi_{r’,m} e^{-\frac{||{\bf u_{h’}+u_{r’} ,m-u_{t’}}||<em>2^2}{\sigma</em>{h’}^2+\sigma_{t’}^2} } \right) + C\left(\sum_{r\in R} \sum_{m=1}^{M_r} ||{\bf u_{r,m} }||<em>2^2 + \sum</em>{e\in E}||{\bf u_e}||_2^2 \right)<br>$$</p><blockquote><p>此外还应用了一个技巧来控制训练过程中的参数更新过程。对于那些非常不可能的三元组，将跳过更新过程。因此，引入了与TransE 相似的条件: 训练算法只在满足以下条件时更新嵌入向量:</p><p>$$<br>\frac{\Bbb P{(h,r,t)} }{\Bbb P{(h’,r’,t’)} }= \frac{\sum_{m=1}^{M_r} \pi_{r,m} e^{-\frac{||{\bf u_h+u_r, m-u_t}||_2^2}{\sigma_h^2+\sigma_t^2} } }{\sum_{m=1}^{M_{r’} } \pi_{r’,m} e^{-\frac{||{\bf u_{h’}+u_{r’} , m-u_{t’}}||<em>2^2}{\sigma</em>{h’}^2+\sigma_{t’}^2} } }  \leq M_r e^{\gamma}<br>$$</p><ul><li>$\gamma$ : 控制更新条件</li></ul></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TransG&quot;&gt;&lt;a href=&quot;#TransG&quot; class=&quot;headerlink&quot; title=&quot;TransG&quot;&gt;&lt;/a&gt;TransG&lt;/h1&gt;&lt;p&gt;论文地址： &lt;a href=&quot;https://arxiv.org/pdf/1509.05488.pdf&quot; t
      
    
    </summary>
    
      <category term="知识图谱" scheme="http://yoururl.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="Knowledge graph" scheme="http://yoururl.com/tags/Knowledge-graph/"/>
    
  </entry>
  
  <entry>
    <title>知识图谱：知识表示之TransA模型</title>
    <link href="http://yoururl.com/2019/01/20/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA%E4%B9%8BTransA/"/>
    <id>http://yoururl.com/2019/01/20/知识表示之TransA/</id>
    <published>2019-01-19T16:05:00.000Z</published>
    <updated>2019-03-05T03:06:58.209Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TransA"><a href="#TransA" class="headerlink" title="TransA"></a>TransA</h1><p>论文地址: <a href="https://arxiv.org/pdf/1509.05490.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1509.05490.pdf</a></p><h2 id="模型改进"><a href="#模型改进" class="headerlink" title="模型改进"></a>模型改进</h2><h3 id="缺陷"><a href="#缺陷" class="headerlink" title="缺陷"></a>缺陷</h3><p><img src="https://s2.ax1x.com/2019/03/05/kXcy01.png" alt="kXcy01.png"></p><p>TransE模型本质上是一种欧式距离的计算，对应一个等势超球面。</p><blockquote><p> 上图中蓝色部分为正例，红色部分为负例，TransE模型错误划分7个点；利用本文提出的基于马氏距离的TransA模型，其PCA降维图对应一个椭圆，该模型只错误划分三个点。</p></blockquote><ul><li><p>目前基于转移的方法构造了等式超球面，不容易划分匹配与不匹配的尾部实体；而且等式超球面形状固定、不够灵活；</p><blockquote><p>疑问：“等式超球面在等式面上权重处处相等，且等势面广，容易将不匹配的实体包含进来？？？</p></blockquote></li><li><p>权重的问题：损失函数过于简单，向量的每一维度等价考虑，无法突出维度的重要性差异；</p></li></ul><p><img src="https://s2.ax1x.com/2019/03/05/kXc6Tx.png" alt="kXc6Tx.png"></p><blockquote><p>上图所示，对于关系 has-part 而言，TransE模型根据欧式距离计算生成了像 ”Room-has-Goniff“这样的三元组。而正确的结果是”Room-has-Wall“。</p><p>对x,y轴进行分解，发现Room在x轴上距离Wall更近，因此可以认为该图在x轴维度上更重要。TransA模型通过引入加权矩阵，对每一个维度赋予不同权重。</p><p>轴分量损失： $loss_x = (h_x+r_x-t_x)$ ,  $loss_y=(h_y+r_y-t_y)$</p></blockquote><h2 id="Adaptive-Metric-Approach"><a href="#Adaptive-Metric-Approach" class="headerlink" title="Adaptive Metric Approach"></a>Adaptive Metric Approach</h2><ul><li>TransA利用椭圆表面，而不是球面，这样可以更好的表示由复杂关系引起的复杂的嵌入拓扑；</li><li>根据自适应度量方法，TransA可以自动从数据中学习权重，加权变换特征维度；</li></ul><p>得分函数：</p><p>$$<br>f_r(h,t)=(|{\bf h+r-t}|)^T {\bf W}_r(|{\bf h+r-t}|)<br>$$</p><ul><li>$|{\bf h+r-t} |  \doteq (|h_1+r_1-t_1|,|h_1+r_1-t_1|,…,|h_n+r_n-t_n|)$</li><li>${\bf w}_r$ 是与自适应度相关的对称非负权重矩阵；</li><li>采用绝对值运算能很好的定义得分函数，保证${\bf w}_r$是非负的；</li></ul><p>将得分函数扩展为一个诱导范数:<br>$$<br>N_r({\bf e})=\sqrt{f_r(h,t)}<br>$$</p><ul><li><p>${\bf e} \doteq {\bf h+r-t}$  </p></li><li><p>$N_r$ 是非负的，单位的，绝对齐次的。<br>$$<br>N_r({\bf e}_1+{\bf e}_2)=\sqrt{|{\bf e_1}+{\bf e_2}|^T{\bf W_r} |{\bf e_1}+{\bf e_2} |} \leq  \sqrt{|{\bf e_1}|^T {\bf W_r} |{\bf e_1}|} + \sqrt{|{\bf e_2}|^T {\bf W_r} |{\bf e_2}|} = N_r({\bf e}_1) + N_r({\bf e}_2)<br>$$</p></li></ul><p>$$<br>{\bf W_r}={\bf L_r}^T{\bf D_r L_r}<br>$$</p><p>$$<br>f_r=({\bf L_r}|{\bf h+r-t}|)^T {\bf D_r} ({\bf L_r}|{\bf h+r-t}|)<br>$$</p><ul><li>${\bf D_r}$ : 对角矩阵$diag (w_1, w_2,…, w_n)$，对角元素代表向量每一维度$i$以权重$w_i$嵌入 ;</li></ul><h4 id="等势面"><a href="#等势面" class="headerlink" title="等势面"></a>等势面</h4><p>其他基于平移的方法：</p><ul><li>欧式距离定义等势面<br>$$<br>||({\bf t-h-r})||_2^2={\cal C}<br>$$</li></ul><p>TransA方法：</p><ul><li><p><a href="https://www.cnblogs.com/likai198981/p/3167928.html" target="_blank" rel="noopener">马氏距离</a>定义等势面</p><p>$$<br>|{\bf t-h-r}|^T {\bf W_r} |{\bf t-h-r}|= {\cal C}<br>$$</p></li></ul><blockquote><p>马氏距离利用协方差，有效计算样本各特性之间的联系，与尺度无关。</p><p>从而可以看出，TransA利用马氏距离，可以更好的应对1-N关系，由于矩阵对称，反过来对于N-1关系也有效；N-N关系可以看成多个1-N关系；因此TransA对于复杂关系的处理很有效。</p></blockquote><h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>$$<br>\left( \sum_{e \in E}||{\bf e}||<em>2^2 + \sum</em>{r \in R}||{\bf r}||_2^2 \right)<br>$$</p><p>$$<br>{\cal L}=\sum_{(h,r,t) \in \Delta} \sum_{(h’,r’,t’) \in \Delta’} [\gamma + f_r(h, t)-f_{r’}(h’, t’)]<em>+ + C \left (\sum</em>{e \in E}||{\bf e}||<em>2^2 + \sum</em>{r \in R}||{\bf r}||<em>2^2 \right) + \lambda \left (\sum</em>{r \in R}||{\bf W_r}||_F^2 \right)<br>$$</p><ul><li>$\lambda$ : 正则化自适应权重矩阵</li><li><p>$C$ : 控制缩放比例</p></li><li><p>${\bf [W_r]}_{ij} \geq 0$ :  在每轮的训练中，${\bf W_r}$ 可以通过将推导值设为零直接计算出来。为保证${\bf W_r}$的非负，将${\bf W_r}$的所有负项都设为零。<br>$$<br>\bf W_r = -\sum_{(h,r,t)\in \Delta} \left(|{\bf h+r-t}||{\bf h+r-t}|^T \right) + \sum_{(h’,r’,t’)\in \Delta’} \left(|{\bf h’+r’-t’}||{\bf h’+r’-t’}|^T \right)<br>$$</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TransA&quot;&gt;&lt;a href=&quot;#TransA&quot; class=&quot;headerlink&quot; title=&quot;TransA&quot;&gt;&lt;/a&gt;TransA&lt;/h1&gt;&lt;p&gt;论文地址: &lt;a href=&quot;https://arxiv.org/pdf/1509.05490.pdf&quot; t
      
    
    </summary>
    
      <category term="知识图谱" scheme="http://yoururl.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="Knowledge graph" scheme="http://yoururl.com/tags/Knowledge-graph/"/>
    
  </entry>
  
  <entry>
    <title>知识图谱：知识表示之TransR模型</title>
    <link href="http://yoururl.com/2019/01/20/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA%E4%B9%8BTransR/"/>
    <id>http://yoururl.com/2019/01/20/知识表示之TransR/</id>
    <published>2019-01-19T16:03:00.000Z</published>
    <updated>2019-03-05T03:05:37.256Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TransR"><a href="#TransR" class="headerlink" title="TransR"></a>TransR</h1><p>论文地址: <a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/download/9571/9523/" target="_blank" rel="noopener">http://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/download/9571/9523/</a></p><h2 id="模型改进"><a href="#模型改进" class="headerlink" title="模型改进"></a>模型改进</h2><p>TransE 和 TransH 都假设实体和关系嵌入在相同的空间中。然而，一个实体是多种属性的综合体，不同关系对应实体的不同属性，即头尾节点和关系可能不在一个向量空间中，在公共语义空间中不能表示它们。</p><p><img src="https://s2.ax1x.com/2019/03/05/kXcAOA.png" alt="kXcAOA.png"></p><ul><li>对每个三元组，实体空间中的实体首先通过运算 $M_r$ 映射到与它相关的 $r$ 关系空间, 保证 ${\bf h}_r + r \approx {\bf t}_r$ , 关系特定投影可以使实际持有该关系(表示为彩色圆圈)的头/尾实体彼此靠近，也可以使不持有该关系(表示为彩色三角形)的头/尾实体远离。</li><li>TransR对每个关系$r$都分配了一个空间${\bf M}_r \in R^{k \times d}$。</li><li>特定关系下，头尾实体会表现不同的模式；</li></ul><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>提出了一种新的方法，<strong>在不同的空间中建模实体和关系</strong>，即，<strong>实体空间</strong>和<strong>关系空间</strong>，并在关系空间中进行转换，因此命名为TransR。</p><h3 id="TransR-1"><a href="#TransR-1" class="headerlink" title="TransR"></a>TransR</h3><p>TransR 模型中，对每一个三元组，实体嵌入 ${\bf h,t} \in {\Bbb R}^k$ , 关系嵌入 ${ {\bf r} \in {\Bbb R}^d}$, 两个空间的维度不一定相同（属于不同空间）。  </p><ul><li>对每一个关系$r$，定义一个投影矩阵 ${\bf M}_r \in {\Bbb R}^{k \times d}$, 将实体从实体空间投影到关系空间：</li></ul><p>$$<br>{ {\bf h_r} = {\bf hM}_r}<br>$$</p><p>$$<br>{ {\bf t_r} = {\bf tM}_r}<br>$$</p><ul><li><p>得分函数：<br>$$<br>f_r(h,t)=||{ {\bf h}_r} + {\bf r} - {\bf t}_r||_2^2<br>$$</p></li><li><p>实体和关系嵌入的范数约束<br>$$<br>||{\bf h}||_2 \leq 1, ||{\bf t}||_2 \leq 1,||{\bf r}||_2 \leq 1, ||{\bf hM}_r||_2 \leq 1, ||{\bf tM}_r||_2 \leq 1<br>$$</p></li></ul><h3 id="Cluster-based-TransR-CTransR"><a href="#Cluster-based-TransR-CTransR" class="headerlink" title="Cluster-based TransR (CTransR)"></a>Cluster-based TransR (CTransR)</h3><p>上述模型包括TransE, TransH和TransR，仅仅通过单个的关系向量还不足以建立从头实体到尾实体的所有转移，<strong>即对于同一条关系$r$  来讲，$r$ 具有多种语义上的表示</strong>。为了更好地建模这些关系，引入了<strong>分段线性回归</strong>的思想来扩展TransR。</p><ul><li><p>对于一个特定的关系$r$，把训练数据中的所有实体对 $(h, t)$ 聚类到多个组中，每个组中的实体对都期望表现出相似的$r$关系。其中所有实体对$(h,t)$通过的向量偏移$(h−t)$来聚类；</p><blockquote><p>为什么根据$(h-t)$(也就是$r$)就能聚类:</p><p> CTransR考虑的问题是对一个关系只用一个表示无法体现这一种关系的多义性，比如关系（location location contains）其实包含country-city、country-university、continent-country等多种含义。</p><p><img src="https://s2.ax1x.com/2019/03/05/kXc1yj.png" alt="kXc1yj.png"></p><p>原文提到，这里的$h,t$是经过TRansE模型预训练得到的: </p><p><img src="https://s2.ax1x.com/2019/03/05/kXcJwq.png" alt="kXcJwq.png"></p><hr><p><img src="https://s2.ax1x.com/2019/03/05/kXcNkV.png" alt="kXcNkV.png"></p><p> 而TransE模型的映射是唯一（one to one）的，大关系下的不同子关系通过映射后其实是不同的向量表示，那么$(h-t)$的结果也不相同，根据不同的结果可以用来进行聚类。</p></blockquote></li><li><p>对每一个簇, 学习一个<strong>分离关系向量</strong> ${\bf r}_c$ ，对每种关系，学习投影矩阵 ${\bf M}_r$</p></li><li><p>定义实体和关系的投影向量为：</p></li></ul><p>$$<br>{ {\bf h}_{r,c} = {\bf hM}<em>r}<br>$$<br>$$<br>{ {\bf t}</em>{r,c} = {\bf tM}_r}<br>$$</p><ul><li>得分函数：</li></ul><p>$$<br>f_r(h,t)=||{ {\bf h}_{r,c}} + {\bf r}<em>c - {\bf t}</em>{r,c}||_2^2 + \alpha ||{\bf r}_c - {\bf r}||_2^2<br>$$</p><p>$||{\bf r}_c - {\bf r}||_2^2$ 这一项确保群特异性关系向量 ${\bf r}_c$ 距离原始关系向量 ${\bf r}$ 不太远， $\alpha$ 控制约束效果</p><ul><li>实体和关系嵌入的范数约束  </li></ul><p>$$<br>||{\bf h}||_2 \leq 1, ||{\bf t}||_2 \leq 1,||{\bf r}||_2 \leq 1, ||{\bf hM}_r||_2 \leq 1, ||{\bf tM}_r||_2 \leq 1<br>$$</p><h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p>损失函数：<br>$$<br>{\cal L}=\sum_{(h,r,t)\in \Delta} \sum_{(h’,r,t’)\in \Delta’} max (0, \gamma + f_r(h, t)-f_{r}(h, t) )<br>$$</p><h3 id="负样本生成"><a href="#负样本生成" class="headerlink" title="负样本生成"></a>负样本生成</h3><p>为首尾实体替换分配不同的概率。对于那些1- n、n -1和n -n关系，给“one”设置更高的概率，产生假阴性样本的机会将会减少</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TransR&quot;&gt;&lt;a href=&quot;#TransR&quot; class=&quot;headerlink&quot; title=&quot;TransR&quot;&gt;&lt;/a&gt;TransR&lt;/h1&gt;&lt;p&gt;论文地址: &lt;a href=&quot;http://www.aaai.org/ocs/index.php/AAAI/
      
    
    </summary>
    
      <category term="知识图谱" scheme="http://yoururl.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="Knowledge graph" scheme="http://yoururl.com/tags/Knowledge-graph/"/>
    
  </entry>
  
  <entry>
    <title>知识图谱：知识表示之TransH模型</title>
    <link href="http://yoururl.com/2019/01/20/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA%E4%B9%8BTransH/"/>
    <id>http://yoururl.com/2019/01/20/知识表示之TransH/</id>
    <published>2019-01-19T16:02:00.000Z</published>
    <updated>2019-03-05T03:04:12.008Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TransH"><a href="#TransH" class="headerlink" title="TransH"></a>TransH</h1><p>论文地址：<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/viewFile/8531/8546" target="_blank" rel="noopener">https://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/viewFile/8531/8546</a></p><h2 id="模型改进"><a href="#模型改进" class="headerlink" title="模型改进"></a>模型改进</h2><p><img src="https://s2.ax1x.com/2019/03/05/kX6zo6.png" alt="kX6zo6.png"></p><p>将特定关系的转移向量 $d_r$ 放置于特定关系的超平面 $w_r$ ,而不是映射到相同的实体嵌入空间；  </p><p>对于三元组 $(h,r,t)$，嵌入向量 ${\bf h}$ 和 ${\bf t}$ 投影到超平面 ${\bf {w_r}}$ , 投影被表示为 ${\bf h_{\bot}}$ 和 ${\bf t_{\bot}}$ 。投影 ${h_{\bot}}$ 和 ${t_{\bot}}$ 能被转移向量 ${\bf d_r}$ 连接， 当三元组为正样本时有更低的错误率，为负样本时错误率上升；   </p><blockquote><p>TransH将一个关系$r$表示成两个向量：超平面法向量${\bf W}_r$和超平面内的关系向量${\bf d_r}$表示；</p><p>该关系连接的不同实体对在超平面上的投影只对应一个向量表示： ${\bf h_{\bot}}$ 和 ${\bf t_{\bot}}$，</p><p>也就是，唯一的${\bf W}_r$和${\bf d_r}$ 确定了该关系在空间中的唯一超平面；</p></blockquote><ul><li><p>定义一个得分函数,衡量三元组的合理性：<br>$$<br>||{\bf h_{\bot} } + {\bf d_r} - {\bf t_{\bot} }||_2^2<br>$$</p></li><li><p>超平面法向量限制为 $||{\bf w}_r ||_2 = 1$, 超平面投影的表示为</p></li></ul><p>$$<br>{\bf h_{\bot} } = {\bf h} - {\bf w}_r^T {\bf h}{\bf w}_r<br>$$</p><p>$$<br>{\bf t_{\bot} } = {\bf t} - {\bf w}_r^T {\bf h}{\bf w}_r<br>$$</p><blockquote><p>推导： 嵌入向量在超平面法向量上的投影长度，再乘上法向量方向向量：<br>$d=\frac{ | {\bf w}_r^T h| }{| |{\bf w}| |} \cdot \frac{ {\bf w}_r}{| |{\bf w}| |}=\frac{ {\bf w}_r^T {\bf h}{\bf w}_r}{| |{\bf w}^2| |}={\bf w}_r^T {\bf h}{\bf w}_r$</p></blockquote><p>最终得分函数：</p><p>$$<br>f_r({\bf h},{\bf t}) = | |({\bf h} - {\bf w}_r^T {\bf h} {\bf w}_r) + {\bf d}_r -({\bf t} - {\bf w}_r^T {\bf h} {\bf w}_r)| |_2^2<br>$$</p><p>模型参数：</p><ul><li>所有实体的嵌入向量  ${ {\bf e_i}}_{r=1}^{ |E| }$ ; </li><li>所有关系超平面和转移向量  ${ ( {\bf w_r, d_r})}_{r=1}^{ |R| }$  ;</li></ul><p>在TransH中，通过引入投射到特定关系超平面上的机制，使实体在不同的关系/三元组中扮演不同的角色。</p><h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>$$<br>{\cal L}=\sum_{(h,r,t)\in \Delta} \sum_{(h’,r’,t’)\in \Delta’_{(h,r, t)} } [\gamma + f_r({\bf h}, {\bf t})-f_{r’}({\bf h’}, {\bf t’}) ]_+<br>$$</p><ul><li>$\Delta$: 正确三元组集合</li><li>$\Delta’$: 错误三元组集合</li><li>$\gamma$: margin 距离超参数，表示正负样本之间的距离</li><li>$[x]_+$: $max(0,x)$</li></ul><p>训练的限制条件：</p><ul><li>$\forall e\in E, ||{\bf e}||_2 \leq 1$ ,   # 控制实体嵌入大小</li><li>$\forall r \in R, \frac{|{\bf w}_t^T {\bf d}_r|}{||{\bf d}_r||_2} \leq \epsilon$ , # 正交，控制转移向量落在超平面</li><li>$\forall r \in R. ||{\bf w}_r||_2=1$ , # 单位法向量</li></ul><p>软约束：</p><p>$$<br>{\cal L}=\sum_{(h,r,t)\in \Delta} \sum_{(h’,r’,t’)\in \Delta’_{(h,r, t)} } [\gamma + f_r({\bf h}, {\bf t})-f_{r’}({\bf h’}, {\bf t’}) ]<em>+ + C\left{\sum</em>{e\in E}[||{\bf e}||<em>2^2 -1]</em>+ + \sum_{r \in R}\left[\frac{({\bf w}_t^T {\bf d}_r)^2}{||{\bf d}_r||<em>2^2} - \epsilon ^2\right]</em>+ \right}<br>$$</p><ul><li>C是软约束的超参数权重</li><li>注意到约束3不在loss公式里，在访问每一个mini-batch时将每一个${\bf w}_r$投影到单位  <a href="https://blog.csdn.net/zouxy09/article/details/24971995" target="_blank" rel="noopener">$L_2- \bf {ball}$</a> </li><li>随机梯度下降，正样本的集合被随机遍历多次，当访问一个正样本时，一个负样本被随机构造。</li></ul><h3 id="负样本构造"><a href="#负样本构造" class="headerlink" title="负样本构造"></a>负样本构造</h3><p>相对于TransE模型的随机采样生成负样本，TransH模型的创新点：<br><strong>赋予头尾实体采样概率</strong>   </p><ul><li>处理1-N关系时，赋予头部实体更高的采样概率；</li><li>处理N-1关系时，赋予尾部实体更高的采样概率；  </li></ul><p>在所有关系r的三元组中，首先获取两个数据：</p><ul><li>$tph$: 每一个头部实体对应的平均尾部实体;</li><li>$hpt$: 每一个尾部实体对应的平均头部实体;</li></ul><p>针对这两个数据进行映射的分类：</p><p>$$<br>\left { \begin{array}{rcl}<br>1-1    &amp; \mbox{for} &amp; tph_r&lt;1.5,hpt_r &lt;1.5 \<br>N-N    &amp; \mbox{for} &amp; tph_r \geq 1.5,hpt_r \geq 1.5 \<br>1-N    &amp; \mbox{for} &amp; tph_r \geq 1.5,hpt_r &lt; 1.5 \<br>N-1    &amp; \mbox{for} &amp; tph_r &lt; 1.5,hpt_r \geq 1.5 \<br>\end{array}\right.<br>$$</p><p>定义一个伯努利分布进行采样：</p><ul><li>$\frac{tph}{tph+hpt}$: 采样头部实体的概率;</li><li>$\frac{hpt}{tph+hpt}$: 采样尾部实体的概率;</li></ul><h2 id="实验部分-未完待补充"><a href="#实验部分-未完待补充" class="headerlink" title="实验部分(未完待补充)"></a>实验部分(未完待补充)</h2><p>在三个任务上研究评估模型：从不同视角和应用层面，评估对陌生三元组的预测精度</p><ul><li>link prediction</li><li>triplets classification</li><li>relational fact extraction</li></ul><p>实验数据使用：<br><img src="http://p5bxip6n0.bkt.clouddn.com/18-11-1/13704280.jpg" alt=""></p><h4 id="link-prediction"><a href="#link-prediction" class="headerlink" title="link prediction"></a>link prediction</h4><p><strong>任务</strong>：三元组的头部或者尾部实体缺失，给定 $(h,r)$ 预测 $t$ 或者给定 $(r,t)$ 预测 $h$ , 返回预测的候选排名；<br><strong>评估协议</strong>： 对于给定的三元组，用每个实体 $e$ 取代尾部实体 $t$ ，并计算损坏样本的差异性分数，升序排列获取原始三元组的排名；<br><strong>过滤</strong>： 生成的损坏三元组可能原本就存在于知识图谱中，需要删去；<br><strong>报告指标</strong>：  </p><ul><li>Mean:平均排名:</li><li>$Hits@10$: 排名不超过10的比例</li></ul><h4 id="triplets-classification"><a href="#triplets-classification" class="headerlink" title="triplets classification"></a>triplets classification</h4><p><strong>任务</strong>: 对给定三元组进行二分类判断正负样本；</p><h4 id="relational-fact-extraction"><a href="#relational-fact-extraction" class="headerlink" title="relational fact extraction"></a>relational fact extraction</h4><p>(待补充)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TransH&quot;&gt;&lt;a href=&quot;#TransH&quot; class=&quot;headerlink&quot; title=&quot;TransH&quot;&gt;&lt;/a&gt;TransH&lt;/h1&gt;&lt;p&gt;论文地址：&lt;a href=&quot;https://www.aaai.org/ocs/index.php/AAAI/
      
    
    </summary>
    
      <category term="知识图谱" scheme="http://yoururl.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="Knowledge graph" scheme="http://yoururl.com/tags/Knowledge-graph/"/>
    
  </entry>
  
  <entry>
    <title>知识图谱：知识表示之TransE模型</title>
    <link href="http://yoururl.com/2019/01/20/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA%E4%B9%8BTransE/"/>
    <id>http://yoururl.com/2019/01/20/知识表示之TransE/</id>
    <published>2019-01-19T16:01:00.000Z</published>
    <updated>2019-03-05T03:03:39.527Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TransE"><a href="#TransE" class="headerlink" title="TransE"></a>TransE</h1><p>论文地址：<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/viewFile/8531/8546" target="_blank" rel="noopener">https://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/viewFile/8531/8546</a>  </p><h2 id="模型概述"><a href="#模型概述" class="headerlink" title="模型概述"></a>模型概述</h2><ul><li>三元组：   $(h,{\scr l},t)$  </li><li>embedding之后， 头部实体嵌入向量加上关系嵌入向量，更接近与尾部实体嵌入向量</li><li>依赖于简化的参数集，只学习每个实体和每个关系的一个<strong>低维向量</strong>表示</li></ul><p><img src="https://s2.ax1x.com/2019/03/05/kXcCWD.png" alt="kXcCWD.png"></p><p>细节：</p><ul><li>训练集 $S$: 包含三元组 $(h,{\scr l},t)$， 实体 $h,t\in E(实体集)$, 关系 ${\scr l} \in L(关系集)$；</li><li>embeddings 在 $\Bbb R^k$ 中取值</li><li>${\bf h}+{\scr l}\approx {\bf t}$ , ${\bf t}$ 应该为 ${\bf h}+{\scr l}$ 的最邻近， 然后 ${\bf h}+{\scr l}$ 与其他的 $t$ 尽可能远；  这里的“接近”程度可以用 $L_1$或$L_2$范数衡量；<br>理想状态下一个正确的三元组的embedding 之间存在 ${\bf h}+{\scr l}={\bf t}$ 的关系，错误的三元组没有；</li><li>利用基于能量的框架，三元组的势能表示为 $d(h, {\scr l}, t)=||h+{\scr l}-t||_2$ ， 正确的三元组势能越低越好，错误的三元组势能越高越好；</li></ul><h2 id="损失函数："><a href="#损失函数：" class="headerlink" title="损失函数："></a>损失函数：</h2><h3 id="带negative-sample的max-margin损失函数"><a href="#带negative-sample的max-margin损失函数" class="headerlink" title="带negative sample的max margin损失函数"></a>带negative sample的max margin损失函数</h3><p>训练方法：margin-based ranking criterion<br>$$<br>{\cal L}=\sum_{(h,{\scr l},t)\in S} \sum_{(h’,{\scr l},t’)\in S’<em>{(h,{\scr l}, t)} } [\gamma + d(h+{\scr l}, t)-d(h’+{\scr l}, t’) ]</em>+<br>$$</p><p>$$<br>d(h, {\scr l}, t)=||h+{\scr l}-t||_2<br>$$</p><ul><li>$S$: 正确三元组集合</li><li>$S’$: 错误三元组集合</li><li>$\gamma$: margin 距离超参数，表示正负样本之间的距离，常数;</li><li>$[x]_+$: $max(0,x)$</li></ul><blockquote><p>最小化loss可以使正样本势能越低，负样本势能越高，但两者的能量差距达到一定程度 $\gamma$ 就足够了， 再大loss也只是0；</p></blockquote><h3 id="负样本生成"><a href="#负样本生成" class="headerlink" title="负样本生成"></a>负样本生成</h3><p>$$<br>S’_{(h,{\scr l},t)} = {(h’,{\scr l},t)|h’\in E}\bigcup {(h,{\scr l},t’)|t’ \in E}<br>$$</p><ul><li>对于三元组 $(h,{\scr l},t)$， 随机使用知识库中的某个实体 $h’$ 替换 $h$，或用某个实体 $t’$ 替换 $t$, 得到两个负样本 $(h’,{\scr l},t)$ 和 $(h,{\scr l},t’)$;  </li><li>对生成的负样本进行筛选过滤，若该负样本原本存在于知识库，则重新生成；  </li><li>然后，有人认为，生成负样本时不应该完全随机，而是应该选择与被替换实体类型相似的实体来进行替换；</li></ul><h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-11-1/93529922.jpg" alt=""></p><h2 id="TransE局限性"><a href="#TransE局限性" class="headerlink" title="TransE局限性"></a>TransE局限性</h2><p>考虑在没有错误embedding的情况下，$h+{\scr l}=t$  当 $(h,{\scr l},t) \in \Delta$ 时，我们可以从TransE模型中看出：</p><ul><li>若 $(h,{\scr l},t) \in \Delta$ 且 $(t,{\scr l},h) \in \Delta$, $r$是一个自反映射， 因此 $r=0$ 且 $h=t$;</li><li>若 $\forall i \in {0,…,m},(h_i,r,t)\in \Delta$ , $r$是一个N-1映射，且 $h_0=…=h_m$;<br>类似的，$\forall i \in {0,…,m},(h,r,t_i)\in \Delta$ , $r$是一个1-N映射，且 $t_0=…=t_m$;  </li></ul><p>当涉及相同关系时，忽略了实体的分布式表示，导致实体呈现相同的嵌入表示。</p><blockquote><p>例如，假如知识库中有两个三元组，分别是(美国, 总统, 奥巴马)和(美国, 总统, 布什)。这里的关系“总统”是典型的 1-N 的复杂关系。如果用 TransE 从这两个三元组学习知识表示，将会使奥巴马和布什的向量变得相同。<br>因而，TransE 模型在处理 1-N、N-1、N-N 复杂关系时存在局限性。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TransE&quot;&gt;&lt;a href=&quot;#TransE&quot; class=&quot;headerlink&quot; title=&quot;TransE&quot;&gt;&lt;/a&gt;TransE&lt;/h1&gt;&lt;p&gt;论文地址：&lt;a href=&quot;https://www.aaai.org/ocs/index.php/AAAI/
      
    
    </summary>
    
      <category term="知识图谱" scheme="http://yoururl.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="Knowledge graph" scheme="http://yoururl.com/tags/Knowledge-graph/"/>
    
  </entry>
  
  <entry>
    <title>复杂网络：网络测度之中心性</title>
    <link href="http://yoururl.com/2019/01/20/%E7%BD%91%E7%BB%9C%E6%B5%8B%E5%BA%A6%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%BA%A6%E4%B8%8E%E4%B8%AD%E5%BF%83%E6%80%A7/"/>
    <id>http://yoururl.com/2019/01/20/网络测度（一）：度与中心性/</id>
    <published>2019-01-19T16:01:00.000Z</published>
    <updated>2019-01-26T15:28:24.221Z</updated>
    
    <content type="html"><![CDATA[<h2 id="度"><a href="#度" class="headerlink" title="度"></a>度</h2><ul><li><p>定义：<strong>与结点直接相连的边数目</strong></p></li><li><p>对于无向图：</p><ul><li><p>结点 $i$ 的度 可用邻接矩阵表示为  $k_i=\sum_{j=1}^n A_{ij}$  ;</p></li><li><p>无向图中，若边数量为 $m$ , 则边端点为 $2m$ , <strong>边的端点数与所有顶点度总和相等</strong> ， $2m=\sum_{i=1}^n k_i$  或<br>$$<br>m = \frac{1}{2} \sum_{i=1}^n k_i = \frac{1}{2} \sum_{ij} A_{ij}<br>$$</p></li><li><p>顶点度均值 $c = \frac{1}{n} \sum_{i=1}^n k_i$ ;<br>$$<br>c=\frac{2m}{n}<br>$$</p><blockquote><p>$cn=2m$ : 顶点度总和 == 无向边端点数</p></blockquote></li></ul></li><li><blockquote><p>简单图（无重边和自边）中，可能最大边数为 $\frac{1}{2}n(n-1)$ 个。</p><p><strong>连通度</strong>或<strong>密度</strong> $\rho$ : 图中实际出现的边数与边最大值的比值<br>$$<br>\rho = \frac{实际边数}{边最大值} = \frac{m}{\frac{n(n-1)}{2} } = \frac{c}{n-1}<br>$$<br><em>网络规模足够大， 连通度可近似表示   $\rho=c\n$ </em> </p></blockquote></li></ul><ul><li><blockquote><p>根据 $\rho$  定义的网络疏密：</p><p>当 $n \rightarrow \infty $ 时：</p><ul><li><p>$\rho$ 趋于常数， 即度均值 $c\rightarrow \infty$ ，网络为密集的；</p><p>此类网络当网络规模扩大时，邻接矩阵中非零元的比例会保持常数；</p></li><li><p>$\rho \rightarrow 0$， 网络为稀疏的；</p><p>此类网络当网络规模扩大时，邻接矩阵中非零元的比例趋于零； </p></li></ul></blockquote></li><li><blockquote><p><strong>正则图</strong>： 所有结点的度相同；</p><p>$k-正则图$： 所有结点的度为$k$;</p></blockquote></li><li><p>对于有向图：</p><ul><li><p>每个结点有两个度:       考虑从结点$j$到$i$有一条边：</p><ul><li>入度：连接到该结点的入边数；   $k_i^{in}=\sum_{j=1}^n A_{ij}$ </li><li>出度：连接到该结点的出边数；   $k_j^{out}=\sum_{i=1}^n A_{ij}$ </li></ul></li><li><p>有向图中，边数目 $m$ 等于<strong>入边端点数总和</strong>，也等于<strong>出边端点数总和</strong>，有<br>$$<br>m = \sum_{i=1}^n k_i^{in} = \sum_{j=1}^n k_{j}^{out} = \sum_{ij} A_{ij}<br>$$</p></li><li><p>有向图的入度均值 $c_{in}$ 等于出度均值 $c_{out}$ ,即<br>$$<br>c_{in} = \frac{1}{n}\sum_{i=1}^n k_i^{in} = \frac{1}{n}\sum_{j=1}^n k_j^{out} = c_{out}<br>$$</p><p>$$<br>c=c_{in}=c_{out}=\frac{m}{n}<br>$$</p></li></ul></li></ul><h2 id="中心性"><a href="#中心性" class="headerlink" title="中心性"></a>中心性</h2><p>中心性(Centrality)是社交网络分析中用以表达社交网络中结点在整个网络中所在中心的程度。</p><h3 id="度中心性"><a href="#度中心性" class="headerlink" title="度中心性"></a>度中心性</h3><ul><li>定义： 刻画结点中心性的连接中心度， 一个结点与其他点直接链接的总和（度$d$）；</li><li>无向图的结点$v_i$中心性 $C_d$ ： $C_d(v_i) = d_i$ ;                            </li><li>有向图的结点度中心性：<ul><li>入度： 刻画结点受欢迎程度，表示结点的突出性(prominence)或声望(prestige),   $C_d(v_i) = d_i^{in} （声望）$</li><li>出度：表示结点的合群性(gregariousness), $C_d(v_i) = d_i^{out} （合群性）$</li><li>结合入度出度： $C_d(v_i)=d_i^{in} + d_i^{out}$ ;</li></ul></li></ul><blockquote><p>度中心性度量方法不能用于比较不同网络中的中心性值，需要归一化；</p></blockquote><h3 id="度中心性的归一化"><a href="#度中心性的归一化" class="headerlink" title="度中心性的归一化"></a>度中心性的归一化</h3><ul><li>使用最大可能度数：<br>$$<br>C_d^{norm}(v_i)=\frac{度中心度}{最大可能度数}=\frac{d_i}{n-1}<br>$$</li></ul><ul><li>使用最大度数：<br>$$<br>C_d^{max}(v_i) = \frac{度中心度}{最大度数} = \frac{d_i}{\max_jd_j}<br>$$</li></ul><ul><li>使用度数和：<br>$$<br>C_d^{sum}(v_i)=\frac{度中心度}{度数和}=\frac{d_i}{\sum_jd_j} = \frac{d_i}{2m}<br>$$</li></ul><h3 id="特征向量中心性"><a href="#特征向量中心性" class="headerlink" title="特征向量中心性"></a>特征向量中心性</h3><p>在度中心性度量中，认为具有较多连接的结点更为重要。但在社交网络中，拥有更多的邻居结点并不能确保该结点就是重要的，拥有更多重要的邻居结点才能提供更有力的信息。因为很多情况下，一个结点会由于连接到一些很重要的结点从而使得自身的重要性得到提升。</p><p>特征向量中心性通过结合<strong>无向图的邻居节点</strong>（或<strong>有向图的输入邻居结点</strong>）的重要性来概括度中心性。</p><p>对于每个结点$i$,令其的中心性为$x_i$。 计算$i$的所有邻居结点的中心性之和：<br>$$<br>x_i’ = \sum_i A_{ij} x_j   \     \Longrightarrow   \  \bf x’ = Ax    (矩阵形式)<br>$$<br>重复估算过程，得到中心性计算公式：<br>$$<br>\bf x(t) = A^tx(0)<br>$$</p><blockquote><p>$\bf x(0)$  为邻接矩阵特征向量$\bf v_i$的线性组合， 即  $\bf x(0) = \sum_i c_i v_i$ ;</p><p>根据特征值的定义： $Av_i = \lambda v_i$ </p></blockquote><p>最终得：<br>$$<br>\bf x{(t)} = A^t\sum_i c_i v_i = \sum_i c_i\lambda_i^tv_i = \lambda_1^t \sum_i c_i[\frac{\lambda_i}{\lambda_1}]^t v_i<br>$$<br>其中， $\lambda_i$ 为 $\bf A$ 的 特征值， $\lambda_1$ 为其中最大的特征值。</p><blockquote><p>当 $i\neq 1$ 时，对于所有 $i$ ，$\frac{\lambda_i}{\lambda_1}&lt;1$ 。当 $t$ 增大时， 除第一项外其他项都呈指数级下降，当$t \rightarrow \infty$ 时， $\bf x(t) \rightarrow c_1\lambda_1^t v_t$  。<strong>中心性向量的极限与邻接矩阵中的主特征向量成正比</strong>， 因此可等价认为中心性$\bf x$满足: $\bf Ax=\lambda_1 x$</p></blockquote><p>由此可得出，<strong>结点$i$的中心性与该结点邻居节点的中心性之和成正比</strong> ：<br>$$<br>x_i = \frac{1}{\lambda_i} \sum_j A_{ij} x_j<br>$$</p><blockquote><p>该公式赋予特征向量中心性的性质：使得它的值会随两方面因素变大：</p><ul><li>该结点具有多个邻居结点；</li><li>该结点的邻居节点中有重要的结点；</li></ul></blockquote><h4 id="Perron-Frobenius-Theorem"><a href="#Perron-Frobenius-Theorem" class="headerlink" title="Perron-Frobenius Theorem:"></a>Perron-Frobenius Theorem:</h4><p>假设$A\in \Bbb R^{n \times n}$ 时[强]连通图的邻接矩阵，或者 $A:A_{i,j} &gt;0$ （即一个正的$n\times n$的矩阵）。 存在一个正实数（Perron-Frobenius特征值）$\lambda_{max}$，满足$\lambda_{max}$ 是矩阵$\bf A$的特征值，并且$\bf A $的其余特征值均严格小于$\lambda_{max}$。 $\lambda_{max}$ 所对应的特征向量为$v=(v_1,v_2,v_3,…,v_n)$，满足$\forall v_i&gt;0$ 。</p><p>根据该定理，我们可以<strong>通过求解矩阵$A$ 的特征值得到正的中心性值，选取其中最大的特征值 $\lambda_{max}$ ,其对应特征向量为 $x_i$，该特征向量的所有部分均为正值，并且其分量对应于各结点的特征向量中心性，其中特征向量中最大分量对应的结点考虑为最中心的结点</strong></p><blockquote><p>寻找最中心结点：</p><ul><li>计算邻接矩阵的特征值；</li><li>选择最大的特征值，计算对应的特征向量；</li><li>特征向量最大分量对应的结点有最大的特征向量中心性，考虑为最中心的结点。</li></ul></blockquote><p>理论上讲，特征向量中心性对于有向和无向网络都适用，但在有向网络中存在一些问题。</p><ul><li><p>有向网络对应的邻接矩阵通常非对称，意味着有两类特征向量，即左特征向量和右特征向量。左特征向量对应该结点指向的结点（出），右特征向量对应指向该结点的结点（入）。中心性主要由指向该结点的结点赋予，因此选择<strong>右特征向量</strong>。</p><p>在有向网络中结点$i$的特征中心性的正确定义为：<strong>结点的特征向量中心性与指向该结点的所有结点的中心性之和成正比。</strong></p></li><li><p>如果有向网络中结点$B$的所有入边都来源于特征向量中心性为0的邻居结点，则结点$B$的特征向量中心性也为0。</p></li></ul><h3 id="Katz中心性"><a href="#Katz中心性" class="headerlink" title="Katz中心性"></a>Katz中心性</h3><p>Katz中心性是特征向量中心性的变体，解决上述有向网络中零特征向量中心性传递带来的问题。</p><ul><li><p>定义：为网络中的每个结点赋予少量的中心性，不考虑该结点在网络中的具体位置或者其邻居节点的中心性。<br>$$<br>x_i = \alpha \sum_i A_{ij} x_j + \beta<br>$$<br>偏差项$\beta$ 用来解决中心性值为0 的问题；</p><p>矩阵表示上述公式，$\beta$ 作为整体因子其取值并不重要，通常设定为1：<br>$$<br>\bf x=\alpha Ax+\beta 1  \ \Longrightarrow  \beta=1 \Longrightarrow \<br>x=(I-\alpha A)^{-1} 1<br>$$</p></li><li><p>自由参数$\alpha$ 负责调节特征向量与常数项之间的平衡。</p><ul><li><p>当$\alpha=0$ 时， 式（14）只剩下常数项，所有结点赋予相同的中心性$\beta$;</p></li><li><p>当$\alpha$ 变大时，中心性不断提高，$\beta$ 的影响将减小，最终达到一个点，在该点中心性发散。该情况出现在$\bf det(A-\alpha^{-1}I)=0$ 的那一点；</p><blockquote><p>该公式为特征方程，当$\alpha =\lambda_{max}^{-1}$时，行列式第一次经过零点；因此应选择一个小于该值的$\alpha$ 值，保证中心性收敛。</p><p>很多研究中，将$\alpha$ 设为稍小于最大值$\lambda_{max}^{-1}$的值，这样可以使公式中特征向量项权值最大，而使常数项权值最小。</p></blockquote></li></ul></li></ul><h4 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h4><p>对于增加的常数项，根据结点的不同赋予不同的值，可以定义一种更加通用的中心性：<br>$$<br>x_i = \alpha \sum_j A_{ij} x_j + \beta_i<br>$$<br>其中$\beta_i$是每一个结点与网络无关的固有中心性。因此中心性向量$\bf x$可描述为<br>$$<br>\bf x=(I-\alpha A)^{-1} \beta<br>$$</p><h3 id="PageRank"><a href="#PageRank" class="headerlink" title="PageRank"></a>PageRank</h3><p>Katz中心性的不足之处在于，Katz中心性较高的结点会向它指向的结点传递其高中心性，这是不可取的，因为该高中心性结点指向的结点数量可能很大，但并不是每一个被指向的结点都具有很高的中心性。因此，<strong>被有重要影响的结点指向的结点，其从重要节点获得的中心性会因为与其他结点共享而被稀释。</strong></p><ul><li>定义：从网络邻居结点获得的中心性与邻居结点的中心性除以它们的出度成正比。</li></ul><p>$$<br>x_i = \alpha \sum_i A_{ij} \frac{x_j}{k_j^{out} } + \beta<br>$$</p><blockquote><p>对于网络中出度$k_j^{out}=0$的结点 ，会产生0/0的结果（因为对于所有$i$，$A_{ij}=0$）。</p><p>解决此问题： 没有出度的结点对其他结点的中心性贡献为0，因此将这些结点的出度设定为1；实际可将$k_j^{out}$ 设定为任何一个非零值。</p></blockquote><p>​    表示为矩阵形式，同样将$\beta$设定为1<br>$$<br>\bf x=\alpha AD^{-1}x+\beta1    \  \Longrightarrow \beta=1 \Longrightarrow \  x=(I-\alpha AD^{-1})^{-1} 1=D(D-\alpha A)^{-1} 1<br>$$<br>​    其中， $\bf D$ 为对角矩阵，其元素为 $D_{ii}=\max(k_i^{out},1)$</p><blockquote><p>与katz中心性类似，$\alpha$ 的值应小于$AD^{-1}$的最大特征值的倒数，即$\frac{1}{\lambda_{max} }$ ;</p><p>对于无向网络，其最大特征值为1，因此 $\alpha$ 应选择小于1的值；</p><p>对于有向网络，通常主特征值实际取值近似1；</p></blockquote><h4 id="拓展-1"><a href="#拓展-1" class="headerlink" title="拓展"></a>拓展</h4><p>PageRank推广，使得常数项$\beta$ 对不同顶点取不同的值：<br>$$<br>x_i = \alpha \sum_i A_{ij} \frac{x_j}{k_j^{out} } + \beta_i<br>$$<br>矩阵形式为：<br>$$<br>\bf x=D(D-\alpha A)^{-1} \beta<br>$$</p><blockquote><p>利用该公式对网页进行排序时，其中$\beta_i$的值可以基于网页与查询条件的文本相似性给出。</p></blockquote><blockquote><h4 id="四种中心性测度"><a href="#四种中心性测度" class="headerlink" title="四种中心性测度"></a>四种中心性测度</h4><table><thead><tr><th></th><th>带常数项</th><th>不带常数项</th></tr></thead><tbody><tr><td>除以出度</td><td>$\bf x=D(D-\alpha A)^{-1}1$       RageRank</td><td>$\bf x = AD^{-1}x$     度中心性</td></tr><tr><td>不做任何除法</td><td>$\bf x=(I-\alpha A)^{-1} 1$             Katz中心性</td><td>$\bf x=\lambda_1^{-1}Ax$      特征向量中心性</td></tr></tbody></table></blockquote><h3 id="针对引文网络的中心性"><a href="#针对引文网络的中心性" class="headerlink" title="针对引文网络的中心性"></a>针对引文网络的中心性</h3><h4 id="核心结点与权威结点"><a href="#核心结点与权威结点" class="headerlink" title="核心结点与权威结点"></a>核心结点与权威结点</h4><ul><li>权威结点（authority）: 包含所关注主题有用的信息的结点；</li><li>核心结点（hub)：指向权威结点的结点，说明到哪能找到最合适的权威结点；</li></ul><p>核心结点与权威结点只存在于有向网络中，在有向网络中可以定义两种中心性，</p><ul><li><p>权威中心性</p><p>与指向该结点的核心中心性之和成正比；<br>$$<br>x_i=\alpha \sum_j A_{ij}y_j<br>$$</p></li><li><p>核心中心性</p><p>与该结点指向的结点的权威中心性之和成正比；<br>$$<br>y_i =\beta \sum_j A_{ji}x_j<br>$$<br>矩阵表示：<br>$$<br>\bf x=\alpha Ay  ,    y=\beta A^Tx    \ \Longrightarrow<br>AA^Tx=\lambda x,   A^TAy=\lambda y<br>$$<br>其中，$\lambda=(\alpha \beta)^{-1}$</p><blockquote><p>权威中心性与核心中心性分别由具有相同特征值的矩阵$AA^T$和$A^TA$对应的特征向量决定。</p><p>因此矩阵$AA^T$和$A^TA$ 有相同的主特征值$\lambda$ ：</p><p>若 $\bf AA^Tx=\lambda x$ , 公式两边都乘以 $A^T$ , 可以得到 $\bf A^TA(A^Tx)=\lambda(A^Tx)$。因此$A^Tx$ 也是矩阵$A^TA$ 的特征值为$\lambda$ 的特征向量， 即$\bf y=A^Tx$ 。 </p></blockquote><blockquote><ul><li>$AA^T$ 是共引矩阵，权威中心性可以粗略的认为是共引网络的特征向量中心性；</li><li>$A^TA$ 是文献耦合矩阵，核心中心性就是文献耦合网络的特征向量中心性；</li></ul></blockquote></li></ul><h3 id="接近度中心性"><a href="#接近度中心性" class="headerlink" title="接近度中心性"></a>接近度中心性</h3><p>接近中心性不同于其他中心性测度，度量了一个结点到其他结点的平均距离。接近中心性的思想是结点越趋于中心，越能快速到达其他结点。形象化的描述为，这些结点满足与其他结点之间有最小平均最短路径。</p><ul><li>定义：平均测地距离的倒数<br>$$<br>C_i=\frac{1}{\ell_i}    \<br>\ell_i = \frac{1}{n}\sum_j d_{ij}    \  or \<br>\ell_i = \frac{1}{n-1} \sum_{j(\neq i)} d_{ij}<br>$$</li></ul><blockquote><ul><li><p>问题1：接近中心性最大最小值之间的动态变化范围很小。大部分网络中，顶点之间的测地距离$d_{ij}$ 一般很小，随网络规模增长呈对数级速度增长。而且最短测地距离与最长测地距离确定了平均距离$\ell_i$的上下限，因此$\ell_i$和$C_i$的取值范围都较小。结点接近中心性的密集意味着网络结构的微小变化就会引起接近度中心性值排序的显著变化。</p></li><li><p>问题2：若将不同分支中的结点间的测地距离定义为无穷大，那么假设任何一个多于一个分支的网络中所有结点$i$的$\ell_i$ 都为无穷大，则$C_i$ 为零。</p></li><li>解决方法之一是<strong>只计算在同一分支内部的结点的平均测地距离</strong>，但仍然存在固有缺陷：小规模分支内部结点间的距离普遍偏小，与大规模分支中的结点相比，其$\ell_i$较小，$C_i$更大。产生不理想的结果：<strong>大多数情况下，小规模分支中结点之间的连通程度比大规模分支中要低，因此应赋予较低的中心性</strong>。</li></ul></blockquote><p>重定义接近中心性，使用结点之间的<strong>调和平均测地距离</strong>：<br>$$<br>C_i’= \frac{1}{n-1}\sum_{j(\neq i)} \frac{1}{d_{ij} }<br>$$</p><ul><li><p>网络平均测地距离：</p><ul><li>对于只有一个分支的网络，所有结点对之间的平均距离为</li></ul><p>$$<br>\ell = \frac{1}{n^2}\sum_{ij}d_{ij} = \frac{1}{n}\sum_i \ell_i<br>$$</p><p>​    即所有结点的平均测地距离$\ell_i$的平均值。</p><ul><li><p>对于多分支网络，<em>只计算同一分支内部结点之间路径的平均长度</em>。令${ {\scr C}_m }$表示网络中分支的集合，定义：<br>$$<br>\ell = \frac{\sum_m \sum_{ij\in {\scr C}<em>m} d</em>{ij} }{\sum_m n_m^2}<br>$$<br>其中，$n_m$为分支$\scr C_m$中的结点数。</p><p>另一中定义方式为定义一个调和平均距离$\ell ’$ ：<br>$$<br>\frac{1}{\ell ‘} = \frac{1}{n(n-1)} \sum_{i \neq j} \frac{1}{d_{ij} }=\frac{1}{n}\sum_i C_i’    \  \Longleftrightarrow \<br>\ell ‘ = \frac{n}{\sum_i C_i’}<br>$$</p></li></ul></li></ul><h3 id="介数中心性"><a href="#介数中心性" class="headerlink" title="介数中心性"></a>介数中心性</h3><p>考虑结点在连接其他结点时表现的”中介“次数，即其他结点间通过结点$v_i$的最短路径的数目。</p><p><strong>介数中心性衡量某个结点对其他结点对之间信息流动的影响力。</strong> </p><ul><li><p>定义：<br>$$<br>C_b(v_i) = \sum_{s \neq t \neq v_i} \frac{s到t经过v_i的最短路径数目}{s到t的最短路径数目} =\sum_{s \neq t \neq v_i} \frac{\sigma_{st}(v_i)}{\sigma_{st} }<br>$$</p></li><li><p>归一化：</p><ul><li><p>最大值：当结点$v_i$出现在连接任意结点对$(s,t)$的所有最短路径中时，该结点的中间中心性对应最大值1，即$\forall (s,t), s \neq t \neq v_i , \frac{\sigma_{st} (v_i)}{\sigma_{st} } = 1$。 因此，最大值为：<br>$$<br>C_b(v_i)=\sum_{s \neq t \neq v_i} \frac{\sigma_{st}(v_i)}{\sigma_{st} }=\sum_{s \neq t \neq v_i} 1 = 2<br>\begin{pmatrix}<br>n-1 \<br>2\<br>\end{pmatrix} = (n-1)(n-2)<br>$$</p></li><li></li></ul><p>$$<br>C_b^{norm}(v_i) = \frac{C_b(v_i)}{2\begin{pmatrix}<br>n-1 \<br>2\<br>\end{pmatrix} }<br>$$</p></li></ul><h4 id="另一种表述"><a href="#另一种表述" class="headerlink" title="另一种表述"></a>另一种表述</h4><p>表示一般性网络的介数，定义$n_{st}^i$为从$s$到$t$经过$i$的测地路径数量，定义$g_{st}$为从$s$到$t$的测地路径总数。那么结点$i$的介数中心性可以表示为<br>$$<br>x_i = \sum_{st} \frac{n_{st}^i}{g_{st} }<br>$$<br>介数中心性主要是度量一个结点“介于”其他结点的程度。</p><blockquote><p>一个结点的度可以很低，与其相连的结点的度也很低，与其他结点之间的平均距离很长，但仍有较高的介数。</p><p><a href="https://imgchr.com/i/kulBSH" target="_blank" rel="noopener"><img src="images/kulBSH.png" alt="kulBSH.png"></a></p><p>如图，结点A是网络中两个结点群组之间的桥梁，由于两个群组结点之间的任何最短路径都必须经过结点A，因此A获得了很高的介数。结点A对于其他结点间信息流动起到控制作用，此类结点在社会学文献中称为”<strong>中间人</strong>“。</p></blockquote><ul><li><p>归一化：（考虑自环）</p><ul><li>基于结点对：<br>$$<br>x_i= \frac{1}{n^2}\sum_{st} \frac{n_{st}^i}{g_{st} }<br>$$</li></ul></li></ul><ul><li>基于介数最大可能值：<br>$$<br>x_i = \frac{1}{n^2-n+1} \sum_{st}\frac{n_{st}^i}{g_{st} }<br>$$</li></ul><h3 id="群体中心性"><a href="#群体中心性" class="headerlink" title="群体中心性"></a>群体中心性</h3><p>考虑如何将度中心性、接近中心性以及中间中心性应用到一组结点上。</p><p>假设$S$表示需要求解群体中心性的结点集，$V-S$表示上述集合之外的结点集。</p><h4 id="群体度中心性"><a href="#群体度中心性" class="headerlink" title="群体度中心性"></a>群体度中心性</h4><p>群体度中心性是群体外部结点连接到群体内部结点的数目。形式化的定义为：<br>$$<br>C_d^{group}(S)=|{v_i \in V-S| v_i连接到v_j \in S}|<br>$$<br>与度中心性相似，可以利用有向图中的入度或出度。同时该值可以进行归一化。</p><p>最理想的情况为，群体中的结点均连接到群体外的所有结点上，此时$C_d^{group}(S)$的最大值为$V-S$。使用群体度中心性除以$|V-S|$进行归一化处理。</p><h4 id="群体介数中心性"><a href="#群体介数中心性" class="headerlink" title="群体介数中心性"></a>群体介数中心性</h4><p>群体介数中心性被定义为：<br>$$<br>C_b^{group}(S) = \sum_{s\neq t, s\notin S, t \notin S}  \frac{\sigma_{st}(S)}{\sigma_{st} }<br>$$<br>其中，$\sigma_{st}(S)$ 表示从$s$到$t$经过集合$S$中元素的最短路径的数目。</p><p>最理想的情况下，从$s$到$t$的所有的最短路径均经过集合$S$中的元素，因此，$C_b^{group}(S)$的最大值为${2\begin{pmatrix}  |V-S| \ 2\  \end{pmatrix} }$。</p><p>和介数中心性相似，使用介数中心性除以最大值进行归一化处理。</p><h4 id="群体接近中心性"><a href="#群体接近中心性" class="headerlink" title="群体接近中心性"></a>群体接近中心性</h4><p>群体接近中心性被定义为：<br>$$<br>C_c^{group}(S)=\frac{1}{\bar l_S^{group} }<br>$$<br>其中，$\bar l <em>S^{group} = \frac{1}{|V-S|}\sum</em>{v_j \notin S} l_{S,v_j}$，$l_{S,v_j}$是群体$S$与群体之外的元素$v_j \in V-S$的最短路径的长度。该长度可以以多种方式定义，一种方法是寻找$S$中距离$v_j$最近的成员元素：<br>$$<br>l_{S,v_j} = \min_{v_i \in S}l_{v_i,v_j}<br>$$<br>另一种是使用最大距离或者平均距离。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;度&quot;&gt;&lt;a href=&quot;#度&quot; class=&quot;headerlink&quot; title=&quot;度&quot;&gt;&lt;/a&gt;度&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;定义：&lt;strong&gt;与结点直接相连的边数目&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;对于无向图：&lt;/p&gt;
&lt;ul&gt;

      
    
    </summary>
    
      <category term="复杂网络" scheme="http://yoururl.com/categories/%E5%A4%8D%E6%9D%82%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Networks" scheme="http://yoururl.com/tags/Networks/"/>
    
  </entry>
  
  <entry>
    <title>知识图谱：知识表示之TransD模型</title>
    <link href="http://yoururl.com/2019/01/20/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA%E4%B9%8BTransD/"/>
    <id>http://yoururl.com/2019/01/20/知识表示之TransD/</id>
    <published>2019-01-19T16:01:00.000Z</published>
    <updated>2019-03-05T03:06:16.704Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TransD"><a href="#TransD" class="headerlink" title="TransD"></a>TransD</h1><p>论文地址: <a href="http://www.aclweb.org/anthology/P15-1067" target="_blank" rel="noopener">http://www.aclweb.org/anthology/P15-1067</a></p><p>TransR /CTransR模型存在的问题：</p><ul><li>对于一种关系，所有实体共享一样的映射矩阵${\bf M}_r$。然而被同一个关系链接的实体拥有不同的类型和属性，这些差异需要用不同的映射来体现；</li><li>实体与关系间的映射是可逆的，没有理由只通过关系来构建映射矩阵；</li><li>矩阵向量乘法运算，参数多，模型运算量大；</li></ul><p>创新点：</p><ul><li>TransD可以说是TransR/CTransR的简化版本，它同时考虑了实体和关系之间的多样性，用两个向量来动态重构mapping矩阵；</li><li>相比TransR/CTransR有更小的计算量，且没有矩阵运算，可以在大规模KG上应用；</li></ul><p><strong>实体关系的多语义表示</strong>：</p><p><img src="https://s2.ax1x.com/2019/03/05/kXcDX9.png" alt="kXcDX9.png"></p><h2 id="模型改进"><a href="#模型改进" class="headerlink" title="模型改进"></a>模型改进</h2><p>TransD 模型同 CTransR 模型一样，都是为了解决关系的多种语义表示。相比较 CTransR 采用聚类的方式，TransD 提出一种<strong>动态变化矩阵</strong>的方法。</p><p><img src="https://s2.ax1x.com/2019/03/05/kXc0l4.png" alt="kXc0l4.png"></p><p>每一个命名对象（实体关系）用两个向量表示：</p><ul><li>$(h,r,t)$ :  自身的关系（语义）表示；</li><li>$(h_p, r_p, t_p)$ :  实体空间中的投影，用于构建映射矩阵的表示；</li></ul><p>具体公式如下图所示：</p><p>$$<br>{\bf M}_{rh} = {\bf r}_p{\bf h}_p^T + {\bf I}^{m \times n}<br>$$</p><p>$$<br>{\bf M}_{rt} = {\bf r}_p{\bf t}_p^T + {\bf I}^{m \times n}<br>$$</p><ul><li>下标$p$表示投影向量， ${\bf h} , {\bf h}_p, {\bf t} , {\bf t}_p \in {\Bbb R}^n$ ,  ${\bf r}, {\bf r}_p \in {\Bbb R}^m$</li><li>映射矩阵的每一个元素都包含了实体和关系信息；</li><li>通过向量相乘生成的矩阵对单位矩阵（代表不做变换）进行调整；</li></ul><p>定义向量在关系空间的投影：<br>$$<br>{\bf h_{\perp} }={\bf M}_{rh} {\bf h}<br>$$</p><p>$$<br>{\bf t_{\perp} }={\bf M}_{rt} {\bf t}<br>$$</p><p>得分函数：</p><p>$$<br>f_r({\bf h,t})= -|| {\bf h_\perp} + {\bf {r-t}_\perp}||_2^2<br>$$</p><ul><li>限制条件：  </li></ul><p>$$<br>||{\bf h}||_2 \leq 1, ||{\bf t}||_2 \leq 1,     ||{\bf r}||<em>2 \leq 1, ||{\bf h</em>\perp}||<em>2 \leq 1, ||{\bf t</em>\perp}||_2 \leq 1<br>$$</p><h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p>假设训练集中有$n_t$个三元组，用$(h_i,r_i,t_i)(i=1,2,…,n_t)$表示第$i$个三元组。</p><p>每个三元组有标签$y_i$表示三元组的正负性质：<br>$$<br>\Delta = {(h_j,r_j,t_j)|y_j=1}<br>$$</p><p>$$<br>\Delta’ = {(h_j,r_j,t_j)|y_j=0}<br>$$</p><h3 id="负样本生成"><a href="#负样本生成" class="headerlink" title="负样本生成"></a>负样本生成</h3><p>$$<br>\Delta’ = {(h_l,r_k,t_k)|h_l\neq h_k \wedge y_k=1} \cup {(h_k,r_k,t_l)|t_l\neq t_k \wedge y_k=1}<br>$$</p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>$$<br>{\cal L}=\sum_{\xi \in \Delta} \sum_{\xi’ \in \Delta’ } [\gamma + f_r(\xi’)-f_{r}(\xi) ]_+<br>$$</p><ul><li>$\xi$ : 正样本， $\xi’$ : 负样本</li></ul><p>为加快收敛和避免过拟合：</p><ul><li><p>利用TransE模型初始化实体和关系嵌入向量；</p></li><li><p>用单位矩阵初始化转移矩阵；   </p></li></ul><h2 id="和其他模型的联系"><a href="#和其他模型的联系" class="headerlink" title="和其他模型的联系"></a>和其他模型的联系</h2><h3 id="TransE"><a href="#TransE" class="headerlink" title="TransE"></a>TransE</h3><p>当向量维度满足$m=n$，且所有用于构建映射矩阵的投影向量都为0时，TransE是TransD的一种特殊情况。</p><h3 id="TransH"><a href="#TransH" class="headerlink" title="TransH"></a>TransH</h3><p>当向量维度满足$m=n$时，实体的投影向量能被表示为：<br>$$<br>{\bf h_{\perp} }={\bf M}_{rh} {\bf h} = {\bf h}+{\bf h}_p^T {\bf h} {\bf r}_p<br>$$</p><p>$$<br>{\bf t_{\perp} }={\bf M}_{rt} {\bf t} = {\bf t}+{\bf t}_p^T {\bf t} {\bf r}_p<br>$$</p><p>此时，投影向量仅由关系表示。</p><h3 id="TransR-CTransR"><a href="#TransR-CTransR" class="headerlink" title="TransR/CTransR"></a>TransR/CTransR</h3><p>相比TransR对每个关系直接定义一个映射矩阵，TransD通过为每个实体关系对设置一个投影向量，来为三元组动态的构造映射矩阵。</p><p>另外，TransD没有矩阵向量乘法操作，可以用向量运算代替：</p><p>假设$m \geq n$，投影向量能按以下方式计算：<br>$$<br>{\bf h_{\perp} }={\bf M}_{rh} {\bf h} = {\bf h}_p^T {\bf h} {\bf r}_p + [{\bf h}^T, {\bf 0}^T]^T<br>$$</p><p>$$<br>{\bf t_{\perp} }={\bf M}_{rt} {\bf t} = {\bf t}_p^T {\bf t} {\bf r}_p + [{\bf t}^T, {\bf 0}^T]^T<br>$$</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TransD&quot;&gt;&lt;a href=&quot;#TransD&quot; class=&quot;headerlink&quot; title=&quot;TransD&quot;&gt;&lt;/a&gt;TransD&lt;/h1&gt;&lt;p&gt;论文地址: &lt;a href=&quot;http://www.aclweb.org/anthology/P15-106
      
    
    </summary>
    
      <category term="知识图谱" scheme="http://yoururl.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="Knowledge graph" scheme="http://yoururl.com/tags/Knowledge-graph/"/>
    
  </entry>
  
  <entry>
    <title>R安装与关联jupyter</title>
    <link href="http://yoururl.com/2018/12/14/R%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E5%88%B0jupyter/"/>
    <id>http://yoururl.com/2018/12/14/R安装配置到jupyter/</id>
    <published>2018-12-13T16:01:00.000Z</published>
    <updated>2019-01-26T14:57:23.797Z</updated>
    
    <content type="html"><![CDATA[<h2 id="R安装并配置到jupyter"><a href="#R安装并配置到jupyter" class="headerlink" title="R安装并配置到jupyter"></a>R安装并配置到jupyter</h2><ul><li><p>安装R</p><p>版本：<a href="https://mran.revolutionanalytics.com/download" target="_blank" rel="noopener">Microsoft R Open 3.5.1</a></p></li><li><p>cmd进入R会话</p></li></ul><ul><li><p>输入如下配置命令;</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">install.packages(<span class="string">"devtools"</span>)</span><br><span class="line">devtools::install_github(<span class="string">"IRkernel/IRkernel"</span>)</span><br><span class="line">IRkernel::installspec()</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;R安装并配置到jupyter&quot;&gt;&lt;a href=&quot;#R安装并配置到jupyter&quot; class=&quot;headerlink&quot; title=&quot;R安装并配置到jupyter&quot;&gt;&lt;/a&gt;R安装并配置到jupyter&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;安装R&lt;/p&gt;
&lt;p&gt;版本
      
    
    </summary>
    
      <category term="安装与配置" scheme="http://yoururl.com/categories/%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/"/>
    
    
      <category term="Install &amp; config" scheme="http://yoururl.com/tags/Install-config/"/>
    
  </entry>
  
  <entry>
    <title>jupyterLab安装与配置</title>
    <link href="http://yoururl.com/2018/12/01/%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AEjupyterLab/"/>
    <id>http://yoururl.com/2018/12/01/安装与配置jupyterLab/</id>
    <published>2018-11-30T16:01:00.000Z</published>
    <updated>2019-01-26T14:41:16.205Z</updated>
    
    <content type="html"><![CDATA[<h2 id="安装与更新-jupyterLab"><a href="#安装与更新-jupyterLab" class="headerlink" title="安装与更新 jupyterLab"></a>安装与更新 jupyterLab</h2><ul><li>安装jupyterLab</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install -c conda-forge jupyterlab</span><br></pre></td></tr></table></figure><ul><li>更新jupyterlab</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U jupyterlab</span><br></pre></td></tr></table></figure><h2 id="安装nodejs"><a href="#安装nodejs" class="headerlink" title="安装nodejs"></a>安装nodejs</h2><ul><li>安装nodejs</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install -c conda-forge nodejs</span><br></pre></td></tr></table></figure><ul><li>安装扩展</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension install my-extension</span><br></pre></td></tr></table></figure><ul><li>列出扩展</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension list</span><br></pre></td></tr></table></figure><ul><li>卸载扩展</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension uninstall my-extension</span><br></pre></td></tr></table></figure><ul><li>启用扩展</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension enable my-extension</span><br></pre></td></tr></table></figure><ul><li>禁用扩展</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension disable my-extension</span><br></pre></td></tr></table></figure><h2 id="插件"><a href="#插件" class="headerlink" title="插件"></a>插件</h2><ul><li>目录</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension install @jupyterlab/toc</span><br></pre></td></tr></table></figure><ul><li>tensorboard</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension install jupyterlab_tensorboard</span><br></pre></td></tr></table></figure><ul><li>html</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension install @mflevine/jupyterlab_html</span><br></pre></td></tr></table></figure><ul><li>latex</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension install @jupyterlab/latex</span><br></pre></td></tr></table></figure><ul><li>go-to-definition</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension install @krassowski/jupyterlab_go_to_definition</span><br></pre></td></tr></table></figure><ul><li>voyager</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension install jupyterlab_voyager</span><br></pre></td></tr></table></figure><ul><li>statusbar</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension install @jupyterlab/statusbar</span><br></pre></td></tr></table></figure><ul><li>celltags</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension install @jupyterlab/celltags</span><br></pre></td></tr></table></figure><ul><li>drawio</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter labextension install jupyterlab-drawio</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;安装与更新-jupyterLab&quot;&gt;&lt;a href=&quot;#安装与更新-jupyterLab&quot; class=&quot;headerlink&quot; title=&quot;安装与更新 jupyterLab&quot;&gt;&lt;/a&gt;安装与更新 jupyterLab&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;安装jupyte
      
    
    </summary>
    
      <category term="安装与配置" scheme="http://yoururl.com/categories/%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/"/>
    
    
      <category term="Install &amp; config" scheme="http://yoururl.com/tags/Install-config/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow环境 人脸识别 FaceNet 应用（一）:FaceNet安装与验证测试集</title>
    <link href="http://yoururl.com/2018/07/15/windows%E4%B8%8Bpython3.5%E5%AE%89%E8%A3%85facenet/"/>
    <id>http://yoururl.com/2018/07/15/windows下python3.5安装facenet/</id>
    <published>2018-07-15T02:15:33.025Z</published>
    <updated>2018-03-20T08:07:06.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>作者：Andy_z<br>文献：<a href="https://arxiv.org/abs/1503.03832" target="_blank" rel="noopener">FaceNet: A Unified Embedding for Face Recognition and Clustering</a><br><a href="https://pan.baidu.com/s/1R70SWpSmF7SoZB5vkHdfpw" target="_blank" rel="noopener">数据集及模型下载通道</a>：(密码：3wty)</p></blockquote><p>##一、前提条件</p><p>###1.&emsp;已安装Tensorflow</p><p>###2.&emsp;已在安装下列包(二选一):   </p><p>&emsp;&emsp;a.&emsp;python下安装scipy, scikit-learn, opencv-python, h5py, matplotlib, Pillow, requests, psutil</p><p>&emsp;&emsp;b.&emsp;安装Anaconda集成环境</p><p>###3.&emsp;已更新Sklearn至最新版本(二选一):</p><p>&emsp;&emsp;a.&emsp;可在propmt下”conda update conda “</p><p>&emsp;&emsp;b.&emsp;直接在cmd命令行下”pip install -U scikit-learn”</p><p>###4.&emsp;已安装git</p><blockquote><p>备注:如果没有完成以上的第3点,之后执行align时,可能会出现”no module named facenet”,”no module named align”,”no module named scikit-learn”等情况</p></blockquote><p>##二、安装和配置FaceNet</p><p>&emsp;&emsp;1.&emsp;在cmd命令行，定位到自己想下载的文件夹,用git下载FaceNet源代码工程:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone --recursive https://github.com/davidsandberg/facenet.git</span><br></pre></td></tr></table></figure><blockquote><p>建议：最好定位在&emsp;&emsp;Anaconda3\Lib\site-packages&emsp;&emsp;下安装。因为FaceNet也相当于一个python库。</p></blockquote><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-15/23373226.jpg" alt=""></p><p>&emsp;&emsp;2.&emsp;下载数据集LFW。LFW数据集是由美国马萨诸塞大学阿姆斯特分校计算机视觉实验室整理的。下载地址：<a href="http://vis-www.cs.umass.edu/lfw/lfw.tgz" target="_blank" rel="noopener">http://vis-www.cs.umass.edu/lfw/lfw.tgz</a>, 下载完成后，把数据解压到目录 ..facenet\data\lfw\raw  下面,新建一个空文件夹命名为”lfw_160”。可以看到数据集中每张图像的分辩率是250*250。</p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-15/8023931.jpg" alt=""></p><p>&emsp;&emsp;3.&emsp;设置环境变量,以下方法二选一:</p><p>&emsp;&emsp;a.&emsp;在cmd命令行键入：set PYTHONPATH=…\facenet\src, 例如笔者的是:set PYTHONPATH=D:\Anaconda2\envs\py3.6\Lib\site-packages\facenet\src</p><p>&emsp;&emsp;b.&emsp;在 计算机–&gt;属性–&gt;高级系统设置–&gt;环境变量中,新建PYTHONPATH,键入 D:\Anaconda2\envs\py3.6\Lib\site-packages\facenet\src</p><p>检验:在cmd命令行下面，键入set，查看设置情况</p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-15/66907272.jpg" alt=""></p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-15/56240084.jpg" alt=""></p><p>##三、图像数据预处理</p><blockquote><p>也可直接使用下载的已处理数据集</p></blockquote><p>&emsp;&emsp;我们需要将待检测所使用的数据集校准为和预训练模型所使用的数据集大小一致。</p><p>&emsp;&emsp;1.&emsp;使用&emsp;facenet\src\align\align_dataset_mtcnn.py&emsp;进行校准,校准后的图片存在&emsp;..facenet\data\lfw\lfw_160&emsp;下面。在cmd命令行 或者 对应语言版本的propmt下，定位到facenet所在位置，键入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python src\align\align_dataset_mtcnn.py data/lfw/raw data/lfw/lfw_160</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;官方Wiki说明</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python src/align/align_dataset_mtcnn.py ~/datasets/casia/CASIA-maxpy-clean/ ~/datasets/casia/casia_maxpy_mtcnnpy_182 --image_size 182 --margin 44</span><br></pre></td></tr></table></figure><blockquote><p>上述命令生成的脸部缩略图是182x182像素。</p></blockquote><p>&emsp;&emsp;2.&emsp;校准后发现图像大小变了</p><p>##四、评估谷歌预训练模型在数据集的准确率</p><p>&emsp;&emsp;1.&emsp;下载预训练的模型。把下载的文件解压到src\models\目录下面。</p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-15/34564036.jpg" alt=""></p><p>&emsp;&emsp;2.&emsp;程序下载好了,测试数据集LFW也有了,模型也有了,接下来就可以评估模型在数据集的准确率了。在cmd命令行或者propmt下定位到facenet文件夹下，输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python src\validate_on_lfw.py data\lfw\lfw_160 src\models\20170512-110547</span><br></pre></td></tr></table></figure><p>紧接着,预测中,结果如图：</p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-15/47530520.jpg" alt=""></p><p>##五、其他</p><p>###5.1 对比<br>&emsp;&emsp;facenet可以直接比对两个人脸经过它的网络映射之后的欧氏距离，运行程序为facenet-master\src\compare.py。<br>-1、在compare.py所在目录下放入要比对的文件1.jpg和2.jpg，打开cmd命令行窗口<br>-2、cd到compare.py所在路径<br>-3、输入 python compare.py models/20170512-110547 1.png 2.png</p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-16/42045957.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;作者：Andy_z&lt;br&gt;文献：&lt;a href=&quot;https://arxiv.org/abs/1503.03832&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;FaceNet: A Unified Embedding for F
      
    
    </summary>
    
      <category term="人脸识别" scheme="http://yoururl.com/categories/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/"/>
    
    
      <category term="Summary" scheme="http://yoururl.com/tags/Summary/"/>
    
      <category term="facenet" scheme="http://yoururl.com/tags/facenet/"/>
    
      <category term="face recognition" scheme="http://yoururl.com/tags/face-recognition/"/>
    
  </entry>
  
  <entry>
    <title>Jupyter notebook: How to create a slideshow</title>
    <link href="http://yoururl.com/2018/07/15/Jupyter%20notebook%EF%BC%9AHow%20to%20create%20a%20slideshow/"/>
    <id>http://yoururl.com/2018/07/15/Jupyter notebook：How to create a slideshow/</id>
    <published>2018-07-15T02:15:32.933Z</published>
    <updated>2018-04-25T17:54:21.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="利用Jupyter-notebook-制作PPT"><a href="#利用Jupyter-notebook-制作PPT" class="headerlink" title="利用Jupyter notebook 制作PPT"></a>利用Jupyter notebook 制作PPT</h1><p>使用 Jupyter notebook 作为 slide 主要优点：  </p><ul><li>运行 notebook 可以播放幻灯片  </li><li>导出 slides.html 格式的幻灯片，方便在浏览器打开播放</li></ul><h2 id="工具依赖"><a href="#工具依赖" class="headerlink" title="工具依赖"></a>工具依赖</h2><ul><li>RISE</li><li>reveal.js </li></ul><h3 id="RISE"><a href="#RISE" class="headerlink" title="RISE"></a>RISE</h3><p>RISE allows you to instantly turn your Jupyter Notebooks into a slideshow. No out-of-band conversion is needed, switch from jupyter notebook to a live reveal.js-based slideshow in a single keystroke, and back.</p><h4 id="Install-RISE"><a href="#Install-RISE" class="headerlink" title="Install RISE"></a>Install RISE</h4><h4 id="Option-1-Using-conda"><a href="#Option-1-Using-conda" class="headerlink" title="Option 1 - Using conda :"></a>Option 1 - Using conda :</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install -c damianavila82 rise</span><br></pre></td></tr></table></figure><h4 id="Option-2-Using-pip"><a href="#Option-2-Using-pip" class="headerlink" title="Option 2 - Using pip::"></a>Option 2 - Using pip::</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install RISE</span><br></pre></td></tr></table></figure><p>and then two more steps to install the JS and CSS in the proper places:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter-nbextension install rise --py --sys-prefix</span><br></pre></td></tr></table></figure><p>and enable the nbextension:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter-nbextension enable rise --py --sys-prefix</span><br></pre></td></tr></table></figure><h3 id="reveal-js"><a href="#reveal-js" class="headerlink" title="reveal.js"></a>reveal.js</h3><p>A framework for easily creating beautiful presentations using HTML. <a href="https://revealjs.com/#/" target="_blank" rel="noopener">Check out the live demo.</a></p><p>reveal.js comes with a broad range of features including nested slides, Markdown contents, PDF export, speaker notes and a JavaScript API. There’s also a fully featured visual editor and platform for sharing reveal.js presentations at slides.com.  </p><p>Reveal.js 是一个使用 HTML 语言制作演示文稿的 Web 框架，支持插入多种格式的内容，并以类似 PPT 的形式呈现。  </p><p>Reveal.js 具有许多优势：</p><ul><li>制作灵活、不限应用，只需修改 HTML 文件</li><li>发布灵活、不限平台，只需打开 HTML 文件</li><li>丰富的特性，支持过渡动画、代码高亮、视频背景、Markdown 语法、导出 PDF 等</li><li>极度轻量，占用空间和内存少</li></ul><p>配置流程：  </p><ul><li>在 notebook 文件目录（包含 .ipnb 文件）下， clone <a href="https://github.com/hakimel/reveal.js.git" target="_blank" rel="noopener">reveal.js</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/hakimel/reveal.js.git</span><br></pre></td></tr></table></figure><h2 id="slide-设置"><a href="#slide-设置" class="headerlink" title="slide 设置"></a>slide 设置</h2><p>这里有一个幻灯片<a href="http://www.slideviper.oquanta.info/tutorial/slideshow_tutorial_slides.html#/" target="_blank" rel="noopener">示例</a>供参考，其制作风格简洁明晰。</p><p>那么如何用 Jupyter Notebook 制作幻灯片呢？<br>首先在 notebook 的菜单栏选择 View &gt; Cell Toolbar &gt; Slideshow，这时在文档的每个单元右上角显示了 Slide Type 的选项。通过设置不同的类型，来控制幻灯片的格式。有如下5中类型：</p><ul><li>Slide：主页面，通过按左右方向键进行切换。</li><li>Sub-Slide：副页面，通过按上下方向键进行切换。</li><li>Fragment：一开始是隐藏的，按空格键或方向键后显示，实现动态效果。</li><li>Skip：在幻灯片中不显示的单元。</li><li>Notes：作为演讲者的备忘笔记，也不在幻灯片中显示。</li></ul><h2 id="生成幻灯片"><a href="#生成幻灯片" class="headerlink" title="生成幻灯片"></a>生成幻灯片</h2><p>在notebook中设置cell 的slide属性，确认后保存，例如 notebook.ipynb<br>使用nbconvert 来将notebook文件转换为HTML  </p><pre><code class="python">jupyter nbconvert --to slides notebook.ipynb --reveal-prefix=reveal.js</code></pre><p>生成文件： notebook.slides.html , 直接用浏览器打开即可播放幻灯片</p><p>有时候不想要input cell显示在slide上面，这个时候可以使用下面的设置：  </p><pre><code class="python">jupyter nbconvert RainStromNetworkAnalysis.ipynb --to slides --TemplateExporter.exclude_input=<span class="keyword">True</span>  </code></pre><p>同样的使用下面的命令虽然可以隐藏input cell但是不能生成slide只能生成html文件：  </p><pre><code class="python">jupyter nbconvert --template=nbextensions --to=slides RainStromNetworkAnalysis.ipynb</code></pre><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>Reveal.js 支持 Markdown 语法，我们得以直接在 Markdown 编辑器里做 PPT。以上只是制作了最简单的 PPT，我们后续还可以添加各种动画效果、背景、图表等内容。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;利用Jupyter-notebook-制作PPT&quot;&gt;&lt;a href=&quot;#利用Jupyter-notebook-制作PPT&quot; class=&quot;headerlink&quot; title=&quot;利用Jupyter notebook 制作PPT&quot;&gt;&lt;/a&gt;利用Jupyter note
      
    
    </summary>
    
      <category term="Jupyter" scheme="http://yoururl.com/categories/Jupyter/"/>
    
    
      <category term="Jupyter" scheme="http://yoururl.com/tags/Jupyter/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow环境 人脸识别 FaceNet 应用（二）:FaceNet官方WiKi解读</title>
    <link href="http://yoururl.com/2018/07/15/FaceNet%20%E5%AE%98%E6%96%B9WiKi%E8%A7%A3%E8%AF%BB/"/>
    <id>http://yoururl.com/2018/07/15/FaceNet 官方WiKi解读/</id>
    <published>2018-07-15T02:15:32.918Z</published>
    <updated>2018-03-23T08:27:53.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>作者：Andy_z<br>文献：<a href="https://github.com/davidsandberg/facenet/wiki" target="_blank" rel="noopener">官方WiKi</a></p></blockquote><p>##一、分类器训练</p><p>###1.1 运行 train_softmax.py 文件训练<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">python src/train_softmax.py</span><br><span class="line">--logs_base_dir ~/logs/facenet/</span><br><span class="line">--models_base_dir ~/models/facenet/</span><br><span class="line">--data_dir ~/datasets/casia/casia_maxpy_mtcnnalign_182</span><br><span class="line">--image_size 160</span><br><span class="line">--model_def models.inception_resnet_v1</span><br><span class="line">--lfw_dir /home/david/datasets/lfw/lfw_mtcnnalign_160</span><br><span class="line">--optimizer RMSPROP</span><br><span class="line">--learning_rate -1</span><br><span class="line">--max_nrof_epochs 80</span><br><span class="line">--keep_probability 0.8</span><br><span class="line">--random_crop</span><br><span class="line">--random_flip</span><br><span class="line">--learning_rate_schedule_file data/learning_rate_schedule_classifier_casia.txt</span><br><span class="line">--weight_decay 5e-5</span><br><span class="line">--center_loss_factor 1e-2</span><br><span class="line">--center_loss_alfa 0.9</span><br></pre></td></tr></table></figure></p><ul><li><strong>log_base_dir</strong>:<br><strong>models_base_dir</strong>:<br>训练开始时，以数据/时间训练开始的训练会话的子目录以yyyymmdd-hhmm的格式在以上两个目录中创建。  </li><li><strong>data_dir</strong>：  用于指出训练数据集的位置，可以通过用冒号分隔路径来使用几个数据集的联合。<br>model_def： 给出推理网络的描述符，上述样例中  models.inception_resnet_v1 指向models包中的<br>inception_resnet_v1模块。 该模块定义一个函数 inference(images, …)，images是输入图像的占位符(Inception-ResNet-v1的尺寸&lt;?, 160,160,3&gt;),并返回一个embeddings变量的引用。  </li><li><strong>lfw_dir</strong>：如果将参数lfw_dir设置为指向LFW数据集的基本目录，那么每1000个批次将在LFW上对该模型进行评估。有关如何在LFW上评估现有模型的信息，请参阅 Validate-on-LFW 页面。 如果在训练期间不需要对LFW进行评估，则可以将lfw_dir参数留空。 但请注意，此处使用的LFW数据集应与训练数据集一致。  </li><li><strong>max_nrof_epochs</strong>：最大训练周期。  </li><li><strong>learning_rate_schedule_file</strong>：为了改善最终模型的性能，当训练开始收敛时，学习速率降低10倍。 这是通过在参数learning_rate_schedule_file指向的文本文件中定义的学习速率时间表来完成的，同时还将参数learning_rate设置为负值。 为了简单起见，本例中data / learning_rate_schedule_classifier_casia.txt中使用的学习率也包括在库中。</li></ul><blockquote><p>注：train_tripletloss.py和train_softmax.py的区别：这是作者对论文做出的一个延伸，除了使用facenet里提到的train_tripletloss三元组损失函数来训练，还实现了用softmax的训练方法来训练。当然，在样本量很小的情况下，用softmax训练会更容易收敛。但是，当训练集中包含大量的不同个体(超过10万)时，最后一层的softmax输出数量就会变得非常大，但是使用train_tripletloss的训练仍然可以正常工作。</p></blockquote><p>###1.2 运行 train_softmax.py 文件训练</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">python src/train_tripletloss.py</span><br><span class="line">--logs_base_dir ~/logs/facenet/</span><br><span class="line">--models_base_dir ~/models/facenet/</span><br><span class="line">--data_dir ~/datasets/casia/casia_maxpy_mtcnnalign_182_160</span><br><span class="line">--image_size 160</span><br><span class="line">--model_def models.inception_resnet_v1</span><br><span class="line">--lfw_dir ~/datasets/lfw/lfw_mtcnnalign_160</span><br><span class="line">--optimizer RMSPROP</span><br><span class="line">--learning_rate 0.01</span><br><span class="line">--weight_decay 1e-4</span><br><span class="line">--max_nrof_epochs 500</span><br></pre></td></tr></table></figure><p>##二、可视化TensorBoard<br>&emsp;&emsp;监视训练过程，使用TensorBoard:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=~/logs/facenet --port 6006</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;打开浏览器：<a href="http://localhost:6006/" target="_blank" rel="noopener">http://localhost:6006/</a></p><p>##三、用自己的图像训练分类器</p><p>###3.1 在LFW上训练分类器  </p><p>&emsp;&emsp;对于这个实验，我们使用LFW图像的子集来训练分类器。 LFW数据集分为训练和测试集。 然后加载预训练模型，然后使用此模型为选定图像生成特征。 预训练模型通常在更大的数据集上进行训练以提供良好的性能（本例中为MS-Celeb-1M数据集的一个子集）。</p><ul><li>将数据集分解为训练和测试集</li><li>加载预训练模型进行特征提取</li><li>计算数据集中图像的嵌入</li><li><p>模式= TRAIN：</p><ul><li>使用来自数据集的训练部分的嵌入来训练分类器  </li><li>将训练好的分类模型保存为python pickle</li></ul></li><li><p>模式= CLASSIFY：</p><ul><li>加载分类模型</li><li>使用来自数据集测试部分的嵌入来测试分类器  </li></ul></li></ul><blockquote><p>classifier.py定义参数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">def parse_arguments(argv):</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line"></span><br><span class="line">    parser.add_argument(&apos;mode&apos;, type=str, choices=[&apos;TRAIN&apos;, &apos;CLASSIFY&apos;],</span><br><span class="line">        help=&apos;Indicates if a new classifier should be trained or a classification &apos; +</span><br><span class="line">        &apos;model should be used for classification&apos;, default=&apos;CLASSIFY&apos;)</span><br><span class="line">    parser.add_argument(&apos;data_dir&apos;, type=str,</span><br><span class="line">        help=&apos;Path to the data directory containing aligned LFW face patches.&apos;)</span><br><span class="line">    parser.add_argument(&apos;model&apos;, type=str,</span><br><span class="line">        help=&apos;Could be either a directory containing the meta_file and ckpt_file or a model protobuf (.pb) file&apos;)</span><br><span class="line">    parser.add_argument(&apos;classifier_filename&apos;,</span><br><span class="line">        help=&apos;Classifier model file name as a pickle (.pkl) file. &apos; +</span><br><span class="line">        &apos;For training this is the output and for classification this is an input.&apos;)</span><br><span class="line">    parser.add_argument(&apos;--use_split_dataset&apos;,</span><br><span class="line">        help=&apos;Indicates that the dataset specified by data_dir should be split into a training and test set. &apos; +  </span><br><span class="line">        &apos;Otherwise a separate test set can be specified using the test_data_dir option.&apos;, action=&apos;store_true&apos;)</span><br><span class="line">    parser.add_argument(&apos;--test_data_dir&apos;, type=str,</span><br><span class="line">        help=&apos;Path to the test data directory containing aligned images used for testing.&apos;)</span><br><span class="line">    parser.add_argument(&apos;--batch_size&apos;, type=int,</span><br><span class="line">        help=&apos;Number of images to process in a batch.&apos;, default=90)</span><br><span class="line">    parser.add_argument(&apos;--image_size&apos;, type=int,</span><br><span class="line">        help=&apos;Image size (height, width) in pixels.&apos;, default=160)</span><br><span class="line">    parser.add_argument(&apos;--seed&apos;, type=int,</span><br><span class="line">        help=&apos;Random seed.&apos;, default=666)</span><br><span class="line">    parser.add_argument(&apos;--min_nrof_images_per_class&apos;, type=int,</span><br><span class="line">        help=&apos;Only include classes with at least this number of images in the dataset&apos;, default=20)</span><br><span class="line">    parser.add_argument(&apos;--nrof_train_images_per_class&apos;, type=int,</span><br><span class="line">        help=&apos;Use this number of images from each class for training and the rest for testing&apos;, default=10)</span><br><span class="line"></span><br><span class="line">    return parser.parse_args(argv)</span><br></pre></td></tr></table></figure></p></blockquote><ul><li><strong>mode</strong>：  指示训练新分类器还是进行分类测试集。’TRAIN’,    ‘CLASSIFY’</li><li><strong>data_dir</strong>：  包含对齐的LFW面部补丁的数据目录路径。</li><li><strong>model</strong>：  可能是包含meta_file和ckpt_file或模型protobuf(.pb)文件的目录</li><li><strong>classifier_filename</strong>：  分类器模型文件名称作pickle（.pkl）文件，对于训练过程，这是输出；对于分类过程，这是输入。</li><li><strong>use_split_dataset</strong>：  指示由data_dir指定的数据集应该分为训练集和测试集。 否则可以使用test_data_dir选项指定单独的测试集。</li><li><strong>test_data_dir</strong>：  包含用于测试的对齐图像的测试数据目录的路径。</li><li><strong>batch_size</strong>：  一个批次的图像运行数量。</li><li><strong>image_size</strong> ：  图像的像素尺寸。</li><li><strong>seed</strong>:   随机seed。</li><li><strong>min_nrof_images_per_class</strong>：  仅包含数据集中至少包含这些数量的图像的类。</li><li><strong>nrof_train_images_per_class</strong>：  从每个类中使用这个数量的图像进行训练，其余的进行测试。</li></ul><p>&emsp;&emsp;在数据集的训练集部分训练分类器的步骤如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">python src/classifier.py</span><br><span class="line">TRAIN</span><br><span class="line">data/lfw/lfw_align_mtcnnpy_160/</span><br><span class="line">src/models/20170512-110547/20170512-110547.pb</span><br><span class="line">src/models/lfw_classifier.pkl</span><br><span class="line">--batch_size 1000</span><br><span class="line">--min_nrof_images_per_class 40</span><br><span class="line">--nrof_train_images_per_class 35</span><br><span class="line">--use_split_dataset</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python src/classifier.py TRAIN data/lfw/lfw_align_mtcnnpy_160/ src/models/20170512-110547/20170512-110547.pb src/models/lfw_classifier.pkl --batch_size 1000 --min_nrof_images_per_class 40 --nrof_train_images_per_class 35 --use_split_dataset</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;训练输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Number of classes: 19</span><br><span class="line">Number of images: 665</span><br><span class="line">Loading feature extraction model</span><br><span class="line">Model filename: src/models/20170512-110547/20170512-110547.pb</span><br><span class="line">Calculating features for images</span><br><span class="line">Training classifier</span><br><span class="line">Saved classifier model to file &quot;src/models/lfw_classifier.pkl&quot;</span><br></pre></td></tr></table></figure></p><p>&emsp;&emsp;训练好的分类器可以稍后用于使用测试集进行分类：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">python src/classifier.py</span><br><span class="line">CLASSIFY</span><br><span class="line">data/lfw/lfw_align_mtcnnpy_160/</span><br><span class="line">src/models/20170512-110547/20170512-110547.pb</span><br><span class="line">src/models/lfw_classifier.pkl</span><br><span class="line">--batch_size 1000</span><br><span class="line">--min_nrof_images_per_class 40</span><br><span class="line">--nrof_train_images_per_class 35</span><br><span class="line">--use_split_dataset</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python src/classifier.py CLASSIFY data/lfw/lfw_align_mtcnnpy_160/ src/models/20170512-110547/20170512-110547.pb src/models/lfw_classifier.pkl --batch_size 1000 --min_nrof_images_per_class 40 --nrof_train_images_per_class 35 --use_split_dataset</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;单独指定测试集</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python src/classifier.py CLASSIFY data/lfw/test_lfw src/models/20170512-110547/20170512-110547.pb src/models/lfw_classifier.pkl --batch_size 1000 --min_nrof_images_per_class 40 --nrof_train_images_per_class 35 --test_data_dir data/lfw/test_lfw</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;这里使用数据集的测试集部分进行分类，并显示分类结果和分类概率。 该子集的分类准确度为〜0.98。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Number of classes: 19</span><br><span class="line">Number of images: 1202</span><br><span class="line">Loading feature extraction model</span><br><span class="line">Model filename: src/models/20170512-110547/20170512-110547.pb</span><br><span class="line">Calculating features for images</span><br><span class="line">Testing classifier</span><br><span class="line">Loaded classifier model from file &quot;src/models/lfw_classifier.pkl&quot;</span><br><span class="line">   0  Ariel Sharon: 0.712</span><br><span class="line">   1  Ariel Sharon: 0.771</span><br><span class="line">   2  Ariel Sharon: 0.807</span><br><span class="line">   3  Ariel Sharon: 0.785</span><br><span class="line">   4  Ariel Sharon: 0.750</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">1197  Vladimir Putin: 0.536</span><br><span class="line">1198  Vladimir Putin: 0.723</span><br><span class="line">1199  Vladimir Putin: 0.715</span><br><span class="line">1200  Vladimir Putin: 0.663</span><br><span class="line">1201  Vladimir Putin: 0.732</span><br><span class="line">Accuracy: 0.999</span><br></pre></td></tr></table></figure></p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-21/53475149.jpg" alt=""></p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-21/76473615.jpg" alt=""></p><p>##四、基于mtcnn与facenet的人脸识别（单张图像识别分类）</p><p>&emsp;&emsp;代码：facenet/contributed/predict.py  </p><p>&emsp;&emsp;主要功能：</p><ul><li><p>① 使用mtcnn进行人脸检测并对齐与裁剪</p></li><li><p>② 对裁剪的人脸使用facenet进行embedding</p></li><li><p>③ 执行predict.py进行人脸识别（需要训练好的svm模型）</p></li></ul><p>&emsp;&emsp;参数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def parse_arguments(argv):</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(&apos;image_files&apos;, type=str, nargs=&apos;+&apos;, help=&apos;Path(s) of the image(s)&apos;)</span><br><span class="line">    parser.add_argument(&apos;model&apos;, type=str,</span><br><span class="line">        help=&apos;Could be either a directory containing the meta_file and ckpt_file or a model protobuf (.pb) file&apos;)</span><br><span class="line">    parser.add_argument(&apos;classifier_filename&apos;,</span><br><span class="line">        help=&apos;Classifier model file name as a pickle (.pkl) file. &apos; +</span><br><span class="line">        &apos;For training this is the output and for classification this is an input.&apos;)</span><br><span class="line">    parser.add_argument(&apos;--image_size&apos;, type=int,</span><br><span class="line">        help=&apos;Image size (height, width) in pixels.&apos;, default=160)</span><br><span class="line">    parser.add_argument(&apos;--seed&apos;, type=int,</span><br><span class="line">        help=&apos;Random seed.&apos;, default=666)</span><br><span class="line">    parser.add_argument(&apos;--margin&apos;, type=int,</span><br><span class="line">        help=&apos;Margin for the crop around the bounding box (height, width) in pixels.&apos;, default=44)</span><br><span class="line">    parser.add_argument(&apos;--gpu_memory_fraction&apos;, type=float,</span><br><span class="line">        help=&apos;Upper bound on the amount of GPU memory that will be used by the process.&apos;, default=1.0)</span><br><span class="line">    return parser.parse_args(argv)</span><br></pre></td></tr></table></figure></p><ul><li><strong>image_files</strong>： 被识别图像路径</li><li><strong>model</strong>：包含meta_file和ckpt_file或模型protobuf（.pb）文件的目录</li><li><strong>classifier_filename</strong>：分类器模型文件名称作为pickle（.pkl）文件</li></ul><p>&emsp;&emsp;测试：用三中生成的lfw_classifier.pkl作为分类器模型进行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python predict.py d:/Anaconda3/Lib/site-packages/facenet/data/images/3.png D:/Anaconda3/Lib/site-packages/facenet/src/models/20170512-110547 D:/Anaconda3/Lib/site-packages/facenet/src/models/lfw_classifier.pkl</span><br></pre></td></tr></table></figure><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-22/3119407.jpg" alt=""></p><p>python contributed/predict.py data/images/2.png src/models/20170512-110547 src/models/lfw_classifier_whole.pkl</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;作者：Andy_z&lt;br&gt;文献：&lt;a href=&quot;https://github.com/davidsandberg/facenet/wiki&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;官方WiKi&lt;/a&gt;&lt;/p&gt;
&lt;/bloc
      
    
    </summary>
    
      <category term="人脸识别" scheme="http://yoururl.com/categories/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/"/>
    
    
      <category term="Summary" scheme="http://yoururl.com/tags/Summary/"/>
    
      <category term="facenet" scheme="http://yoururl.com/tags/facenet/"/>
    
      <category term="face recognition" scheme="http://yoururl.com/tags/face-recognition/"/>
    
  </entry>
  
  <entry>
    <title>DeepFool</title>
    <link href="http://yoururl.com/2018/07/15/Deep%20Fool/"/>
    <id>http://yoururl.com/2018/07/15/Deep Fool/</id>
    <published>2018-07-15T02:15:32.911Z</published>
    <updated>2018-03-14T07:20:13.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>作者：Andy_z<br>翻译文献：<a href="https://arxiv.org/abs/1511.04599" target="_blank" rel="noopener">DeepFool: a simple and accurate method to fool deep neural networks</a><br>^_^: 红色小字为作者自己的小白理解，如有错误，请谅解。欢迎纠正！</p></blockquote><p><a href="1">^_^</a></p><p>#符号说明</p><table><thead><tr><th>符号</th><th>说明</th></tr></thead><tbody><tr><td>$x$</td><td>原始图像</td></tr><tr><td>$r$</td><td>扰动</td></tr><tr><td>$\hat{k}(x)$</td><td>预测标签</td></tr><tr><td>$Δ(x;\hat{k})$</td><td>$\hat{k}$ 在点 $x$ 处的鲁棒性</td></tr><tr><td>$\mathbb{E}_x$</td><td>数据分布期望</td></tr></tbody></table><p>&emsp;&emsp;对于给定分类器，定义对抗扰动:<br>$$<br>∆(x;<br>\hat{k}) := \min_r ||r||_2 \;\; s.t.\; \hat{k}(x + r) ≠ \hat{k}(x),</p><p>\tag{1}<br>$$</p><p>&emsp;&emsp;分类器的鲁棒性定义为：<br>$$<br>ρ_{adv}(\hat{k}) = \mathbb{E}_x \,\frac{∆(x;\hat{k})}{ ||x||_2},<br>\tag{2}<br>$$</p><p>#对于二分类器的DeepFool</p><p>&emsp;&emsp;多分类器可以看作是二值分类器的集合，因此先研究二分类器算法。</p><ul><li><p>我们假设 $\hat{k}(x) = sign(f(x))$ ，其中 $f$ 是一个任意的标量值图像分类函数，$f:\mathbb{R}^n \rightarrow \mathbb{R}$ 。<br>用 ${\scr F}=^\Delta={x:f(x)=0}$ 表示 $f$ 的零水平集。<br>首先分析当 $f$ 是一个<a href="https://baike.baidu.com/item/%E4%BB%BF%E5%B0%84%E5%87%BD%E6%95%B0/9276178?fr=aladdin" target="_blank" rel="noopener">仿射</a>分类器 $f(x)=w^Tx+b$ ，然后推导出一般算法，该算法可应用于任何可微二值分类器 $f$。</p></li><li><p>当 $f$ 是仿射的分类器时，$f$ 在 $x_0$ 点处的鲁棒性: $\Delta (x_0;f)$ ，等于从 $x_0$ 到分离仿射超平面 ${\scr F}={x:w^Tx+b=0}$ 的距离（见图2），</p></li></ul><blockquote><p>之后，我们通过 $f$ 或其相应的离散映射 $\hat{k}$ 来引用分类器。 因此，$ρ<em>{adv}(\hat{k})=ρ</em>{adv}(f) 和 Δ(x; \hat{k})=Δ(x; f)$。</p></blockquote><center><font color="#0099ff" size="2" face="黑体">图2：线性二值分类器的对抗样本 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-13/76583305.jpg" alt=""></p><ul><li>改变分类器决策的最小扰动对应于 $x_0$ 到 ${\scr F}$ 上的正交投影。  由下列封闭式公式给出：<br>$$<br>r_∗(x_0) := arg \min ||r||_2<br>\;\;s.t. \;sign(f(x_0 + r))  \not= sign(f(x_0))<br>= −\frac{f(x_0)}{\sideset{}{^2_2}{||w||}}w,<br>\tag{3}<br>$$</li></ul><blockquote><font color="#FF0000" size="2" face="黑体"><a href="1">^_^</a>:推导参考支持向量机概念。</font></blockquote><ul><li>现在假设 $f$ 是一般的二元可微分类器，我们采用迭代过程来估计鲁棒性 $\Delta (x_0;f)$ ，具体而言，在每次迭代中，$f$ 围绕当前点 $x_i$线性化，并且线性化分类器的最小扰动被计算为:<br>$$<br>arg \min_{r_i} ||r_i||_2 \;\;s.t.\; f(x_i) + ∇f(x_i)^Tr_i = 0,<br>\tag{4}<br>$$</li></ul><blockquote><font color="#FF0000" size="2" face="黑体"><a href="1">^_^</a>:梯度方向即为垂直超平面的方向，也就是超平面的法线上方向，可以最快达到分类边界。</font></blockquote><ul><li>算法的迭代 $i$ 中的扰动 $r_i$ 是使用方程（3）中的封闭形式解来计算的，并且在下一个迭代 $x_{i + 1}$ 被更新。当 $x_{i + 1}$ 改变分类器的符号时，该算法停止。</li></ul><center><font color="#0099ff" size="2" face="黑体">算法1：二值分类器的DeepFool算法 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-13/47575515.jpg" alt=""></p><center><font color="#0099ff" size="2" face="黑体">图3：算法1的几何图示 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-13/85167736.jpg" alt=""></p><blockquote><p>  当 $n=2$ 时，假设 $x_0∈ \mathbb{R}^n$ 。 绿色平面是 $x→f(x_0)+∇f(x_0)^T(x−x_0)$ 的图形，与分类器函数 $x→f(x)$ 相切。橙色线表示 $f(x_0) + ∇f(x_0)^T(x-x_0) = 0$ ， $x_0$ 投影到 $\mathbb{R}^n$ 的橙色超平面进一步得到 $x_1$ 。</p></blockquote><p>&emsp;&emsp;以上算法经常能收敛到零水平集 ${\scr F}$ 。但为了到达分类边界的另一边，最后的扰动向量 $\hat{r}$ 需要乘 $1+η$，且 $η≪1$ 。在后续实验中 $η=0.02$ 。</p><p>#对于多分类器的DeepFool</p><p>&emsp;&emsp;将DeepFool方法推广到多分类器。多分类器最常用的方法是 <a href="http://blog.csdn.net/u013082989/article/details/53001746" target="_blank" rel="noopener">one-vs-all</a>(一对多)。因此基于该分类方案提出方法。</p><ul><li>在该方案中，分类器有 $c$ 类输出， 因此分类器能被定义为 $f: \mathbb{R}^n \rightarrow \mathbb{R}^c$  。分类是通过以下映射完成的：<br>$$<br>\hat{k}(x)=arg\max_k \;f_k(x),<br>\tag{5}<br>$$<br>&emsp;&emsp;&emsp; $f_k(x)$ 是 $f(x)$ 对应于第 $k$ 类的输出。</li></ul><p>&emsp;&emsp;与二分类情况类似，我们首先提出了线性情况的建议方法，然后将其推广到其他分类器。</p><p>##仿射多分类器</p><ul><li>$f(x)$ 是仿射分类器，$f(x)=W^T+b$ 。映射 $\hat{k}$ 是“one-vs-all”分类方案的结果。欺骗分类器的最小扰动表示如下：<br>$$<br>arg \min_r||r||_2 \;\;s.t.\;∃k : \sideset{}{^T_k}w(x_0+r)+b_k ≥ \sideset{}{^T_{\hat{k}(x_0)}}w(x_0 + r)+b_{\hat{k}(x_0)},<br>\tag{6}<br>$$</li></ul><blockquote><font color="#FF0000" size="2" face="黑体"><a href="1">^_^</a>:计算最小扰动，首先要保证分类与原始点产生变化(即扰动导致分类结果变化)，那么约束条件就是，存在一类，使得这一类的分类置信度大于 原始预测的置信度</font></blockquote><p>&emsp;&emsp;&emsp; $w_k$ 是 $W$ 的第 $k$ 列。从几何上看，上述问题对应于计算 $x_0$ 和 凸多面体 $P$ 的补集的距离：<br>$$<br>P=\bigcap_{k=1}^{c}{x:f_{\hat{k}(x_0)}(x)≥ f_k(x)},<br>\tag{7}<br>$$</p><p>&emsp;&emsp;&emsp;其中， $x_0$ 落在 $P$ 内部。距离用 $dist(x_0,P^c)$ 表示。 多面体 $P$ 定义了 $f$ 输出标签 $\hat{k}(x_0)$ 的范围。 设置如图4所示：</p><center><font color="#0099ff" size="2" face="黑体">图4：仿射多分类器输出标签空间区域 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-13/35279198.jpg" alt=""></p><blockquote><p>若 $x_0$ 属于类别4，令 ${\scr F}_k={x:f_k(x)-f_4(x)=0}$ 。这些超平面用实线表示，P的边界用绿色虚线表示。</p></blockquote><ul><li>定义 $\hat{l}(x_0)$ 为离 $P$ 的边界最近的超平面(如图4中的 $\hat{l}(x_0)=3$)。 $\hat{l}(x_0)$ 计算如下：</li></ul><p>$$\hat{l}(x_0)=arg \min_{k\not={\hat{k}(x_0)}}\frac{|f_k(x_0)-f_{\hat{k}(x_0)}(x_0)|}{||w_k-w_{\hat{k}(x_0)}||_2}.<br>\tag{8}<br>$$</p><p>&emsp;&emsp;&emsp;最小扰动 $r_<em>(x_0)$ 是把 $x_0$ 投影到超平面的向量：<br>$$<br>r_</em>(x_0)=\frac{|f_{\hat{l}(x_0)}(x_0)-f_{\hat{k}(x_0)}(x_0)|}{\sideset{}{^2_2}{||w_{\hat{l}(x_0)}-w_{\hat{k}(x_0)}||}}(w_{\hat{l}(x_0)}-w_{\hat{k}(x_0)}).<br>\tag{9}<br>$$</p><p>&emsp;&emsp;&emsp;换句话说，我们在 $P$ 的面上发现了 $x_0$ 的最近投影。</p><p>##一般多分类器<br>&emsp;&emsp;现在将DeepFool算法扩展到一般的多分类器。</p><ul><li>对于一般的非线性分类器，式(7)中的集合 $P$ 描述的分类器输出标签 $\hat{k}(x_0)$ 的区域空间不再是一个多面体。在二分类情况下解释迭代的线性过程，我们用一个多面体 $\tilde{P}_i$ 在迭代次数 $i$ 下近似集合 $P$ 。<br>$$<br>\tilde{P}<em>i= \bigcap</em>{k=1}^{c}{x:f_k(x_i)-f_{\hat{k}(x_0)}(x_i) + ∇f_k(x_i)^Tx-∇f_{\hat{k}(x_0)}(x_i)^Tx≤0}.<br>\tag{10}<br>$$</li></ul><center><font color="#0099ff" size="2" face="黑体">图5：非线性多分类器输出标签区域空间 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-14/81096955.jpg" alt=""></p><ul><li><p>随后用 $dist(x_i,\sideset{}{_i^c}{\tilde{P}})$ 在迭代次数 $i$ 下近似 $x_i$ 到 $P$ 补集的距离。算法的每次迭代中，到达多面体 $\tilde{P}_i$ 边界的扰动向量被计算，当前预测更新。</p><p>该算法在算法2中给出。应该注意，所提出的算法以<a href="http://www.52ml.net/10359.html" target="_blank" rel="noopener">贪心</a>方式运行，并且不能保证收敛于(1)中的最佳扰动。 然而，我们在实践中观察到，我们的算法产生非常小的扰动，这被认为是最小扰动的良好近似。</p></li></ul><center><font color="#0099ff" size="2" face="黑体">算法2：多分类器的DeepFool算法</font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-13/66140912.jpg" alt=""></p><p>&emsp;&emsp;应该指出的是，DeepFool的优化策略与现有的优化技术密切相关。 在二分类情况下，它可以看作牛顿迭代算法，用于在欠定情况下找到非线性方程组的根。 这种算法被称为正常流量法。 我们在二分类情况下的算法可以被看作是梯度下降算法，具有在每次迭代时自动选择的自适应步长。 算法2中的线性化也类似于序列凸规划，其中约束在每一步被线性化。</p><p>##拓展到 $L_p$ 范数<br>&emsp;&emsp;我们已经用 $L_2$ 范数计算了扰动。我们的框架不限制选择，提出的算法可以调节，用任何 $L_p$ 范数  $(p∈[1,∞])$ 来寻找最小对抗扰动。</p><ul><li>为此，算法2中第10行和第11行的更新步骤必须分别由以下更新代替：</li></ul><p>$$<br>\hat{l}\leftarrow arg\min_{k\not=\hat{k}(x_0)}\frac{|f’_k|}{||w’_k||_q},<br>\tag{11}<br>$$</p><p>$$<br>r_i\leftarrow\frac{|f’_{\hat{l}}|}{\sideset{}{^q_q}{||w’<em>{\hat{l}}||}}|w’</em>{\hat{l}}|^{q-1}\bigodot sign(w’_{\hat{l}}),<br>\tag{12}<br>$$</p><p>&emsp;&emsp;&emsp; $\bigodot$ 是逐点乘积，$q=\frac{p}{p-1}$ 。当 $p=∞$ 时(即 $l_∞$ 范数)， 更新步骤变成：<br>$$<br>\hat{l}\leftarrow arg\min_{k\not=\hat{k}(x_0)}\frac{|f’_k|}{||w’_k||_1},<br>\tag{13}<br>$$</p><p>$$<br>r_i\leftarrow\frac{|f’<em>{\hat{l}}|}{||w’</em>{\hat{l}}||<em>1} sign(w’</em>{\hat{l}}),<br>\tag{14}<br>$$</p><p>#实验</p><p>##设置</p><p>&emsp;&emsp;我们现在在应用于MNIST，CIFAR-10和ImageNet图像分类数据集的深度卷积神经网络架构上测试我们的DeepFool算法。 我们考虑以下深度神经网络架构：</p><ul><li><p><strong>MNIST</strong>：一个双层全连接网络和一个双层LeNet卷积神经网络结构。 这两个网络都是使用MatConvNet包通过SGD进行训练。</p></li><li><p><strong>CIFAR-10</strong>：我们训练了三层LeNet架构，以及网络网络（NIN）架构。</p></li><li><p><strong>ILSVRC 2012</strong>：我们使用了CaffeNet 和GoogLeNet预训练模型</p></li></ul><p>&emsp;&emsp;为了评估分类器 $f$ 的对抗扰动的鲁棒性， 定义平均鲁棒性 $\hat{ρ}<em>{adv}(f)$ :<br>$$<br>\hat{ρ}</em>{adv}(f)=\frac{1}{|{\scr D}|}\sum_{x∈{\scr D}}\frac{||\hat{r}(x)||_2}{||x||_2},<br>\tag{15}<br>$$</p><p>其中，$\hat{r}(x)$ 是使用DeepFool得到的预测最小扰动 ， ${\scr D}$ 代表测试集。</p><p>##结论</p><p>&emsp;&emsp;我们在表1中呈现了使用不同方法计算的每个分类器的准确度和平均鲁棒性 $\hatρ_{adv}$ 。 我们还显示了每种方法计算一个对抗样本所需的运行时间。 可以看出，DeepFool估计的扰动比使用竞争方法计算的扰动更小（因此更接近于(1)中定义的最小扰动）。 例如，使用DeepFool获得的平均扰动比FGSM估计的平均扰动低5倍。 在ILSVRC2012挑战数据集上，平均扰动比FGSM小一个数量级。 此外，与<a href="https://arxiv.org/abs/1312.6199" target="_blank" rel="noopener">18</a>中的方法相比，所提出的方法也产生更小的扰动矢量， 所提出的方法因此在检测可能欺骗神经网络的方向上更精确。 因此，DeepFool可以用作精确评估分类器鲁棒性的有用工具。</p><center><font color="#0099ff" size="2" face="黑体">表一：不同分类器在不同数据集的对抗鲁棒性 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-13/44616336.jpg" alt=""></p><blockquote><p>每个方法计算一个样本所需的时间在时间栏中给出。 时间是在2015年中的MacBook Pro上计算的，无需CUDA支持。 星号标记表示使用GTX 750 Ti GPU计算的值。[4]:FGSM</p></blockquote><p>&emsp;&emsp;在复杂性方面，所提出的方法比[18]中提出的标准方法快得多。事实上，虽然[18]方法涉及到一系列目标函数的代价最小化，但我们经验性地观察到，DeepFool在少数迭代（即小于3）中收敛于愚弄分类器的扰动向量。因此，与现有技术方法相比，所提出的方法达到更精确的扰动矢量，同时在计算上是有效的。这使得它很容易被用作基线方法来估计大规模数据集上非常深的神经网络的鲁棒性。在这种情况下，我们首先对大规模ImageNet数据集上最先进的分类器的鲁棒性进行量化评估。可以看出，尽管测试精度非常高，但这些方法对对抗扰动极不稳定：幅度比原始图像小1000倍的扰动足以欺骗最先进的深度神经网络。</p><center><font color="#0099ff" size="2" face="黑体">图6：对抗扰动的样本对比 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-13/11841802.jpg" alt=""></p><p>&emsp;&emsp;第一行：被分类为 $\hat{k}(x)=$ “鲸鱼”的原始图像 $x$ 。<br>&emsp;&emsp;第二行：被分类为 $\hat{k}(x+r)=$ “乌龟”的图像 $x + r$ 以及由DeepFool计算出的相应扰动 $r$ 。<br>&emsp;&emsp;第三行：被分类为“乌龟”的图像以及由FGSM计算出的相应扰动。 DeepFool导致更小的扰动。</p><p>&emsp;&emsp;可以观察到，DeepFool 产生难以察觉的对抗扰动，而FGSM输出具有更高范数的扰动图像。</p><ul><li>注意到，当扰动用最大范数计算时，上述结论依然成立： DeepFool 较其他方法生成更小的对抗扰动。</li></ul><center><font color="#0099ff" size="2" face="黑体">表2：对抗扰动的最大范数鲁棒性 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-14/22804987.jpg" alt=""></p><blockquote><p>分别基于DeepFool(最小的 $l_∞$ 扰动)和FGSM的四个不同网络的 $\sideset{}{^∞_{adv}}{\hat{ρ}}$ 值， 错误分类率达到90%</p></blockquote><p>$$<br>\sideset{}{^∞<em>{adv}}{\hat{ρ}}(f)=\frac{1}{|{\scr D}|} \sum</em>{x\in{\scr D}}\frac{||\hat{r}(x)||<em>∞}{||x||</em>∞},<br>$$</p><p>&emsp;&emsp;其中  $\hat{r}(x)$  分别使用DeepFool( $p =∞$ ，参见3.3节)和快速梯度符号法计算。</p><p>###使用对抗样本进行微调</p><p>&emsp;&emsp;在本节中，我们对表1中的对抗样本所用的网络进行微调，为MNIST和CIFAR-10任务构建更鲁棒的分类器。具体来说，对于每个网络，我们进行了两个实验：<br>&emsp;&emsp;(1)在DeepFool的对抗样本中微调网络，<br>&emsp;&emsp;(2)在快速梯度符号对抗样本上微调网络。<br>我们通过执行另外5个训练周期对网络进行微调，仅在扰动的训练集上减少了50％的学习速率。对于每个实验，所有5个额外的周期使用相同的训练数据。为了完整性，我们还对原始数据执行了5个额外的周期。图7a至图7d显示了不同微调策略的 $\hat{ρ}<em>{adv}$ 的演变，其中鲁棒性 $\hat{ρ}</em>{adv}$ 是使用DeepFool估算的，因为这是最准确的方法，如表1所示。观察到即使在一个额外周期之后，对DeepFool对抗样本的微调也增强了网络对对抗扰动的鲁棒性。例如，MNIST网络的鲁棒性提高了50％，NIN的鲁棒性提高了约40％。  </p><center><font color="#0099ff" size="2" face="黑体">图7：微调效果 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-14/88045331.jpg" alt=""></p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-14/19503473.jpg" alt=""></p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-14/15536386.jpg" alt=""></p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-14/98947187.jpg" alt=""></p><p>&emsp;&emsp;另一方面，令人惊讶的是，FGSM可能会导致网络的对抗扰动鲁棒性下降。我们推测这种行为是由于使用FGSM估计的扰动远远大于最小对抗扰动。用过度扰动的图像微调网络会降低网络对对抗扰动的鲁棒性。为了验证这个假设，我们在图8中比较了一个网络的对抗鲁棒性，这个网络用DeepFool获得的对抗样本进行了微调，其中扰动的范数被故意乘以 $α= 1,2,3$ 。</p><center><font color="#0099ff" size="2" face="黑体">图8：调整扰动范数对鲁棒性的影响 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-14/47701062.jpg" alt=""></p><p>&emsp;&emsp;有趣的是，我们看到通过放大对抗性扰动的范数，微调网络的鲁棒性降低。这可以解释为什么过度扰动的图像会降低MNIST网络的鲁棒性：这些扰动可能真的改变数据的类别，因此基于这些样本进行的微调可能导致鲁棒性的下降（有关说明，请参见图9） 。这证实了我们的假设，并进一步显示了设计精确方法来计算最小扰动的重要性。</p><center><font color="#0099ff" size="2" face="黑体">图9：不同 α 值带来的图片数字识别类型的改变</font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-14/9476430.jpg" alt=""></p><blockquote><p>原始图像被识别为 “1”，DeepFool 扰动图像被识别为”7”。</p></blockquote><p>&emsp;&emsp;表3列出了微调网络的精度。 可以看出，使用DeepFool进行微调可以提高网络的准确性。 相反，使用FGSM进行微调导致了我们所有实验中测试精度的降低。 这证实了FGSM输出一些不太可能出现在测试数据中的过度扰动图像。 因此，它降低了该方法的性能，因为它充当正则化器而不代表原始数据的分布。 这种效应类似于几何数据增强方案，其中原始样本的大变换对泛化具有相反的效果。</p><center><font color="#0099ff" size="2" face="黑体">表3：微调网络精度 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-14/96929609.jpg" alt=""></p><blockquote><p>微调后的网络测试错误率（五个周期后）。 每列对应于不同类型的增强扰动。</p></blockquote><p>&emsp;&emsp;为了强调对最小扰动的正确估计的重要性，我们现在表明使用近似方法可能导致关于网络的对抗鲁棒性的错误结论。 我们对快速梯度符号对抗样本中的NIN分类器进行了微调。 我们遵循前面描述的程序，但是这次我们将学习率降低了90％。 我们已经使用DeepFool和FGSM评估了此网络在不同额外周期的对抗鲁棒性。 如图10所示，红线 夸大了训练对对抗样本的影响。 此外，它不足以证明在第一个额外周期失去鲁棒性。</p><center><font color="#0099ff" size="2" face="黑体">图10：正则化的鲁棒性 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-14/82983733.jpg" alt=""></p><blockquote><p>如何用不同的方法判断对抗鲁棒性。 这些值通过原始网络的相应 $\hat{ρ}_{adv}$ 进行归一化。</p></blockquote><p>&emsp;&emsp;这些观察结果证实，使用准确的工具来衡量分类器的鲁棒性对于得出有关网络鲁棒性的结论是至关重要的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;作者：Andy_z&lt;br&gt;翻译文献：&lt;a href=&quot;https://arxiv.org/abs/1511.04599&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;DeepFool: a simple and accurate 
      
    
    </summary>
    
      <category term="对抗攻击" scheme="http://yoururl.com/categories/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/"/>
    
    
      <category term="Deep learning" scheme="http://yoururl.com/tags/Deep-learning/"/>
    
      <category term="Adversarial attack" scheme="http://yoururl.com/tags/Adversarial-attack/"/>
    
      <category term="Translation" scheme="http://yoururl.com/tags/Translation/"/>
    
  </entry>
  
</feed>

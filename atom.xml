<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Andy_z &#39;s Blog</title>
  
  <subtitle>Coding - Thinking - Sharing - Deep learning</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoururl.com/"/>
  <updated>2019-01-26T05:50:53.975Z</updated>
  <id>http://yoururl.com/</id>
  
  <author>
    <name>Andy_z</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>知识图谱：知识表示之TransH模型</title>
    <link href="http://yoururl.com/2019/01/20/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA%E4%B9%8BTransH/"/>
    <id>http://yoururl.com/2019/01/20/知识表示之TransH/</id>
    <published>2019-01-19T16:02:00.000Z</published>
    <updated>2019-01-26T05:50:53.975Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TransH"><a href="#TransH" class="headerlink" title="TransH"></a>TransH</h1><p>论文地址：<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/viewFile/8531/8546" target="_blank" rel="noopener">https://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/viewFile/8531/8546</a></p><h2 id="模型改进"><a href="#模型改进" class="headerlink" title="模型改进"></a>模型改进</h2><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-11-1/58905342.jpg" alt=""></p><p>将特定关系的转移向量 $d_r$ 放置于特定关系的超平面 $w_r$ ,而不是映射到相同的实体嵌入空间；  </p><p>对于三元组 $(h,r,t)$，嵌入向量 ${\bf h}$ 和 ${\bf t}$ 投影到超平面 ${\bf w<em>r}$ , 投影被表示为 ${\bf h</em>\bot}$ 和 ${\bf t<em>\bot}$ 。投影 ${\bf h</em>\bot}$ 和 ${\bf t_\bot}$ 能被转移向量 ${\bf d_r}$ 连接， 当三元组为正样本时有更低的错误率，为负样本时错误率上升；   </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TransH&quot;&gt;&lt;a href=&quot;#TransH&quot; class=&quot;headerlink&quot; title=&quot;TransH&quot;&gt;&lt;/a&gt;TransH&lt;/h1&gt;&lt;p&gt;论文地址：&lt;a href=&quot;https://www.aaai.org/ocs/index.php/AAAI/
      
    
    </summary>
    
      <category term="知识图谱" scheme="http://yoururl.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="Knowledge graph" scheme="http://yoururl.com/tags/Knowledge-graph/"/>
    
  </entry>
  
  <entry>
    <title>复杂网络：网络测度之中心性</title>
    <link href="http://yoururl.com/2019/01/20/%E7%BD%91%E7%BB%9C%E5%BA%A6%E4%B8%8E%E4%B8%AD%E5%BF%83%E6%80%A7/"/>
    <id>http://yoururl.com/2019/01/20/网络度与中心性/</id>
    <published>2019-01-19T16:01:00.000Z</published>
    <updated>2019-01-26T04:58:27.313Z</updated>
    
    <content type="html"><![CDATA[<h2 id="度"><a href="#度" class="headerlink" title="度"></a>度</h2><ul><li><p>定义：<strong>与结点直接相连的边数目</strong></p></li><li><p>对于无向图：</p><ul><li><p>结点 $i$ 的度 可用邻接矩阵表示为  $k<em>i=\sum</em>{j=1}^n A_{ij}$  ;</p></li><li><p>无向图中，若边数量为 $m$ , 则边端点为 $2m$ , <strong>边的端点数与所有顶点度总和相等</strong> ， $2m=\sum_{i=1}^n k_i$  或</p><script type="math/tex; mode=display">m = \frac{1}{2} \sum_{i=1}^n k_i = \frac{1}{2} \sum_{ij} A_{ij}</script></li><li><p>顶点度均值 $c = \frac{1}{n} \sum_{i=1}^n k_i$ ;</p><script type="math/tex; mode=display">c=\frac{2m}{n}</script><blockquote><p>$cn=2m$ : 顶点度总和 == 无向边端点数</p></blockquote></li></ul></li><li><blockquote><p>简单图（无重边和自边）中，可能最大边数为 $\frac{1}{2}n(n-1)$ 个。</p><p><strong>连通度</strong>或<strong>密度</strong> $\rho$ : 图中实际出现的边数与边最大值的比值</p><script type="math/tex; mode=display">\rho = \frac{实际边数}{边最大值} = \frac{m}{\frac{n(n-1)}{2}} = \frac{c}{n-1}</script><p><em>网络规模足够大， 连通度可近似表示   $\rho=c\n$ </em> </p></blockquote></li></ul><ul><li><blockquote><p>根据 $\rho$  定义的网络疏密：</p><p>当 $n \rightarrow \infty $ 时：</p><ul><li><p>$\rho$ 趋于常数， 即度均值 $c\rightarrow \infty$ ，网络为密集的；</p><p>此类网络当网络规模扩大时，邻接矩阵中非零元的比例会保持常数；</p></li><li><p>$\rho \rightarrow 0$， 网络为稀疏的；</p><p>此类网络当网络规模扩大时，邻接矩阵中非零元的比例趋于零； </p></li></ul></blockquote></li><li><blockquote><p><strong>正则图</strong>： 所有结点的度相同；</p><p>$k-正则图$： 所有结点的度为$k$;</p></blockquote></li><li><p>对于有向图：</p><ul><li><p>每个结点有两个度:       考虑从结点$j$到$i$有一条边：</p><ul><li>入度：连接到该结点的入边数；   $k<em>i^{in}=\sum</em>{j=1}^n A_{ij}$ </li><li>出度：连接到该结点的出边数；   $k<em>j^{out}=\sum</em>{i=1}^n A_{ij}$ </li></ul></li><li><p>有向图中，边数目 $m$ 等于<strong>入边端点数总和</strong>，也等于<strong>出边端点数总和</strong>，有</p><script type="math/tex; mode=display">m = \sum_{i=1}^n k_i^{in} = \sum_{j=1}^n k_{j}^{out} = \sum_{ij} A_{ij}</script></li><li><p>有向图的入度均值 $c<em>{in}$ 等于出度均值 $c</em>{out}$ ,即</p><script type="math/tex; mode=display">c_{in} = \frac{1}{n}\sum_{i=1}^n k_i^{in} = \frac{1}{n}\sum_{j=1}^n k_j^{out} = c_{out}</script><script type="math/tex; mode=display">c=c_{in}=c_{out}=\frac{m}{n}</script></li></ul></li></ul><h2 id="中心性"><a href="#中心性" class="headerlink" title="中心性"></a>中心性</h2><p>中心性(Centrality)是社交网络分析中用以表达社交网络中结点在整个网络中所在中心的程度。</p><h3 id="度中心性"><a href="#度中心性" class="headerlink" title="度中心性"></a>度中心性</h3><ul><li>定义： 刻画结点中心性的连接中心度， 一个结点与其他点直接链接的总和（度$d$）；</li><li>无向图的结点$v_i$中心性 $C_d$ ： $C_d(v_i) = d_i$ ;                            </li><li>有向图的结点度中心性：<ul><li>入度： 刻画结点受欢迎程度，表示结点的突出性(prominence)或声望(prestige),   $C_d(v_i) = d_i^{in} （声望）$</li><li>出度：表示结点的合群性(gregariousness), $C_d(v_i) = d_i^{out} （合群性）$</li><li>结合入度出度： $C_d(v_i)=d_i^{in} + d_i^{out}$ ;</li></ul></li></ul><blockquote><p>度中心性度量方法不能用于比较不同网络中的中心性值，需要归一化；</p></blockquote><h3 id="度中心性的归一化"><a href="#度中心性的归一化" class="headerlink" title="度中心性的归一化"></a>度中心性的归一化</h3><ul><li>使用最大可能度数：<script type="math/tex; mode=display">C_d^{norm}(v_i)=\frac{度中心度}{最大可能度数}=\frac{d_i}{n-1}</script></li></ul><ul><li>使用最大度数：<script type="math/tex; mode=display">C_d^{max}(v_i) = \frac{度中心度}{最大度数} = \frac{d_i}{\max_jd_j}</script></li></ul><ul><li>使用度数和：<script type="math/tex; mode=display">C_d^{sum}(v_i)=\frac{度中心度}{度数和}=\frac{d_i}{\sum_jd_j} = \frac{d_i}{2m}</script></li></ul><h3 id="特征向量中心性"><a href="#特征向量中心性" class="headerlink" title="特征向量中心性"></a>特征向量中心性</h3><p>在度中心性度量中，认为具有较多连接的结点更为重要。但在社交网络中，拥有更多的邻居结点并不能确保该结点就是重要的，拥有更多重要的邻居结点才能提供更有力的信息。因为很多情况下，一个结点会由于连接到一些很重要的结点从而使得自身的重要性得到提升。</p><p>特征向量中心性通过结合<strong>无向图的邻居节点</strong>（或<strong>有向图的输入邻居结点</strong>）的重要性来概括度中心性。</p><p>对于每个结点$i$,令其的中心性为$x_i$。 计算$i$的所有邻居结点的中心性之和： </p><script type="math/tex; mode=display">x_i' = \sum_i A_{ij} x_j   \\     \Longrightarrow   \\  \bf x' = Ax    (矩阵形式)</script><p>重复估算过程，得到中心性计算公式：</p><script type="math/tex; mode=display">\bf x(t) = A^tx(0)</script><blockquote><p>$\bf x(0)$  为邻接矩阵特征向量$\bf v_i$的线性组合， 即  $\bf x(0) = \sum_i c_i v_i$ ;</p><p>根据特征值的定义： $Av_i = \lambda v_i$ </p></blockquote><p>最终得：</p><script type="math/tex; mode=display">\bf x{(t)} = A^t\sum_i c_i v_i = \sum_i c_i\lambda_i^tv_i = \lambda_1^t \sum_i c_i[\frac{\lambda_i}{\lambda_1}]^t v_i</script><p>其中， $\lambda_i$ 为 $\bf A$ 的 特征值， $\lambda_1$ 为其中最大的特征值。</p><blockquote><p>当 $i\neq 1$ 时，对于所有 $i$ ，$\frac{\lambda_i}{\lambda_1}&lt;1$ 。当 $t$ 增大时， 除第一项外其他项都呈指数级下降，当$t \rightarrow \infty$ 时， $\bf x(t) \rightarrow c_1\lambda_1^t v_t$  。<strong>中心性向量的极限与邻接矩阵中的主特征向量成正比</strong>， 因此可等价认为中心性$\bf x$满足: $\bf Ax=\lambda_1 x$</p></blockquote><p>由此可得出，<strong>结点$i$的中心性与该结点邻居节点的中心性之和成正比</strong> ： </p><script type="math/tex; mode=display">x_i = \frac{1}{\lambda_i} \sum_j A_{ij} x_j</script><blockquote><p>该公式赋予特征向量中心性的性质：使得它的值会随两方面因素变大：</p><ul><li>该结点具有多个邻居结点；</li><li>该结点的邻居节点中有重要的结点；</li></ul></blockquote><h4 id="Perron-Frobenius-Theorem"><a href="#Perron-Frobenius-Theorem" class="headerlink" title="Perron-Frobenius Theorem:"></a>Perron-Frobenius Theorem:</h4><p>假设$A\in \Bbb R^{n \times n}$ 时[强]连通图的邻接矩阵，或者 $A:A<em>{i,j} &gt;0$ （即一个正的$n\times n$的矩阵）。 存在一个正实数（Perron-Frobenius特征值）$\lambda</em>{max}$，满足$\lambda<em>{max}$ 是矩阵$\bf A$的特征值，并且$\bf A $的其余特征值均严格小于$\lambda</em>{max}$。 $\lambda_{max}$ 所对应的特征向量为$v=(v_1,v_2,v_3,…,v_n)$，满足$\forall v_i&gt;0$ 。</p><p>根据该定理，我们可以<strong>通过求解矩阵$A$ 的特征值得到正的中心性值，选取其中最大的特征值 $\lambda_{max}$ ,其对应特征向量为 $x_i$，该特征向量的所有部分均为正值，并且其分量对应于各结点的特征向量中心性，其中特征向量中最大分量对应的结点考虑为最中心的结点</strong></p><blockquote><p>寻找最中心结点：</p><ul><li>计算邻接矩阵的特征值；</li><li>选择最大的特征值，计算对应的特征向量；</li><li>特征向量最大分量对应的结点有最大的特征向量中心性，考虑为最中心的结点。</li></ul></blockquote><p>理论上讲，特征向量中心性对于有向和无向网络都适用，但在有向网络中存在一些问题。</p><ul><li><p>有向网络对应的邻接矩阵通常非对称，意味着有两类特征向量，即左特征向量和右特征向量。左特征向量对应该结点指向的结点（出），右特征向量对应指向该结点的结点（入）。中心性主要由指向该结点的结点赋予，因此选择<strong>右特征向量</strong>。</p><p>在有向网络中结点$i$的特征中心性的正确定义为：<strong>结点的特征向量中心性与指向该结点的所有结点的中心性之和成正比。</strong></p></li><li><p>如果有向网络中结点$B$的所有入边都来源于特征向量中心性为0的邻居结点，则结点$B$的特征向量中心性也为0。</p></li></ul><h3 id="Katz中心性"><a href="#Katz中心性" class="headerlink" title="Katz中心性"></a>Katz中心性</h3><p>Katz中心性是特征向量中心性的变体，解决上述有向网络中零特征向量中心性传递带来的问题。</p><ul><li><p>定义：为网络中的每个结点赋予少量的中心性，不考虑该结点在网络中的具体位置或者其邻居节点的中心性。</p><script type="math/tex; mode=display">x_i = \alpha \sum_i A_{ij} x_j + \beta</script><p>偏差项$\beta$ 用来解决中心性值为0 的问题；</p><p>矩阵表示上述公式，$\beta$ 作为整体因子其取值并不重要，通常设定为1：</p><script type="math/tex; mode=display">\bf x=\alpha Ax+\beta 1  \\ \Longrightarrow  \beta=1 \Longrightarrow \\x=(I-\alpha A)^{-1} 1</script></li><li><p>自由参数$\alpha$ 负责调节特征向量与常数项之间的平衡。</p><ul><li><p>当$\alpha=0$ 时， 式（14）只剩下常数项，所有结点赋予相同的中心性$\beta$;</p></li><li><p>当$\alpha$ 变大时，中心性不断提高，$\beta$ 的影响将减小，最终达到一个点，在该点中心性发散。该情况出现在$\bf det(A-\alpha^{-1}I)=0$ 的那一点；</p><blockquote><p>该公式为特征方程，当$\alpha =\lambda_{max}^{-1}$时，行列式第一次经过零点；因此应选择一个小于该值的$\alpha$ 值，保证中心性收敛。</p><p>很多研究中，将$\alpha$ 设为稍小于最大值$\lambda_{max}^{-1}$的值，这样可以使公式中特征向量项权值最大，而使常数项权值最小。</p></blockquote></li></ul></li></ul><h4 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h4><p>对于增加的常数项，根据结点的不同赋予不同的值，可以定义一种更加通用的中心性：</p><script type="math/tex; mode=display">x_i = \alpha \sum_j A_{ij} x_j + \beta_i</script><p>其中$\beta_i$是每一个结点与网络无关的固有中心性。因此中心性向量$\bf x$可描述为</p><script type="math/tex; mode=display">\bf x=(I-\alpha A)^{-1} \beta</script><h3 id="PageRank"><a href="#PageRank" class="headerlink" title="PageRank"></a>PageRank</h3><p>Katz中心性的不足之处在于，Katz中心性较高的结点会向它指向的结点传递其高中心性，这是不可取的，因为该高中心性结点指向的结点数量可能很大，但并不是每一个被指向的结点都具有很高的中心性。因此，<strong>被有重要影响的结点指向的结点，其从重要节点获得的中心性会因为与其他结点共享而被稀释。</strong></p><ul><li>定义：从网络邻居结点获得的中心性与邻居结点的中心性除以它们的出度成正比。</li></ul><script type="math/tex; mode=display">x_i = \alpha \sum_i A_{ij} \frac{x_j}{k_j^{out}} + \beta</script><blockquote><p>对于网络中出度$k<em>j^{out}=0$的结点 ，会产生0/0的结果（因为对于所有$i$，$A</em>{ij}=0$）。</p><p>解决此问题： 没有出度的结点对其他结点的中心性贡献为0，因此将这些结点的出度设定为1；实际可将$k_j^{out}$ 设定为任何一个非零值。</p></blockquote><p>​    表示为矩阵形式，同样将$\beta$设定为1</p><script type="math/tex; mode=display">\bf x=\alpha AD^{-1}x+\beta1    \\  \Longrightarrow \beta=1 \Longrightarrow \\  x=(I-\alpha AD^{-1})^{-1} 1=D(D-\alpha A)^{-1} 1</script><p>​    其中， $\bf D$ 为对角矩阵，其元素为 $D_{ii}=\max(k_i^{out},1)$</p><blockquote><p>与katz中心性类似，$\alpha$ 的值应小于$AD^{-1}$的最大特征值的倒数，即$\frac{1}{\lambda_{max}}$ ;</p><p>对于无向网络，其最大特征值为1，因此 $\alpha$ 应选择小于1的值；</p><p>对于有向网络，通常主特征值实际取值近似1；</p></blockquote><h4 id="拓展-1"><a href="#拓展-1" class="headerlink" title="拓展"></a>拓展</h4><p>PageRank推广，使得常数项$\beta$ 对不同顶点取不同的值：</p><script type="math/tex; mode=display">x_i = \alpha \sum_i A_{ij} \frac{x_j}{k_j^{out}} + \beta_i</script><p>矩阵形式为：</p><script type="math/tex; mode=display">\bf x=D(D-\alpha A)^{-1} \beta</script><blockquote><p>利用该公式对网页进行排序时，其中$\beta_i$的值可以基于网页与查询条件的文本相似性给出。</p><h4 id="四种中心性测度"><a href="#四种中心性测度" class="headerlink" title="四种中心性测度"></a>四种中心性测度</h4><div class="table-container"><table><thead><tr><th></th><th>带常数项</th><th>不带常数项</th></tr></thead><tbody><tr><td>除以出度</td><td>$\bf x=D(D-\alpha A)^{-1}1$       RageRank</td><td>$\bf x = AD^{-1}x$     度中心性</td></tr><tr><td>不做任何除法</td><td>$\bf x=(I-\alpha A)^{-1} 1$             Katz中心性</td><td>$\bf x=\lambda_1^{-1}Ax$      特征向量中心性</td></tr></tbody></table></div></blockquote><h3 id="针对引文网络的中心性"><a href="#针对引文网络的中心性" class="headerlink" title="针对引文网络的中心性"></a>针对引文网络的中心性</h3><h4 id="核心结点与权威结点"><a href="#核心结点与权威结点" class="headerlink" title="核心结点与权威结点"></a>核心结点与权威结点</h4><ul><li>权威结点（authority）: 包含所关注主题有用的信息的结点；</li><li>核心结点（hub)：指向权威结点的结点，说明到哪能找到最合适的权威结点；</li></ul><p>核心结点与权威结点只存在于有向网络中，在有向网络中可以定义两种中心性，</p><ul><li><p>权威中心性</p><p>与指向该结点的核心中心性之和成正比；</p><script type="math/tex; mode=display">x_i=\alpha \sum_j A_{ij}y_j</script></li><li><p>核心中心性</p><p>与该结点指向的结点的权威中心性之和成正比；</p><script type="math/tex; mode=display">y_i =\beta \sum_j A_{ji}x_j</script><p>矩阵表示：</p><script type="math/tex; mode=display">\bf x=\alpha Ay  ,    y=\beta A^Tx    \\ \LongrightarrowAA^Tx=\lambda x,   A^TAy=\lambda y</script><p>其中，$\lambda=(\alpha \beta)^{-1}$</p><blockquote><p>权威中心性与核心中心性分别由具有相同特征值的矩阵$AA^T$和$A^TA$对应的特征向量决定。</p><p>因此矩阵$AA^T$和$A^TA$ 有相同的主特征值$\lambda$ ：</p><p>若 $\bf AA^Tx=\lambda x$ , 公式两边都乘以 $A^T$ , 可以得到 $\bf A^TA(A^Tx)=\lambda(A^Tx)$。因此$A^Tx$ 也是矩阵$A^TA$ 的特征值为$\lambda$ 的特征向量， 即$\bf y=A^Tx$ 。 </p><ul><li>$AA^T$ 是共引矩阵，权威中心性可以粗略的认为是共引网络的特征向量中心性；</li><li>$A^TA$ 是文献耦合矩阵，核心中心性就是文献耦合网络的特征向量中心性；</li></ul></blockquote></li></ul><h3 id="接近度中心性"><a href="#接近度中心性" class="headerlink" title="接近度中心性"></a>接近度中心性</h3><p>接近中心性不同于其他中心性测度，度量了一个结点到其他结点的平均距离。接近中心性的思想是结点越趋于中心，越能快速到达其他结点。形象化的描述为，这些结点满足与其他结点之间有最小平均最短路径。</p><ul><li>定义：平均测地距离的倒数<script type="math/tex; mode=display">C_i=\frac{1}{\ell_i}    \\\ell_i = \frac{1}{n}\sum_j d_{ij}    \\  or \\\ell_i = \frac{1}{n-1} \sum_{j(\neq i)} d_{ij}</script></li></ul><blockquote><ul><li><p>问题1：接近中心性最大最小值之间的动态变化范围很小。大部分网络中，顶点之间的测地距离$d_{ij}$ 一般很小，随网络规模增长呈对数级速度增长。而且最短测地距离与最长测地距离确定了平均距离$\ell_i$的上下限，因此$\ell_i$和$C_i$的取值范围都较小。结点接近中心性的密集意味着网络结构的微小变化就会引起接近度中心性值排序的显著变化。</p></li><li><p>问题2：若将不同分支中的结点间的测地距离定义为无穷大，那么假设任何一个多于一个分支的网络中所有结点$i$的$\ell_i$ 都为无穷大，则$C_i$ 为零。</p></li><li>解决方法之一是<strong>只计算在同一分支内部的结点的平均测地距离</strong>，但仍然存在固有缺陷：小规模分支内部结点间的距离普遍偏小，与大规模分支中的结点相比，其$\ell_i$较小，$C_i$更大。产生不理想的结果：<strong>大多数情况下，小规模分支中结点之间的连通程度比大规模分支中要低，因此应赋予较低的中心性</strong>。</li></ul></blockquote><p>重定义接近中心性，使用结点之间的<strong>调和平均测地距离</strong>：</p><script type="math/tex; mode=display">C_i'= \frac{1}{n-1}\sum_{j(\neq i)} \frac{1}{d_{ij}}</script><ul><li><p>网络平均测地距离：</p><ul><li>对于只有一个分支的网络，所有结点对之间的平均距离为</li></ul><script type="math/tex; mode=display">\ell = \frac{1}{n^2}\sum_{ij}d_{ij} = \frac{1}{n}\sum_i \ell_i</script><p>​    即所有结点的平均测地距离$\ell_i$的平均值。</p><ul><li><p>对于多分支网络，<em>只计算同一分支内部结点之间路径的平均长度</em>。令${ {\scr C}_m }$表示网络中分支的集合，定义：</p><script type="math/tex; mode=display">\ell = \frac{\sum_m \sum_{ij\in {\scr C}_m} d_{ij}}{\sum_m n_m^2}</script><p>其中，$n_m$为分支$\scr C_m$中的结点数。</p><p>另一中定义方式为定义一个调和平均距离$\ell ’$ ：</p><script type="math/tex; mode=display">\frac{1}{\ell '} = \frac{1}{n(n-1)} \sum_{i \neq j} \frac{1}{d_{ij}}=\frac{1}{n}\sum_i C_i'    \\  \Longleftrightarrow \\\ell ' = \frac{n}{\sum_i C_i'}</script></li></ul></li></ul><h3 id="介数中心性"><a href="#介数中心性" class="headerlink" title="介数中心性"></a>介数中心性</h3><p>考虑结点在连接其他结点时表现的”中介“次数，即其他结点间通过结点$v_i$的最短路径的数目。</p><p><strong>介数中心性衡量某个结点对其他结点对之间信息流动的影响力。</strong> </p><ul><li><p>定义：</p><script type="math/tex; mode=display">C_b(v_i) = \sum_{s \neq t \neq v_i} \frac{s到t经过v_i的最短路径数目}{s到t的最短路径数目} =\sum_{s \neq t \neq v_i} \frac{\sigma_{st}(v_i)}{\sigma_{st}}</script></li><li><p>归一化：</p><ul><li><p>最大值：当结点$v<em>i$出现在连接任意结点对$(s,t)$的所有最短路径中时，该结点的中间中心性对应最大值1，即$\forall (s,t), s \neq t \neq v_i , \frac{\sigma</em>{st} (v<em>i)}{\sigma</em>{st}} = 1$。 因此，最大值为：</p><script type="math/tex; mode=display">C_b(v_i)=\sum_{s \neq t \neq v_i} \frac{\sigma_{st}(v_i)}{\sigma_{st}}=\sum_{s \neq t \neq v_i} 1 = 2 \begin{pmatrix}n-1 \\2\\\end{pmatrix} = (n-1)(n-2)</script></li><li></li></ul><script type="math/tex; mode=display">C_b^{norm}(v_i) = \frac{C_b(v_i)}{2\begin{pmatrix}n-1 \\2\\\end{pmatrix}}</script></li></ul><h4 id="另一种表述"><a href="#另一种表述" class="headerlink" title="另一种表述"></a>另一种表述</h4><p>表示一般性网络的介数，定义$n<em>{st}^i$为从$s$到$t$经过$i$的测地路径数量，定义$g</em>{st}$为从$s$到$t$的测地路径总数。那么结点$i$的介数中心性可以表示为</p><script type="math/tex; mode=display">x_i = \sum_{st} \frac{n_{st}^i}{g_{st}}</script><p>介数中心性主要是度量一个结点“介于”其他结点的程度。</p><blockquote><p>一个结点的度可以很低，与其相连的结点的度也很低，与其他结点之间的平均距离很长，但仍有较高的介数。</p><p><img src="images/1548337276217.png" alt="1548337276217"></p><p>如图，结点A是网络中两个结点群组之间的桥梁，由于两个群组结点之间的任何最短路径都必须经过结点A，因此A获得了很高的介数。结点A对于其他结点间信息流动起到控制作用，此类结点在社会学文献中称为”<strong>中间人</strong>“。</p></blockquote><ul><li><p>归一化：（考虑自环）</p><ul><li>基于结点对：<script type="math/tex; mode=display">x_i= \frac{1}{n^2}\sum_{st} \frac{n_{st}^i}{g_{st}}</script></li></ul></li></ul><ul><li>基于介数最大可能值：<script type="math/tex; mode=display">x_i = \frac{1}{n^2-n+1} \sum_{st}\frac{n_{st}^i}{g_{st}}</script></li></ul><h3 id="群体中心性"><a href="#群体中心性" class="headerlink" title="群体中心性"></a>群体中心性</h3><p>考虑如何将度中心性、接近中心性以及中间中心性应用到一组结点上。</p><p>假设$S$表示需要求解群体中心性的结点集，$V-S$表示上述集合之外的结点集。</p><h4 id="群体度中心性"><a href="#群体度中心性" class="headerlink" title="群体度中心性"></a>群体度中心性</h4><p>群体度中心性是群体外部结点连接到群体内部结点的数目。形式化的定义为：</p><script type="math/tex; mode=display">C_d^{group}(S)=|\{v_i \in V-S| v_i连接到v_j \in S\}|</script><p>与度中心性相似，可以利用有向图中的入度或出度。同时该值可以进行归一化。</p><p>最理想的情况为，群体中的结点均连接到群体外的所有结点上，此时$C_d^{group}(S)$的最大值为$V-S$。使用群体度中心性除以$|V-S|$进行归一化处理。</p><h4 id="群体介数中心性"><a href="#群体介数中心性" class="headerlink" title="群体介数中心性"></a>群体介数中心性</h4><p>群体介数中心性被定义为：</p><script type="math/tex; mode=display">C_b^{group}(S) = \sum_{s\neq t, s\notin S, t \notin S}  \frac{\sigma_{st}(S)}{\sigma_{st}}</script><p>其中，$\sigma_{st}(S)$ 表示从$s$到$t$经过集合$S$中元素的最短路径的数目。</p><p>最理想的情况下，从$s$到$t$的所有的最短路径均经过集合$S$中的元素，因此，$C_b^{group}(S)$的最大值为${2\begin{pmatrix}  |V-S| \ 2\  \end{pmatrix}}$。</p><p>和介数中心性相似，使用介数中心性除以最大值进行归一化处理。</p><h4 id="群体接近中心性"><a href="#群体接近中心性" class="headerlink" title="群体接近中心性"></a>群体接近中心性</h4><p>群体接近中心性被定义为：</p><script type="math/tex; mode=display">C_c^{group}(S)=\frac{1}{\bar l_S^{group}}</script><p>其中，$\bar l <em>S^{group} = \frac{1}{|V-S|}\sum</em>{v<em>j \notin S} l</em>{S,v<em>j}$，$l</em>{S,v_j}$是群体$S$与群体之外的元素$v_j \in V-S$的最短路径的长度。该长度可以以多种方式定义，一种方法是寻找$S$中距离$v_j$最近的成员元素：</p><script type="math/tex; mode=display">l_{S,v_j} = \min_{v_i \in S}l_{v_i,v_j}</script><p>另一种是使用最大距离或者平均距离。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;度&quot;&gt;&lt;a href=&quot;#度&quot; class=&quot;headerlink&quot; title=&quot;度&quot;&gt;&lt;/a&gt;度&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;定义：&lt;strong&gt;与结点直接相连的边数目&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;对于无向图：&lt;/p&gt;
&lt;ul&gt;

      
    
    </summary>
    
      <category term="复杂网络" scheme="http://yoururl.com/categories/%E5%A4%8D%E6%9D%82%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Networks" scheme="http://yoururl.com/tags/Networks/"/>
    
  </entry>
  
  <entry>
    <title>知识图谱：知识表示之TransE模型</title>
    <link href="http://yoururl.com/2019/01/20/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA%E4%B9%8BTransE/"/>
    <id>http://yoururl.com/2019/01/20/知识表示之TransE/</id>
    <published>2019-01-19T16:01:00.000Z</published>
    <updated>2019-01-26T05:40:20.233Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TransE"><a href="#TransE" class="headerlink" title="TransE"></a>TransE</h1><p>论文地址：<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/viewFile/8531/8546" target="_blank" rel="noopener">https://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/viewFile/8531/8546</a>  </p><h2 id="模型概述"><a href="#模型概述" class="headerlink" title="模型概述"></a>模型概述</h2><ul><li>三元组：   $(h,{\scr l},t)$  </li><li>embedding之后， 头部实体嵌入向量加上关系嵌入向量，更接近与尾部实体嵌入向量</li><li>依赖于简化的参数集，只学习每个实体和每个关系的一个<strong>低维向量</strong>表示</li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-11-1/57933532.jpg" alt=""></p><p>细节：</p><ul><li>训练集 $S$: 包含三元组 $(h,{\scr l},t)$， 实体 $h,t\in E(实体集)$, 关系 ${\scr l} \in L(关系集)$；</li><li>embeddings 在 $\Bbb R^k$ 中取值</li><li>${\bf h}+{\scr l}\approx {\bf t}$ , ${\bf t}$ 应该为 ${\bf h}+{\scr l}$ 的最邻近， 然后 ${\bf h}+{\scr l}$ 与其他的 $t$ 尽可能远；  这里的“接近”程度可以用 $L_1$或$L_2$范数衡量；<br>理想状态下一个正确的三元组的embedding 之间存在 ${\bf h}+{\scr l}={\bf t}$ 的关系，错误的三元组没有；</li><li>利用基于能量的框架，三元组的势能表示为 $d(h, {\scr l}, t)=||h+{\scr l}-t||_2$ ， 正确的三元组势能越低越好，错误的三元组势能越高越好；</li></ul><h2 id="损失函数："><a href="#损失函数：" class="headerlink" title="损失函数："></a>损失函数：</h2><h3 id="带negative-sample的max-margin损失函数"><a href="#带negative-sample的max-margin损失函数" class="headerlink" title="带negative sample的max margin损失函数"></a>带negative sample的max margin损失函数</h3><p>训练方法：margin-based ranking criterion</p><script type="math/tex; mode=display">{\cal L}=\sum_{(h,{\scr l},t)\in S} \sum_{(h',{\scr l},t')\in S'_{(h,{\scr l}, t)} } [\gamma + d(h+{\scr l}, t)-d(h'+{\scr l}, t') ]_+</script><script type="math/tex; mode=display">d(h, {\scr l}, t)=||h+{\scr l}-t||_2</script><ul><li>$S$: 正确三元组集合</li><li>$S’$: 错误三元组集合</li><li>$\gamma$: margin 距离超参数，表示正负样本之间的距离，常数;</li><li>$[x]_+$: $max(0,x)$</li></ul><blockquote><p>最小化loss可以使正样本势能越低，负样本势能越高，但两者的能量差距达到一定程度 $\gamma$ 就足够了， 再大loss也只是0；</p></blockquote><h3 id="负样本生成"><a href="#负样本生成" class="headerlink" title="负样本生成"></a>负样本生成</h3><script type="math/tex; mode=display">S'_{(h,{\scr l},t)} = \{(h',{\scr l},t)|h'\in E\}\bigcup \{(h,{\scr l},t')|t' \in E\}</script><ul><li>对于三元组 $(h,{\scr l},t)$， 随机使用知识库中的某个实体 $h’$ 替换 $h$，或用某个实体 $t’$ 替换 $t$, 得到两个负样本 $(h’,{\scr l},t)$ 和 $(h,{\scr l},t’)$;  </li><li>对生成的负样本进行筛选过滤，若该负样本原本存在于知识库，则重新生成；  </li><li>然后，有人认为，生成负样本时不应该完全随机，而是应该选择与被替换实体类型相似的实体来进行替换；</li></ul><h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-11-1/93529922.jpg" alt=""></p><h2 id="TransE局限性"><a href="#TransE局限性" class="headerlink" title="TransE局限性"></a>TransE局限性</h2><p>考虑在没有错误embedding的情况下，$h+{\scr l}=t$  当 $(h,{\scr l},t) \in \Delta$ 时，我们可以从TransE模型中看出：</p><ul><li>若 $(h,{\scr l},t) \in \Delta$ 且 $(t,{\scr l},h) \in \Delta$, $r$是一个自反映射， 因此 $r=0$ 且 $h=t$;</li><li>若 $\forall i \in {0,…,m},(h_i,r,t)\in \Delta$ , $r$是一个N-1映射，且 $h_0=…=h_m$;<br>类似的，$\forall i \in {0,…,m},(h,r,t_i)\in \Delta$ , $r$是一个1-N映射，且 $t_0=…=t_m$;  </li></ul><p>当涉及相同关系时，忽略了实体的分布式表示，导致实体呈现相同的嵌入表示。</p><blockquote><p>例如，假如知识库中有两个三元组，分别是(美国, 总统, 奥巴马)和(美国, 总统, 布什)。这里的关系“总统”是典型的 1-N 的复杂关系。如果用 TransE 从这两个三元组学习知识表示，将会使奥巴马和布什的向量变得相同。<br>因而，TransE 模型在处理 1-N、N-1、N-N 复杂关系时存在局限性。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TransE&quot;&gt;&lt;a href=&quot;#TransE&quot; class=&quot;headerlink&quot; title=&quot;TransE&quot;&gt;&lt;/a&gt;TransE&lt;/h1&gt;&lt;p&gt;论文地址：&lt;a href=&quot;https://www.aaai.org/ocs/index.php/AAAI/
      
    
    </summary>
    
      <category term="知识图谱" scheme="http://yoururl.com/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    
      <category term="Knowledge graph" scheme="http://yoururl.com/tags/Knowledge-graph/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow环境 人脸识别 FaceNet 应用（一）:FaceNet安装与验证测试集</title>
    <link href="http://yoururl.com/2018/07/15/windows%E4%B8%8Bpython3.5%E5%AE%89%E8%A3%85facenet/"/>
    <id>http://yoururl.com/2018/07/15/windows下python3.5安装facenet/</id>
    <published>2018-07-15T02:15:33.025Z</published>
    <updated>2018-03-20T08:07:06.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>作者：Andy_z<br>文献：<a href="https://arxiv.org/abs/1503.03832" target="_blank" rel="noopener">FaceNet: A Unified Embedding for Face Recognition and Clustering</a><br><a href="https://pan.baidu.com/s/1R70SWpSmF7SoZB5vkHdfpw" target="_blank" rel="noopener">数据集及模型下载通道</a>：(密码：3wty)</p></blockquote><h2 id="一、前提条件"><a href="#一、前提条件" class="headerlink" title="一、前提条件"></a>一、前提条件</h2><h3 id="1-emsp-已安装Tensorflow"><a href="#1-emsp-已安装Tensorflow" class="headerlink" title="1.&emsp;已安装Tensorflow"></a>1.&emsp;已安装Tensorflow</h3><h3 id="2-emsp-已在安装下列包-二选一"><a href="#2-emsp-已在安装下列包-二选一" class="headerlink" title="2.&emsp;已在安装下列包(二选一):"></a>2.&emsp;已在安装下列包(二选一):</h3><p>&emsp;&emsp;a.&emsp;python下安装scipy, scikit-learn, opencv-python, h5py, matplotlib, Pillow, requests, psutil</p><p>&emsp;&emsp;b.&emsp;安装Anaconda集成环境</p><h3 id="3-emsp-已更新Sklearn至最新版本-二选一"><a href="#3-emsp-已更新Sklearn至最新版本-二选一" class="headerlink" title="3.&emsp;已更新Sklearn至最新版本(二选一):"></a>3.&emsp;已更新Sklearn至最新版本(二选一):</h3><p>&emsp;&emsp;a.&emsp;可在propmt下”conda update conda “</p><p>&emsp;&emsp;b.&emsp;直接在cmd命令行下”pip install -U scikit-learn”</p><h3 id="4-emsp-已安装git"><a href="#4-emsp-已安装git" class="headerlink" title="4.&emsp;已安装git"></a>4.&emsp;已安装git</h3><blockquote><p>备注:如果没有完成以上的第3点,之后执行align时,可能会出现”no module named facenet”,”no module named align”,”no module named scikit-learn”等情况</p></blockquote><h2 id="二、安装和配置FaceNet"><a href="#二、安装和配置FaceNet" class="headerlink" title="二、安装和配置FaceNet"></a>二、安装和配置FaceNet</h2><p>&emsp;&emsp;1.&emsp;在cmd命令行，定位到自己想下载的文件夹,用git下载FaceNet源代码工程:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone --recursive https://github.com/davidsandberg/facenet.git</span><br></pre></td></tr></table></figure><blockquote><p>建议：最好定位在&emsp;&emsp;Anaconda3\Lib\site-packages&emsp;&emsp;下安装。因为FaceNet也相当于一个python库。</p></blockquote><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-15/23373226.jpg" alt=""></p><p>&emsp;&emsp;2.&emsp;下载数据集LFW。LFW数据集是由美国马萨诸塞大学阿姆斯特分校计算机视觉实验室整理的。下载地址：<a href="http://vis-www.cs.umass.edu/lfw/lfw.tgz" target="_blank" rel="noopener">http://vis-www.cs.umass.edu/lfw/lfw.tgz</a>, 下载完成后，把数据解压到目录 ..facenet\data\lfw\raw  下面,新建一个空文件夹命名为”lfw_160”。可以看到数据集中每张图像的分辩率是250*250。</p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-15/8023931.jpg" alt=""></p><p>&emsp;&emsp;3.&emsp;设置环境变量,以下方法二选一:</p><p>&emsp;&emsp;a.&emsp;在cmd命令行键入：set PYTHONPATH=…\facenet\src, 例如笔者的是:set PYTHONPATH=D:\Anaconda2\envs\py3.6\Lib\site-packages\facenet\src</p><p>&emsp;&emsp;b.&emsp;在 计算机—&gt;属性—&gt;高级系统设置—&gt;环境变量中,新建PYTHONPATH,键入 D:\Anaconda2\envs\py3.6\Lib\site-packages\facenet\src</p><p>检验:在cmd命令行下面，键入set，查看设置情况</p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-15/66907272.jpg" alt=""></p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-15/56240084.jpg" alt=""></p><h2 id="三、图像数据预处理"><a href="#三、图像数据预处理" class="headerlink" title="三、图像数据预处理"></a>三、图像数据预处理</h2><blockquote><p>也可直接使用下载的已处理数据集</p></blockquote><p>&emsp;&emsp;我们需要将待检测所使用的数据集校准为和预训练模型所使用的数据集大小一致。</p><p>&emsp;&emsp;1.&emsp;使用&emsp;facenet\src\align\align_dataset_mtcnn.py&emsp;进行校准,校准后的图片存在&emsp;..facenet\data\lfw\lfw_160&emsp;下面。在cmd命令行 或者 对应语言版本的propmt下，定位到facenet所在位置，键入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python src\align\align_dataset_mtcnn.py data/lfw/raw data/lfw/lfw_160</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;官方Wiki说明</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python src/align/align_dataset_mtcnn.py ~/datasets/casia/CASIA-maxpy-clean/ ~/datasets/casia/casia_maxpy_mtcnnpy_182 --image_size 182 --margin 44</span><br></pre></td></tr></table></figure><blockquote><p>上述命令生成的脸部缩略图是182x182像素。</p></blockquote><p>&emsp;&emsp;2.&emsp;校准后发现图像大小变了</p><h2 id="四、评估谷歌预训练模型在数据集的准确率"><a href="#四、评估谷歌预训练模型在数据集的准确率" class="headerlink" title="四、评估谷歌预训练模型在数据集的准确率"></a>四、评估谷歌预训练模型在数据集的准确率</h2><p>&emsp;&emsp;1.&emsp;下载预训练的模型。把下载的文件解压到src\models\目录下面。</p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-15/34564036.jpg" alt=""></p><p>&emsp;&emsp;2.&emsp;程序下载好了,测试数据集LFW也有了,模型也有了,接下来就可以评估模型在数据集的准确率了。在cmd命令行或者propmt下定位到facenet文件夹下，输入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python src\validate_on_lfw.py data\lfw\lfw_160 src\models\20170512-110547</span><br></pre></td></tr></table></figure><p>紧接着,预测中,结果如图：</p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-15/47530520.jpg" alt=""></p><h2 id="五、其他"><a href="#五、其他" class="headerlink" title="五、其他"></a>五、其他</h2><h3 id="5-1-对比"><a href="#5-1-对比" class="headerlink" title="5.1 对比"></a>5.1 对比</h3><p>&emsp;&emsp;facenet可以直接比对两个人脸经过它的网络映射之后的欧氏距离，运行程序为facenet-master\src\compare.py。<br>-1、在compare.py所在目录下放入要比对的文件1.jpg和2.jpg，打开cmd命令行窗口<br>-2、cd到compare.py所在路径<br>-3、输入 python compare.py models/20170512-110547 1.png 2.png</p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-16/42045957.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;作者：Andy_z&lt;br&gt;文献：&lt;a href=&quot;https://arxiv.org/abs/1503.03832&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;FaceNet: A Unified Embedding for F
      
    
    </summary>
    
      <category term="人脸识别" scheme="http://yoururl.com/categories/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/"/>
    
    
      <category term="Summary" scheme="http://yoururl.com/tags/Summary/"/>
    
      <category term="facenet" scheme="http://yoururl.com/tags/facenet/"/>
    
      <category term="face recognition" scheme="http://yoururl.com/tags/face-recognition/"/>
    
  </entry>
  
  <entry>
    <title>Jupyter notebook: How to create a slideshow</title>
    <link href="http://yoururl.com/2018/07/15/Jupyter%20notebook%EF%BC%9AHow%20to%20create%20a%20slideshow/"/>
    <id>http://yoururl.com/2018/07/15/Jupyter notebook：How to create a slideshow/</id>
    <published>2018-07-15T02:15:32.933Z</published>
    <updated>2018-04-25T17:54:21.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="利用Jupyter-notebook-制作PPT"><a href="#利用Jupyter-notebook-制作PPT" class="headerlink" title="利用Jupyter notebook 制作PPT"></a>利用Jupyter notebook 制作PPT</h1><p>使用 Jupyter notebook 作为 slide 主要优点：  </p><ul><li>运行 notebook 可以播放幻灯片  </li><li>导出 slides.html 格式的幻灯片，方便在浏览器打开播放</li></ul><h2 id="工具依赖"><a href="#工具依赖" class="headerlink" title="工具依赖"></a>工具依赖</h2><ul><li>RISE</li><li>reveal.js </li></ul><h3 id="RISE"><a href="#RISE" class="headerlink" title="RISE"></a>RISE</h3><p>RISE allows you to instantly turn your Jupyter Notebooks into a slideshow. No out-of-band conversion is needed, switch from jupyter notebook to a live reveal.js-based slideshow in a single keystroke, and back.</p><h4 id="Install-RISE"><a href="#Install-RISE" class="headerlink" title="Install RISE"></a>Install RISE</h4><h4 id="Option-1-Using-conda"><a href="#Option-1-Using-conda" class="headerlink" title="Option 1 - Using conda :"></a>Option 1 - Using conda :</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install -c damianavila82 rise</span><br></pre></td></tr></table></figure><h4 id="Option-2-Using-pip"><a href="#Option-2-Using-pip" class="headerlink" title="Option 2 - Using pip::"></a>Option 2 - Using pip::</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install RISE</span><br></pre></td></tr></table></figure><p>and then two more steps to install the JS and CSS in the proper places:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter-nbextension install rise --py --sys-prefix</span><br></pre></td></tr></table></figure><p>and enable the nbextension:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter-nbextension enable rise --py --sys-prefix</span><br></pre></td></tr></table></figure><h3 id="reveal-js"><a href="#reveal-js" class="headerlink" title="reveal.js"></a>reveal.js</h3><p>A framework for easily creating beautiful presentations using HTML. <a href="https://revealjs.com/#/" target="_blank" rel="noopener">Check out the live demo.</a></p><p>reveal.js comes with a broad range of features including nested slides, Markdown contents, PDF export, speaker notes and a JavaScript API. There’s also a fully featured visual editor and platform for sharing reveal.js presentations at slides.com.  </p><p>Reveal.js 是一个使用 HTML 语言制作演示文稿的 Web 框架，支持插入多种格式的内容，并以类似 PPT 的形式呈现。  </p><p>Reveal.js 具有许多优势：</p><ul><li>制作灵活、不限应用，只需修改 HTML 文件</li><li>发布灵活、不限平台，只需打开 HTML 文件</li><li>丰富的特性，支持过渡动画、代码高亮、视频背景、Markdown 语法、导出 PDF 等</li><li>极度轻量，占用空间和内存少</li></ul><p>配置流程：  </p><ul><li>在 notebook 文件目录（包含 .ipnb 文件）下， clone <a href="https://github.com/hakimel/reveal.js.git" target="_blank" rel="noopener">reveal.js</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/hakimel/reveal.js.git</span><br></pre></td></tr></table></figure><h2 id="slide-设置"><a href="#slide-设置" class="headerlink" title="slide 设置"></a>slide 设置</h2><p>这里有一个幻灯片<a href="http://www.slideviper.oquanta.info/tutorial/slideshow_tutorial_slides.html#/" target="_blank" rel="noopener">示例</a>供参考，其制作风格简洁明晰。</p><p>那么如何用 Jupyter Notebook 制作幻灯片呢？<br>首先在 notebook 的菜单栏选择 View &gt; Cell Toolbar &gt; Slideshow，这时在文档的每个单元右上角显示了 Slide Type 的选项。通过设置不同的类型，来控制幻灯片的格式。有如下5中类型：</p><ul><li>Slide：主页面，通过按左右方向键进行切换。</li><li>Sub-Slide：副页面，通过按上下方向键进行切换。</li><li>Fragment：一开始是隐藏的，按空格键或方向键后显示，实现动态效果。</li><li>Skip：在幻灯片中不显示的单元。</li><li>Notes：作为演讲者的备忘笔记，也不在幻灯片中显示。</li></ul><h2 id="生成幻灯片"><a href="#生成幻灯片" class="headerlink" title="生成幻灯片"></a>生成幻灯片</h2><p>在notebook中设置cell 的slide属性，确认后保存，例如 notebook.ipynb<br>使用nbconvert 来将notebook文件转换为HTML  </p><pre><code class="lang-python">jupyter nbconvert --to slides notebook.ipynb --reveal-prefix=reveal.js</code></pre><p>生成文件： notebook.slides.html , 直接用浏览器打开即可播放幻灯片</p><p>有时候不想要input cell显示在slide上面，这个时候可以使用下面的设置：  </p><pre><code class="lang-python">jupyter nbconvert RainStromNetworkAnalysis.ipynb --to slides --TemplateExporter.exclude_input=True</code></pre><p>同样的使用下面的命令虽然可以隐藏input cell但是不能生成slide只能生成html文件：  </p><pre><code class="lang-python">jupyter nbconvert --template=nbextensions --to=slides RainStromNetworkAnalysis.ipynb</code></pre><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>Reveal.js 支持 Markdown 语法，我们得以直接在 Markdown 编辑器里做 PPT。以上只是制作了最简单的 PPT，我们后续还可以添加各种动画效果、背景、图表等内容。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;利用Jupyter-notebook-制作PPT&quot;&gt;&lt;a href=&quot;#利用Jupyter-notebook-制作PPT&quot; class=&quot;headerlink&quot; title=&quot;利用Jupyter notebook 制作PPT&quot;&gt;&lt;/a&gt;利用Jupyter note
      
    
    </summary>
    
      <category term="Jupyter" scheme="http://yoururl.com/categories/Jupyter/"/>
    
    
      <category term="Jupyter" scheme="http://yoururl.com/tags/Jupyter/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow环境 人脸识别 FaceNet 应用（二）:FaceNet官方WiKi解读</title>
    <link href="http://yoururl.com/2018/07/15/FaceNet%20%E5%AE%98%E6%96%B9WiKi%E8%A7%A3%E8%AF%BB/"/>
    <id>http://yoururl.com/2018/07/15/FaceNet 官方WiKi解读/</id>
    <published>2018-07-15T02:15:32.918Z</published>
    <updated>2018-03-23T08:27:53.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>作者：Andy_z<br>文献：<a href="https://github.com/davidsandberg/facenet/wiki" target="_blank" rel="noopener">官方WiKi</a></p></blockquote><h2 id="一、分类器训练"><a href="#一、分类器训练" class="headerlink" title="一、分类器训练"></a>一、分类器训练</h2><h3 id="1-1-运行-train-softmax-py-文件训练"><a href="#1-1-运行-train-softmax-py-文件训练" class="headerlink" title="1.1 运行 train_softmax.py 文件训练"></a>1.1 运行 train_softmax.py 文件训练</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">python src/train_softmax.py</span><br><span class="line">--logs_base_dir ~/logs/facenet/</span><br><span class="line">--models_base_dir ~/models/facenet/</span><br><span class="line">--data_dir ~/datasets/casia/casia_maxpy_mtcnnalign_182</span><br><span class="line">--image_size 160</span><br><span class="line">--model_def models.inception_resnet_v1</span><br><span class="line">--lfw_dir /home/david/datasets/lfw/lfw_mtcnnalign_160</span><br><span class="line">--optimizer RMSPROP</span><br><span class="line">--learning_rate -1</span><br><span class="line">--max_nrof_epochs 80</span><br><span class="line">--keep_probability 0.8</span><br><span class="line">--random_crop</span><br><span class="line">--random_flip</span><br><span class="line">--learning_rate_schedule_file data/learning_rate_schedule_classifier_casia.txt</span><br><span class="line">--weight_decay 5e-5</span><br><span class="line">--center_loss_factor 1e-2</span><br><span class="line">--center_loss_alfa 0.9</span><br></pre></td></tr></table></figure><ul><li><strong>log_base_dir</strong>:<br><strong>models_base_dir</strong>:<br>训练开始时，以数据/时间训练开始的训练会话的子目录以yyyymmdd-hhmm的格式在以上两个目录中创建。  </li><li><strong>data_dir</strong>：  用于指出训练数据集的位置，可以通过用冒号分隔路径来使用几个数据集的联合。<br>model_def： 给出推理网络的描述符，上述样例中  models.inception_resnet_v1 指向models包中的<br>inception_resnet_v1模块。 该模块定义一个函数 inference(images, …)，images是输入图像的占位符(Inception-ResNet-v1的尺寸&lt;?, 160,160,3&gt;),并返回一个embeddings变量的引用。  </li><li><strong>lfw_dir</strong>：如果将参数lfw_dir设置为指向LFW数据集的基本目录，那么每1000个批次将在LFW上对该模型进行评估。有关如何在LFW上评估现有模型的信息，请参阅 Validate-on-LFW 页面。 如果在训练期间不需要对LFW进行评估，则可以将lfw_dir参数留空。 但请注意，此处使用的LFW数据集应与训练数据集一致。  </li><li><strong>max_nrof_epochs</strong>：最大训练周期。  </li><li><strong>learning_rate_schedule_file</strong>：为了改善最终模型的性能，当训练开始收敛时，学习速率降低10倍。 这是通过在参数learning_rate_schedule_file指向的文本文件中定义的学习速率时间表来完成的，同时还将参数learning_rate设置为负值。 为了简单起见，本例中data / learning_rate_schedule_classifier_casia.txt中使用的学习率也包括在库中。</li></ul><blockquote><p>注：train_tripletloss.py和train_softmax.py的区别：这是作者对论文做出的一个延伸，除了使用facenet里提到的train_tripletloss三元组损失函数来训练，还实现了用softmax的训练方法来训练。当然，在样本量很小的情况下，用softmax训练会更容易收敛。但是，当训练集中包含大量的不同个体(超过10万)时，最后一层的softmax输出数量就会变得非常大，但是使用train_tripletloss的训练仍然可以正常工作。</p></blockquote><h3 id="1-2-运行-train-softmax-py-文件训练"><a href="#1-2-运行-train-softmax-py-文件训练" class="headerlink" title="1.2 运行 train_softmax.py 文件训练"></a>1.2 运行 train_softmax.py 文件训练</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">python src/train_tripletloss.py</span><br><span class="line">--logs_base_dir ~/logs/facenet/</span><br><span class="line">--models_base_dir ~/models/facenet/</span><br><span class="line">--data_dir ~/datasets/casia/casia_maxpy_mtcnnalign_182_160</span><br><span class="line">--image_size 160</span><br><span class="line">--model_def models.inception_resnet_v1</span><br><span class="line">--lfw_dir ~/datasets/lfw/lfw_mtcnnalign_160</span><br><span class="line">--optimizer RMSPROP</span><br><span class="line">--learning_rate 0.01</span><br><span class="line">--weight_decay 1e-4</span><br><span class="line">--max_nrof_epochs 500</span><br></pre></td></tr></table></figure><h2 id="二、可视化TensorBoard"><a href="#二、可视化TensorBoard" class="headerlink" title="二、可视化TensorBoard"></a>二、可视化TensorBoard</h2><p>&emsp;&emsp;监视训练过程，使用TensorBoard:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=~/logs/facenet --port 6006</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;打开浏览器：<a href="http://localhost:6006/" target="_blank" rel="noopener">http://localhost:6006/</a></p><h2 id="三、用自己的图像训练分类器"><a href="#三、用自己的图像训练分类器" class="headerlink" title="三、用自己的图像训练分类器"></a>三、用自己的图像训练分类器</h2><h3 id="3-1-在LFW上训练分类器"><a href="#3-1-在LFW上训练分类器" class="headerlink" title="3.1 在LFW上训练分类器"></a>3.1 在LFW上训练分类器</h3><p>&emsp;&emsp;对于这个实验，我们使用LFW图像的子集来训练分类器。 LFW数据集分为训练和测试集。 然后加载预训练模型，然后使用此模型为选定图像生成特征。 预训练模型通常在更大的数据集上进行训练以提供良好的性能（本例中为MS-Celeb-1M数据集的一个子集）。</p><ul><li>将数据集分解为训练和测试集</li><li>加载预训练模型进行特征提取</li><li>计算数据集中图像的嵌入</li><li><p>模式= TRAIN：</p><ul><li>使用来自数据集的训练部分的嵌入来训练分类器  </li><li>将训练好的分类模型保存为python pickle</li></ul></li><li><p>模式= CLASSIFY：</p><ul><li>加载分类模型</li><li>使用来自数据集测试部分的嵌入来测试分类器  </li></ul></li></ul><blockquote><p>classifier.py定义参数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">def parse_arguments(argv):</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line"></span><br><span class="line">    parser.add_argument(&apos;mode&apos;, type=str, choices=[&apos;TRAIN&apos;, &apos;CLASSIFY&apos;],</span><br><span class="line">        help=&apos;Indicates if a new classifier should be trained or a classification &apos; +</span><br><span class="line">        &apos;model should be used for classification&apos;, default=&apos;CLASSIFY&apos;)</span><br><span class="line">    parser.add_argument(&apos;data_dir&apos;, type=str,</span><br><span class="line">        help=&apos;Path to the data directory containing aligned LFW face patches.&apos;)</span><br><span class="line">    parser.add_argument(&apos;model&apos;, type=str,</span><br><span class="line">        help=&apos;Could be either a directory containing the meta_file and ckpt_file or a model protobuf (.pb) file&apos;)</span><br><span class="line">    parser.add_argument(&apos;classifier_filename&apos;,</span><br><span class="line">        help=&apos;Classifier model file name as a pickle (.pkl) file. &apos; +</span><br><span class="line">        &apos;For training this is the output and for classification this is an input.&apos;)</span><br><span class="line">    parser.add_argument(&apos;--use_split_dataset&apos;,</span><br><span class="line">        help=&apos;Indicates that the dataset specified by data_dir should be split into a training and test set. &apos; +  </span><br><span class="line">        &apos;Otherwise a separate test set can be specified using the test_data_dir option.&apos;, action=&apos;store_true&apos;)</span><br><span class="line">    parser.add_argument(&apos;--test_data_dir&apos;, type=str,</span><br><span class="line">        help=&apos;Path to the test data directory containing aligned images used for testing.&apos;)</span><br><span class="line">    parser.add_argument(&apos;--batch_size&apos;, type=int,</span><br><span class="line">        help=&apos;Number of images to process in a batch.&apos;, default=90)</span><br><span class="line">    parser.add_argument(&apos;--image_size&apos;, type=int,</span><br><span class="line">        help=&apos;Image size (height, width) in pixels.&apos;, default=160)</span><br><span class="line">    parser.add_argument(&apos;--seed&apos;, type=int,</span><br><span class="line">        help=&apos;Random seed.&apos;, default=666)</span><br><span class="line">    parser.add_argument(&apos;--min_nrof_images_per_class&apos;, type=int,</span><br><span class="line">        help=&apos;Only include classes with at least this number of images in the dataset&apos;, default=20)</span><br><span class="line">    parser.add_argument(&apos;--nrof_train_images_per_class&apos;, type=int,</span><br><span class="line">        help=&apos;Use this number of images from each class for training and the rest for testing&apos;, default=10)</span><br><span class="line"></span><br><span class="line">    return parser.parse_args(argv)</span><br></pre></td></tr></table></figure></p></blockquote><ul><li><strong>mode</strong>：  指示训练新分类器还是进行分类测试集。’TRAIN’,    ‘CLASSIFY’</li><li><strong>data_dir</strong>：  包含对齐的LFW面部补丁的数据目录路径。</li><li><strong>model</strong>：  可能是包含meta_file和ckpt_file或模型protobuf(.pb)文件的目录</li><li><strong>classifier_filename</strong>：  分类器模型文件名称作pickle（.pkl）文件，对于训练过程，这是输出；对于分类过程，这是输入。</li><li><strong>use_split_dataset</strong>：  指示由data_dir指定的数据集应该分为训练集和测试集。 否则可以使用test_data_dir选项指定单独的测试集。</li><li><strong>test_data_dir</strong>：  包含用于测试的对齐图像的测试数据目录的路径。</li><li><strong>batch_size</strong>：  一个批次的图像运行数量。</li><li><strong>image_size</strong> ：  图像的像素尺寸。</li><li><strong>seed</strong>:   随机seed。</li><li><strong>min_nrof_images_per_class</strong>：  仅包含数据集中至少包含这些数量的图像的类。</li><li><strong>nrof_train_images_per_class</strong>：  从每个类中使用这个数量的图像进行训练，其余的进行测试。</li></ul><p>&emsp;&emsp;在数据集的训练集部分训练分类器的步骤如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">python src/classifier.py</span><br><span class="line">TRAIN</span><br><span class="line">data/lfw/lfw_align_mtcnnpy_160/</span><br><span class="line">src/models/20170512-110547/20170512-110547.pb</span><br><span class="line">src/models/lfw_classifier.pkl</span><br><span class="line">--batch_size 1000</span><br><span class="line">--min_nrof_images_per_class 40</span><br><span class="line">--nrof_train_images_per_class 35</span><br><span class="line">--use_split_dataset</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python src/classifier.py TRAIN data/lfw/lfw_align_mtcnnpy_160/ src/models/20170512-110547/20170512-110547.pb src/models/lfw_classifier.pkl --batch_size 1000 --min_nrof_images_per_class 40 --nrof_train_images_per_class 35 --use_split_dataset</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;训练输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Number of classes: 19</span><br><span class="line">Number of images: 665</span><br><span class="line">Loading feature extraction model</span><br><span class="line">Model filename: src/models/20170512-110547/20170512-110547.pb</span><br><span class="line">Calculating features for images</span><br><span class="line">Training classifier</span><br><span class="line">Saved classifier model to file &quot;src/models/lfw_classifier.pkl&quot;</span><br></pre></td></tr></table></figure></p><p>&emsp;&emsp;训练好的分类器可以稍后用于使用测试集进行分类：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">python src/classifier.py</span><br><span class="line">CLASSIFY</span><br><span class="line">data/lfw/lfw_align_mtcnnpy_160/</span><br><span class="line">src/models/20170512-110547/20170512-110547.pb</span><br><span class="line">src/models/lfw_classifier.pkl</span><br><span class="line">--batch_size 1000</span><br><span class="line">--min_nrof_images_per_class 40</span><br><span class="line">--nrof_train_images_per_class 35</span><br><span class="line">--use_split_dataset</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python src/classifier.py CLASSIFY data/lfw/lfw_align_mtcnnpy_160/ src/models/20170512-110547/20170512-110547.pb src/models/lfw_classifier.pkl --batch_size 1000 --min_nrof_images_per_class 40 --nrof_train_images_per_class 35 --use_split_dataset</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;单独指定测试集</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python src/classifier.py CLASSIFY data/lfw/test_lfw src/models/20170512-110547/20170512-110547.pb src/models/lfw_classifier.pkl --batch_size 1000 --min_nrof_images_per_class 40 --nrof_train_images_per_class 35 --test_data_dir data/lfw/test_lfw</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;这里使用数据集的测试集部分进行分类，并显示分类结果和分类概率。 该子集的分类准确度为〜0.98。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Number of classes: 19</span><br><span class="line">Number of images: 1202</span><br><span class="line">Loading feature extraction model</span><br><span class="line">Model filename: src/models/20170512-110547/20170512-110547.pb</span><br><span class="line">Calculating features for images</span><br><span class="line">Testing classifier</span><br><span class="line">Loaded classifier model from file &quot;src/models/lfw_classifier.pkl&quot;</span><br><span class="line">   0  Ariel Sharon: 0.712</span><br><span class="line">   1  Ariel Sharon: 0.771</span><br><span class="line">   2  Ariel Sharon: 0.807</span><br><span class="line">   3  Ariel Sharon: 0.785</span><br><span class="line">   4  Ariel Sharon: 0.750</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">1197  Vladimir Putin: 0.536</span><br><span class="line">1198  Vladimir Putin: 0.723</span><br><span class="line">1199  Vladimir Putin: 0.715</span><br><span class="line">1200  Vladimir Putin: 0.663</span><br><span class="line">1201  Vladimir Putin: 0.732</span><br><span class="line">Accuracy: 0.999</span><br></pre></td></tr></table></figure></p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-21/53475149.jpg" alt=""></p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-21/76473615.jpg" alt=""></p><h2 id="四、基于mtcnn与facenet的人脸识别（单张图像识别分类）"><a href="#四、基于mtcnn与facenet的人脸识别（单张图像识别分类）" class="headerlink" title="四、基于mtcnn与facenet的人脸识别（单张图像识别分类）"></a>四、基于mtcnn与facenet的人脸识别（单张图像识别分类）</h2><p>&emsp;&emsp;代码：facenet/contributed/predict.py  </p><p>&emsp;&emsp;主要功能：</p><ul><li><p>① 使用mtcnn进行人脸检测并对齐与裁剪</p></li><li><p>② 对裁剪的人脸使用facenet进行embedding</p></li><li><p>③ 执行predict.py进行人脸识别（需要训练好的svm模型）</p></li></ul><p>&emsp;&emsp;参数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def parse_arguments(argv):</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(&apos;image_files&apos;, type=str, nargs=&apos;+&apos;, help=&apos;Path(s) of the image(s)&apos;)</span><br><span class="line">    parser.add_argument(&apos;model&apos;, type=str,</span><br><span class="line">        help=&apos;Could be either a directory containing the meta_file and ckpt_file or a model protobuf (.pb) file&apos;)</span><br><span class="line">    parser.add_argument(&apos;classifier_filename&apos;,</span><br><span class="line">        help=&apos;Classifier model file name as a pickle (.pkl) file. &apos; +</span><br><span class="line">        &apos;For training this is the output and for classification this is an input.&apos;)</span><br><span class="line">    parser.add_argument(&apos;--image_size&apos;, type=int,</span><br><span class="line">        help=&apos;Image size (height, width) in pixels.&apos;, default=160)</span><br><span class="line">    parser.add_argument(&apos;--seed&apos;, type=int,</span><br><span class="line">        help=&apos;Random seed.&apos;, default=666)</span><br><span class="line">    parser.add_argument(&apos;--margin&apos;, type=int,</span><br><span class="line">        help=&apos;Margin for the crop around the bounding box (height, width) in pixels.&apos;, default=44)</span><br><span class="line">    parser.add_argument(&apos;--gpu_memory_fraction&apos;, type=float,</span><br><span class="line">        help=&apos;Upper bound on the amount of GPU memory that will be used by the process.&apos;, default=1.0)</span><br><span class="line">    return parser.parse_args(argv)</span><br></pre></td></tr></table></figure></p><ul><li><strong>image_files</strong>： 被识别图像路径</li><li><strong>model</strong>：包含meta_file和ckpt_file或模型protobuf（.pb）文件的目录</li><li><strong>classifier_filename</strong>：分类器模型文件名称作为pickle（.pkl）文件</li></ul><p>&emsp;&emsp;测试：用三中生成的lfw_classifier.pkl作为分类器模型进行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python predict.py d:/Anaconda3/Lib/site-packages/facenet/data/images/3.png D:/Anaconda3/Lib/site-packages/facenet/src/models/20170512-110547 D:/Anaconda3/Lib/site-packages/facenet/src/models/lfw_classifier.pkl</span><br></pre></td></tr></table></figure><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-22/3119407.jpg" alt=""></p><p>python contributed/predict.py data/images/2.png src/models/20170512-110547 src/models/lfw_classifier_whole.pkl</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;作者：Andy_z&lt;br&gt;文献：&lt;a href=&quot;https://github.com/davidsandberg/facenet/wiki&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;官方WiKi&lt;/a&gt;&lt;/p&gt;
&lt;/bloc
      
    
    </summary>
    
      <category term="人脸识别" scheme="http://yoururl.com/categories/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/"/>
    
    
      <category term="Summary" scheme="http://yoururl.com/tags/Summary/"/>
    
      <category term="facenet" scheme="http://yoururl.com/tags/facenet/"/>
    
      <category term="face recognition" scheme="http://yoururl.com/tags/face-recognition/"/>
    
  </entry>
  
  <entry>
    <title>DeepFool</title>
    <link href="http://yoururl.com/2018/07/15/Deep%20Fool/"/>
    <id>http://yoururl.com/2018/07/15/Deep Fool/</id>
    <published>2018-07-15T02:15:32.911Z</published>
    <updated>2018-03-14T07:20:13.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>作者：Andy<em>z<br>翻译文献：<a href="https://arxiv.org/abs/1511.04599" target="_blank" rel="noopener">DeepFool: a simple and accurate method to fool deep neural networks</a><br>^</em>^: 红色小字为作者自己的小白理解，如有错误，请谅解。欢迎纠正！</p></blockquote><p><sup><a href="#fn__^" id="reffn__^">_^</a></sup></p><h1 id="符号说明"><a href="#符号说明" class="headerlink" title="符号说明"></a>符号说明</h1><div class="table-container"><table><thead><tr><th>符号</th><th>说明</th></tr></thead><tbody><tr><td>$x$</td><td>原始图像</td></tr><tr><td>$r$</td><td>扰动</td></tr><tr><td>$\hat{k}(x)$</td><td>预测标签</td></tr><tr><td>$Δ(x;\hat{k})$</td><td>$\hat{k}$ 在点 $x$ 处的鲁棒性</td></tr><tr><td>$\mathbb{E}_x$</td><td>数据分布期望</td></tr></tbody></table></div><p>&emsp;&emsp;对于给定分类器，定义对抗扰动:</p><script type="math/tex; mode=display">∆(x;\hat{k}) := \min_r ||r||_2 \;\; s.t.\; \hat{k}(x + r) ≠ \hat{k}(x),\tag{1}</script><p>&emsp;&emsp;分类器的鲁棒性定义为：</p><script type="math/tex; mode=display">ρ_{adv}(\hat{k}) = \mathbb{E}_x \,\frac{∆(x;\hat{k})}{ ||x||_2},\tag{2}</script><h1 id="对于二分类器的DeepFool"><a href="#对于二分类器的DeepFool" class="headerlink" title="对于二分类器的DeepFool"></a>对于二分类器的DeepFool</h1><p>&emsp;&emsp;多分类器可以看作是二值分类器的集合，因此先研究二分类器算法。</p><ul><li><p>我们假设 $\hat{k}(x) = sign(f(x))$ ，其中 $f$ 是一个任意的标量值图像分类函数，$f:\mathbb{R}^n \rightarrow \mathbb{R}$ 。<br>用 ${\scr F}=^\Delta={x:f(x)=0}$ 表示 $f$ 的零水平集。<br>首先分析当 $f$ 是一个<a href="https://baike.baidu.com/item/%E4%BB%BF%E5%B0%84%E5%87%BD%E6%95%B0/9276178?fr=aladdin" target="_blank" rel="noopener">仿射</a>分类器 $f(x)=w^Tx+b$ ，然后推导出一般算法，该算法可应用于任何可微二值分类器 $f$。</p></li><li><p>当 $f$ 是仿射的分类器时，$f$ 在 $x_0$ 点处的鲁棒性: $\Delta (x_0;f)$ ，等于从 $x_0$ 到分离仿射超平面 ${\scr F}={x:w^Tx+b=0}$ 的距离（见图2），</p></li></ul><blockquote><p>之后，我们通过 $f$ 或其相应的离散映射 $\hat{k}$ 来引用分类器。 因此，$ρ<em>{adv}(\hat{k})=ρ</em>{adv}(f) 和 Δ(x; \hat{k})=Δ(x; f)$。</p></blockquote><center><font color="#0099ff" size="2" face="黑体">图2：线性二值分类器的对抗样本 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-13/76583305.jpg" alt=""></p><ul><li>改变分类器决策的最小扰动对应于 $x_0$ 到 ${\scr F}$ 上的正交投影。  由下列封闭式公式给出：<script type="math/tex; mode=display">r_∗(x_0) := arg \min ||r||_2   \;\;s.t. \;sign(f(x_0 + r))  \not= sign(f(x_0))= −\frac{f(x_0)}{\sideset{}{^2_2}{||w||}}w,\tag{3}</script></li></ul><blockquote><font color="#FF0000" size="2" face="黑体">[^_^]:推导参考支持向量机概念。</font></blockquote><ul><li>现在假设 $f$ 是一般的二元可微分类器，我们采用迭代过程来估计鲁棒性 $\Delta (x_0;f)$ ，具体而言，在每次迭代中，$f$ 围绕当前点 $x_i$线性化，并且线性化分类器的最小扰动被计算为:<script type="math/tex; mode=display">arg \min_{r_i} ||r_i||_2 \;\;s.t.\; f(x_i) + ∇f(x_i)^Tr_i = 0,\tag{4}</script></li></ul><blockquote><font color="#FF0000" size="2" face="黑体">[^_^]:梯度方向即为垂直超平面的方向，也就是超平面的法线上方向，可以最快达到分类边界。</font></blockquote><ul><li>算法的迭代 $i$ 中的扰动 $r<em>i$ 是使用方程（3）中的封闭形式解来计算的，并且在下一个迭代 $x</em>{i + 1}$ 被更新。当 $x_{i + 1}$ 改变分类器的符号时，该算法停止。</li></ul><center><font color="#0099ff" size="2" face="黑体">算法1：二值分类器的DeepFool算法 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-13/47575515.jpg" alt=""></p><center><font color="#0099ff" size="2" face="黑体">图3：算法1的几何图示 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-13/85167736.jpg" alt=""></p><blockquote><p>  当 $n=2$ 时，假设 $x_0∈ \mathbb{R}^n$ 。 绿色平面是 $x→f(x_0)+∇f(x_0)^T(x−x_0)$ 的图形，与分类器函数 $x→f(x)$ 相切。橙色线表示 $f(x_0) + ∇f(x_0)^T(x-x_0) = 0$ ， $x_0$ 投影到 $\mathbb{R}^n$ 的橙色超平面进一步得到 $x_1$ 。</p></blockquote><p>&emsp;&emsp;以上算法经常能收敛到零水平集 ${\scr F}$ 。但为了到达分类边界的另一边，最后的扰动向量 $\hat{r}$ 需要乘 $1+η$，且 $η≪1$ 。在后续实验中 $η=0.02$ 。</p><h1 id="对于多分类器的DeepFool"><a href="#对于多分类器的DeepFool" class="headerlink" title="对于多分类器的DeepFool"></a>对于多分类器的DeepFool</h1><p>&emsp;&emsp;将DeepFool方法推广到多分类器。多分类器最常用的方法是 <a href="http://blog.csdn.net/u013082989/article/details/53001746" target="_blank" rel="noopener">one-vs-all</a>(一对多)。因此基于该分类方案提出方法。</p><ul><li>在该方案中，分类器有 $c$ 类输出， 因此分类器能被定义为 $f: \mathbb{R}^n \rightarrow \mathbb{R}^c$  。分类是通过以下映射完成的：<script type="math/tex; mode=display">\hat{k}(x)=arg\max_k \;f_k(x),\tag{5}</script>&emsp;&emsp;&emsp; $f_k(x)$ 是 $f(x)$ 对应于第 $k$ 类的输出。</li></ul><p>&emsp;&emsp;与二分类情况类似，我们首先提出了线性情况的建议方法，然后将其推广到其他分类器。</p><h2 id="仿射多分类器"><a href="#仿射多分类器" class="headerlink" title="仿射多分类器"></a>仿射多分类器</h2><ul><li>$f(x)$ 是仿射分类器，$f(x)=W^T+b$ 。映射 $\hat{k}$ 是“one-vs-all”分类方案的结果。欺骗分类器的最小扰动表示如下：<script type="math/tex; mode=display">arg \min_r||r||_2 \;\;s.t.\;∃k : \sideset{}{^T_k}w(x_0+r)+b_k ≥ \sideset{}{^T_{\hat{k}(x_0)}}w(x_0 + r)+b_{\hat{k}(x_0)},\tag{6}</script></li></ul><blockquote><font color="#FF0000" size="2" face="黑体">[^_^]:计算最小扰动，首先要保证分类与原始点产生变化(即扰动导致分类结果变化)，那么约束条件就是，存在一类，使得这一类的分类置信度大于 原始预测的置信度</font></blockquote><p>&emsp;&emsp;&emsp; $w_k$ 是 $W$ 的第 $k$ 列。从几何上看，上述问题对应于计算 $x_0$ 和 凸多面体 $P$ 的补集的距离：</p><script type="math/tex; mode=display">P=\bigcap_{k=1}^{c}\{x:f_{\hat{k}(x_0)}(x)≥ f_k(x)\},\tag{7}</script><p>&emsp;&emsp;&emsp;其中， $x_0$ 落在 $P$ 内部。距离用 $dist(x_0,P^c)$ 表示。 多面体 $P$ 定义了 $f$ 输出标签 $\hat{k}(x_0)$ 的范围。 设置如图4所示：</p><center><font color="#0099ff" size="2" face="黑体">图4：仿射多分类器输出标签空间区域 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-13/35279198.jpg" alt=""></p><blockquote><p>若 $x_0$ 属于类别4，令 ${\scr F}_k={x:f_k(x)-f_4(x)=0}$ 。这些超平面用实线表示，P的边界用绿色虚线表示。</p></blockquote><ul><li>定义 $\hat{l}(x_0)$ 为离 $P$ 的边界最近的超平面(如图4中的 $\hat{l}(x_0)=3$)。 $\hat{l}(x_0)$ 计算如下：</li></ul><script type="math/tex; mode=display">\hat{l}(x_0)=arg \min_{k\not={\hat{k}(x_0)}}\frac{|f_k(x_0)-f_{\hat{k}(x_0)}(x_0)|}{||w_k-w_{\hat{k}(x_0)}||_2}.\tag{8}</script><p>&emsp;&emsp;&emsp;最小扰动 $r_*(x_0)$ 是把 $x_0$ 投影到超平面的向量：</p><script type="math/tex; mode=display">r_*(x_0)=\frac{|f_{\hat{l}(x_0)}(x_0)-f_{\hat{k}(x_0)}(x_0)|}{\sideset{}{^2_2}{||w_{\hat{l}(x_0)}-w_{\hat{k}(x_0)}||}}(w_{\hat{l}(x_0)}-w_{\hat{k}(x_0)}).\tag{9}</script><p>&emsp;&emsp;&emsp;换句话说，我们在 $P$ 的面上发现了 $x_0$ 的最近投影。</p><h2 id="一般多分类器"><a href="#一般多分类器" class="headerlink" title="一般多分类器"></a>一般多分类器</h2><p>&emsp;&emsp;现在将DeepFool算法扩展到一般的多分类器。</p><ul><li>对于一般的非线性分类器，式(7)中的集合 $P$ 描述的分类器输出标签 $\hat{k}(x_0)$ 的区域空间不再是一个多面体。在二分类情况下解释迭代的线性过程，我们用一个多面体 $\tilde{P}_i$ 在迭代次数 $i$ 下近似集合 $P$ 。<script type="math/tex; mode=display">\tilde{P}_i= \bigcap_{k=1}^{c}\{x:f_k(x_i)-f_{\hat{k}(x_0)}(x_i) + ∇f_k(x_i)^Tx-∇f_{\hat{k}(x_0)}(x_i)^Tx≤0\}.\tag{10}</script></li></ul><center><font color="#0099ff" size="2" face="黑体">图5：非线性多分类器输出标签区域空间 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-14/81096955.jpg" alt=""></p><ul><li><p>随后用 $dist(x_i,\sideset{}{_i^c}{\tilde{P}})$ 在迭代次数 $i$ 下近似 $x_i$ 到 $P$ 补集的距离。算法的每次迭代中，到达多面体 $\tilde{P}_i$ 边界的扰动向量被计算，当前预测更新。</p><p>该算法在算法2中给出。应该注意，所提出的算法以<a href="http://www.52ml.net/10359.html" target="_blank" rel="noopener">贪心</a>方式运行，并且不能保证收敛于(1)中的最佳扰动。 然而，我们在实践中观察到，我们的算法产生非常小的扰动，这被认为是最小扰动的良好近似。</p></li></ul><center><font color="#0099ff" size="2" face="黑体">算法2：多分类器的DeepFool算法</font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-13/66140912.jpg" alt=""></p><p>&emsp;&emsp;应该指出的是，DeepFool的优化策略与现有的优化技术密切相关。 在二分类情况下，它可以看作牛顿迭代算法，用于在欠定情况下找到非线性方程组的根。 这种算法被称为正常流量法。 我们在二分类情况下的算法可以被看作是梯度下降算法，具有在每次迭代时自动选择的自适应步长。 算法2中的线性化也类似于序列凸规划，其中约束在每一步被线性化。</p><h2 id="拓展到-L-p-范数"><a href="#拓展到-L-p-范数" class="headerlink" title="拓展到 $L_p$ 范数"></a>拓展到 $L_p$ 范数</h2><p>&emsp;&emsp;我们已经用 $L_2$ 范数计算了扰动。我们的框架不限制选择，提出的算法可以调节，用任何 $L_p$ 范数  $(p∈[1,∞])$ 来寻找最小对抗扰动。</p><ul><li>为此，算法2中第10行和第11行的更新步骤必须分别由以下更新代替：</li></ul><script type="math/tex; mode=display">\hat{l}\leftarrow arg\min_{k\not=\hat{k}(x_0)}\frac{|f'_k|}{||w'_k||_q},\tag{11}</script><script type="math/tex; mode=display">r_i\leftarrow\frac{|f'_{\hat{l}}|}{\sideset{}{^q_q}{||w'_{\hat{l}}||}}|w'_{\hat{l}}|^{q-1}\bigodot sign(w'_{\hat{l}}),\tag{12}</script><p>&emsp;&emsp;&emsp; $\bigodot$ 是逐点乘积，$q=\frac{p}{p-1}$ 。当 $p=∞$ 时(即 $l_∞$ 范数)， 更新步骤变成：</p><script type="math/tex; mode=display">\hat{l}\leftarrow arg\min_{k\not=\hat{k}(x_0)}\frac{|f'_k|}{||w'_k||_1},\tag{13}</script><script type="math/tex; mode=display">r_i\leftarrow\frac{|f'_{\hat{l}}|}{||w'_{\hat{l}}||_1} sign(w'_{\hat{l}}),\tag{14}</script><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><h2 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h2><p>&emsp;&emsp;我们现在在应用于MNIST，CIFAR-10和ImageNet图像分类数据集的深度卷积神经网络架构上测试我们的DeepFool算法。 我们考虑以下深度神经网络架构：</p><ul><li><p><strong>MNIST</strong>：一个双层全连接网络和一个双层LeNet卷积神经网络结构。 这两个网络都是使用MatConvNet包通过SGD进行训练。</p></li><li><p><strong>CIFAR-10</strong>：我们训练了三层LeNet架构，以及网络网络（NIN）架构。</p></li><li><p><strong>ILSVRC 2012</strong>：我们使用了CaffeNet 和GoogLeNet预训练模型</p></li></ul><p>&emsp;&emsp;为了评估分类器 $f$ 的对抗扰动的鲁棒性， 定义平均鲁棒性 $\hat{ρ}_{adv}(f)$ :</p><script type="math/tex; mode=display">\hat{ρ}_{adv}(f)=\frac{1}{|{\scr D}|}\sum_{x∈{\scr D}}\frac{||\hat{r}(x)||_2}{||x||_2},\tag{15}</script><p>其中，$\hat{r}(x)$ 是使用DeepFool得到的预测最小扰动 ， ${\scr D}$ 代表测试集。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>&emsp;&emsp;我们在表1中呈现了使用不同方法计算的每个分类器的准确度和平均鲁棒性 $\hatρ_{adv}$ 。 我们还显示了每种方法计算一个对抗样本所需的运行时间。 可以看出，DeepFool估计的扰动比使用竞争方法计算的扰动更小（因此更接近于(1)中定义的最小扰动）。 例如，使用DeepFool获得的平均扰动比FGSM估计的平均扰动低5倍。 在ILSVRC2012挑战数据集上，平均扰动比FGSM小一个数量级。 此外，与<a href="https://arxiv.org/abs/1312.6199" target="_blank" rel="noopener">18</a>中的方法相比，所提出的方法也产生更小的扰动矢量， 所提出的方法因此在检测可能欺骗神经网络的方向上更精确。 因此，DeepFool可以用作精确评估分类器鲁棒性的有用工具。</p><center><font color="#0099ff" size="2" face="黑体">表一：不同分类器在不同数据集的对抗鲁棒性 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-13/44616336.jpg" alt=""></p><blockquote><p>每个方法计算一个样本所需的时间在时间栏中给出。 时间是在2015年中的MacBook Pro上计算的，无需CUDA支持。 星号标记表示使用GTX 750 Ti GPU计算的值。[4]:FGSM</p></blockquote><p>&emsp;&emsp;在复杂性方面，所提出的方法比[18]中提出的标准方法快得多。事实上，虽然[18]方法涉及到一系列目标函数的代价最小化，但我们经验性地观察到，DeepFool在少数迭代（即小于3）中收敛于愚弄分类器的扰动向量。因此，与现有技术方法相比，所提出的方法达到更精确的扰动矢量，同时在计算上是有效的。这使得它很容易被用作基线方法来估计大规模数据集上非常深的神经网络的鲁棒性。在这种情况下，我们首先对大规模ImageNet数据集上最先进的分类器的鲁棒性进行量化评估。可以看出，尽管测试精度非常高，但这些方法对对抗扰动极不稳定：幅度比原始图像小1000倍的扰动足以欺骗最先进的深度神经网络。</p><center><font color="#0099ff" size="2" face="黑体">图6：对抗扰动的样本对比 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-13/11841802.jpg" alt=""></p><p>&emsp;&emsp;第一行：被分类为 $\hat{k}(x)=$ “鲸鱼”的原始图像 $x$ 。<br>&emsp;&emsp;第二行：被分类为 $\hat{k}(x+r)=$ “乌龟”的图像 $x + r$ 以及由DeepFool计算出的相应扰动 $r$ 。<br>&emsp;&emsp;第三行：被分类为“乌龟”的图像以及由FGSM计算出的相应扰动。 DeepFool导致更小的扰动。</p><p>&emsp;&emsp;可以观察到，DeepFool 产生难以察觉的对抗扰动，而FGSM输出具有更高范数的扰动图像。</p><ul><li>注意到，当扰动用最大范数计算时，上述结论依然成立： DeepFool 较其他方法生成更小的对抗扰动。</li></ul><center><font color="#0099ff" size="2" face="黑体">表2：对抗扰动的最大范数鲁棒性 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-14/22804987.jpg" alt=""></p><blockquote><p>分别基于DeepFool(最小的 $l<em>∞$ 扰动)和FGSM的四个不同网络的 $\sideset{}{^∞</em>{adv}}{\hat{ρ}}$ 值， 错误分类率达到90%</p></blockquote><script type="math/tex; mode=display">\sideset{}{^∞_{adv}}{\hat{ρ}}(f)=\frac{1}{|{\scr D}|} \sum_{x\in{\scr D}}\frac{||\hat{r}(x)||_∞}{||x||_∞},</script><p>&emsp;&emsp;其中  $\hat{r}(x)$  分别使用DeepFool( $p =∞$ ，参见3.3节)和快速梯度符号法计算。</p><h3 id="使用对抗样本进行微调"><a href="#使用对抗样本进行微调" class="headerlink" title="使用对抗样本进行微调"></a>使用对抗样本进行微调</h3><p>&emsp;&emsp;在本节中，我们对表1中的对抗样本所用的网络进行微调，为MNIST和CIFAR-10任务构建更鲁棒的分类器。具体来说，对于每个网络，我们进行了两个实验：<br>&emsp;&emsp;(1)在DeepFool的对抗样本中微调网络，<br>&emsp;&emsp;(2)在快速梯度符号对抗样本上微调网络。<br>我们通过执行另外5个训练周期对网络进行微调，仅在扰动的训练集上减少了50％的学习速率。对于每个实验，所有5个额外的周期使用相同的训练数据。为了完整性，我们还对原始数据执行了5个额外的周期。图7a至图7d显示了不同微调策略的 $\hat{ρ}<em>{adv}$ 的演变，其中鲁棒性 $\hat{ρ}</em>{adv}$ 是使用DeepFool估算的，因为这是最准确的方法，如表1所示。观察到即使在一个额外周期之后，对DeepFool对抗样本的微调也增强了网络对对抗扰动的鲁棒性。例如，MNIST网络的鲁棒性提高了50％，NIN的鲁棒性提高了约40％。  </p><center><font color="#0099ff" size="2" face="黑体">图7：微调效果 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-14/88045331.jpg" alt=""></p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-14/19503473.jpg" alt=""></p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-14/15536386.jpg" alt=""></p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-14/98947187.jpg" alt=""></p><p>&emsp;&emsp;另一方面，令人惊讶的是，FGSM可能会导致网络的对抗扰动鲁棒性下降。我们推测这种行为是由于使用FGSM估计的扰动远远大于最小对抗扰动。用过度扰动的图像微调网络会降低网络对对抗扰动的鲁棒性。为了验证这个假设，我们在图8中比较了一个网络的对抗鲁棒性，这个网络用DeepFool获得的对抗样本进行了微调，其中扰动的范数被故意乘以 $α= 1,2,3$ 。</p><center><font color="#0099ff" size="2" face="黑体">图8：调整扰动范数对鲁棒性的影响 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-14/47701062.jpg" alt=""></p><p>&emsp;&emsp;有趣的是，我们看到通过放大对抗性扰动的范数，微调网络的鲁棒性降低。这可以解释为什么过度扰动的图像会降低MNIST网络的鲁棒性：这些扰动可能真的改变数据的类别，因此基于这些样本进行的微调可能导致鲁棒性的下降（有关说明，请参见图9） 。这证实了我们的假设，并进一步显示了设计精确方法来计算最小扰动的重要性。</p><center><font color="#0099ff" size="2" face="黑体">图9：不同 α 值带来的图片数字识别类型的改变</font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-14/9476430.jpg" alt=""></p><blockquote><p>原始图像被识别为 “1”，DeepFool 扰动图像被识别为”7”。</p></blockquote><p>&emsp;&emsp;表3列出了微调网络的精度。 可以看出，使用DeepFool进行微调可以提高网络的准确性。 相反，使用FGSM进行微调导致了我们所有实验中测试精度的降低。 这证实了FGSM输出一些不太可能出现在测试数据中的过度扰动图像。 因此，它降低了该方法的性能，因为它充当正则化器而不代表原始数据的分布。 这种效应类似于几何数据增强方案，其中原始样本的大变换对泛化具有相反的效果。</p><center><font color="#0099ff" size="2" face="黑体">表3：微调网络精度 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-14/96929609.jpg" alt=""></p><blockquote><p>微调后的网络测试错误率（五个周期后）。 每列对应于不同类型的增强扰动。</p></blockquote><p>&emsp;&emsp;为了强调对最小扰动的正确估计的重要性，我们现在表明使用近似方法可能导致关于网络的对抗鲁棒性的错误结论。 我们对快速梯度符号对抗样本中的NIN分类器进行了微调。 我们遵循前面描述的程序，但是这次我们将学习率降低了90％。 我们已经使用DeepFool和FGSM评估了此网络在不同额外周期的对抗鲁棒性。 如图10所示，红线 夸大了训练对对抗样本的影响。 此外，它不足以证明在第一个额外周期失去鲁棒性。</p><center><font color="#0099ff" size="2" face="黑体">图10：正则化的鲁棒性 </font></center><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-14/82983733.jpg" alt=""></p><blockquote><p>如何用不同的方法判断对抗鲁棒性。 这些值通过原始网络的相应 $\hat{ρ}_{adv}$ 进行归一化。</p></blockquote><p>&emsp;&emsp;这些观察结果证实，使用准确的工具来衡量分类器的鲁棒性对于得出有关网络鲁棒性的结论是至关重要的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;作者：Andy&lt;em&gt;z&lt;br&gt;翻译文献：&lt;a href=&quot;https://arxiv.org/abs/1511.04599&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;DeepFool: a simple and accura
      
    
    </summary>
    
      <category term="对抗攻击" scheme="http://yoururl.com/categories/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/"/>
    
    
      <category term="Deep learning" scheme="http://yoururl.com/tags/Deep-learning/"/>
    
      <category term="Adversarial attack" scheme="http://yoururl.com/tags/Adversarial-attack/"/>
    
      <category term="Translation" scheme="http://yoururl.com/tags/Translation/"/>
    
  </entry>
  
  <entry>
    <title>前端-html基础</title>
    <link href="http://yoururl.com/2018/07/15/01-HTML/"/>
    <id>http://yoururl.com/2018/07/15/01-HTML/</id>
    <published>2018-07-14T16:00:00.000Z</published>
    <updated>2018-07-15T04:26:02.980Z</updated>
    
    <content type="html"><![CDATA[<hr><p> 学习目标:</p><ul><li>了解常用浏览器</li><li>掌握WEB标准</li><li>理解标签语义化</li><li>掌握常用的排版标签</li><li>掌握常用的文本格式化图像链接等标签</li><li>掌握三种列表标签</li><li>掌握表格标签</li><li>掌握表格标签</li><li>掌握表单标签<br>typora-copy-images-to: media</li></ul><hr><h1 id="自我介绍"><a href="#自我介绍" class="headerlink" title="自我介绍"></a>自我介绍</h1><p>传智讲师   刘晓强     江湖人称  强哥  </p><p>但是不是</p><p><img src="media/qq.jpg"></p><p>也不是：</p><p><img src="media/lk.jpg"></p><p>其实这是我：</p><p><img src="media/gt.jpg"></p><p>前端基础  html +css    基础班        html 2 +css  7天    9 天 传统布局    +  3天 html 5 +css3 基础</p><p>就业班   js     移动web       php + 项目  15      node      vue     框架  微信 …  大前端    </p><h1 id="HTML-第一天目标"><a href="#HTML-第一天目标" class="headerlink" title="HTML 第一天目标"></a>HTML 第一天目标</h1><p>能够写出基本的页面（里面包含图片、各种标签和链接）</p><h1 id="开发工具"><a href="#开发工具" class="headerlink" title="开发工具"></a>开发工具</h1><p>我们主要用的 开发工具有   chrome  、  sublime 、  photoshop</p><h2 id="浏览器（显示）"><a href="#浏览器（显示）" class="headerlink" title="浏览器（显示）"></a>浏览器（显示）</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">浏览器是网页显示、运行的平台，常用的浏览器有IE、火狐（Firefox）、谷歌（Chrome）、Safari和Opera等。我们平时称为五大浏览器。</span><br></pre></td></tr></table></figure><p><img src="media/b.png"></p><h3 id="查看浏览器占有的市场份额（知晓）"><a href="#查看浏览器占有的市场份额（知晓）" class="headerlink" title="查看浏览器占有的市场份额（知晓）"></a>查看浏览器占有的市场份额（知晓）</h3><p>查看网站： <a href="http://tongji.baidu.com/data/browser" target="_blank">http://tongji.baidu.com/data/browser</a></p><p><img src="media/count.png"></p><p> 这些工具你认识几个？</p><h2 id="sublime（书写）"><a href="#sublime（书写）" class="headerlink" title="sublime（书写）"></a>sublime（书写）</h2><p> <img src="media/s.png"></p><p>  普通青年    Dreamweaver</p><p>  文艺青年    sublime</p><p>  高手和傻子  用记事本</p><p>  其实。。。。</p><p>  <img src="media/node.png"></p><h2 id="Photoshop-协助"><a href="#Photoshop-协助" class="headerlink" title="Photoshop(协助)"></a>Photoshop(协助)</h2><p><img src="media/1498465020015.png" alt="1498465020015"></p><p>PS 工具是我们使用频率比较高的软件之一， 我们学习PS目的不是为了设计海报做电商和UI的，而是要求：</p><ol><li><strong>熟练的切图</strong></li><li>能和网站美工美眉有共同话题。。。。。</li></ol><h1 id="认识网页"><a href="#认识网页" class="headerlink" title="认识网页"></a>认识网页</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">网页主要由文字、图像和超链接等元素构成。当然，除了这些元素，网页中还可以包含音频、视频以及Flash等。</span><br></pre></td></tr></table></figure><p><img src="media/mi.png" alt=""></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">思考：  网页是如何形成的呢?</span><br></pre></td></tr></table></figure><p><img src="media/web.png"></p><h1 id="常见浏览器内核介绍"><a href="#常见浏览器内核介绍" class="headerlink" title="常见浏览器内核介绍"></a>常见浏览器内核介绍</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">浏览器是网页运行的平台，常用的浏览器有IE、火狐（Firefox）、谷歌（Chrome）、Safari和Opera等。我们平时称为五大浏览器。</span><br></pre></td></tr></table></figure><p><img src="media/b.png"></p><h2 id="浏览器内核（理解）"><a href="#浏览器内核（理解）" class="headerlink" title="浏览器内核（理解）"></a>浏览器内核（理解）</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">浏览器内核又可以分成两部分：渲染引擎(layout engineer 或者 Rendering Engine)和 JS 引擎。</span><br><span class="line">渲染引擎 它负责取得网页的内容（HTML、XML、图像等等）、整理讯息（例如加入 CSS 等），以及计算网页的显示方式，然后会输出至显示器或打印机。浏览器的内核的不同对于网页的语法解释会有不同，所以渲染的效果也不相同。</span><br><span class="line">JS 引擎 则是解析 Javascript 语言，执行 javascript语言来实现网页的动态效果。</span><br><span class="line"></span><br><span class="line">最开始渲染引擎和 JS 引擎并没有区分的很明确，后来 JS 引擎越来越独立，内核就倾向于只指渲染引擎。有一个网页标准计划小组制作了一个 ACID 来测试引擎的兼容性和性能。内核的种类很多，如加上没什么人使用的非商业的免费内核，可能会有10多种，但是常见的浏览器内核可以分这四种：Trident、Gecko、Blink、Webkit。</span><br></pre></td></tr></table></figure><p>（1）Trident(IE内核) </p><p>国内很多的双核浏览器的其中一核便是 Trident，美其名曰 “兼容模式”。</p><p>代表： IE、傲游、世界之窗浏览器、Avant、腾讯TT、猎豹安全浏览器、360极速浏览器、百度浏览器等。</p><p>Window10 发布后，IE 将其内置浏览器命名为 Edge，Edge 最显著的特点就是新内核 EdgeHTML。</p><p>（2）Gecko(firefox) </p><p>Gecko(Firefox 内核)： Mozilla FireFox(火狐浏览器) 采用该内核，Gecko 的特点是代码完全公开，因此，其可开发程度很高，全世界的程序员都可以为其编写代码，增加功能。 可惜这几年已经没落了， 比如 打开速度慢、升级频繁、猪一样的队友flash、神一样的对手chrome。</p><p>（3） webkit(Safari)  </p><p> Safari 是苹果公司开发的浏览器，所用浏览器内核的名称是大名鼎鼎的 WebKit。</p><p> 现在很多人错误地把 webkit 叫做 chrome内核（即使 chrome内核已经是 blink 了），苹果感觉像被别人抢了媳妇，都哭晕再厕所里面了。</p><p> 代表浏览器：傲游浏览器3、 Apple Safari (Win/Mac/iPhone/iPad)、Symbian手机浏览器、Android 默认浏览器，</p><p>（4） Chromium/Blink(chrome) </p><p>   在 Chromium 项目中研发 Blink 渲染引擎（即浏览器核心），内置于 Chrome 浏览器之中。Blink 其实是 WebKit 的分支。 </p><p>​     大部分国产浏览器最新版都采用Blink内核。二次开发</p><p>（5） Presto(Opera) </p><p>  Presto（已经废弃） 是挪威产浏览器 opera 的 “前任” 内核，为何说是 “前任”，因为最新的 opera 浏览器早已将之抛弃从而投入到了谷歌怀抱了。  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">了解一点：</span><br></pre></td></tr></table></figure><p>移动端的浏览器内核主要说的是系统内置浏览器的内核。</p><p>Android手机而言，使用率最高的就是Webkit内核，大部分国产浏览器宣称的自己的内核，基本上也是属于webkit二次开发。</p><p>iOS以及WP7平台上，由于系统原因，系统大部分自带浏览器内核，一般是Safari或者IE内核Trident的</p><h1 id="Web标准（重点）"><a href="#Web标准（重点）" class="headerlink" title="Web标准（重点）"></a>Web标准（重点）</h1><p>通过以上浏览器的内核不同，我们知道他们工作原理、解析肯定不同，显示就会有差别。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">问：  哪个语言再全国基本都可以听得懂？</span><br></pre></td></tr></table></figure><p><img src="media/bz.png"></p><h2 id="Web-标准的好处"><a href="#Web-标准的好处" class="headerlink" title="Web 标准的好处"></a>Web 标准的好处</h2><p><em>1</em>、让Web的发展前景更广阔<br><em>2</em>、内容能被更广泛的设备访问<br><em>3</em>、更容易被搜寻引擎搜索<br><em>4</em>、降低网站流量费用<br><em>5</em>、使网站更易于维护<br><em>6</em>、提高页面浏览速度</p><h2 id="Web-标准构成"><a href="#Web-标准构成" class="headerlink" title="Web 标准构成"></a>Web 标准构成</h2><p> Web标准不是某一个标准，而是由W3C和其他标准化组织制定的一系列标准的集合。</p><p>主要包括结构（Structure）、表现（Presentation）和行为（Behavior）三个方面。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">结构标准：结构用于对网页元素进行整理和分类，咱们主要学的是HTML。 最重要</span><br><span class="line">表现标准：表现用于设置网页元素的版式、颜色、大小等外观样式，主要指的是CSS。</span><br><span class="line">行为标准：行为是指网页模型的定义及交互的编写，咱们主要学的是 Javascript</span><br></pre></td></tr></table></figure><p>理想状态我们的源码： .HTML    .css   .js </p><p>直观感受：</p><p><img src="media/gx.png"></p><p>总结WEB标准：</p><p>结构标准：   <img src="media/hb1.png">  决定你是否有个好天然身体 </p><p>表现标准：   <img src="media/hb2.png">  决定你是否打扮的美丽外观</p><p>行为标准：   <img src="media/hb3.jpg" width="420">  决定你是否有吸引人的行为</p><h2 id="课堂一练："><a href="#课堂一练：" class="headerlink" title="课堂一练："></a>课堂一练：</h2><p><strong>1.关于WEB标准下列说法正确的是: </strong></p><p>A html决定页面的行为，css决定页面的样式，js决定页面的结构</p><p>B html决定页面的样式，css决定页面的结构，js决定页面的行为</p><p>C html决定页面的结构，css决定页面的样式，js决定页面的行为</p><p>D 以上都不正确</p><p>2 <strong>web 标准里边规定三层分离不包括哪部分</strong></p><p>A．HTML</p><p>B．CSS</p><p>C．JavaScript</p><p>D．PHP</p><p>3.<strong>关于WEB标准下列说法正确的是</strong></p><p>A．html相当于人的动作行为，CSS相当于人的穿着打扮，javascript相当于人的骨架结构；</p><p>B．html相当于人的骨架结构，CSS相当于人的穿着打扮，javascript相当于人的动作行为；</p><p>C．html相当于人的穿着打扮，CSS相当于人的骨架结构，javascript相当于人的动作行为；</p><p>D．html相当于人的骨架结构，CSS相当于人的动作行为，javascript相当于人的穿着打扮；</p><h1 id="HTML-初识"><a href="#HTML-初识" class="headerlink" title="HTML 初识"></a>HTML 初识</h1><p>一般先学习HTML+CSS， 这里我们先定一个小目标，先学HTML,后学习CSS。</p><p>HTML（英文Hyper Text Markup Language的缩写）中文译为“超文本标签语言”。是用来描述网页的一种语言。</p><p>所谓超文本，因为它可以加入图片、声音、动画、多媒体等内容，不仅如此，它还可以从一个文件跳转到另一个文件，与世界各地主机的文件连接。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">h1</span>&gt;</span> 我是一个大标题 <span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br></pre></td></tr></table></figure><p>   注意：   体会 文本    标签    语言   几个词语</p><ul><li>HTML 指的是超文本标记语言 (<strong>H</strong>yper <strong>T</strong>ext <strong>M</strong>arkup <strong>L</strong>anguage)</li><li>HTML 不是一种编程语言，而是一种标记语言 (markup language)</li><li>标记语言是一套标记标签 (markup tag)</li></ul><p>总结： HTML 作用就是用标记标签来描述网页，把网页内容在浏览器中展示出来。 </p><p>用文字来描述网页标签</p><h2 id="HTML骨架格式"><a href="#HTML骨架格式" class="headerlink" title="HTML骨架格式"></a>HTML骨架格式</h2><p>日常生活的书信，我们要遵循共同的约定。 </p><p><img src="media/mess.png" alt=""></p><p>同理：HTML 有自己的语言语法骨架格式：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">HTML</span>&gt;</span>   </span><br><span class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span>     </span><br><span class="line">        <span class="tag">&lt;<span class="name">title</span>&gt;</span><span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">HTML</span>&gt;</span></span><br></pre></td></tr></table></figure><p>课堂练习1：    书写我们的第一个HTML 页面！</p><ol><li>新建一个demo 的 TXT 文件。</li><li>里面写入刚才的HTML 骨架。月薪过万 你我之间  黑马洗练  一飞冲天</li><li>把后缀名改为 .HTML。</li><li>右击—谷歌浏览器打开。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">1 HTML标签：</span><br><span class="line"></span><br><span class="line">作用所有HTML中标签的一个根节点。 最大的标签   根标签</span><br><span class="line"></span><br><span class="line">2 head标签： 文档的头部</span><br><span class="line"></span><br><span class="line">文档的头部描述了文档的各种属性和信息，包括文档的标题、在 Web 中的位置以及和其他文档的关系等。绝大多数文档头部包含的数据都不会真正作为内容显示给读者。</span><br><span class="line"></span><br><span class="line">注意在head标签中我们必须要设置的标签是title</span><br><span class="line"></span><br><span class="line">3.title标签： 文档的标题</span><br><span class="line"></span><br><span class="line">作用：让页面拥有一个属于自己的标题。</span><br><span class="line"></span><br><span class="line">4.body标签：文档的主体  以后我们的页面内容 基本都是放到body里面的</span><br><span class="line"></span><br><span class="line">body 元素包含文档的所有内容（比如文本、超链接、图像、表格和列表等等。）</span><br></pre></td></tr></table></figure><p>为了便于记忆，我们请出刚才要辞职回家养猪的二师兄来帮忙， 我称之为  猪八戒记忆法</p><p><img src="media/pig.png"></p><h2 id="HTML标签分类"><a href="#HTML标签分类" class="headerlink" title="HTML标签分类"></a>HTML标签分类</h2><p>  在HTML页面中，带有“&lt; &gt;”符号的元素被称为HTML标签，如上面提到的 &lt;HTML&gt;、&lt;head&gt;、&lt;body&gt;都是HTML骨架结构标签。所谓标签就是放在“&lt; &gt;” 标签符中表示某个功能的编码命令，也称为HTML标签或 HTML元素</p><p>1.双标签</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">标签名</span>&gt;</span> 内容 <span class="tag">&lt;/<span class="name">标签名</span>&gt;</span></span><br></pre></td></tr></table></figure><p>该语法中“&lt;标签名&gt;”表示该标签的作用开始，一般称为“开始标签（start tag）”，“&lt;/标签名&gt;” 表示该标签的作用结束，一般称为“结束标签（end tag）”。和开始标签相比，结束标签只是在前面加了一个关闭符“/”。</p><blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; 比如 <span class="tag">&lt;<span class="name">body</span>&gt;</span>我是文字  <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><p>2.单标签</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">标签名</span> /&gt;</span></span><br></pre></td></tr></table></figure><p>  单标签也称空标签，是指用一个标签符号即可完整地描述某个功能的标签。</p><blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; 比如  <span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><h2 id="HTML标签关系"><a href="#HTML标签关系" class="headerlink" title="HTML标签关系"></a>HTML标签关系</h2><p>标签的相互关系就分为两种：</p><p>1.嵌套关系</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span>  <span class="tag">&lt;<span class="name">title</span>&gt;</span> <span class="tag">&lt;/<span class="name">title</span>&gt;</span>  <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br></pre></td></tr></table></figure><p><img src="media/father.jpg"></p><p>2.并列关系</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure><p><img src="media/xiong.jpg"></p><p>倡议： 如果两个标签之间的关系是嵌套关系，子元素最好缩进一个tab键的身位。如果是并列关系，最好上下对齐。</p><h2 id="课堂一练"><a href="#课堂一练" class="headerlink" title="课堂一练"></a>课堂一练</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">请问下列哪个标签是错误的？</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A  &lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">B  &lt;strong&gt;&lt;div&gt;&lt;/div&gt;&lt;/strong&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C  &lt;head&gt;&lt;title&gt;&lt;/head&gt;&lt;/title&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">D  &lt;body&gt;&lt;div&gt;&lt;/div&gt;&lt;/body&gt;</span><br></pre></td></tr></table></figure><p>  <a href="key.HTML" target="_blank">sublime 一些常用快捷键  点我查看 </a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">再页面中输入 以下2个单词</span><br><span class="line">1.  html: 5   </span><br><span class="line">2.  !</span><br><span class="line">   在sublime里面然后按下tab键盘即可生成HTML骨架</span><br></pre></td></tr></table></figure><h1 id="文档类型-lt-DOCTYPE-gt"><a href="#文档类型-lt-DOCTYPE-gt" class="headerlink" title="文档类型&lt;!DOCTYPE&gt;"></a>文档类型&lt;!DOCTYPE&gt;</h1><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE html&gt;</span></span><br></pre></td></tr></table></figure><p>同学你用啥手机？你咋回答？  </p><p>这句话就是告诉我们使用哪个html版本？  我们使用的是 html 5 的版本。  html有很多版本，那我们应该告诉用户和浏览器我们使用的版本号。</p><p>&lt;!DOCTYPE&gt; 标签位于文档的最前面，用于向浏览器说明当前文档使用哪种 HTML 或 XHTML 标准规范，必需在开头处使用&lt;!DOCTYPE&gt;标签为所有的XHTML文档指定XHTML版本和类型，只有这样浏览器才能按指定的文档类型进行解析。</p><p>注意：  一些老网站可能用的还是老版本的文档类型比如 XHTML之类的，但是我们学的是HTML5,而且HTML5的文档类型兼容很好(向下兼容的原则)，所以大家放心的使用HTML5的文档类型就好了。</p><h1 id="字符集"><a href="#字符集" class="headerlink" title="字符集"></a>字符集</h1><meta charset="UTF-8"><p>utf-8是目前最常用的字符集编码方式，常用的字符集编码方式还有gbk和gb2312。</p><p>gb2312 简单中文  包括6763个汉字</p><p>BIG5   繁体中文 港澳台等用</p><p>GBK包含全部中文字符    是GB2312的扩展，加入对繁体字的支持，兼容GB2312</p><p>UTF-8则包含全世界所有国家需要用到的字符</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">记住一点，以后我们统统使用UTF-8 字符集, 这样就避免出现字符集不统一而引起乱码的情况了。</span><br></pre></td></tr></table></figure><h1 id="HTML标签的语义化"><a href="#HTML标签的语义化" class="headerlink" title="HTML标签的语义化"></a>HTML标签的语义化</h1><p>白话： 所谓标签语义化，就是指标签的含义。</p><h2 id="为什么要有语义化标签"><a href="#为什么要有语义化标签" class="headerlink" title="为什么要有语义化标签"></a>为什么要有语义化标签</h2><ol><li><p>方便代码的阅读和维护</p></li><li><p>同时让浏览器或是网络爬虫可以很好地解析，从而更好分析其中的内容 </p></li><li><p>使用语义化标签会具有更好地搜索引擎优化 </p></li></ol><p>核心：合适的地方给一个最为合理的标签。</p><p>语义是否良好： 当我们去掉CSS之后，网页结构依然组织有序，并且有良好的可读性。</p><p>白话，一眼看去，就知道那个是重点，结构是什么，知道每块的内容是干啥的。</p><p>遵循的原则：先确定语义的HTML ，再选合适的CSS。</p><h1 id="HTML常用标签"><a href="#HTML常用标签" class="headerlink" title="HTML常用标签"></a>HTML常用标签</h1><p> 首先 HTML和CSS是两种完全不同的语言，我们学的是结构，就只写HTML标签，认识标签就可以了。 不会再给结构标签指定样式了。</p><p> HTML标签有很多，这里我们学习最为常用的，后面有些较少用的，我们可以查下手册就可以了。 </p><h2 id="排版标签"><a href="#排版标签" class="headerlink" title="排版标签"></a>排版标签</h2><p>排版标签主要和css搭配使用，显示网页结构的标签，是网页布局最常用的标签。</p><h3 id="标题标签-熟记"><a href="#标题标签-熟记" class="headerlink" title="标题标签 (熟记)"></a>标题标签 (熟记)</h3><p> 单词缩写：  head   头部. 标题     title  文档标题</p><p>为了使网页更具有语义化，我们经常会在页面中用到标题标签，HTML提供了6个等级的标题，即</p><p> </p><h1>、<h2>、<h3>、<h4>、<h5>和<h6><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">标题标签语义：  作为标题使用，并且依据重要性递减</span><br></pre></td></tr></table></figure><p>其基本语法格式如下：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">hn</span>&gt;</span>   标题文本   <span class="tag">&lt;/<span class="name">hn</span>&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>注意：  h1 标签因为重要，尽量少用，不要动不动就向你扔了一个h1。 一般h1 都是给logo使用，或者页面中最重要标题信息。</p></blockquote><p>  <img src="media/dog.gif"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">传智播客学前端，</span><br><span class="line">　　前端学院四十班。</span><br><span class="line">　　新班强哥讲台站，</span><br><span class="line">　　又带新颜技术钻。</span><br><span class="line">　　标题一共六级选，</span><br><span class="line">　　具体效果刷新见。</span><br><span class="line">　　        ------强哥</span><br></pre></td></tr></table></figure><h3 id="段落标签-熟记"><a href="#段落标签-熟记" class="headerlink" title="段落标签( 熟记)"></a>段落标签( 熟记)</h3><p>单词缩写：  paragraph  段落  [ˈpærəgræf]    无须记这个单词</p><p> 在网页中要把文字有条理地显示出来，离不开段落标签，就如同我们平常写文章一样，整个网页也可以分为若干个段落，而段落的标签就是</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">p</span>&gt;</span>  文本内容  <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br></pre></td></tr></table></figure><p>是HTML文档中最常见的标签，默认情况下，文本在一个段落中会根据浏览器窗口的大小自动换行。</p><h3 id="水平线标签-认识"><a href="#水平线标签-认识" class="headerlink" title="水平线标签(认识)"></a>水平线标签(认识)</h3><p>单词缩写：  horizontal  横线    [ˌhɔrəˈzɑntl]    同上</p><p>在网页中常常看到一些水平线将段落与段落之间隔开，使得文档结构清晰，层次分明。这些水平线可以通过插入图片实现，也可以简单地通过标签来完成，<hr>就是创建横跨网页水平线的标签。其基本语法格式如下：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">hr</span> /&gt;</span>是单标签</span><br></pre></td></tr></table></figure><p> 在网页中显示默认样式的水平线。</p><p>课堂练习2：    新闻页面 </p><p><img src="media/sh.png"> </p><h3 id="换行标签-熟记"><a href="#换行标签-熟记" class="headerlink" title="换行标签(熟记)"></a>换行标签(熟记)</h3><p>单词缩写：  break   打断 ,换行</p><p>在HTML中，一个段落中的文字会从左到右依次排列，直到浏览器窗口的右端，然后自动换行。如果希望某段文本强制换行显示，就需要使用换行标签</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">br</span> /&gt;</span></span><br></pre></td></tr></table></figure><p>这时如果还像在word中直接敲回车键换行就不起作用了。</p><h2 id="课堂一练-1"><a href="#课堂一练-1" class="headerlink" title="课堂一练"></a>课堂一练</h2><p>关于标签下列说法正确的是 </p><p>(A) P1是段落标签</p><p>(B) H1 是标题标签</p><p>(C) Hr是换行标签</p><p>(D) Br 是一条直线</p><p> 2 关于标签下列说法不正确的是</p><p>(A) H标签有6个等级分别是</p><h1> <h2> <h3> <h4> <h5>和<h6><p></p><p>(B) h1到h6 文字从小到大 </p><p>(C) p标签一行只能放一个</p><p>(D) P是段落标签会给文字加上段落的语义</p><h3 id="div-span标签-重点"><a href="#div-span标签-重点" class="headerlink" title="div span标签(重点)"></a>div span标签(重点)</h3><p>div  span    是没有语义的     是我们网页布局主要的2个盒子     css+div</p><p>div 就是  division  的缩写   分割， 分区的意思  其实有很多div 来组合网页。</p><p>span, 跨度，跨距；范围    </p><p>语法格式：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span>&gt;</span> 这是头部 <span class="tag">&lt;/<span class="name">div</span>&gt;</span>    <span class="tag">&lt;<span class="name">span</span>&gt;</span>今日价格<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="文本格式化标签-熟记"><a href="#文本格式化标签-熟记" class="headerlink" title="文本格式化标签(熟记)"></a>文本格式化标签(熟记)</h2><p>在网页中，有时需要为文字设置粗体、斜体或下划线效果，这时就需要用到HTML中的文本格式化标签，使文字以特殊的方式显示。</p><p><img src="media/tab.png"></p><p>  b  i  s  u   只有使用 没有 强调的意思       strong   em  del   ins  语义更强烈</p><h2 id="标签属性"><a href="#标签属性" class="headerlink" title="标签属性"></a>标签属性</h2><p><img src="media/ttt.jpg" width="300"></p><p>属性就是特性 比如 手机的颜色 手机的尺寸 ，总结就是手机的。。</p><p>手机的颜色是黑色   手机的尺寸是 8寸</p><p>水平线的长度是 200  </p><p>图片的宽度 是  300    键  值对</p><p>使用HTML制作网页时，如果想让HTML标签提供更多的信息，可以使用HTML标签的属性加以设置。其基本语法格式如下：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">标签名</span> 属性<span class="attr">1</span>=<span class="string">"属性值1"</span> 属性<span class="attr">2</span>=<span class="string">"属性值2"</span> …&gt;</span> 内容 <span class="tag">&lt;/<span class="name">标签名</span>&gt;</span></span><br></pre></td></tr></table></figure><p>在上面的语法中，</p><p>1.标签可以拥有多个属性，必须写在开始标签中，位于标签名后面。</p><p>2.属性之间不分先后顺序，标签名与属性、属性与属性之间均以空格分开。</p><p>3.任何标签的属性都有默认值，省略该属性则取默认值。</p><p>采取  键值对 的格式   key=”value”  的格式  </p><p>比如:  </p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">hr</span> <span class="attr">width</span>=<span class="string">"400"</span> /&gt;</span></span><br></pre></td></tr></table></figure><p>属性  是 宽度  </p><p>值    是 400 </p><p>提倡：   尽量不使用 样式属性。   <img src="media/sm.jpg"> </p><h2 id="图像标签img-重点"><a href="#图像标签img-重点" class="headerlink" title="图像标签img (重点)"></a>图像标签img (重点)</h2><p>单词缩写：   image  图像</p><p>HTML网页中任何元素的实现都要依靠HTML标签，要想在网页中显示图像就需要使用图像标签，接下来将详细介绍图像标签<img>以及和他相关的属性。其基本语法格式如下：</p><p>该语法中src属性用于指定图像文件的路径和文件名，他是img标签的必需属性。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">"图像URL"</span> /&gt;</span></span><br></pre></td></tr></table></figure><p><img src="media/img.png"></p><p><strong>当网页显示图片时,鼠标滑上图片显示文字描述是以下哪个属性<em>**</em></strong></p><p>(A) 设置alt属性</p><p>(B) 设置title属性</p><p>(C) 设置href 属性</p><p>(D) 设置src 属性</p><p><strong>2  在HTML中，使用<img>标签插入图像，下列选项关于<img>的src属性说法正确的是 </strong></p><p>(A) 用来设置图片的格式</p><p>(B) 用来设置图片的所在位置</p><p>(C) 用来设置鼠标指向图片时显示的文字</p><p>(D) 用来设置图片是否能正确显示 </p><h2 id="链接标签-重点"><a href="#链接标签-重点" class="headerlink" title="链接标签(重点)"></a>链接标签(重点)</h2><p>单词缩写：  anchor 的缩写  [ˈæŋkə(r)] 。基本解释 锚, 铁锚 的</p><p>在HTML中创建超链接非常简单，只需用标签环绕需要被链接的对象即可，其基本语法格式如下：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"跳转目标"</span> <span class="attr">target</span>=<span class="string">"目标窗口的弹出方式"</span>&gt;</span>文本或图像<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure><p>href：用于指定链接目标的url地址，当为标签应用href属性时，它就具有了超链接的功能。  Hypertext Reference的缩写。意思是超文本引用</p><p>target：用于指定链接页面的打开方式，其取值有_self和_blank两种，其中_self为默认值，_blank为在新窗口中打开方式。</p><p>注意：</p><p>1.外部链接 需要添加 http:// www.baidu.com</p><p>2.内部链接 直接链接内部页面名称即可 比如 &lt; a href=”index.html”&gt; 首页 &lt;/a &gt;    </p><p>3.如果当时没有确定链接目标时，通常将链接标签的href属性值定义为“#”(即href=”#”)，表示该链接暂时为一个空链接。</p><p>4.不仅可以创建文本超链接，在网页中各种网页元素，如图像、表格、音频、视频等都可以添加超链接。</p><h3 id="锚点定位-（难点）"><a href="#锚点定位-（难点）" class="headerlink" title="锚点定位 （难点）"></a>锚点定位 （难点）</h3><p>通过创建锚点链接，用户能够快速定位到目标内容。<br>创建锚点链接分为两步：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.使用“a href=”#id名&gt;“链接文本"<span class="tag">&lt;/<span class="name">a</span>&gt;</span>创建链接文本（被点击的）</span><br><span class="line">  <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"#two"</span>&gt;</span>   </span><br><span class="line"></span><br><span class="line">2.使用相应的id名标注跳转目标的位置。</span><br><span class="line">  <span class="tag">&lt;<span class="name">h3</span> <span class="attr">id</span>=<span class="string">"two"</span>&gt;</span>第2集<span class="tag">&lt;/<span class="name">h3</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="base-标签-基本的"><a href="#base-标签-基本的" class="headerlink" title="base 标签   基本的"></a>base 标签   基本的</h3><p>base 可以设置整体链接的打开状态   </p><p>base 写到  <head>  </head>  之间   </p><p>把所有的连接 都默认添加 target=”_blank”</p><p> <img src="media/base.png"></p><h2 id="课堂一练-2"><a href="#课堂一练-2" class="headerlink" title="课堂一练"></a>课堂一练</h2><p> 1在HTML中，关于a标签说法不正确的是（）</p><p>(A) a标签可以通过href属性跳转到另外一个页面</p><p>(B) a标签可以通过targer属性设置在是否在新窗口中打开</p><p>(C) a标签只能在当前页面设置锚点链接，让用户能够快速定位到目标内</p><p>(D) a标签可以通过href=”#”设置一个空链接</p><p>2如果想跳转到当前页面里名为show的锚点，下列写法是正确的</p><p>A  &lt; a href=”.show”&gt;跳转&lt;/a&gt;</p><p>B &lt; a href=”#show”&gt;跳转&lt;/a&gt;</p><p>C &lt; a href=” show”&gt;跳转&lt;/a&gt;</p><p>D &lt; a src=” #show”&gt;跳转&lt;/a&gt;</p><p>3如果想跳转到同目录下的名为success.html文件里名为show的锚点，下列写法是正确的</p><p>(A) &lt; a href=”success.html#show”&gt;跳转&lt;/a&gt;</p><p>(B)  &lt; a href=”#show”&gt;跳转&lt;/a&gt; </p><p>(C)  &lt; a href=”success#show”&gt;跳转&lt;/a&gt;<br>(D) &lt; a src=”success.html#show”&gt;跳转&lt;/a&gt;</p><h2 id="特殊字符标签-（理解）"><a href="#特殊字符标签-（理解）" class="headerlink" title="特殊字符标签 （理解）"></a>特殊字符标签 （理解）</h2><p> <img src="media/zifu.png"></p><h2 id="注释标签"><a href="#注释标签" class="headerlink" title="注释标签"></a>注释标签</h2><p>在HTML中还有一种特殊的标签——注释标签。如果需要在HTML文档中添加一些便于阅读和理解但又不需要显示在页面中的注释文字，就需要使用注释标签。其基本语法格式如下：<br>​        </p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 注释语句 --&gt;</span>   ctrl + /       或者 ctrl +shift + /</span><br></pre></td></tr></table></figure><p>注释内容不会显示在浏览器窗口中，但是作为HTML文档内容的一部分，也会被下载到用户的计算机上，查看源代码时就可以看到。</p><p>注释重要性：</p><p><img src="media/zs.png"></p><h1 id="路径-重点、难点"><a href="#路径-重点、难点" class="headerlink" title="路径(重点、难点)"></a>路径(重点、难点)</h1><p><img src="media/dt.png" width="400"></p><p><img src="media/lj.png"></p><p>实际工作中，通常新建一个文件夹专门用于存放图像文件，这时再插入图像，就需要采用“路径”的方式来指定图像文件的位置。</p><p>根目录  当前目录 </p><p>路径可以分为： 相对路径和绝对路径</p><h2 id="相对路径"><a href="#相对路径" class="headerlink" title="相对路径"></a>相对路径</h2><p>以引用文件之网页所在位置为参考基础，而建立出的目录路径。因此，当保存于不同目录的网页引用同一个文件时，所使用的路径将不相同，故称之为相对路径。</p><ol><li>图像文件和HTML文件位于同一文件夹：只需输入图像文件的名称即可，如&lt;img src=”logo.gif” /&gt;。</li><li>图像文件位于HTML文件的下一级文件夹：输入文件夹名和文件名，之间用“/”隔开，如&lt;img src=”img/img01/logo.gif” /&gt;。</li><li>图像文件位于HTML文件的上一级文件夹：在文件名之前加入“../” ，如果是上两级，则需要使用 “../ ../”，以此类推，如&lt;img src=”../logo.gif” /&gt;。</li></ol><h2 id="绝对路径"><a href="#绝对路径" class="headerlink" title="绝对路径"></a>绝对路径</h2><p>绝对路径以Web站点根目录为参考基础的目录路径。之所以称为绝对，意指当所有网页引用同一个文件时，所使用的路径都是一样的</p><p>“D:\web\img\logo.gif”，或完整的网络地址，例如“<a href="http://www.itcast.cn/images/logo.gif”。" target="_blank" rel="noopener">http://www.itcast.cn/images/logo.gif”。</a></p><h2 id="课堂一练-3"><a href="#课堂一练-3" class="headerlink" title="课堂一练"></a>课堂一练</h2><p>1.<strong>在下面结构中，哪种写法可以在index页面中有输出img.gif</strong></p><p><img src="media/1512226080266.png" alt="1512226080266"></p><p>(A) <img src="”../image/img.gif”">         </p><p>(B) <img src="”image/img.gif”"> </p><p>(C) <img src="”image../img.gif”">    </p><p>(D) <img src="”img.gif/image”"></p><p><strong>2在下面结构中，哪种写法可以在index页面中有输出1.jpg</strong></p><p><img src="media/1512226099480.png" alt="1512226099480"></p><p>(A) <img src="”../1/2/1.jpg”">        </p><p>(B) <img src="”/1/2/1.jpg”"></p><p>(C) <img src="”1/2/1.jpg”">    </p><p>(D) <img src="”1.jpg”"></p><p>3在下面结构中哪种写法可以在index页面中有输出img.gif</p><p><img src="media/1512226121609.png" alt="1512226121609"></p><p>(A) <img src="”demo/image/img.gif”">     </p><p>(B) <img src="”image/img.gif”"> </p><p>(C) <img src="”image../img.gif”">    </p><p>(D) <img src="”img.gif/image/demo”"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>  每一天都有一个主题 我们HTML第一天的主题就是 &lt;认识标签&gt;</p><p>学HTML 之前 觉得 很神秘  </p><p><img src="media/z.png"></p><p>等你学完之后忽然发现</p><p><img src="media/rh.jpg" width="615"></p><p>总结今天的思路贯穿线：</p><p><img src="media/a.png" width="1000"></p><h1 id="列表标签"><a href="#列表标签" class="headerlink" title="列表标签"></a>列表标签</h1><p>什么是列表？</p><p><img src="media/list.png"></p><p>把…制成表,以表显示</p><p>容器里面装载着文字或图表的一种形式，叫列表。</p><p>列表最大的特点就是  整齐 、整洁、 有序</p><h2 id="无序列表-ul-（重点）"><a href="#无序列表-ul-（重点）" class="headerlink" title="无序列表 ul （重点）"></a>无序列表 ul （重点）</h2><p>无序列表的各个列表项之间没有顺序级别之分，是并列的。其基本语法格式如下：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">ul</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span>&gt;</span>列表项1<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span>&gt;</span>列表项2<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span>&gt;</span>列表项3<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">  ......</span><br><span class="line"><span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br></pre></td></tr></table></figure><p>比如下面这些，新闻是没有顺序的，不用排队，先到先得，后发布先显示。</p><p><img src="media/ul.png"></p><p>脚下留心：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. &lt;ul&gt;&lt;/ul&gt;中只能嵌套&lt;li&gt;&lt;/li&gt;，直接在&lt;ul&gt;&lt;/ul&gt;标签中输入其他标签或者文字的做法是不被允许的。</span><br><span class="line">2. &lt;li&gt;与&lt;/li&gt;之间相当于一个容器，可以容纳所有元素。</span><br><span class="line">3. 无序列表会带有自己样式属性，放下那个样式，一会让CSS来！</span><br></pre></td></tr></table></figure><h2 id="有序列表-ol-（了解）"><a href="#有序列表-ol-（了解）" class="headerlink" title="有序列表 ol （了解）"></a>有序列表 ol （了解）</h2><p><img src="media/gold.png"></p><p>有序列表即为有排列顺序的列表，其各个列表项按照一定的顺序排列定义，有序列表的基本语法格式如下：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">ol</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span>&gt;</span>列表项1<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span>&gt;</span>列表项2<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span>&gt;</span>列表项3<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">  ......</span><br><span class="line"><span class="tag">&lt;/<span class="name">ol</span>&gt;</span></span><br></pre></td></tr></table></figure><p>  所有特性基本与ul 一致。  </p><p>  但是实际工作中， 较少用 ol img src=”media/1.jpg” /&gt;</p><h2 id="自定义列表（理解）"><a href="#自定义列表（理解）" class="headerlink" title="自定义列表（理解）"></a>自定义列表（理解）</h2><p>定义列表常用于对术语或名词进行解释和描述，定义列表的列表项前没有任何项目符号。其基本语法如下：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dl</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">dt</span>&gt;</span>名词1<span class="tag">&lt;/<span class="name">dt</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">dd</span>&gt;</span>名词1解释1<span class="tag">&lt;/<span class="name">dd</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">dd</span>&gt;</span>名词1解释2<span class="tag">&lt;/<span class="name">dd</span>&gt;</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="tag">&lt;<span class="name">dt</span>&gt;</span>名词2<span class="tag">&lt;/<span class="name">dt</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">dd</span>&gt;</span>名词2解释1<span class="tag">&lt;/<span class="name">dd</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">dd</span>&gt;</span>名词2解释2<span class="tag">&lt;/<span class="name">dd</span>&gt;</span></span><br><span class="line">  ...</span><br><span class="line"><span class="tag">&lt;/<span class="name">dl</span>&gt;</span></span><br></pre></td></tr></table></figure><p> <img src="media/2.jpg"> </p><p>用的还可以：</p><p><img src="media/mix.png"></p><h1 id="表格-table-会使用"><a href="#表格-table-会使用" class="headerlink" title="表格 table(会使用)"></a>表格 table(会使用)</h1><p><img src="http://zcr4.ncfstatic.com/attachment/201403/27/10/5333888008f05_thumb_670x0.jpg" alt="img"></p><p>存在即是合理的。  表格的现在还是较为常用的一种标签，但不是用来布局，常见处理、显示表格式数据。</p><p><img src="media/table.png"></p><p>ps:  这些地方用表格，你会觉得生活还是那么美好。。。。忍不住想说  PPAP i hava a pen  </p><h2 id="创建表格"><a href="#创建表格" class="headerlink" title="创建表格"></a>创建表格</h2><p>在HTML网页中，要想创建表格，就需要使用表格相关的标签。创建表格的基本语法格式如下：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">table</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">tr</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">td</span>&gt;</span>单元格内的文字<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    ...</span><br><span class="line">  <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br><span class="line">  ...</span><br><span class="line"><span class="tag">&lt;/<span class="name">table</span>&gt;</span></span><br></pre></td></tr></table></figure><p>在上面的语法中包含三对HTML标签，分别为 &lt;table&gt;&lt;/table&gt;、&lt;tr&gt;&lt;/tr&gt;、&lt;td&gt;&lt;/td&gt;，他们是创建表格的基本标签，缺一不可，下面对他们进行具体地解释</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.table用于定义一个表格。</span><br><span class="line"></span><br><span class="line">2.tr 用于定义表格中的一行，必须嵌套在 table标签中，在 table中包含几对 tr，就有几行表格。</span><br><span class="line"></span><br><span class="line">3.td /td：用于定义表格中的单元格，必须嵌套在&lt;tr&gt;&lt;/tr&gt;标签中，一对 &lt;tr&gt; &lt;/tr&gt;中包含几对&lt;td&gt;&lt;/td&gt;，就表示该行中有多少列（或多少个单元格）。</span><br></pre></td></tr></table></figure><p>注意：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1. &lt;tr&gt;&lt;/tr&gt;中只能嵌套&lt;td&gt;&lt;/td&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2. &lt;td&gt;&lt;/td&gt;标签，他就像一个容器，可以容纳所有的元素</span><br></pre></td></tr></table></figure><h2 id="表格属性"><a href="#表格属性" class="headerlink" title="表格属性"></a>表格属性</h2><p><img src="media/tt.png"></p><h2 id="表头标签"><a href="#表头标签" class="headerlink" title="表头标签"></a>表头标签</h2><p>表头一般位于表格的第一行或第一列，其文本加粗居中，如下图所示，即为设置了表头的表格。设置表头非常简单，只需用表头标签&lt;th&gt;&lt;/th&gt;替代相应的单元格标签&lt;td&gt;&lt;/td&gt;即可。</p><p> <img src="media/th.png"></p><h2 id="表格结构（了解）"><a href="#表格结构（了解）" class="headerlink" title="表格结构（了解）"></a>表格结构（了解）</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">在使用表格进行布局时，可以将表格划分为头部、主体和页脚（页脚因为有兼容性问题，我们不在赘述），具体 如下所示：</span><br><span class="line"></span><br><span class="line">&lt;thead&gt;&lt;/thead&gt;：用于定义表格的头部。</span><br><span class="line"></span><br><span class="line">必须位于&lt;table&gt;&lt;/table&gt; 标签中，一般包含网页的logo和导航等头部信息。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;tbody&gt;&lt;/tbody&gt;：用于定义表格的主体。</span><br><span class="line"></span><br><span class="line">位于&lt;table&gt;&lt;/table&gt;标签中，一般包含网页中除头部和底部之外的其他内容。</span><br></pre></td></tr></table></figure><p><img src="media/thead.png"></p><h2 id="表格标题"><a href="#表格标题" class="headerlink" title="表格标题"></a>表格标题</h2><p><strong>表格的标题： caption</strong></p><p><strong>定义和用法</strong></p><p>caption 元素定义表格标题。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">table</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">caption</span>&gt;</span>我是表格标题<span class="tag">&lt;/<span class="name">caption</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">table</span>&gt;</span></span><br></pre></td></tr></table></figure><p>caption 标签必须紧随 table 标签之后。您只能对每个表格定义一个标题。通常这个标题会被居中于表格之上。</p><h2 id="合并单元格-难点"><a href="#合并单元格-难点" class="headerlink" title="合并单元格(难点)"></a>合并单元格(难点)</h2><p>跨行合并：rowspan    跨列合并：colspan</p><p>合并单元格的思想：</p><p>​     将多个内容合并的时候，就会有多余的东西，把它删除。    例如 把 3个 td 合并成一个， 那就多余了2个，需要删除。</p><p>​     公式：  删除的个数  =  合并的个数  - 1   </p><p>   合并的顺序 先上   先左 </p><h2 id="总结表格"><a href="#总结表格" class="headerlink" title="总结表格"></a>总结表格</h2><ol><li><p>表格提供了HTML 中定义表格式数据的方法。</p></li><li><p>表格中由行中的单元格组成。</p></li><li><p>表格中没有列元素，列的个数取决于行的单元格个数。</p></li><li><p>表格不要纠结于外观，那是CSS 的作用。</p><p>​</p><p><strong>表格的学习要求：  能手写表格结构，并且能合并单元格。</strong></p></li></ol><h1 id="表单标签-掌握"><a href="#表单标签-掌握" class="headerlink" title="表单标签(掌握)"></a>表单标签(掌握)</h1><p>现实中的表单，类似我们去银行办理信用卡填写的单子。 如下图</p><p><img src="media/car.jpg" width="500"></p><p>目的是为了收集用户信息。</p><p>在我们网页中， 我们也需要跟用户进行交互，收集用户资料，此时也需要表单。</p><p>在HTML中，一个完整的表单通常由表单控件（也称为表单元素）、提示信息和表单域3个部分构成。</p><p><img src="media/bd.png"></p><p>  表单控件：</p><p>​       包含了具体的表单功能项，如单行文本输入框、密码输入框、复选框、提交按钮、重置按钮等。</p><p>  提示信息：</p><p>​        一个表单中通常还需要包含一些说明性的文字，提示用户进行填写和操作。</p><p>  表单域：  </p><p>​      他相当于一个容器，用来容纳所有的表单控件和提示信息，可以通过他定义处理表单数据所用程序的url地址，以及数据提交到服务器的方法。如果不定义表单域，表单中的数据就无法传送到后台服务器。</p><h2 id="input-控件-重点"><a href="#input-控件-重点" class="headerlink" title="input 控件(重点)"></a>input 控件(重点)</h2><p>在上面的语法中，&lt;input /&gt;标签为单标签，type属性为其最基本的属性，其取值有多种，用于指定不同的控件类型。除了type属性之外，&lt;input /&gt;标签还可以定义很多其他的属性，其常用属性如下表所示。</p><p><img src="media/input.png"></p><h2 id="label标签-理解"><a href="#label标签-理解" class="headerlink" title="label标签(理解)"></a>label标签(理解)</h2><p>label 标签为 input 元素定义标注（标签）。</p><p>作用：  用于绑定一个表单元素, 当点击label标签的时候, 被绑定的表单元素就会获得输入焦点</p><p>如何绑定元素呢？</p><p>for 属性规定 label 与哪个表单元素绑定。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">"male"</span>&gt;</span>Male<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"radio"</span> <span class="attr">name</span>=<span class="string">"sex"</span> <span class="attr">id</span>=<span class="string">"male"</span> <span class="attr">value</span>=<span class="string">"male"</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="textarea控件-文本域"><a href="#textarea控件-文本域" class="headerlink" title="textarea控件(文本域)"></a>textarea控件(文本域)</h2><p>如果需要输入大量的信息，就需要用到&lt;textarea&gt;&lt;/textarea&gt;标签。通过textarea控件可以轻松地创建多行文本输入框，其基本语法格式如下：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">textarea</span> <span class="attr">cols</span>=<span class="string">"每行中的字符数"</span> <span class="attr">rows</span>=<span class="string">"显示的行数"</span>&gt;</span></span><br><span class="line">  文本内容</span><br><span class="line"><span class="tag">&lt;/<span class="name">textarea</span>&gt;</span></span><br></pre></td></tr></table></figure><p><img src="media/textarea.png"></p><h2 id="下拉菜单"><a href="#下拉菜单" class="headerlink" title="下拉菜单"></a>下拉菜单</h2><p>使用select控件定义下拉菜单的基本语法格式如下</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">select</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">option</span>&gt;</span>选项1<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">option</span>&gt;</span>选项2<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">option</span>&gt;</span>选项3<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">  ...</span><br><span class="line"><span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br></pre></td></tr></table></figure><p>注意：</p><ol><li>&lt;select&gt;&lt;/select&gt;中至少应包含一对&lt;option&gt;&lt;/option&gt;。</li><li>在option 中定义selected =” selected “时，当前项即为默认选中项。</li></ol><h2 id="表单域"><a href="#表单域" class="headerlink" title="表单域"></a>表单域</h2><p>在HTML中，form标签被用于定义表单域，即创建一个表单，以实现用户信息的收集和传递，form中的所有内容都会被提交给服务器。创建表单的基本语法格式如下：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">"url地址"</span> <span class="attr">method</span>=<span class="string">"提交方式"</span> <span class="attr">name</span>=<span class="string">"表单名称"</span>&gt;</span></span><br><span class="line">  各种表单控件</span><br><span class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br></pre></td></tr></table></figure><p>常用属性：</p><ol><li>Action<br>在表单收集到信息后，需要将信息传递给服务器进行处理，action属性用于指定接收并处理表单数据的服务器程序的url地址。</li><li>method<br>用于设置表单数据的提交方式，其取值为get或post。</li><li>name<br>用于指定表单的名称，以区分同一个页面中的多个表单。</li></ol><p>注意：  每个表单都应该有自己表单域。</p><h1 id="查文档"><a href="#查文档" class="headerlink" title="查文档"></a>查文档</h1><p>经常查阅文档是一个非常好的学习习惯。</p><p>W3C :  <a href="http://www.w3school.com.cn/" target="_blank" rel="noopener">http://www.w3school.com.cn/</a></p><p>MDN: <a href="https://developer.mozilla.org/zh-CN/" target="_blank" rel="noopener">https://developer.mozilla.org/zh-CN/</a></p></h6></h5></h4></h3></h2></h1></h6></h5></h4></h3></h2></h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;hr&gt;
&lt;p&gt; 学习目标:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;了解常用浏览器&lt;/li&gt;
&lt;li&gt;掌握WEB标准&lt;/li&gt;
&lt;li&gt;理解标签语义化&lt;/li&gt;
&lt;li&gt;掌握常用的排版标签&lt;/li&gt;
&lt;li&gt;掌握常用的文本格式化图像链接等标签&lt;/li&gt;
&lt;li&gt;掌握三种列表标签&lt;/li&gt;
&lt;
      
    
    </summary>
    
      <category term="html" scheme="http://yoururl.com/categories/html/"/>
    
    
      <category term="html" scheme="http://yoururl.com/tags/html/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow 基础（八）： 神经网络优化</title>
    <link href="http://yoururl.com/2018/05/01/Tensorflow%20%E5%9F%BA%E7%A1%80%EF%BC%88%E5%85%AB%EF%BC%89%EF%BC%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/"/>
    <id>http://yoururl.com/2018/05/01/Tensorflow 基础（八）：神经网络优化/</id>
    <published>2018-04-30T16:00:00.000Z</published>
    <updated>2018-05-01T08:07:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="神经网络优化"><a href="#神经网络优化" class="headerlink" title="神经网络优化"></a>神经网络优化</h1><ul><li>学习率设置  </li><li>过拟合问题  </li><li>滑动平均模型</li></ul><h2 id="学习率设置"><a href="#学习率设置" class="headerlink" title="学习率设置"></a>学习率设置</h2><p>在梯度下降算法中，对于参数 $\theta$，其梯度为 $\frac{\partial}{\partial \theta}J(\theta)$ 。还需要定义一个学习率 $\eta$ (learning rate)来定义每次参数更新的幅度。通过参数的梯度和学习率，参数更新公式为：  </p><script type="math/tex; mode=display">\theta _{n+1} =\theta _n - \eta \frac{\partial}{\partial \theta _n} J(\theta _n)</script><p>如果学习率过大，可能会导致参数在极优值两侧来回移动；如果学习率过小，虽然能保证收敛性，但会大大降低优化速度。<br>为解决学习率的问题，Tensorflow 提供了一种更加灵活的学习率设置方法—-指数衰减法。通过这个函数可以使用较大的学习率快速得到一个较优的解，然后随着迭代的继续逐步减小学习率，使得模型在训练后期更加稳定。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tf.train.exponential_decay(</span><br><span class="line">    learning_rate,          <span class="comment"># 初始学习率</span></span><br><span class="line">    global_step,            <span class="comment"># </span></span><br><span class="line">    decay_steps,            <span class="comment"># 衰减速度， 完整使用一边训练数据所需要的迭代轮数，  decay_steps =  dataset_size / batch_size</span></span><br><span class="line">    decay_rate,             <span class="comment"># 衰减系数</span></span><br><span class="line">    staircase=<span class="keyword">False</span>,        <span class="comment"># True：阶梯衰减（global_step / decay_steps 为整数）； False：连续衰减</span></span><br><span class="line">    name=<span class="keyword">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 该函数会指数级的减小学习率，实现了以下代码功能</span></span><br><span class="line">decayed_learning_rate = learning_rate * decay_rate ^ (global_step / decay_steps)</span><br></pre></td></tr></table></figure><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-4-29/64880644.jpg" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">global_step = tf.Variable(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 生成学习率</span></span><br><span class="line">learning_rate = tf.train.exponential_decay(learning_rate=<span class="number">0.1</span>, global_step=global_step, decay_steps=<span class="number">100</span>, decay_rate=<span class="number">0.96</span>, staircase=<span class="keyword">True</span>)</span><br><span class="line"><span class="comment"># 使用指数衰减的学习率，在minimize函数中传入global_step将自动更新该参数，从而使得学习率得到相应更新</span></span><br><span class="line">learning_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(...my loss..., global_step=global_step)</span><br></pre></td></tr></table></figure><h2 id="过拟合问题"><a href="#过拟合问题" class="headerlink" title="过拟合问题"></a>过拟合问题</h2><p>过拟合指的是模型对于训练数据拟合程度过度的情况。</p><p>当某个模型过度的学习训练数据中的细节和噪音，以至于模型在新的数据上表现很差，我们称发生了<strong>过拟合</strong>。这意味着训练数据中的噪音或者随机波动也被当做概念被模型学习了,这会<strong>导致模型比较复杂</strong>。而问题就在于这些概念不适用于新的数据，从而导致模型<strong>泛化性能变差</strong>。  </p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-4-30/788202.jpg" alt="">  </p><p>为了防止过拟合，我们需要用到一些方法，如：early stopping、数据集扩增（Data augmentation）、正则化（Regularization）、Dropout等。</p><h3 id="Early-stopping"><a href="#Early-stopping" class="headerlink" title="Early stopping"></a>Early stopping</h3><p>对模型进行训练的过程即是对模型的参数进行学习更新的过程，这个参数学习的过程往往会用到一些迭代方法，如梯度下降（Gradient descent）学习算法。Early stopping便是一种<strong>迭代次数截断</strong>的方法来防止过拟合，即在模型对训练数据集迭代收敛之前停止迭代来防止过拟合。  </p><p>Early stopping方法的具体做法是：  </p><ul><li>在每一个Epoch结束时（一个Epoch集为对所有的训练数据的一轮遍历）计算验证集的 accuracy，    </li><li>在训练的过程中，记录到目前为止最好的 validation accuracy，当连续10次 Epoch（或者更多次）没达到最佳 accuracy 时，则可以认为 accuracy 不再提高了。此时便可以停止迭代了（Early Stopping）。<br>这种策略也称为“No-improvement-in-n”， n 即 Epoch 的次数，可以根据实际情况取，如10、20、30……  </li></ul><h3 id="数据集扩增（Data-augmentation）"><a href="#数据集扩增（Data-augmentation）" class="headerlink" title="数据集扩增（Data augmentation）"></a>数据集扩增（Data augmentation）</h3><p>在数据挖掘领域流行着这样的一句话，“有时候往往拥有更多的数据胜过一个好的模型”。因为我们在使用训练数据训练模型，通过这个模型对将来的数据进行拟合，前提是，<strong>训练数据与测试数据是独立同分布的</strong>。更多的数据往往使估计与模拟更准确。<br>通俗得讲，数据集扩增即需要得到更多的符合要求的数据，即和已有的数据是独立同分布的，或者近似独立同分布的。一般有以下方法：  </p><ul><li>从数据源采集更多数据  </li><li>复制原有数据加噪声  </li><li>重采样  </li><li>根据当前数据集估计数据分布参数，使用该分布产生更多数据等</li></ul><h3 id="正则化-（regularization）"><a href="#正则化-（regularization）" class="headerlink" title="正则化 （regularization）"></a>正则化 （regularization）</h3><p>正则化的本质：<strong>约束（限制）要优化的参数</strong>。<br>正则化中我们将保留所有的特征变量，但是会减小特征变量的数量级（参数数值的大小 $\theta (j)$ ）。</p><p>这个方法非常有效，当我们有很多特征变量时，其中每一个变量都能对预测产生一点影响。正如我们在房价预测的例子中看到的那样，我们可以有很多特征变量，其中每一个变量都是有用的，因此我们不希望把它们删掉，这就导致了正则化概念的发生。</p><p><a href="https://jjzhou012.github.io/2017/08/20/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E6%AD%A3%E5%88%99%E5%8C%96/" target="_blank" rel="noopener">正则化</a>  </p><ul><li>L1正则化可以产生稀疏权值矩阵，即产生一个稀疏模型，可以用于特征选择。  </li><li>L2正则化可以防止模型过拟合（overfitting）；一定程度上，L1也可以防止过拟合。<br>实践中，可以将L1，L2正则化同时使用：  </li></ul><script type="math/tex; mode=display">R(w)=\sum_i \alpha \left|w_i \right|+(1-\alpha)w_i^2</script><p>Tensorflow 可以优化带正则化的损失函数。以下给出一个简单的带L2正则化的损失函数定义：    </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">w = tf.Variable(tf.random_normal([<span class="number">2</span>, <span class="number">1</span>], stddev=<span class="number">1</span>, seed=<span class="number">1</span>))</span><br><span class="line">y = tf.matmul(x, w)</span><br><span class="line"><span class="comment"># loss 由两部分组成，第一部分为均方误差损失函数，刻画了模型在训练数据上的表现；  </span></span><br><span class="line"><span class="comment"># 第二部分为正则化，防止模型过度模拟训练数据中的随机噪声</span></span><br><span class="line"><span class="comment"># lambda 为正则化项的权重，w为需要计算正则化损失的参数</span></span><br><span class="line">loss = tf.reduce_mean(tf.square(y_ - y)) + tf.contrib.layers.l2_regularizer(<span class="keyword">lambda</span>)(w)</span><br></pre></td></tr></table></figure><p>Tensorflow 提供了一些正则化函数：<br><img src="http://p5bxip6n0.bkt.clouddn.com/18-5-1/6239431.jpg" alt=""><br>以下是一些使用样例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">w = tf.constant([[<span class="number">1.0</span>, <span class="number">-2.0</span>], [<span class="number">-3.0</span>, <span class="number">4.0</span>]])  </span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># L1正则化，输出为（|1|+|-2|+|-3|+|4|）* 0.5=5</span></span><br><span class="line">    print(sess.run(tf.contrib.layers.l1_regularizer(<span class="number">0.5</span>)(w)))</span><br><span class="line">    <span class="comment"># L2正则化， 输出为（1^2 + (-2)^2 + (-3)^2 + 4^2）/ 2 * 0.5 = 7.5</span></span><br><span class="line">    <span class="comment"># Tensorflow 会将L2正则化损失值除以2使得求导得到的结果更加简洁</span></span><br><span class="line">    print(sess.run(tf.contrib.layers.l2_regularizer(<span class="number">0.5</span>)(w)))</span><br><span class="line">    <span class="comment"># L1,L2同时使用</span></span><br><span class="line">    print(sess.run(tf.contrib.layers.l1_l2_regularizer(<span class="number">0.5</span>, <span class="number">0.5</span>)(w)))</span><br></pre></td></tr></table></figure><pre><code>5.07.512.5</code></pre><p>在简单的神经网络中，这样的方式可以很好的计算带正则化的损失函数了。但当神经网络的参数增多之后，这样的方式可能导致损失函数loss的定义很长，可读性差且容易出错。更主要的是，当网络结构复杂之后定义网络结构的部分和计算损失函数的部分可能不在同一函数中，这样通过变量这样的方式计算损失函数就不方便了，为解决这个问题，可以使用 Tensorflow 中提供的集合（collection），它可以在一个计算图中保留一组实体。<br>下面代码给出了通过集合计算一个5层神经网络带L2正则化的损失函数的计算方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取一层神经网络边上的权重，并将这个权重的L2正则化损失加入名为‘losses’的集合中</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_weight</span><span class="params">(shape, lambda)</span>:</span></span><br><span class="line">    <span class="comment"># 生成一个变量</span></span><br><span class="line">    var = tf.Variable(tf.random_normal(shape), dtype=tf.float32)</span><br><span class="line">    <span class="comment"># add_to_collection函数将这个新生成变量的L2正则化损失项加入集合。</span></span><br><span class="line">    <span class="comment"># 这个函数的第一参数‘los''ses’是集合的名字，第二个参数是要加入集合的内容</span></span><br><span class="line">    tf.add_to_collection(<span class="string">'losses'</span>, tf.contrib.layers.l2_regularizer(<span class="keyword">lambda</span>)(var))</span><br><span class="line">    <span class="comment"># 返回生成的变量</span></span><br><span class="line">    <span class="keyword">return</span> var</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义输入输出</span></span><br><span class="line">x = tf.placeholder(dtype=tf.float32, shape=(<span class="keyword">None</span>, <span class="number">2</span>))</span><br><span class="line">y_ = tf.placeholder(dtype=tf.float32, shape=(<span class="keyword">None</span>, <span class="number">1</span>))</span><br><span class="line">batch_size = <span class="number">8</span></span><br><span class="line"><span class="comment"># 定义每一层网络的节点个数</span></span><br><span class="line">lay_dim = [<span class="number">2</span>, <span class="number">10</span>, <span class="number">10</span>, <span class="number">10</span>, <span class="number">1</span>]</span><br><span class="line"><span class="comment"># 神经网络层数</span></span><br><span class="line">n_layers = len(lay_dim)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个变量维护前向传播时最深层的节点，开始为输入层。</span></span><br><span class="line">cur_layer = x</span><br><span class="line"><span class="comment"># 当前层的节点个数, 开始为输入层</span></span><br><span class="line">in_dim = lay_dim[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过一个循环来生成5层全连接的神经网络结构</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, n_layers):</span><br><span class="line">    <span class="comment"># 下一层的节点个数</span></span><br><span class="line">    out_dim = lay_dim[i]</span><br><span class="line">    <span class="comment"># 生成当前层中的权重变量，并将这个变量的L2正则化损失加入计算图上的集合</span></span><br><span class="line">    w = get_weight(shape=[in_dim, out_dim], <span class="number">0.001</span>)</span><br><span class="line">    bias = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=[out_dim]))</span><br><span class="line">    <span class="comment"># 使用ReLU激活函数</span></span><br><span class="line">    cur_layer = tf.nn.relu(tf.matmul(cur_layer, w) + bias) </span><br><span class="line">    <span class="comment"># 进入下一层之前更新节点个数</span></span><br><span class="line">    in_dim = lay_dim[i]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在定义神经网络前向传播的同时已经将所有L2正则化损失加入了图上的集合  </span></span><br><span class="line"><span class="comment"># 这里只需要计算刻画模型在训练数据上表现的损失函数</span></span><br><span class="line">mse_loss = tf.reduce_mean(tf.square(y_ - cur_layer))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将均方误差损失函数加入损失集合</span></span><br><span class="line">tf.add_to_collection(<span class="string">'losses'</span>, mse_loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># get_collection 得到一个列表，这个列表是所有这个集合中的元素，在这个样例中，</span></span><br><span class="line"><span class="comment"># 这些元素就是损失函数的不同部分，将它们加起来就可以得到最终的损失函数</span></span><br><span class="line">loss = tf.add_n(tf.get_collection(<span class="string">'losses'</span>))</span><br></pre></td></tr></table></figure><p>通过以上代码可以看出，通过使用集合的方法在网络结构比较复杂的情况下可以使代码可读性更高。</p><h3 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h3><p>Dropout是指在模型训练时随机让网络某些隐含层节点的权重不工作，不工作的那些节点可以暂时认为不是网络结构的一部分，但是它的权重得保留下来（只是暂时不更新而已），因为下次样本输入时它可能又得工作了。<br>DNNs是以概率 $p$ 舍弃部分神经元，其它神经元以概率 $q=1-p$ 被保留，舍去的神经元的输出都被设置为零。<br><img src="http://p5bxip6n0.bkt.clouddn.com/18-5-1/96305551.jpg" alt=""><br>上图为Dropout的可视化表示，左边是应用Dropout之前的网络，右边是应用了Dropout的同一个网络。  </p><p>dropout函数实现：引用keras的dropout实现源码  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dropout</span><span class="params">(x, level)</span>:</span></span><br><span class="line">    <span class="comment"># level是概率值，必须在0~1之间  </span></span><br><span class="line">    <span class="keyword">if</span> level &lt; <span class="number">0</span> <span class="keyword">or</span> level &gt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">'Dropout level must be in interval [0, 1].'</span>)</span><br><span class="line">    retain_pron = <span class="number">1.</span> - level</span><br><span class="line">    <span class="comment"># 通过binomial函数，生成与x一样的维数向量。binomial函数就像抛硬币一样，我们可以把每个神经元当做抛硬币一样  </span></span><br><span class="line">    <span class="comment"># 硬币正面的概率为p，n表示每个神经元试验的次数  </span></span><br><span class="line">    <span class="comment"># 因为我们每个神经元只需要抛一次就可以了所以n=1，size参数是神经元数量。  </span></span><br><span class="line">    <span class="comment"># 生成一个0，1分布的向量，0表示神经元被屏蔽，也就是dropout</span></span><br><span class="line">    sample = np.random.binomial(n=<span class="number">1</span>, p=retain_pron, size=x.shape)</span><br><span class="line">    print(sample)</span><br><span class="line">    <span class="comment"># 输入屏蔽部分神经元</span></span><br><span class="line">    x *=sample</span><br><span class="line">    print(x)</span><br><span class="line">    <span class="comment"># dropout后进行scale</span></span><br><span class="line">    x /= retain_pron</span><br><span class="line">    print(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试dropout， 输入向量x，经过dropout的结果</span></span><br><span class="line">x = np.asarray([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>], dtype=np.float32)</span><br><span class="line">dropout(x, <span class="number">0.4</span>)</span><br></pre></td></tr></table></figure><pre><code>[0 1 0 1 1 1 1 0 1 1 0][0. 1. 0. 3. 4. 5. 6. 0. 8. 9. 0.][ 0.         1.6666666  0.         5.         6.6666665  8.333333 10.         0.        13.333333  14.999999   0.       ]array([ 0.       ,  1.6666666,  0.       ,  5.       ,  6.6666665,        8.333333 , 10.       ,  0.       , 13.333333 , 14.999999 ,        0.       ], dtype=float32)</code></pre><p>为什么要进行rescale？<br>这被称为inverted dropout。当模型使用了dropout layer，训练的时候只有占比为 $p$ 的隐藏层单元参与训练，那么在预测的时候，如果所有的隐藏层单元都需要参与进来，则得到的结果相比训练时平均要大 $p$ ，为了避免这种情况，就需要测试的时候将输出结果乘以 $\frac{1}{p}$ 使下一层的输入规模保持不变。而利用inverted dropout，我们可以在训练的时候直接将dropout后留下的权重扩大 $\frac{1}{p}$ 倍，这样就可以使结果的scale保持不变，而在预测的时候也不用做额外的操作了，更方便一些。</p><p>Tensorflow 中的 dropout：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">keep_prob = tf.placeholder(tf.float32)</span><br><span class="line">x = tf.Variable(tf.ones(shape=[<span class="number">10</span>], dtype=tf.float32))</span><br><span class="line">y = tf.nn.dropout(x, keep_prob=keep_prob)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init_op = tf.global_variables_initializer()</span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    </span><br><span class="line">    print(sess.run(y, feed_dict=&#123;keep_prob : <span class="number">0.4</span>&#125;))</span><br></pre></td></tr></table></figure><pre><code>[0.  2.5 2.5 0.  0.  2.5 0.  0.  2.5 0. ]</code></pre><h2 id="滑动平均模型"><a href="#滑动平均模型" class="headerlink" title="滑动平均模型"></a>滑动平均模型</h2><p>滑动平均模型，它可以使得模型在测试数据上更鲁棒，在使用随机梯度下降算法训练神经网络时，通过滑动平均模型可以在一定程度上提高最终模型在测试数据上的表现。其实滑动平均模型，主要是通过控制衰减率来控制参数更新前后之间的差距，从而达到减缓参数的变化值（如，参数更新前是5，更新后的值是4，通过滑动平均模型之后，参数的值会在4到5之间），如果参数更新前后的值保持不变，通过滑动平均模型之后，参数的值仍然保持不变。  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.train.ExponentialMovingAverage(</span><br><span class="line">    decay,                              <span class="comment"># 衰减率</span></span><br><span class="line">    num_updates=<span class="keyword">None</span>,                   <span class="comment"># 动态设置decay参数</span></span><br><span class="line">    zero_debias=<span class="keyword">False</span>, </span><br><span class="line">    name=<span class="string">'ExponentialMovingAverage'</span>)</span><br></pre></td></tr></table></figure><ul><li>为了使得模型在训练的初始阶段更新得更快，ExponentialMovingAverage 还提供了 num_updates 参数来动态设置 decay 的大小，设置 num_updates 参数后，每次使用的衰减率为：   <script type="math/tex; mode=display">decay= \min \left\{decay,\  \frac{1 + num\_updates}{10 + num\_updates} \right\}</script>在 num_step 还比较小的时候，min() 会取到右边比较小的部分，也就是有一个比较小的 decay，这个时候模型更新会很快，当 step 增大时，模型更新速度会逐渐降低。</li><li>该函数对每一个待更新的变量（variable）都会维护一个影子变量（shadow variable）。影子变量的初始值就是这个变量的初始值，每次运行变量更新时，影子变量的值会更新为：  <script type="math/tex; mode=display">shadow\_variable = decay * shadow\_variable + (1 - decay) * variable</script>从公式可以看出，decay 决定了模型更新速度，decay 越大，模型越趋于稳定。实际运用中，decay 一般会设置为十分接近 1 的常数（0.999或0.9999）。  </li></ul><p>通过一段代码解释 ExponentialMovingAverage 是如何被使用的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个变量用于计算滑动平均，变量初始值为0。因为所有需要计算滑动平均的变量必须是实数型，所以指定变量类型为tf.float32</span></span><br><span class="line">v1 = tf.Variable(<span class="number">0</span>, dtype=tf.float32)</span><br><span class="line"><span class="comment"># step 变量模拟神经网络迭代轮数，用于动态控制衰减率  ， 即 num_updates 参数</span></span><br><span class="line">step = tf.Variable(<span class="number">0</span>, trainable=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个滑动平均类。初始化时给定衰减率decay和控制衰减率的变量step。</span></span><br><span class="line">ema = tf.train.ExponentialMovingAverage(decay=<span class="number">0.99</span>, num_updates=step)</span><br><span class="line"><span class="comment"># 定义一个更新变量滑动平均的操作。这里定义一个列表，每次执行该操作，列表中的变量会被更新。  </span></span><br><span class="line">maintain_averages_op = ema.apply([v1])</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init_op = tf.global_variables_initializer()</span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 通过ema.average(v1)获取滑动平均之后变量的取值。</span></span><br><span class="line">    <span class="comment"># 初始化之后变量v1的值和v1的滑动平均都为0</span></span><br><span class="line">    print(<span class="string">'初始化变量和滑动平均值'</span>)</span><br><span class="line">    print(sess.run([v1, ema.average(v1)]))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 更新变量v1的值到5</span></span><br><span class="line">    sess.run(tf.assign(v1, <span class="number">5</span>))</span><br><span class="line">    <span class="comment"># 更新v1的滑动平均值。衰减率为 min&#123;0.99 + (1+step)/(10+step)=0.1&#125;=0.1</span></span><br><span class="line">    <span class="comment"># 所以v1的滑动平均会被更新为0.1*0+0.9*5 =4.5</span></span><br><span class="line">    sess.run(maintain_averages_op)</span><br><span class="line">    print(<span class="string">'更新变量v1=5，滑动平均值'</span>)</span><br><span class="line">    print(sess.run([v1, ema.average(v1)]))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 更新step的值为10000</span></span><br><span class="line">    sess.run(tf.assign(step, <span class="number">10000</span>))</span><br><span class="line">    <span class="comment"># 更新变量v1的值到10</span></span><br><span class="line">    sess.run(tf.assign(v1, <span class="number">10</span>))</span><br><span class="line">    <span class="comment"># 更新v1的滑动平均值。衰减率为 min&#123;0.99 + (1+step)/(10+step)=0.999&#125;=0.99</span></span><br><span class="line">    <span class="comment"># 所以v1的滑动平均会被更新为0.99*4.5+0.01*10 =4.555</span></span><br><span class="line">    sess.run(maintain_averages_op)</span><br><span class="line">    print(<span class="string">'更新v1=10,更新step=10000, 滑动平均值'</span>)</span><br><span class="line">    print(sess.run([v1, ema.average(v1)]))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 再次更新滑动平均值，得到新的滑动平均值 0.99*4.555+0.01*10=4.60945</span></span><br><span class="line">    sess.run(maintain_averages_op)</span><br><span class="line">    print(<span class="string">'再次更新'</span>)</span><br><span class="line">    print(sess.run([v1, ema.average(v1)]))</span><br></pre></td></tr></table></figure><pre><code>初始化变量和滑动平均值[0.0, 0.0]更新变量v1=5，滑动平均值[5.0, 4.5]更新v1=10,更新step=10000, 滑动平均值[10.0, 4.555]再次更新[10.0, 4.60945]</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;神经网络优化&quot;&gt;&lt;a href=&quot;#神经网络优化&quot; class=&quot;headerlink&quot; title=&quot;神经网络优化&quot;&gt;&lt;/a&gt;神经网络优化&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;学习率设置  &lt;/li&gt;
&lt;li&gt;过拟合问题  &lt;/li&gt;
&lt;li&gt;滑动平均模型&lt;/li&gt;
&lt;/
      
    
    </summary>
    
      <category term="Tensorflow" scheme="http://yoururl.com/categories/Tensorflow/"/>
    
    
      <category term="Tensorflow" scheme="http://yoururl.com/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>reveal.js</title>
    <link href="http://yoururl.com/2018/04/25/reveal.js/"/>
    <id>http://yoururl.com/2018/04/25/reveal.js/</id>
    <published>2018-04-24T16:00:00.000Z</published>
    <updated>2018-04-25T17:20:27.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="reveal-js"><a href="#reveal-js" class="headerlink" title="reveal.js  "></a>reveal.js <a href="https://travis-ci.org/hakimel/reveal.js" target="_blank" rel="noopener"><img src="https://travis-ci.org/hakimel/reveal.js.svg?branch=master" alt="Build Status"></a> <a href="https://slides.com?ref=github" target="_blank" rel="noopener"><img src="https://s3.amazonaws.com/static.slid.es/images/slides-github-banner-320x40.png?1" alt="Slides" width="160" height="20"></a></h1><p>A framework for easily creating beautiful presentations using HTML. <a href="http://revealjs.com/" target="_blank" rel="noopener">Check out the live demo</a>.</p><p>reveal.js comes with a broad range of features including <a href="https://github.com/hakimel/reveal.js#markup" target="_blank" rel="noopener">nested slides</a>, <a href="https://github.com/hakimel/reveal.js#markdown" target="_blank" rel="noopener">Markdown contents</a>, <a href="https://github.com/hakimel/reveal.js#pdf-export" target="_blank" rel="noopener">PDF export</a>, <a href="https://github.com/hakimel/reveal.js#speaker-notes" target="_blank" rel="noopener">speaker notes</a> and a <a href="https://github.com/hakimel/reveal.js#api" target="_blank" rel="noopener">JavaScript API</a>. There’s also a fully featured visual editor and platform for sharing reveal.js presentations at <a href="https://slides.com?ref=github" target="_blank" rel="noopener">slides.com</a>.</p><h2 id="Table-of-contents"><a href="#Table-of-contents" class="headerlink" title="Table of contents"></a>Table of contents</h2><ul><li><a href="#online-editor">Online Editor</a></li><li><a href="#instructions">Instructions</a><ul><li><a href="#markup">Markup</a></li><li><a href="#markdown">Markdown</a></li><li><a href="#element-attributes">Element Attributes</a></li><li><a href="#slide-attributes">Slide Attributes</a></li></ul></li><li><a href="#configuration">Configuration</a></li><li><a href="#presentation-size">Presentation Size</a></li><li><a href="#dependencies">Dependencies</a></li><li><a href="#ready-event">Ready Event</a></li><li><a href="#auto-sliding">Auto-sliding</a></li><li><a href="#keyboard-bindings">Keyboard Bindings</a></li><li><a href="#touch-navigation">Touch Navigation</a></li><li><a href="#lazy-loading">Lazy Loading</a></li><li><a href="#api">API</a><ul><li><a href="#slide-changed-event">Slide Changed Event</a></li><li><a href="#presentation-state">Presentation State</a></li><li><a href="#slide-states">Slide States</a></li><li><a href="#slide-backgrounds">Slide Backgrounds</a></li><li><a href="#parallax-background">Parallax Background</a></li><li><a href="#slide-transitions">Slide Transitions</a></li><li><a href="#internal-links">Internal links</a></li><li><a href="#fragments">Fragments</a></li><li><a href="#fragment-events">Fragment events</a></li><li><a href="#code-syntax-highlighting">Code syntax highlighting</a></li><li><a href="#slide-number">Slide number</a></li><li><a href="#overview-mode">Overview mode</a></li><li><a href="#fullscreen-mode">Fullscreen mode</a></li><li><a href="#embedded-media">Embedded media</a></li><li><a href="#stretching-elements">Stretching elements</a></li><li><a href="#postmessage-api">postMessage API</a></li></ul></li><li><a href="#pdf-export">PDF Export</a></li><li><a href="#theming">Theming</a></li><li><a href="#speaker-notes">Speaker Notes</a><ul><li><a href="#share-and-print-speaker-notes">Share and Print Speaker Notes</a></li><li><a href="#server-side-speaker-notes">Server Side Speaker Notes</a></li></ul></li><li><a href="#multiplexing">Multiplexing</a><ul><li><a href="#master-presentation">Master presentation</a></li><li><a href="#client-presentation">Client presentation</a></li><li><a href="#socketio-server">Socket.io server</a></li></ul></li><li><a href="#mathjax">MathJax</a></li><li><a href="#installation">Installation</a><ul><li><a href="#basic-setup">Basic setup</a></li><li><a href="#full-setup">Full setup</a></li><li><a href="#folder-structure">Folder Structure</a></li></ul></li><li><a href="#license">License</a></li></ul><h4 id="More-reading"><a href="#More-reading" class="headerlink" title="More reading"></a>More reading</h4><ul><li><a href="https://github.com/hakimel/reveal.js/releases" target="_blank" rel="noopener">Changelog</a>: Up-to-date version history.</li><li><a href="https://github.com/hakimel/reveal.js/wiki/Example-Presentations" target="_blank" rel="noopener">Examples</a>: Presentations created with reveal.js, add your own!</li><li><a href="https://github.com/hakimel/reveal.js/wiki/Browser-Support" target="_blank" rel="noopener">Browser Support</a>: Explanation of browser support and fallbacks.</li><li><a href="https://github.com/hakimel/reveal.js/wiki/Plugins,-Tools-and-Hardware" target="_blank" rel="noopener">Plugins</a>: A list of plugins that can be used to extend reveal.js.</li></ul><h2 id="Online-Editor"><a href="#Online-Editor" class="headerlink" title="Online Editor"></a>Online Editor</h2><p>Presentations are written using HTML or Markdown but there’s also an online editor for those of you who prefer a graphical interface. Give it a try at <a href="https://slides.com?ref=github" target="_blank" rel="noopener">https://slides.com</a>.</p><h2 id="Instructions"><a href="#Instructions" class="headerlink" title="Instructions"></a>Instructions</h2><h3 id="Markup"><a href="#Markup" class="headerlink" title="Markup"></a>Markup</h3><p>Here’s a barebones example of a fully working reveal.js presentation:<br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">"stylesheet"</span> <span class="attr">href</span>=<span class="string">"css/reveal.css"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">"stylesheet"</span> <span class="attr">href</span>=<span class="string">"css/theme/white.css"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"reveal"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"slides"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">section</span>&gt;</span>Slide 1<span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">section</span>&gt;</span>Slide 2<span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"js/reveal.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="undefined">Reveal.initialize();</span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>The presentation markup hierarchy needs to be <code>.reveal &gt; .slides &gt; section</code> where the <code>section</code> represents one slide and can be repeated indefinitely. If you place multiple <code>section</code> elements inside of another <code>section</code> they will be shown as vertical slides. The first of the vertical slides is the “root” of the others (at the top), and will be included in the horizontal sequence. For example:</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"reveal"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"slides"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">section</span>&gt;</span>Single Horizontal Slide<span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">section</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">section</span>&gt;</span>Vertical Slide 1<span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">section</span>&gt;</span>Vertical Slide 2<span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="Markdown"><a href="#Markdown" class="headerlink" title="Markdown"></a>Markdown</h3><p>It’s possible to write your slides using Markdown. To enable Markdown, add the <code>data-markdown</code> attribute to your <code>&lt;section&gt;</code> elements and wrap the contents in a <code>&lt;textarea data-template&gt;</code> like the example below. You’ll also need to add the <code>plugin/markdown/marked.js</code> and <code>plugin/markdown/markdown.js</code> scripts (in that order) to your HTML file.</p><p>This is based on <a href="https://gist.github.com/1343518" target="_blank" rel="noopener">data-markdown</a> from <a href="https://github.com/paulirish" target="_blank" rel="noopener">Paul Irish</a> modified to use <a href="https://github.com/chjj/marked" target="_blank" rel="noopener">marked</a> to support <a href="https://help.github.com/articles/github-flavored-markdown" target="_blank" rel="noopener">GitHub Flavored Markdown</a>. Sensitive to indentation (avoid mixing tabs and spaces) and line breaks (avoid consecutive breaks).</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">section</span> <span class="attr">data-markdown</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">textarea</span> <span class="attr">data-template</span>&gt;</span></span><br><span class="line">## Page title</span><br><span class="line"></span><br><span class="line">A paragraph with some text and a [link](http://hakim.se).</span><br><span class="line"><span class="tag">&lt;/<span class="name">textarea</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="External-Markdown"><a href="#External-Markdown" class="headerlink" title="External Markdown"></a>External Markdown</h4><p>You can write your content as a separate file and have reveal.js load it at runtime. Note the separator arguments which determine how slides are delimited in the external file: the <code>data-separator</code> attribute defines a regular expression for horizontal slides (defaults to <code>^\r?\n---\r?\n$</code>, a newline-bounded horizontal rule)  and <code>data-separator-vertical</code> defines vertical slides (disabled by default). The <code>data-separator-notes</code> attribute is a regular expression for specifying the beginning of the current slide’s speaker notes (defaults to <code>notes?:</code>). The <code>data-charset</code> attribute is optional and specifies which charset to use when loading the external file.</p><p>When used locally, this feature requires that reveal.js <a href="#full-setup">runs from a local web server</a>.  The following example customises all available options:</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">section</span> <span class="attr">data-markdown</span>=<span class="string">"example.md"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">data-separator</span>=<span class="string">"^\n\n\n"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">data-separator-vertical</span>=<span class="string">"^\n\n"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">data-separator-notes</span>=<span class="string">"^Note:"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">data-charset</span>=<span class="string">"iso-8859-15"</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">        Note that Windows uses `\r\n` instead of `\n` as its linefeed character.</span></span><br><span class="line"><span class="comment">        For a regex that supports all operating systems, use `\r?\n` instead of `\n`.</span></span><br><span class="line"><span class="comment">    --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="Element-Attributes"><a href="#Element-Attributes" class="headerlink" title="Element Attributes"></a>Element Attributes</h4><p>Special syntax (through HTML comments) is available for adding attributes to Markdown elements. This is useful for fragments, amongst other things.</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">section</span> <span class="attr">data-markdown</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/template"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="xml">- Item 1 <span class="comment">&lt;!-- .element: class="fragment" data-fragment-index="2" --&gt;</span></span></span><br><span class="line"><span class="xml">- Item 2 <span class="comment">&lt;!-- .element: class="fragment" data-fragment-index="1" --&gt;</span></span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="Slide-Attributes"><a href="#Slide-Attributes" class="headerlink" title="Slide Attributes"></a>Slide Attributes</h4><p>Special syntax (through HTML comments) is available for adding attributes to the slide <code>&lt;section&gt;</code> elements generated by your Markdown.</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">section</span> <span class="attr">data-markdown</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/template"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="xml"><span class="comment">&lt;!-- .slide: data-background="#ff0000" --&gt;</span></span></span><br><span class="line"><span class="undefined">Markdown content</span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="Configuring-marked"><a href="#Configuring-marked" class="headerlink" title="Configuring marked"></a>Configuring <em>marked</em></h4><p>We use <a href="https://github.com/chjj/marked" target="_blank" rel="noopener">marked</a> to parse Markdown. To customise marked’s rendering, you can pass in options when <a href="#configuration">configuring Reveal</a>:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Reveal.initialize(&#123;</span><br><span class="line"><span class="comment">// Options which are passed into marked</span></span><br><span class="line"><span class="comment">// See https://github.com/chjj/marked#options-1</span></span><br><span class="line">markdown: &#123;</span><br><span class="line">smartypants: <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h3 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h3><p>At the end of your page you need to initialize reveal by running the following code. Note that all configuration values are optional and will default to the values specified below.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line">Reveal.initialize(&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Display presentation control arrows</span></span><br><span class="line">controls: <span class="literal">true</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Help the user learn the controls by providing hints, for example by</span></span><br><span class="line"><span class="comment">// bouncing the down arrow when they first encounter a vertical slide</span></span><br><span class="line">controlsTutorial: <span class="literal">true</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Determines where controls appear, "edges" or "bottom-right"</span></span><br><span class="line">controlsLayout: <span class="string">'bottom-right'</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Visibility rule for backwards navigation arrows; "faded", "hidden"</span></span><br><span class="line"><span class="comment">// or "visible"</span></span><br><span class="line">controlsBackArrows: <span class="string">'faded'</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Display a presentation progress bar</span></span><br><span class="line">progress: <span class="literal">true</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Set default timing of 2 minutes per slide</span></span><br><span class="line">defaultTiming: <span class="number">120</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Display the page number of the current slide</span></span><br><span class="line">slideNumber: <span class="literal">false</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Push each slide change to the browser history</span></span><br><span class="line">history: <span class="literal">false</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Enable keyboard shortcuts for navigation</span></span><br><span class="line">keyboard: <span class="literal">true</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Enable the slide overview mode</span></span><br><span class="line">overview: <span class="literal">true</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Vertical centering of slides</span></span><br><span class="line">center: <span class="literal">true</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Enables touch navigation on devices with touch input</span></span><br><span class="line">touch: <span class="literal">true</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Loop the presentation</span></span><br><span class="line">loop: <span class="literal">false</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Change the presentation direction to be RTL</span></span><br><span class="line">rtl: <span class="literal">false</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Randomizes the order of slides each time the presentation loads</span></span><br><span class="line">shuffle: <span class="literal">false</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Turns fragments on and off globally</span></span><br><span class="line">fragments: <span class="literal">true</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Flags if the presentation is running in an embedded mode,</span></span><br><span class="line"><span class="comment">// i.e. contained within a limited portion of the screen</span></span><br><span class="line">embedded: <span class="literal">false</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Flags if we should show a help overlay when the questionmark</span></span><br><span class="line"><span class="comment">// key is pressed</span></span><br><span class="line">help: <span class="literal">true</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Flags if speaker notes should be visible to all viewers</span></span><br><span class="line">showNotes: <span class="literal">false</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Global override for autoplaying embedded media (video/audio/iframe)</span></span><br><span class="line"><span class="comment">// - null: Media will only autoplay if data-autoplay is present</span></span><br><span class="line"><span class="comment">// - true: All media will autoplay, regardless of individual setting</span></span><br><span class="line"><span class="comment">// - false: No media will autoplay, regardless of individual setting</span></span><br><span class="line">autoPlayMedia: <span class="literal">null</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Number of milliseconds between automatically proceeding to the</span></span><br><span class="line"><span class="comment">// next slide, disabled when set to 0, this value can be overwritten</span></span><br><span class="line"><span class="comment">// by using a data-autoslide attribute on your slides</span></span><br><span class="line">autoSlide: <span class="number">0</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Stop auto-sliding after user input</span></span><br><span class="line">autoSlideStoppable: <span class="literal">true</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Use this method for navigation when auto-sliding</span></span><br><span class="line">autoSlideMethod: Reveal.navigateNext,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Enable slide navigation via mouse wheel</span></span><br><span class="line">mouseWheel: <span class="literal">false</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Hides the address bar on mobile devices</span></span><br><span class="line">hideAddressBar: <span class="literal">true</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Opens links in an iframe preview overlay</span></span><br><span class="line"><span class="comment">// Add `data-preview-link` and `data-preview-link="false"` to customise each link</span></span><br><span class="line"><span class="comment">// individually</span></span><br><span class="line">previewLinks: <span class="literal">false</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Transition style</span></span><br><span class="line">transition: <span class="string">'slide'</span>, <span class="comment">// none/fade/slide/convex/concave/zoom</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Transition speed</span></span><br><span class="line">transitionSpeed: <span class="string">'default'</span>, <span class="comment">// default/fast/slow</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Transition style for full page slide backgrounds</span></span><br><span class="line">backgroundTransition: <span class="string">'fade'</span>, <span class="comment">// none/fade/slide/convex/concave/zoom</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Number of slides away from the current that are visible</span></span><br><span class="line">viewDistance: <span class="number">3</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Parallax background image</span></span><br><span class="line">parallaxBackgroundImage: <span class="string">''</span>, <span class="comment">// e.g. "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Parallax background size</span></span><br><span class="line">parallaxBackgroundSize: <span class="string">''</span>, <span class="comment">// CSS syntax, e.g. "2100px 900px"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Number of pixels to move the parallax background per slide</span></span><br><span class="line"><span class="comment">// - Calculated automatically unless specified</span></span><br><span class="line"><span class="comment">// - Set to 0 to disable movement along an axis</span></span><br><span class="line">parallaxBackgroundHorizontal: <span class="literal">null</span>,</span><br><span class="line">parallaxBackgroundVertical: <span class="literal">null</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// The display mode that will be used to show slides</span></span><br><span class="line">display: <span class="string">'block'</span></span><br><span class="line"></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>The configuration can be updated after initialization using the <code>configure</code> method:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Turn autoSlide off</span></span><br><span class="line">Reveal.configure(&#123; <span class="attr">autoSlide</span>: <span class="number">0</span> &#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Start auto-sliding every 5s</span></span><br><span class="line">Reveal.configure(&#123; <span class="attr">autoSlide</span>: <span class="number">5000</span> &#125;);</span><br></pre></td></tr></table></figure><h3 id="Presentation-Size"><a href="#Presentation-Size" class="headerlink" title="Presentation Size"></a>Presentation Size</h3><p>All presentations have a normal size, that is, the resolution at which they are authored. The framework will automatically scale presentations uniformly based on this size to ensure that everything fits on any given display or viewport.</p><p>See below for a list of configuration options related to sizing, including default values:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Reveal.initialize(&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// The "normal" size of the presentation, aspect ratio will be preserved</span></span><br><span class="line"><span class="comment">// when the presentation is scaled to fit different resolutions. Can be</span></span><br><span class="line"><span class="comment">// specified using percentage units.</span></span><br><span class="line">width: <span class="number">960</span>,</span><br><span class="line">height: <span class="number">700</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Factor of the display size that should remain empty around the content</span></span><br><span class="line">margin: <span class="number">0.1</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Bounds for smallest/largest possible scale to apply to content</span></span><br><span class="line">minScale: <span class="number">0.2</span>,</span><br><span class="line">maxScale: <span class="number">1.5</span></span><br><span class="line"></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>If you wish to disable this behavior and do your own scaling (e.g. using media queries), try these settings:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Reveal.initialize(&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">width: <span class="string">"100%"</span>,</span><br><span class="line">height: <span class="string">"100%"</span>,</span><br><span class="line">margin: <span class="number">0</span>,</span><br><span class="line">minScale: <span class="number">1</span>,</span><br><span class="line">maxScale: <span class="number">1</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h3 id="Dependencies"><a href="#Dependencies" class="headerlink" title="Dependencies"></a>Dependencies</h3><p>Reveal.js doesn’t <em>rely</em> on any third party scripts to work but a few optional libraries are included by default. These libraries are loaded as dependencies in the order they appear, for example:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Reveal.initialize(&#123;</span><br><span class="line">dependencies: [</span><br><span class="line"><span class="comment">// Cross-browser shim that fully implements classList - https://github.com/eligrey/classList.js/</span></span><br><span class="line">&#123; <span class="attr">src</span>: <span class="string">'lib/js/classList.js'</span>, <span class="attr">condition</span>: <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123; <span class="keyword">return</span> !<span class="built_in">document</span>.body.classList; &#125; &#125;,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Interpret Markdown in &lt;section&gt; elements</span></span><br><span class="line">&#123; <span class="attr">src</span>: <span class="string">'plugin/markdown/marked.js'</span>, <span class="attr">condition</span>: <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123; <span class="keyword">return</span> !!<span class="built_in">document</span>.querySelector( <span class="string">'[data-markdown]'</span> ); &#125; &#125;,</span><br><span class="line">&#123; <span class="attr">src</span>: <span class="string">'plugin/markdown/markdown.js'</span>, <span class="attr">condition</span>: <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123; <span class="keyword">return</span> !!<span class="built_in">document</span>.querySelector( <span class="string">'[data-markdown]'</span> ); &#125; &#125;,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Syntax highlight for &lt;code&gt; elements</span></span><br><span class="line">&#123; <span class="attr">src</span>: <span class="string">'plugin/highlight/highlight.js'</span>, <span class="attr">async</span>: <span class="literal">true</span>, <span class="attr">callback</span>: <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123; hljs.initHighlightingOnLoad(); &#125; &#125;,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Zoom in and out with Alt+click</span></span><br><span class="line">&#123; <span class="attr">src</span>: <span class="string">'plugin/zoom-js/zoom.js'</span>, <span class="attr">async</span>: <span class="literal">true</span> &#125;,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Speaker notes</span></span><br><span class="line">&#123; <span class="attr">src</span>: <span class="string">'plugin/notes/notes.js'</span>, <span class="attr">async</span>: <span class="literal">true</span> &#125;,</span><br><span class="line"></span><br><span class="line"><span class="comment">// MathJax</span></span><br><span class="line">&#123; <span class="attr">src</span>: <span class="string">'plugin/math/math.js'</span>, <span class="attr">async</span>: <span class="literal">true</span> &#125;</span><br><span class="line">]</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>You can add your own extensions using the same syntax. The following properties are available for each dependency object:</p><ul><li><strong>src</strong>: Path to the script to load</li><li><strong>async</strong>: [optional] Flags if the script should load after reveal.js has started, defaults to false</li><li><strong>callback</strong>: [optional] Function to execute when the script has loaded</li><li><strong>condition</strong>: [optional] Function which must return true for the script to be loaded</li></ul><p>To load these dependencies, reveal.js requires <a href="http://headjs.com/" target="_blank" rel="noopener">head.js</a> <em>(a script loading library)</em> to be loaded before reveal.js.</p><h3 id="Ready-Event"><a href="#Ready-Event" class="headerlink" title="Ready Event"></a>Ready Event</h3><p>A <code>ready</code> event is fired when reveal.js has loaded all non-async dependencies and is ready to start navigating. To check if reveal.js is already ‘ready’ you can call <code>Reveal.isReady()</code>.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Reveal.addEventListener( <span class="string">'ready'</span>, <span class="function"><span class="keyword">function</span>(<span class="params"> event </span>) </span>&#123;</span><br><span class="line"><span class="comment">// event.currentSlide, event.indexh, event.indexv</span></span><br><span class="line">&#125; );</span><br></pre></td></tr></table></figure><p>Note that we also add a <code>.ready</code> class to the <code>.reveal</code> element so that you can hook into this with CSS.</p><h3 id="Auto-sliding"><a href="#Auto-sliding" class="headerlink" title="Auto-sliding"></a>Auto-sliding</h3><p>Presentations can be configured to progress through slides automatically, without any user input. To enable this you will need to tell the framework how many milliseconds it should wait between slides:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Slide every five seconds</span></span><br><span class="line">Reveal.configure(&#123;</span><br><span class="line">  autoSlide: <span class="number">5000</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>When this is turned on a control element will appear that enables users to pause and resume auto-sliding. Alternatively, sliding can be paused or resumed by pressing »A« on the keyboard. Sliding is paused automatically as soon as the user starts navigating. You can disable these controls by specifying <code>autoSlideStoppable: false</code> in your reveal.js config.</p><p>You can also override the slide duration for individual slides and fragments by using the <code>data-autoslide</code> attribute:</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">section</span> <span class="attr">data-autoslide</span>=<span class="string">"2000"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span>&gt;</span>After 2 seconds the first fragment will be shown.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"fragment"</span> <span class="attr">data-autoslide</span>=<span class="string">"10000"</span>&gt;</span>After 10 seconds the next fragment will be shown.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"fragment"</span>&gt;</span>Now, the fragment is displayed for 2 seconds before the next slide is shown.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br></pre></td></tr></table></figure><p>To override the method used for navigation when auto-sliding, you can specify the <code>autoSlideMethod</code> setting. To only navigate along the top layer and ignore vertical slides, set this to <code>Reveal.navigateRight</code>.</p><p>Whenever the auto-slide mode is resumed or paused the <code>autoslideresumed</code> and <code>autoslidepaused</code> events are fired.</p><h3 id="Keyboard-Bindings"><a href="#Keyboard-Bindings" class="headerlink" title="Keyboard Bindings"></a>Keyboard Bindings</h3><p>If you’re unhappy with any of the default keyboard bindings you can override them using the <code>keyboard</code> config option:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Reveal.configure(&#123;</span><br><span class="line">  keyboard: &#123;</span><br><span class="line">    <span class="number">13</span>: <span class="string">'next'</span>, <span class="comment">// go to the next slide when the ENTER key is pressed</span></span><br><span class="line">    <span class="number">27</span>: <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;&#125;, <span class="comment">// do something custom when ESC is pressed</span></span><br><span class="line">    <span class="number">32</span>: <span class="literal">null</span> <span class="comment">// don't do anything when SPACE is pressed (i.e. disable a reveal.js default binding)</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h3 id="Touch-Navigation"><a href="#Touch-Navigation" class="headerlink" title="Touch Navigation"></a>Touch Navigation</h3><p>You can swipe to navigate through a presentation on any touch-enabled device. Horizontal swipes change between horizontal slides, vertical swipes change between vertical slides. If you wish to disable this you can set the <code>touch</code> config option to false when initializing reveal.js.</p><p>If there’s some part of your content that needs to remain accessible to touch events you’ll need to highlight this by adding a <code>data-prevent-swipe</code> attribute to the element. One common example where this is useful is elements that need to be scrolled.</p><h3 id="Lazy-Loading"><a href="#Lazy-Loading" class="headerlink" title="Lazy Loading"></a>Lazy Loading</h3><p>When working on presentation with a lot of media or iframe content it’s important to load lazily. Lazy loading means that reveal.js will only load content for the few slides nearest to the current slide. The number of slides that are preloaded is determined by the <code>viewDistance</code> configuration option.</p><p>To enable lazy loading all you need to do is change your <code>src</code> attributes to <code>data-src</code> as shown below. This is supported for image, video, audio and iframe elements. Lazy loaded iframes will also unload when the containing slide is no longer visible.</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">section</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">img</span> <span class="attr">data-src</span>=<span class="string">"image.png"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">iframe</span> <span class="attr">data-src</span>=<span class="string">"http://hakim.se"</span>&gt;</span><span class="tag">&lt;/<span class="name">iframe</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">video</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">source</span> <span class="attr">data-src</span>=<span class="string">"video.webm"</span> <span class="attr">type</span>=<span class="string">"video/webm"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">source</span> <span class="attr">data-src</span>=<span class="string">"video.mp4"</span> <span class="attr">type</span>=<span class="string">"video/mp4"</span> /&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">video</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><p>The <code>Reveal</code> object exposes a JavaScript API for controlling navigation and reading state:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Navigation</span></span><br><span class="line">Reveal.slide( indexh, indexv, indexf );</span><br><span class="line">Reveal.left();</span><br><span class="line">Reveal.right();</span><br><span class="line">Reveal.up();</span><br><span class="line">Reveal.down();</span><br><span class="line">Reveal.prev();</span><br><span class="line">Reveal.next();</span><br><span class="line">Reveal.prevFragment();</span><br><span class="line">Reveal.nextFragment();</span><br><span class="line"></span><br><span class="line"><span class="comment">// Randomize the order of slides</span></span><br><span class="line">Reveal.shuffle();</span><br><span class="line"></span><br><span class="line"><span class="comment">// Toggle presentation states, optionally pass true/false to force on/off</span></span><br><span class="line">Reveal.toggleOverview();</span><br><span class="line">Reveal.togglePause();</span><br><span class="line">Reveal.toggleAutoSlide();</span><br><span class="line"></span><br><span class="line"><span class="comment">// Shows a help overlay with keyboard shortcuts, optionally pass true/false</span></span><br><span class="line"><span class="comment">// to force on/off</span></span><br><span class="line">Reveal.toggleHelp();</span><br><span class="line"></span><br><span class="line"><span class="comment">// Change a config value at runtime</span></span><br><span class="line">Reveal.configure(&#123; <span class="attr">controls</span>: <span class="literal">true</span> &#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Returns the present configuration options</span></span><br><span class="line">Reveal.getConfig();</span><br><span class="line"></span><br><span class="line"><span class="comment">// Fetch the current scale of the presentation</span></span><br><span class="line">Reveal.getScale();</span><br><span class="line"></span><br><span class="line"><span class="comment">// Retrieves the previous and current slide elements</span></span><br><span class="line">Reveal.getPreviousSlide();</span><br><span class="line">Reveal.getCurrentSlide();</span><br><span class="line"></span><br><span class="line">Reveal.getIndices();        <span class="comment">// &#123; h: 0, v: 0, f: 0 &#125;</span></span><br><span class="line">Reveal.getSlidePastCount();</span><br><span class="line">Reveal.getProgress();       <span class="comment">// (0 == first slide, 1 == last slide)</span></span><br><span class="line">Reveal.getSlides();         <span class="comment">// Array of all slides</span></span><br><span class="line">Reveal.getTotalSlides();    <span class="comment">// Total number of slides</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Returns the speaker notes for the current slide</span></span><br><span class="line">Reveal.getSlideNotes();</span><br><span class="line"></span><br><span class="line"><span class="comment">// State checks</span></span><br><span class="line">Reveal.isFirstSlide();</span><br><span class="line">Reveal.isLastSlide();</span><br><span class="line">Reveal.isOverview();</span><br><span class="line">Reveal.isPaused();</span><br><span class="line">Reveal.isAutoSliding();</span><br></pre></td></tr></table></figure><h3 id="Slide-Changed-Event"><a href="#Slide-Changed-Event" class="headerlink" title="Slide Changed Event"></a>Slide Changed Event</h3><p>A <code>slidechanged</code> event is fired each time the slide is changed (regardless of state). The event object holds the index values of the current slide as well as a reference to the previous and current slide HTML nodes.</p><p>Some libraries, like MathJax (see <a href="https://github.com/hakimel/reveal.js/issues/226#issuecomment-10261609" target="_blank" rel="noopener">#226</a>), get confused by the transforms and display states of slides. Often times, this can be fixed by calling their update or render function from this callback.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Reveal.addEventListener( <span class="string">'slidechanged'</span>, <span class="function"><span class="keyword">function</span>(<span class="params"> event </span>) </span>&#123;</span><br><span class="line"><span class="comment">// event.previousSlide, event.currentSlide, event.indexh, event.indexv</span></span><br><span class="line">&#125; );</span><br></pre></td></tr></table></figure><h3 id="Presentation-State"><a href="#Presentation-State" class="headerlink" title="Presentation State"></a>Presentation State</h3><p>The presentation’s current state can be fetched by using the <code>getState</code> method. A state object contains all of the information required to put the presentation back as it was when <code>getState</code> was first called. Sort of like a snapshot. It’s a simple object that can easily be stringified and persisted or sent over the wire.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Reveal.slide( <span class="number">1</span> );</span><br><span class="line"><span class="comment">// we're on slide 1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> state = Reveal.getState();</span><br><span class="line"></span><br><span class="line">Reveal.slide( <span class="number">3</span> );</span><br><span class="line"><span class="comment">// we're on slide 3</span></span><br><span class="line"></span><br><span class="line">Reveal.setState( state );</span><br><span class="line"><span class="comment">// we're back on slide 1</span></span><br></pre></td></tr></table></figure><h3 id="Slide-States"><a href="#Slide-States" class="headerlink" title="Slide States"></a>Slide States</h3><p>If you set <code>data-state=&quot;somestate&quot;</code> on a slide <code>&lt;section&gt;</code>, “somestate” will be applied as a class on the document element when that slide is opened. This allows you to apply broad style changes to the page based on the active slide.</p><p>Furthermore you can also listen to these changes in state via JavaScript:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Reveal.addEventListener( <span class="string">'somestate'</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line"><span class="comment">// <span class="doctag">TODO:</span> Sprinkle magic</span></span><br><span class="line">&#125;, <span class="literal">false</span> );</span><br></pre></td></tr></table></figure><h3 id="Slide-Backgrounds"><a href="#Slide-Backgrounds" class="headerlink" title="Slide Backgrounds"></a>Slide Backgrounds</h3><p>Slides are contained within a limited portion of the screen by default to allow them to fit any display and scale uniformly. You can apply full page backgrounds outside of the slide area by adding a <code>data-background</code> attribute to your <code>&lt;section&gt;</code> elements. Four different types of backgrounds are supported: color, image, video and iframe.</p><h4 id="Color-Backgrounds"><a href="#Color-Backgrounds" class="headerlink" title="Color Backgrounds"></a>Color Backgrounds</h4><p>All CSS color formats are supported, including hex values, keywords, <code>rgba()</code> or <code>hsl()</code>.</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">section</span> <span class="attr">data-background-color</span>=<span class="string">"#ff0000"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h2</span>&gt;</span>Color<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="Image-Backgrounds"><a href="#Image-Backgrounds" class="headerlink" title="Image Backgrounds"></a>Image Backgrounds</h4><p>By default, background images are resized to cover the full page. Available options:</p><div class="table-container"><table><thead><tr><th style="text-align:left">Attribute</th><th style="text-align:left">Default</th><th style="text-align:left">Description</th></tr></thead><tbody><tr><td style="text-align:left">data-background-image</td><td style="text-align:left"></td><td style="text-align:left">URL of the image to show. GIFs restart when the slide opens.</td></tr><tr><td style="text-align:left">data-background-size</td><td style="text-align:left">cover</td><td style="text-align:left">See <a href="https://developer.mozilla.org/docs/Web/CSS/background-size" target="_blank" rel="noopener">background-size</a> on MDN.</td></tr><tr><td style="text-align:left">data-background-position</td><td style="text-align:left">center</td><td style="text-align:left">See <a href="https://developer.mozilla.org/docs/Web/CSS/background-position" target="_blank" rel="noopener">background-position</a> on MDN.</td></tr><tr><td style="text-align:left">data-background-repeat</td><td style="text-align:left">no-repeat</td><td style="text-align:left">See <a href="https://developer.mozilla.org/docs/Web/CSS/background-repeat" target="_blank" rel="noopener">background-repeat</a> on MDN.</td></tr></tbody></table></div><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">section</span> <span class="attr">data-background-image</span>=<span class="string">"http://example.com/image.png"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h2</span>&gt;</span>Image<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">section</span> <span class="attr">data-background-image</span>=<span class="string">"http://example.com/image.png"</span> <span class="attr">data-background-size</span>=<span class="string">"100px"</span> <span class="attr">data-background-repeat</span>=<span class="string">"repeat"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h2</span>&gt;</span>This background image will be sized to 100px and repeated<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="Video-Backgrounds"><a href="#Video-Backgrounds" class="headerlink" title="Video Backgrounds"></a>Video Backgrounds</h4><p>Automatically plays a full size video behind the slide.</p><div class="table-container"><table><thead><tr><th style="text-align:left">Attribute</th><th style="text-align:left">Default</th><th style="text-align:left">Description</th></tr></thead><tbody><tr><td style="text-align:left">data-background-video</td><td style="text-align:left"></td><td style="text-align:left">A single video source, or a comma separated list of video sources.</td></tr><tr><td style="text-align:left">data-background-video-loop</td><td style="text-align:left">false</td><td style="text-align:left">Flags if the video should play repeatedly.</td></tr><tr><td style="text-align:left">data-background-video-muted</td><td style="text-align:left">false</td><td style="text-align:left">Flags if the audio should be muted.</td></tr><tr><td style="text-align:left">data-background-size</td><td style="text-align:left">cover</td><td style="text-align:left">Use <code>cover</code> for full screen and some cropping or <code>contain</code> for letterboxing.</td></tr></tbody></table></div><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">section</span> <span class="attr">data-background-video</span>=<span class="string">"https://s3.amazonaws.com/static.slid.es/site/homepage/v1/homepage-video-editor.mp4,https://s3.amazonaws.com/static.slid.es/site/homepage/v1/homepage-video-editor.webm"</span> <span class="attr">data-background-video-loop</span> <span class="attr">data-background-video-muted</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h2</span>&gt;</span>Video<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="Iframe-Backgrounds"><a href="#Iframe-Backgrounds" class="headerlink" title="Iframe Backgrounds"></a>Iframe Backgrounds</h4><p>Embeds a web page as a slide background that covers 100% of the reveal.js width and height. The iframe is in the background layer, behind your slides, and as such it’s not possible to interact with it by default. To make your background interactive, you can add the <code>data-background-interactive</code> attribute.</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">section</span> <span class="attr">data-background-iframe</span>=<span class="string">"https://slides.com"</span> <span class="attr">data-background-interactive</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h2</span>&gt;</span>Iframe<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="Background-Transitions"><a href="#Background-Transitions" class="headerlink" title="Background Transitions"></a>Background Transitions</h4><p>Backgrounds transition using a fade animation by default. This can be changed to a linear sliding transition by passing <code>backgroundTransition: &#39;slide&#39;</code> to the <code>Reveal.initialize()</code> call. Alternatively you can set <code>data-background-transition</code> on any section with a background to override that specific transition.</p><h3 id="Parallax-Background"><a href="#Parallax-Background" class="headerlink" title="Parallax Background"></a>Parallax Background</h3><p>If you want to use a parallax scrolling background, set the first two properties below when initializing reveal.js (the other two are optional).</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Reveal.initialize(&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Parallax background image</span></span><br><span class="line">parallaxBackgroundImage: <span class="string">''</span>, <span class="comment">// e.g. "https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Parallax background size</span></span><br><span class="line">parallaxBackgroundSize: <span class="string">''</span>, <span class="comment">// CSS syntax, e.g. "2100px 900px" - currently only pixels are supported (don't use % or auto)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Number of pixels to move the parallax background per slide</span></span><br><span class="line"><span class="comment">// - Calculated automatically unless specified</span></span><br><span class="line"><span class="comment">// - Set to 0 to disable movement along an axis</span></span><br><span class="line">parallaxBackgroundHorizontal: <span class="number">200</span>,</span><br><span class="line">parallaxBackgroundVertical: <span class="number">50</span></span><br><span class="line"></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>Make sure that the background size is much bigger than screen size to allow for some scrolling. <a href="http://revealjs.com/?parallaxBackgroundImage=https%3A%2F%2Fs3.amazonaws.com%2Fhakim-static%2Freveal-js%2Freveal-parallax-1.jpg&amp;parallaxBackgroundSize=2100px%20900px" target="_blank" rel="noopener">View example</a>.</p><h3 id="Slide-Transitions"><a href="#Slide-Transitions" class="headerlink" title="Slide Transitions"></a>Slide Transitions</h3><p>The global presentation transition is set using the <code>transition</code> config value. You can override the global transition for a specific slide by using the <code>data-transition</code> attribute:</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">section</span> <span class="attr">data-transition</span>=<span class="string">"zoom"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h2</span>&gt;</span>This slide will override the presentation transition and zoom!<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">section</span> <span class="attr">data-transition-speed</span>=<span class="string">"fast"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h2</span>&gt;</span>Choose from three transition speeds: default, fast or slow!<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br></pre></td></tr></table></figure><p>You can also use different in and out transitions for the same slide:</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">section</span> <span class="attr">data-transition</span>=<span class="string">"slide"</span>&gt;</span></span><br><span class="line">    The train goes on …</span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">section</span> <span class="attr">data-transition</span>=<span class="string">"slide"</span>&gt;</span></span><br><span class="line">    and on …</span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">section</span> <span class="attr">data-transition</span>=<span class="string">"slide-in fade-out"</span>&gt;</span></span><br><span class="line">    and stops.</span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">section</span> <span class="attr">data-transition</span>=<span class="string">"fade-in slide-out"</span>&gt;</span></span><br><span class="line">    (Passengers entering and leaving)</span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">section</span> <span class="attr">data-transition</span>=<span class="string">"slide"</span>&gt;</span></span><br><span class="line">    And it starts again.</span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="Internal-links"><a href="#Internal-links" class="headerlink" title="Internal links"></a>Internal links</h3><p>It’s easy to link between slides. The first example below targets the index of another slide whereas the second targets a slide with an ID attribute (<code>&lt;section id=&quot;some-slide&quot;&gt;</code>):</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"#/2/2"</span>&gt;</span>Link<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"#/some-slide"</span>&gt;</span>Link<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure><p>You can also add relative navigation links, similar to the built in reveal.js controls, by appending one of the following classes on any element. Note that each element is automatically given an <code>enabled</code> class when it’s a valid navigation route based on the current slide.</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"#"</span> <span class="attr">class</span>=<span class="string">"navigate-left"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"#"</span> <span class="attr">class</span>=<span class="string">"navigate-right"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"#"</span> <span class="attr">class</span>=<span class="string">"navigate-up"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"#"</span> <span class="attr">class</span>=<span class="string">"navigate-down"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"#"</span> <span class="attr">class</span>=<span class="string">"navigate-prev"</span>&gt;</span> <span class="comment">&lt;!-- Previous vertical or horizontal slide --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"#"</span> <span class="attr">class</span>=<span class="string">"navigate-next"</span>&gt;</span> <span class="comment">&lt;!-- Next vertical or horizontal slide --&gt;</span></span><br></pre></td></tr></table></figure><h3 id="Fragments"><a href="#Fragments" class="headerlink" title="Fragments"></a>Fragments</h3><p>Fragments are used to highlight individual elements on a slide. Every element with the class <code>fragment</code> will be stepped through before moving on to the next slide. Here’s an example: <a href="http://revealjs.com/#/fragments" target="_blank" rel="noopener">http://revealjs.com/#/fragments</a></p><p>The default fragment style is to start out invisible and fade in. This style can be changed by appending a different class to the fragment:</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">section</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"fragment grow"</span>&gt;</span>grow<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"fragment shrink"</span>&gt;</span>shrink<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"fragment fade-out"</span>&gt;</span>fade-out<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"fragment fade-up"</span>&gt;</span>fade-up (also down, left and right!)<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"fragment current-visible"</span>&gt;</span>visible only once<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"fragment highlight-current-blue"</span>&gt;</span>blue only once<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"fragment highlight-red"</span>&gt;</span>highlight-red<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"fragment highlight-green"</span>&gt;</span>highlight-green<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"fragment highlight-blue"</span>&gt;</span>highlight-blue<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br></pre></td></tr></table></figure><p>Multiple fragments can be applied to the same element sequentially by wrapping it, this will fade in the text on the first step and fade it back out on the second.</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">section</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"fragment fade-in"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"fragment fade-out"</span>&gt;</span>I'll fade in, then out<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br></pre></td></tr></table></figure><p>The display order of fragments can be controlled using the <code>data-fragment-index</code> attribute.</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">section</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"fragment"</span> <span class="attr">data-fragment-index</span>=<span class="string">"3"</span>&gt;</span>Appears last<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"fragment"</span> <span class="attr">data-fragment-index</span>=<span class="string">"1"</span>&gt;</span>Appears first<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"fragment"</span> <span class="attr">data-fragment-index</span>=<span class="string">"2"</span>&gt;</span>Appears second<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="Fragment-events"><a href="#Fragment-events" class="headerlink" title="Fragment events"></a>Fragment events</h3><p>When a slide fragment is either shown or hidden reveal.js will dispatch an event.</p><p>Some libraries, like MathJax (see #505), get confused by the initially hidden fragment elements. Often times this can be fixed by calling their update or render function from this callback.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Reveal.addEventListener( <span class="string">'fragmentshown'</span>, <span class="function"><span class="keyword">function</span>(<span class="params"> event </span>) </span>&#123;</span><br><span class="line"><span class="comment">// event.fragment = the fragment DOM element</span></span><br><span class="line">&#125; );</span><br><span class="line">Reveal.addEventListener( <span class="string">'fragmenthidden'</span>, <span class="function"><span class="keyword">function</span>(<span class="params"> event </span>) </span>&#123;</span><br><span class="line"><span class="comment">// event.fragment = the fragment DOM element</span></span><br><span class="line">&#125; );</span><br></pre></td></tr></table></figure><h3 id="Code-syntax-highlighting"><a href="#Code-syntax-highlighting" class="headerlink" title="Code syntax highlighting"></a>Code syntax highlighting</h3><p>By default, Reveal is configured with <a href="https://highlightjs.org/" target="_blank" rel="noopener">highlight.js</a> for code syntax highlighting. To enable syntax highlighting, you’ll have to load the highlight plugin (<a href="plugin/highlight/highlight.js">plugin/highlight/highlight.js</a>) and a highlight.js CSS theme (Reveal comes packaged with the zenburn theme: <a href="lib/css/zenburn.css">lib/css/zenburn.css</a>).</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Reveal.initialize(&#123;</span><br><span class="line"><span class="comment">// More info https://github.com/hakimel/reveal.js#dependencies</span></span><br><span class="line">dependencies: [</span><br><span class="line">&#123; <span class="attr">src</span>: <span class="string">'plugin/highlight/highlight.js'</span>, <span class="attr">async</span>: <span class="literal">true</span>, <span class="attr">callback</span>: <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123; hljs.initHighlightingOnLoad(); &#125; &#125;,</span><br><span class="line">]</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>Below is an example with clojure code that will be syntax highlighted. When the <code>data-trim</code> attribute is present, surrounding whitespace is automatically removed.  HTML will be escaped by default. To avoid this, for example if you are using <code>&lt;mark&gt;</code> to call out a line of code, add the <code>data-noescape</code> attribute to the <code>&lt;code&gt;</code> element.</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">section</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">pre</span>&gt;</span><span class="tag">&lt;<span class="name">code</span> <span class="attr">data-trim</span> <span class="attr">data-noescape</span>&gt;</span></span><br><span class="line">(def lazy-fib</span><br><span class="line">  (concat</span><br><span class="line">   [0 1]</span><br><span class="line">   <span class="tag">&lt;<span class="name">mark</span>&gt;</span>((fn rfib [a b]<span class="tag">&lt;/<span class="name">mark</span>&gt;</span></span><br><span class="line">        (lazy-cons (+ a b) (rfib b (+ a b)))) 0 1)))</span><br><span class="line"><span class="tag">&lt;/<span class="name">code</span>&gt;</span><span class="tag">&lt;/<span class="name">pre</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="Slide-number"><a href="#Slide-number" class="headerlink" title="Slide number"></a>Slide number</h3><p>If you would like to display the page number of the current slide you can do so using the <code>slideNumber</code> and <code>showSlideNumber</code> configuration values.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Shows the slide number using default formatting</span></span><br><span class="line">Reveal.configure(&#123; <span class="attr">slideNumber</span>: <span class="literal">true</span> &#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Slide number formatting can be configured using these variables:</span></span><br><span class="line"><span class="comment">//  "h.v": horizontal . vertical slide number (default)</span></span><br><span class="line"><span class="comment">//  "h/v": horizontal / vertical slide number</span></span><br><span class="line"><span class="comment">//    "c": flattened slide number</span></span><br><span class="line"><span class="comment">//  "c/t": flattened slide number / total slides</span></span><br><span class="line">Reveal.configure(&#123; <span class="attr">slideNumber</span>: <span class="string">'c/t'</span> &#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Control which views the slide number displays on using the "showSlideNumber" value:</span></span><br><span class="line"><span class="comment">//     "all": show on all views (default)</span></span><br><span class="line"><span class="comment">// "speaker": only show slide numbers on speaker notes view</span></span><br><span class="line"><span class="comment">//   "print": only show slide numbers when printing to PDF</span></span><br><span class="line">Reveal.configure(&#123; <span class="attr">showSlideNumber</span>: <span class="string">'speaker'</span> &#125;);</span><br></pre></td></tr></table></figure><h3 id="Overview-mode"><a href="#Overview-mode" class="headerlink" title="Overview mode"></a>Overview mode</h3><p>Press »ESC« or »O« keys to toggle the overview mode on and off. While you’re in this mode, you can still navigate between slides,<br>as if you were at 1,000 feet above your presentation. The overview mode comes with a few API hooks:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Reveal.addEventListener( <span class="string">'overviewshown'</span>, <span class="function"><span class="keyword">function</span>(<span class="params"> event </span>) </span>&#123; <span class="comment">/* ... */</span> &#125; );</span><br><span class="line">Reveal.addEventListener( <span class="string">'overviewhidden'</span>, <span class="function"><span class="keyword">function</span>(<span class="params"> event </span>) </span>&#123; <span class="comment">/* ... */</span> &#125; );</span><br><span class="line"></span><br><span class="line"><span class="comment">// Toggle the overview mode programmatically</span></span><br><span class="line">Reveal.toggleOverview();</span><br></pre></td></tr></table></figure><h3 id="Fullscreen-mode"><a href="#Fullscreen-mode" class="headerlink" title="Fullscreen mode"></a>Fullscreen mode</h3><p>Just press »F« on your keyboard to show your presentation in fullscreen mode. Press the »ESC« key to exit fullscreen mode.</p><h3 id="Embedded-media"><a href="#Embedded-media" class="headerlink" title="Embedded media"></a>Embedded media</h3><p>Add <code>data-autoplay</code> to your media element if you want it to automatically start playing when the slide is shown:</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">video</span> <span class="attr">data-autoplay</span> <span class="attr">src</span>=<span class="string">"http://clips.vorwaerts-gmbh.de/big_buck_bunny.mp4"</span>&gt;</span><span class="tag">&lt;/<span class="name">video</span>&gt;</span></span><br></pre></td></tr></table></figure><p>If you want to enable or disable autoplay globally, for all embedded media, you can use the <code>autoPlayMedia</code> configuration option. If you set this to <code>true</code> ALL media will autoplay regardless of individual <code>data-autoplay</code> attributes. If you initialize with <code>autoPlayMedia: false</code> NO media will autoplay.</p><p>Note that embedded HTML5 <code>&lt;video&gt;</code>/<code>&lt;audio&gt;</code> and YouTube/Vimeo iframes are automatically paused when you navigate away from a slide. This can be disabled by decorating your element with a <code>data-ignore</code> attribute.</p><h3 id="Embedded-iframes"><a href="#Embedded-iframes" class="headerlink" title="Embedded iframes"></a>Embedded iframes</h3><p>reveal.js automatically pushes two <a href="https://developer.mozilla.org/en-US/docs/Web/API/Window.postMessage" target="_blank" rel="noopener">post messages</a> to embedded iframes. <code>slide:start</code> when the slide containing the iframe is made visible and <code>slide:stop</code> when it is hidden.</p><h3 id="Stretching-elements"><a href="#Stretching-elements" class="headerlink" title="Stretching elements"></a>Stretching elements</h3><p>Sometimes it’s desirable to have an element, like an image or video, stretch to consume as much space as possible within a given slide. This can be done by adding the <code>.stretch</code> class to an element as seen below:</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">section</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h2</span>&gt;</span>This video will use up the remaining space on the slide<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">video</span> <span class="attr">class</span>=<span class="string">"stretch"</span> <span class="attr">src</span>=<span class="string">"http://clips.vorwaerts-gmbh.de/big_buck_bunny.mp4"</span>&gt;</span><span class="tag">&lt;/<span class="name">video</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br></pre></td></tr></table></figure><p>Limitations:</p><ul><li>Only direct descendants of a slide section can be stretched</li><li>Only one descendant per slide section can be stretched</li></ul><h3 id="postMessage-API"><a href="#postMessage-API" class="headerlink" title="postMessage API"></a>postMessage API</h3><p>The framework has a built-in postMessage API that can be used when communicating with a presentation inside of another window. Here’s an example showing how you’d make a reveal.js instance in the given window proceed to slide 2:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="built_in">window</span>&gt;.postMessage( <span class="built_in">JSON</span>.stringify(&#123; <span class="attr">method</span>: <span class="string">'slide'</span>, <span class="attr">args</span>: [ <span class="number">2</span> ] &#125;), <span class="string">'*'</span> );</span><br></pre></td></tr></table></figure><p>When reveal.js runs inside of an iframe it can optionally bubble all of its events to the parent. Bubbled events are stringified JSON with three fields: namespace, eventName and state. Here’s how you subscribe to them from the parent window:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">window</span>.addEventListener( <span class="string">'message'</span>, <span class="function"><span class="keyword">function</span>(<span class="params"> event </span>) </span>&#123;</span><br><span class="line"><span class="keyword">var</span> data = <span class="built_in">JSON</span>.parse( event.data );</span><br><span class="line"><span class="keyword">if</span>( data.namespace === <span class="string">'reveal'</span> &amp;&amp; data.eventName ===<span class="string">'slidechanged'</span> ) &#123;</span><br><span class="line"><span class="comment">// Slide changed, see data.state for slide number</span></span><br><span class="line">&#125;</span><br><span class="line">&#125; );</span><br></pre></td></tr></table></figure><p>This cross-window messaging can be toggled on or off using configuration flags.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Reveal.initialize(&#123;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Exposes the reveal.js API through window.postMessage</span></span><br><span class="line">postMessage: <span class="literal">true</span>,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Dispatches all reveal.js events to the parent window through postMessage</span></span><br><span class="line">postMessageEvents: <span class="literal">false</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h2 id="PDF-Export"><a href="#PDF-Export" class="headerlink" title="PDF Export"></a>PDF Export</h2><p>Presentations can be exported to PDF via a special print stylesheet. This feature requires that you use <a href="http://google.com/chrome" target="_blank" rel="noopener">Google Chrome</a> or <a href="https://www.chromium.org/Home" target="_blank" rel="noopener">Chromium</a> and to be serving the presentation from a webserver.<br>Here’s an example of an exported presentation that’s been uploaded to SlideShare: <a href="http://www.slideshare.net/hakimel/revealjs-300" target="_blank" rel="noopener">http://www.slideshare.net/hakimel/revealjs-300</a>.</p><h3 id="Page-size"><a href="#Page-size" class="headerlink" title="Page size"></a>Page size</h3><p>Export dimensions are inferred from the configured <a href="#presentation-size">presentation size</a>. Slides that are too tall to fit within a single page will expand onto multiple pages. You can limit how many pages a slide may expand onto using the <code>pdfMaxPagesPerSlide</code> config option, for example <code>Reveal.configure({ pdfMaxPagesPerSlide: 1 })</code> ensures that no slide ever grows to more than one printed page.</p><h3 id="Print-stylesheet"><a href="#Print-stylesheet" class="headerlink" title="Print stylesheet"></a>Print stylesheet</h3><p>To enable the PDF print capability in your presentation, the special print stylesheet at <a href="https://github.com/hakimel/reveal.js/blob/master/css/print/pdf.css" target="_blank" rel="noopener">/css/print/pdf.css</a> must be loaded. The default index.html file handles this for you when <code>print-pdf</code> is included in the query string. If you’re using a different HTML template, you can add this to your HEAD:</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="javascript"><span class="keyword">var</span> link = <span class="built_in">document</span>.createElement( <span class="string">'link'</span> );</span></span><br><span class="line"><span class="javascript">link.rel = <span class="string">'stylesheet'</span>;</span></span><br><span class="line"><span class="javascript">link.type = <span class="string">'text/css'</span>;</span></span><br><span class="line"><span class="javascript">link.href = <span class="built_in">window</span>.location.search.match( <span class="regexp">/print-pdf/gi</span> ) ? <span class="string">'css/print/pdf.css'</span> : <span class="string">'css/print/paper.css'</span>;</span></span><br><span class="line"><span class="javascript"><span class="built_in">document</span>.getElementsByTagName( <span class="string">'head'</span> )[<span class="number">0</span>].appendChild( link );</span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="Instructions-1"><a href="#Instructions-1" class="headerlink" title="Instructions"></a>Instructions</h3><ol><li>Open your presentation with <code>print-pdf</code> included in the query string i.e. <a href="http://localhost:8000/?print-pdf" target="_blank" rel="noopener">http://localhost:8000/?print-pdf</a>. You can test this with <a href="http://revealjs.com?print-pdf" target="_blank" rel="noopener">revealjs.com?print-pdf</a>.<ul><li>If you want to include <a href="#speaker-notes">speaker notes</a> in your export, you can append <code>showNotes=true</code> to the query string: <a href="http://localhost:8000/?print-pdf&amp;showNotes=true" target="_blank" rel="noopener">http://localhost:8000/?print-pdf&amp;showNotes=true</a></li></ul></li><li>Open the in-browser print dialog (CTRL/CMD+P).</li><li>Change the <strong>Destination</strong> setting to <strong>Save as PDF</strong>.</li><li>Change the <strong>Layout</strong> to <strong>Landscape</strong>.</li><li>Change the <strong>Margins</strong> to <strong>None</strong>.</li><li>Enable the <strong>Background graphics</strong> option.</li><li>Click <strong>Save</strong>.</li></ol><p><img src="https://s3.amazonaws.com/hakim-static/reveal-js/pdf-print-settings-2.png" alt="Chrome Print Settings"></p><p>Alternatively you can use the <a href="https://github.com/astefanutti/decktape" target="_blank" rel="noopener">decktape</a> project.</p><h2 id="Theming"><a href="#Theming" class="headerlink" title="Theming"></a>Theming</h2><p>The framework comes with a few different themes included:</p><ul><li>black: Black background, white text, blue links (default theme)</li><li>white: White background, black text, blue links</li><li>league: Gray background, white text, blue links (default theme for reveal.js &lt; 3.0.0)</li><li>beige: Beige background, dark text, brown links</li><li>sky: Blue background, thin dark text, blue links</li><li>night: Black background, thick white text, orange links</li><li>serif: Cappuccino background, gray text, brown links</li><li>simple: White background, black text, blue links</li><li>solarized: Cream-colored background, dark green text, blue links</li></ul><p>Each theme is available as a separate stylesheet. To change theme you will need to replace <strong>black</strong> below with your desired theme name in index.html:</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">"stylesheet"</span> <span class="attr">href</span>=<span class="string">"css/theme/black.css"</span> <span class="attr">id</span>=<span class="string">"theme"</span>&gt;</span></span><br></pre></td></tr></table></figure><p>If you want to add a theme of your own see the instructions here: <a href="https://github.com/hakimel/reveal.js/blob/master/css/theme/README.md" target="_blank" rel="noopener">/css/theme/README.md</a>.</p><h2 id="Speaker-Notes"><a href="#Speaker-Notes" class="headerlink" title="Speaker Notes"></a>Speaker Notes</h2><p>reveal.js comes with a speaker notes plugin which can be used to present per-slide notes in a separate browser window. The notes window also gives you a preview of the next upcoming slide so it may be helpful even if you haven’t written any notes. Press the »S« key on your keyboard to open the notes window.</p><p>A speaker timer starts as soon as the speaker view is opened. You can reset it to 00:00:00 at any time by simply clicking/tapping on it.</p><p>Notes are defined by appending an <code>&lt;aside&gt;</code> element to a slide as seen below. You can add the <code>data-markdown</code> attribute to the aside element if you prefer writing notes using Markdown.</p><p>Alternatively you can add your notes in a <code>data-notes</code> attribute on the slide. Like <code>&lt;section data-notes=&quot;Something important&quot;&gt;&lt;/section&gt;</code>.</p><p>When used locally, this feature requires that reveal.js <a href="#full-setup">runs from a local web server</a>.</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">section</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h2</span>&gt;</span>Some Slide<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">aside</span> <span class="attr">class</span>=<span class="string">"notes"</span>&gt;</span></span><br><span class="line">Oh hey, these are some notes. They'll be hidden in your presentation, but you can see them if you open the speaker notes window (hit »S« on your keyboard).</span><br><span class="line"><span class="tag">&lt;/<span class="name">aside</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br></pre></td></tr></table></figure><p>If you’re using the external Markdown plugin, you can add notes with the help of a special delimiter:</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">section</span> <span class="attr">data-markdown</span>=<span class="string">"example.md"</span> <span class="attr">data-separator</span>=<span class="string">"^\n\n\n"</span> <span class="attr">data-separator-vertical</span>=<span class="string">"^\n\n"</span> <span class="attr">data-separator-notes</span>=<span class="string">"^Note:"</span>&gt;</span><span class="tag">&lt;/<span class="name">section</span>&gt;</span></span><br><span class="line"></span><br><span class="line"># Title</span><br><span class="line">## Sub-title</span><br><span class="line"></span><br><span class="line">Here is some content...</span><br><span class="line"></span><br><span class="line">Note:</span><br><span class="line">This will only display in the notes window.</span><br></pre></td></tr></table></figure><h4 id="Share-and-Print-Speaker-Notes"><a href="#Share-and-Print-Speaker-Notes" class="headerlink" title="Share and Print Speaker Notes"></a>Share and Print Speaker Notes</h4><p>Notes are only visible to the speaker inside of the speaker view. If you wish to share your notes with others you can initialize reveal.js with the <code>showNotes</code> configuration value set to <code>true</code>. Notes will appear along the bottom of the presentations.</p><p>When <code>showNotes</code> is enabled notes are also included when you <a href="https://github.com/hakimel/reveal.js#pdf-export" target="_blank" rel="noopener">export to PDF</a>. By default, notes are printed in a semi-transparent box on top of the slide. If you’d rather print them on a separate page after the slide, set <code>showNotes: &quot;separate-page&quot;</code>.</p><h4 id="Speaker-notes-clock-and-timers"><a href="#Speaker-notes-clock-and-timers" class="headerlink" title="Speaker notes clock and timers"></a>Speaker notes clock and timers</h4><p>The speaker notes window will also show:</p><ul><li>Time elapsed since the beginning of the presentation.  If you hover the mouse above this section, a timer reset button will appear.</li><li>Current wall-clock time</li><li>(Optionally) a pacing timer which indicates whether the current pace of the presentation is on track for the right timing (shown in green), and if not, whether the presenter should speed up (shown in red) or has the luxury of slowing down (blue).</li></ul><p>The pacing timer can be enabled by configuring by the <code>defaultTiming</code> parameter in the <code>Reveal</code> configuration block, which specifies the number of seconds per slide.  120 can be a reasonable rule of thumb.  Timings can also be given per slide <code>&lt;section&gt;</code> by setting the <code>data-timing</code> attribute.  Both values are in numbers of seconds.</p><h2 id="Server-Side-Speaker-Notes"><a href="#Server-Side-Speaker-Notes" class="headerlink" title="Server Side Speaker Notes"></a>Server Side Speaker Notes</h2><p>In some cases it can be desirable to run notes on a separate device from the one you’re presenting on. The Node.js-based notes plugin lets you do this using the same note definitions as its client side counterpart. Include the required scripts by adding the following dependencies:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Reveal.initialize(&#123;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">dependencies: [</span><br><span class="line">&#123; <span class="attr">src</span>: <span class="string">'socket.io/socket.io.js'</span>, <span class="attr">async</span>: <span class="literal">true</span> &#125;,</span><br><span class="line">&#123; <span class="attr">src</span>: <span class="string">'plugin/notes-server/client.js'</span>, <span class="attr">async</span>: <span class="literal">true</span> &#125;</span><br><span class="line">]</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>Then:</p><ol><li>Install <a href="http://nodejs.org/" target="_blank" rel="noopener">Node.js</a> (4.0.0 or later)</li><li>Run <code>npm install</code></li><li>Run <code>node plugin/notes-server</code></li></ol><h2 id="Multiplexing"><a href="#Multiplexing" class="headerlink" title="Multiplexing"></a>Multiplexing</h2><p>The multiplex plugin allows your audience to view the slides of the presentation you are controlling on their own phone, tablet or laptop. As the master presentation navigates the slides, all client presentations will update in real time. See a demo at <a href="https://reveal-js-multiplex-ccjbegmaii.now.sh/" target="_blank" rel="noopener">https://reveal-js-multiplex-ccjbegmaii.now.sh/</a>.</p><p>The multiplex plugin needs the following 3 things to operate:</p><ol><li>Master presentation that has control</li><li>Client presentations that follow the master</li><li>Socket.io server to broadcast events from the master to the clients</li></ol><h4 id="Master-presentation"><a href="#Master-presentation" class="headerlink" title="Master presentation"></a>Master presentation</h4><p>Served from a static file server accessible (preferably) only to the presenter. This need only be on your (the presenter’s) computer. (It’s safer to run the master presentation from your own computer, so if the venue’s Internet goes down it doesn’t stop the show.) An example would be to execute the following commands in the directory of your master presentation:</p><ol><li><code>npm install node-static</code></li><li><code>static</code></li></ol><p>If you want to use the speaker notes plugin with your master presentation then make sure you have the speaker notes plugin configured correctly along with the configuration shown below, then execute <code>node plugin/notes-server</code> in the directory of your master presentation. The configuration below will cause it to connect to the socket.io server as a master, as well as launch your speaker-notes/static-file server.</p><p>You can then access your master presentation at <code>http://localhost:1947</code></p><p>Example configuration:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Reveal.initialize(&#123;</span><br><span class="line"><span class="comment">// other options...</span></span><br><span class="line"></span><br><span class="line">multiplex: &#123;</span><br><span class="line"><span class="comment">// Example values. To generate your own, see the socket.io server instructions.</span></span><br><span class="line">secret: <span class="string">'13652805320794272084'</span>, <span class="comment">// Obtained from the socket.io server. Gives this (the master) control of the presentation</span></span><br><span class="line">id: <span class="string">'1ea875674b17ca76'</span>, <span class="comment">// Obtained from socket.io server</span></span><br><span class="line">url: <span class="string">'https://reveal-js-multiplex-ccjbegmaii.now.sh'</span> <span class="comment">// Location of socket.io server</span></span><br><span class="line">&#125;,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Don't forget to add the dependencies</span></span><br><span class="line">dependencies: [</span><br><span class="line">&#123; <span class="attr">src</span>: <span class="string">'//cdn.socket.io/socket.io-1.3.5.js'</span>, <span class="attr">async</span>: <span class="literal">true</span> &#125;,</span><br><span class="line">&#123; <span class="attr">src</span>: <span class="string">'plugin/multiplex/master.js'</span>, <span class="attr">async</span>: <span class="literal">true</span> &#125;,</span><br><span class="line"></span><br><span class="line"><span class="comment">// and if you want speaker notes</span></span><br><span class="line">&#123; <span class="attr">src</span>: <span class="string">'plugin/notes-server/client.js'</span>, <span class="attr">async</span>: <span class="literal">true</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// other dependencies...</span></span><br><span class="line">]</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h4 id="Client-presentation"><a href="#Client-presentation" class="headerlink" title="Client presentation"></a>Client presentation</h4><p>Served from a publicly accessible static file server. Examples include: GitHub Pages, Amazon S3, Dreamhost, Akamai, etc. The more reliable, the better. Your audience can then access the client presentation via <code>http://example.com/path/to/presentation/client/index.html</code>, with the configuration below causing them to connect to the socket.io server as clients.</p><p>Example configuration:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Reveal.initialize(&#123;</span><br><span class="line"><span class="comment">// other options...</span></span><br><span class="line"></span><br><span class="line">multiplex: &#123;</span><br><span class="line"><span class="comment">// Example values. To generate your own, see the socket.io server instructions.</span></span><br><span class="line">secret: <span class="literal">null</span>, <span class="comment">// null so the clients do not have control of the master presentation</span></span><br><span class="line">id: <span class="string">'1ea875674b17ca76'</span>, <span class="comment">// id, obtained from socket.io server</span></span><br><span class="line">url: <span class="string">'https://reveal-js-multiplex-ccjbegmaii.now.sh'</span> <span class="comment">// Location of socket.io server</span></span><br><span class="line">&#125;,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Don't forget to add the dependencies</span></span><br><span class="line">dependencies: [</span><br><span class="line">&#123; <span class="attr">src</span>: <span class="string">'//cdn.socket.io/socket.io-1.3.5.js'</span>, <span class="attr">async</span>: <span class="literal">true</span> &#125;,</span><br><span class="line">&#123; <span class="attr">src</span>: <span class="string">'plugin/multiplex/client.js'</span>, <span class="attr">async</span>: <span class="literal">true</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// other dependencies...</span></span><br><span class="line">]</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h4 id="Socket-io-server"><a href="#Socket-io-server" class="headerlink" title="Socket.io server"></a>Socket.io server</h4><p>Server that receives the <code>slideChanged</code> events from the master presentation and broadcasts them out to the connected client presentations. This needs to be publicly accessible. You can run your own socket.io server with the commands:</p><ol><li><code>npm install</code></li><li><code>node plugin/multiplex</code></li></ol><p>Or you can use the socket.io server at <a href="https://reveal-js-multiplex-ccjbegmaii.now.sh/" target="_blank" rel="noopener">https://reveal-js-multiplex-ccjbegmaii.now.sh/</a>.</p><p>You’ll need to generate a unique secret and token pair for your master and client presentations. To do so, visit <code>http://example.com/token</code>, where <code>http://example.com</code> is the location of your socket.io server. Or if you’re going to use the socket.io server at <a href="https://reveal-js-multiplex-ccjbegmaii.now.sh/" target="_blank" rel="noopener">https://reveal-js-multiplex-ccjbegmaii.now.sh/</a>, visit <a href="https://reveal-js-multiplex-ccjbegmaii.now.sh/token" target="_blank" rel="noopener">https://reveal-js-multiplex-ccjbegmaii.now.sh/token</a>.</p><p>You are very welcome to point your presentations at the Socket.io server running at <a href="https://reveal-js-multiplex-ccjbegmaii.now.sh/" target="_blank" rel="noopener">https://reveal-js-multiplex-ccjbegmaii.now.sh/</a>, but availability and stability are not guaranteed.</p><p>For anything mission critical I recommend you run your own server. The easiest way to do this is by installing <a href="https://zeit.co/now" target="_blank" rel="noopener">now</a>. With that installed, deploying your own Multiplex server is as easy running the following command from the reveal.js folder: <code>now plugin/multiplex</code>.</p><h5 id="socket-io-server-as-file-static-server"><a href="#socket-io-server-as-file-static-server" class="headerlink" title="socket.io server as file static server"></a>socket.io server as file static server</h5><p>The socket.io server can play the role of static file server for your client presentation, as in the example at <a href="https://reveal-js-multiplex-ccjbegmaii.now.sh/" target="_blank" rel="noopener">https://reveal-js-multiplex-ccjbegmaii.now.sh/</a>. (Open <a href="https://reveal-js-multiplex-ccjbegmaii.now.sh/" target="_blank" rel="noopener">https://reveal-js-multiplex-ccjbegmaii.now.sh/</a> in two browsers. Navigate through the slides on one, and the other will update to match.)</p><p>Example configuration:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Reveal.initialize(&#123;</span><br><span class="line"><span class="comment">// other options...</span></span><br><span class="line"></span><br><span class="line">multiplex: &#123;</span><br><span class="line"><span class="comment">// Example values. To generate your own, see the socket.io server instructions.</span></span><br><span class="line">secret: <span class="literal">null</span>, <span class="comment">// null so the clients do not have control of the master presentation</span></span><br><span class="line">id: <span class="string">'1ea875674b17ca76'</span>, <span class="comment">// id, obtained from socket.io server</span></span><br><span class="line">url: <span class="string">'example.com:80'</span> <span class="comment">// Location of your socket.io server</span></span><br><span class="line">&#125;,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Don't forget to add the dependencies</span></span><br><span class="line">dependencies: [</span><br><span class="line">&#123; <span class="attr">src</span>: <span class="string">'//cdn.socket.io/socket.io-1.3.5.js'</span>, <span class="attr">async</span>: <span class="literal">true</span> &#125;,</span><br><span class="line">&#123; <span class="attr">src</span>: <span class="string">'plugin/multiplex/client.js'</span>, <span class="attr">async</span>: <span class="literal">true</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// other dependencies...</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>It can also play the role of static file server for your master presentation and client presentations at the same time (as long as you don’t want to use speaker notes). (Open <a href="https://reveal-js-multiplex-ccjbegmaii.now.sh/" target="_blank" rel="noopener">https://reveal-js-multiplex-ccjbegmaii.now.sh/</a> in two browsers. Navigate through the slides on one, and the other will update to match. Navigate through the slides on the second, and the first will update to match.) This is probably not desirable, because you don’t want your audience to mess with your slides while you’re presenting. ;)</p><p>Example configuration:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Reveal.initialize(&#123;</span><br><span class="line"><span class="comment">// other options...</span></span><br><span class="line"></span><br><span class="line">multiplex: &#123;</span><br><span class="line"><span class="comment">// Example values. To generate your own, see the socket.io server instructions.</span></span><br><span class="line">secret: <span class="string">'13652805320794272084'</span>, <span class="comment">// Obtained from the socket.io server. Gives this (the master) control of the presentation</span></span><br><span class="line">id: <span class="string">'1ea875674b17ca76'</span>, <span class="comment">// Obtained from socket.io server</span></span><br><span class="line">url: <span class="string">'example.com:80'</span> <span class="comment">// Location of your socket.io server</span></span><br><span class="line">&#125;,</span><br><span class="line"></span><br><span class="line"><span class="comment">// Don't forget to add the dependencies</span></span><br><span class="line">dependencies: [</span><br><span class="line">&#123; <span class="attr">src</span>: <span class="string">'//cdn.socket.io/socket.io-1.3.5.js'</span>, <span class="attr">async</span>: <span class="literal">true</span> &#125;,</span><br><span class="line">&#123; <span class="attr">src</span>: <span class="string">'plugin/multiplex/master.js'</span>, <span class="attr">async</span>: <span class="literal">true</span> &#125;,</span><br><span class="line">&#123; <span class="attr">src</span>: <span class="string">'plugin/multiplex/client.js'</span>, <span class="attr">async</span>: <span class="literal">true</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// other dependencies...</span></span><br><span class="line">]</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h2 id="MathJax"><a href="#MathJax" class="headerlink" title="MathJax"></a>MathJax</h2><p>If you want to display math equations in your presentation you can easily do so by including this plugin. The plugin is a very thin wrapper around the <a href="http://www.mathjax.org/" target="_blank" rel="noopener">MathJax</a> library. To use it you’ll need to include it as a reveal.js dependency, <a href="#dependencies">find our more about dependencies here</a>.</p><p>The plugin defaults to using <a href="http://en.wikipedia.org/wiki/LaTeX" target="_blank" rel="noopener">LaTeX</a> but that can be adjusted through the <code>math</code> configuration object. Note that MathJax is loaded from a remote server. If you want to use it offline you’ll need to download a copy of the library and adjust the <code>mathjax</code> configuration value.</p><p>Below is an example of how the plugin can be configured. If you don’t intend to change these values you do not need to include the <code>math</code> config object at all.</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Reveal.initialize(&#123;</span><br><span class="line"><span class="comment">// other options ...</span></span><br><span class="line"></span><br><span class="line">math: &#123;</span><br><span class="line">mathjax: <span class="string">'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js'</span>,</span><br><span class="line">config: <span class="string">'TeX-AMS_HTML-full'</span>  <span class="comment">// See http://docs.mathjax.org/en/latest/config-files.html</span></span><br><span class="line">&#125;,</span><br><span class="line"></span><br><span class="line">dependencies: [</span><br><span class="line">&#123; <span class="attr">src</span>: <span class="string">'plugin/math/math.js'</span>, <span class="attr">async</span>: <span class="literal">true</span> &#125;</span><br><span class="line">]</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>Read MathJax’s documentation if you need <a href="http://docs.mathjax.org/en/latest/start.html#secure-access-to-the-cdn" target="_blank" rel="noopener">HTTPS delivery</a> or serving of <a href="http://docs.mathjax.org/en/latest/configuration.html#loading-mathjax-from-the-cdn" target="_blank" rel="noopener">specific versions</a> for stability.</p><h2 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h2><p>The <strong>basic setup</strong> is for authoring presentations only. The <strong>full setup</strong> gives you access to all reveal.js features and plugins such as speaker notes as well as the development tasks needed to make changes to the source.</p><h3 id="Basic-setup"><a href="#Basic-setup" class="headerlink" title="Basic setup"></a>Basic setup</h3><p>The core of reveal.js is very easy to install. You’ll simply need to download a copy of this repository and open the index.html file directly in your browser.</p><ol><li>Download the latest version of reveal.js from <a href="https://github.com/hakimel/reveal.js/releases" target="_blank" rel="noopener">https://github.com/hakimel/reveal.js/releases</a></li><li>Unzip and replace the example contents in index.html with your own</li><li>Open index.html in a browser to view it</li></ol><h3 id="Full-setup"><a href="#Full-setup" class="headerlink" title="Full setup"></a>Full setup</h3><p>Some reveal.js features, like external Markdown and speaker notes, require that presentations run from a local web server. The following instructions will set up such a server as well as all of the development tasks needed to make edits to the reveal.js source code.</p><ol><li><p>Install <a href="http://nodejs.org/" target="_blank" rel="noopener">Node.js</a> (4.0.0 or later)</p></li><li><p>Clone the reveal.js repository</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://github.com/hakimel/reveal.js.git</span><br></pre></td></tr></table></figure></li><li><p>Navigate to the reveal.js folder</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> reveal.js</span><br></pre></td></tr></table></figure></li><li><p>Install dependencies</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm install</span><br></pre></td></tr></table></figure></li><li><p>Serve the presentation and monitor source files for changes</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm start</span><br></pre></td></tr></table></figure></li><li><p>Open <a href="http://localhost:8000" target="_blank" rel="noopener">http://localhost:8000</a> to view your presentation</p><p>You can change the port by using <code>npm start -- --port=8001</code>.</p></li></ol><h3 id="Folder-Structure"><a href="#Folder-Structure" class="headerlink" title="Folder Structure"></a>Folder Structure</h3><ul><li><strong>css/</strong> Core styles without which the project does not function</li><li><strong>js/</strong> Like above but for JavaScript</li><li><strong>plugin/</strong> Components that have been developed as extensions to reveal.js</li><li><strong>lib/</strong> All other third party assets (JavaScript, CSS, fonts)</li></ul><h2 id="License"><a href="#License" class="headerlink" title="License"></a>License</h2><p>MIT licensed</p><p>Copyright (C) 2017 Hakim El Hattab, <a href="http://hakim.se" target="_blank" rel="noopener">http://hakim.se</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;reveal-js&quot;&gt;&lt;a href=&quot;#reveal-js&quot; class=&quot;headerlink&quot; title=&quot;reveal.js  &quot;&gt;&lt;/a&gt;reveal.js &lt;a href=&quot;https://travis-ci.org/hakimel/reveal.j
      
    
    </summary>
    
      <category term="reveal.js" scheme="http://yoururl.com/categories/reveal-js/"/>
    
    
      <category term="reveal.js" scheme="http://yoururl.com/tags/reveal-js/"/>
    
  </entry>
  
  <entry>
    <title>python：对象引用、可变性（二）</title>
    <link href="http://yoururl.com/2018/04/18/python%EF%BC%9A%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E3%80%81%E5%8F%AF%E5%8F%98%E6%80%A7%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <id>http://yoururl.com/2018/04/18/python：对象引用、可变性（二）/</id>
    <published>2018-04-17T16:01:00.000Z</published>
    <updated>2018-04-18T17:25:52.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="函数参数引用"><a href="#函数参数引用" class="headerlink" title="函数参数引用"></a>函数参数引用</h3><p>python 唯一支持的参数传递模式是 <strong>共享传参</strong>。<br>共享传参： 指函数的各个形参获得实参中各个引用的副本。 也就是说，函数内部的形参是实参的别名。</p><p>因此，在函数中修改传入参数的可变对象， 会影响实参。 但对象的标识不会改变。</p><p>ex1. 函数可能会修改收到的任何可变对象</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    a += b</span><br><span class="line">    <span class="keyword">return</span> a</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="number">1</span></span><br><span class="line">y = <span class="number">2</span></span><br><span class="line">print(<span class="string">'f: '</span>, f(x, y))</span><br><span class="line">print(<span class="string">'x：'</span>, x)       <span class="comment"># 数字没变</span></span><br><span class="line">print(<span class="string">'y：'</span>, y)</span><br></pre></td></tr></table></figure><pre><code>f:  3x： 1y： 2</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">b = [<span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">print(<span class="string">'f:'</span>, f(a, b))</span><br><span class="line">print(<span class="string">'a:'</span>, a)        <span class="comment"># 列表a变了</span></span><br><span class="line">print(<span class="string">'b:'</span>, b)</span><br></pre></td></tr></table></figure><pre><code>f: [1, 2, 3, 4]a: [1, 2, 3, 4]b: [3, 4]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">t = (<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">u = (<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">print(<span class="string">'f:'</span>, f(t, u))</span><br><span class="line">print(<span class="string">'t:'</span>, t)        <span class="comment"># 元组t没变</span></span><br><span class="line">print(<span class="string">'u:'</span>, u)</span><br></pre></td></tr></table></figure><pre><code>f: (1, 2, 3, 4)t: (1, 2)u: (3, 4)</code></pre><h4 id="不要使用可变类型作为参数默认值"><a href="#不要使用可变类型作为参数默认值" class="headerlink" title="不要使用可变类型作为参数默认值"></a>不要使用可变类型作为参数默认值</h4><p>ex2. 说明可变默认值的影响</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">bus</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, passengers=[])</span>:</span>    <span class="comment"># 默认值为空列表</span></span><br><span class="line">        self.passengers = passengers</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pick</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.passengers.append(name)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">drop</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.passengers.remove(name)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bus1 = bus([<span class="string">'A'</span>, <span class="string">'B'</span>])</span><br><span class="line">bus1.passengers</span><br></pre></td></tr></table></figure><pre><code>[&#39;A&#39;, &#39;B&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bus1.pick(<span class="string">'C'</span>)</span><br><span class="line">bus1.drop(<span class="string">'A'</span>)</span><br><span class="line">bus1.passengers          <span class="comment"># bus1 未出现异常</span></span><br></pre></td></tr></table></figure><pre><code>[&#39;B&#39;, &#39;C&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bus2 = bus()             <span class="comment"># 一开始bus2是空的，因此把默认的空列表赋值给self.passengers</span></span><br><span class="line">bus2.pick(<span class="string">'D'</span>)</span><br><span class="line">bus2.passengers</span><br></pre></td></tr></table></figure><pre><code>[&#39;D&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bus3 = bus()             <span class="comment"># 一开始bus3也是空的，因此把默认的空列表赋值给self.passengers</span></span><br><span class="line">bus3.passengers          <span class="comment"># 但是默认列表不为空， 登上bus2的D出现在bus3中</span></span><br></pre></td></tr></table></figure><pre><code>[&#39;D&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bus3.pick(<span class="string">'E'</span>)</span><br><span class="line">bus2.passengers          <span class="comment"># 登上bus3的E出现在bus2中</span></span><br></pre></td></tr></table></figure><pre><code>[&#39;D&#39;, &#39;E&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bus2.passengers <span class="keyword">is</span> bus3.passengers</span><br></pre></td></tr></table></figure><pre><code>True</code></pre><p>问题是，bus2.passengers 和 bus3.passengers 指代同一个列表</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bus1.passengers <span class="keyword">is</span> bus2.passengers</span><br></pre></td></tr></table></figure><pre><code>False</code></pre><p>而bus1.passengers是另一个列表</p><p>问题在于： 没有指定初始乘客的bus实例会共享一个乘客列表。<br><strong>没有指定初始值的实例会共享一个对象。</strong></p><p>本例中，实例化bus时，如果传入乘客，会按预期运作。但不为bus指定乘客的话，会发生奇怪的事。<br>因为初始化时，self.passengers变成passengers参数默认值的别名。问题的根源在于，<strong>默认值在定义函数时计算（通常在加载模块时），因此默认值变成了函数对象的属性。如果默认值是可变对象，而且修改了它的值，那么后续的函数调用都会收到影响。</strong></p><p>我们可以审查bus.__init__对象，查看它的__defaults__属性中的乘客</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dir(bus.__init__)</span><br></pre></td></tr></table></figure><pre><code>[&#39;__annotations__&#39;, &#39;__call__&#39;, &#39;__class__&#39;, &#39;__closure__&#39;, &#39;__code__&#39;, &#39;__defaults__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__get__&#39;, &#39;__getattribute__&#39;, &#39;__globals__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__kwdefaults__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__name__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__qualname__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bus.__init__.__defaults__</span><br></pre></td></tr></table></figure><pre><code>([&#39;D&#39;, &#39;E&#39;],)</code></pre><p>最后，我们可以验证bus2.passenges是一个别名，它绑定到bus.__init__.__defaults__属性的第一个元素上：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bus.__init__.__defaults__[<span class="number">0</span>] <span class="keyword">is</span> bus2.passengers</span><br></pre></td></tr></table></figure><pre><code>True</code></pre><p>这个问题说明了为什么通常使用None作为接受可变值参数的默认值。</p><h4 id="防御可变参数"><a href="#防御可变参数" class="headerlink" title="防御可变参数"></a>防御可变参数</h4><p>ex3. 接受可变参数的影响</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TwilighBus</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, passengers=None)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> passengers <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            self.passengers = []</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.passengers = passengers      <span class="comment"># 赋值语句把self.passengers 变成passengers的别名， passengers 是传给__init__方法的实参的别名</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pick</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.passengers.append(name)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">drop</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.passengers.remove(name)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">team = [<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'C'</span>]</span><br><span class="line">bus = TwilighBus(team)</span><br><span class="line">bus.drop(<span class="string">'A'</span>)</span><br><span class="line">bus.pick(<span class="string">'D'</span>)</span><br><span class="line">print(<span class="string">'self.passengers: '</span>,bus.passengers)     </span><br><span class="line">print(<span class="string">'team: '</span>,team)                          <span class="comment"># remove()和append()会修改传给构造方法的那个list</span></span><br></pre></td></tr></table></figure><pre><code>self.passengers:  [&#39;B&#39;, &#39;C&#39;, &#39;D&#39;]team:  [&#39;B&#39;, &#39;C&#39;, &#39;D&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">id(team), id(bus.passengers)                  <span class="comment"># 共享同一个对象</span></span><br></pre></td></tr></table></figure><pre><code>(2677046974216, 2677046974216)</code></pre><p>上述例子，类为传给构造方法的列表创建了别名，self.passengers 和 passengers 两个标识共享同一个 list。<br>正确的做法是，在__init__中，传入 passengers 参数时，应该把参数值的副本赋值给self.passengers，如下：<br>ex4. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TwilighBus</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, passengers=None)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> passengers <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            self.passengers = []</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.passengers = list(passengers)    <span class="comment"># 把参数值的副本赋值给self.passengers</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pick</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.passengers.append(name)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">drop</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.passengers.remove(name)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">team = [<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'C'</span>]</span><br><span class="line">bus = TwilighBus(team)</span><br><span class="line">bus.drop(<span class="string">'A'</span>)</span><br><span class="line">bus.pick(<span class="string">'D'</span>)</span><br><span class="line">print(<span class="string">'self.passengers: '</span>,bus.passengers)  </span><br><span class="line">print(<span class="string">'team: '</span>,team)                              <span class="comment"># 不改变初始化时传入的实参</span></span><br></pre></td></tr></table></figure><pre><code>self.passengers:  [&#39;B&#39;, &#39;C&#39;, &#39;D&#39;]team:  [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">id(team), id(bus.passengers)                      <span class="comment"># 不同对象的别名</span></span><br></pre></td></tr></table></figure><pre><code>(2677047040968, 2677046999688)</code></pre><p>除非确实想修改通过参数传入的对象，否则在类中直接把参数赋值给实例变量之前一定要考虑清楚，因为这样会为参数对象创建别名。如果不确定，就创建副本。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;函数参数引用&quot;&gt;&lt;a href=&quot;#函数参数引用&quot; class=&quot;headerlink&quot; title=&quot;函数参数引用&quot;&gt;&lt;/a&gt;函数参数引用&lt;/h3&gt;&lt;p&gt;python 唯一支持的参数传递模式是 &lt;strong&gt;共享传参&lt;/strong&gt;。&lt;br&gt;共享传参： 指函
      
    
    </summary>
    
      <category term="python" scheme="http://yoururl.com/categories/python/"/>
    
    
      <category term="python" scheme="http://yoururl.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>python：对象引用、可变性（一）</title>
    <link href="http://yoururl.com/2018/04/18/python%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8/"/>
    <id>http://yoururl.com/2018/04/18/python对象引用/</id>
    <published>2018-04-17T16:00:00.000Z</published>
    <updated>2018-04-18T17:25:25.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="变量是标注，不是盒子"><a href="#变量是标注，不是盒子" class="headerlink" title="变量是标注，不是盒子"></a>变量是标注，不是盒子</h3><p>ex1 变量a,b引用同一个列表，而非副本:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">b = a</span><br><span class="line">a.append(<span class="number">4</span>)</span><br><span class="line">b</span><br></pre></td></tr></table></figure><pre><code>[1, 2, 3, 4]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b.append(<span class="number">5</span>)</span><br><span class="line">a</span><br></pre></td></tr></table></figure><pre><code>[1, 2, 3, 4, 5]</code></pre><p>把变量分配给对象，毕竟，对象在赋值之前就创建了</p><p>ex2 创建对象之后才会把变量分配给对象:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Cizmo</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'Cizmo id: %d'</span> % id(self))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = Cizmo()</span><br></pre></td></tr></table></figure><pre><code>Cizmo id: 2471747005520</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y = Cizmo() * <span class="number">10</span></span><br></pre></td></tr></table></figure><pre><code>Cizmo id: 2471747003504---------------------------------------------------------------------------TypeError                                 Traceback (most recent call last)&lt;ipython-input-6-4480d877b50b&gt; in &lt;module&gt;()----&gt; 1 y = Cizmo() * 10TypeError: unsupported operand type(s) for *: &#39;Cizmo&#39; and &#39;int&#39;</code></pre><p>在尝试求积之前会先创建一个Cimzo实例，一定不会先创建变量y。</p><p>变量只是标注，可以为对象添加多个标注，相当于别名。</p><h3 id="标识、相等性、别名"><a href="#标识、相等性、别名" class="headerlink" title="标识、相等性、别名"></a>标识、相等性、别名</h3><p>ex3 同一对象可以有多个标注，就是别名:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">charles = &#123;<span class="string">'name'</span>: <span class="string">'charles L. Dodgson'</span>, <span class="string">'born'</span>: <span class="string">'1892'</span>&#125;</span><br><span class="line">lewis = charles</span><br><span class="line">lewis <span class="keyword">is</span> charles</span><br></pre></td></tr></table></figure><pre><code>True</code></pre><p>lewis 是 chaeles 的别名</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">id(lewis), id(charles)</span><br></pre></td></tr></table></figure><pre><code>(2471747375368, 2471747375368)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lewis[<span class="string">'balance'</span>] = <span class="number">950</span></span><br><span class="line">charles</span><br></pre></td></tr></table></figure><pre><code>{&#39;balance&#39;: 950, &#39;born&#39;: &#39;1892&#39;, &#39;name&#39;: &#39;charles L. Dodgson&#39;}</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alex = &#123;<span class="string">'balance'</span>: <span class="number">950</span>, <span class="string">'born'</span>: <span class="string">'1892'</span>, <span class="string">'name'</span>: <span class="string">'charles L. Dodgson'</span>&#125;</span><br><span class="line">alex == charles</span><br></pre></td></tr></table></figure><pre><code>True</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alex <span class="keyword">is</span> <span class="keyword">not</span> charles</span><br></pre></td></tr></table></figure><pre><code>True</code></pre><p>alex 与 charles 绑定的对象有相同的值，但两者标识不同</p><p>每个变量都有标识、类型和值，对象一旦创建，标识不会改变；可以把标志理解为对象在内存中的地址。<br>is 运算符比较两个对象的标识； id()函数返回对象标识的整数表示。</p><h4 id="和-is"><a href="#和-is" class="headerlink" title="== 和 is"></a>== 和 is</h4><p>== 运算符比较两个对象的值（对象中保存的数据），is 比较两个对象的标识。</p><p>is 运算符比 == 速度快，因为其不能重载，python不用寻找并调用特殊方法，直接比较两个整数ID。</p><h4 id="元组的相对不可变性"><a href="#元组的相对不可变性" class="headerlink" title="元组的相对不可变性"></a>元组的相对不可变性</h4><p>元组与多数python集合（列表、字典、集，等）一样，保存的是对象的引用。<br>而str、bytes和 array.array等单一类型序列是扁平的，它们保存的不是引用，而是在连续的内存中保存数据本身（字符、字节和数字）</p><p>元组的不可变性指tuple数据结构的物理内容（即保存的引用）不可变，与引用的对象无关。如果引用的元素是可变的，即使元组本身不可变，元素依然可变。</p><p>ex4 :</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">t1 = (<span class="number">1</span>, <span class="number">2</span>, [<span class="number">3</span>, <span class="number">4</span>])  <span class="comment"># t1 不可变， t1[-1]可变</span></span><br><span class="line">t2 = (<span class="number">1</span>, <span class="number">2</span>, [<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">t1 == t2</span><br></pre></td></tr></table></figure><pre><code>True</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">id(t1[<span class="number">-1</span>])</span><br></pre></td></tr></table></figure><pre><code>2471747846024</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t1[<span class="number">-1</span>].append(<span class="number">5</span>)</span><br><span class="line">t1</span><br></pre></td></tr></table></figure><pre><code>(1, 2, [3, 4, 5])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">id(t1[<span class="number">-1</span>])  <span class="comment"># 标识不变，值变了</span></span><br></pre></td></tr></table></figure><pre><code>2471747846024</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t1 == t2</span><br></pre></td></tr></table></figure><pre><code>False</code></pre><h3 id="浅复制"><a href="#浅复制" class="headerlink" title="浅复制"></a>浅复制</h3><p>复制列表（或多数内置的可变集合）最简单的方式是使用内置的类型构造方法。</p><p>ex5 构造方法 复制列表:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">l1 = [<span class="number">3</span>, [<span class="number">55</span>, <span class="number">44</span>], (<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)]</span><br><span class="line">l2 = list(l1)</span><br><span class="line">l2</span><br></pre></td></tr></table></figure><pre><code>[3, [55, 44], (1, 2, 3)]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">l1 == l2    <span class="comment"># 副本与原列表相等</span></span><br></pre></td></tr></table></figure><pre><code>True</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">l2 <span class="keyword">is</span> l1    <span class="comment"># 但两者指代不同对象</span></span><br></pre></td></tr></table></figure><pre><code>False</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">l1.append(<span class="number">6</span>)</span><br><span class="line">l2</span><br></pre></td></tr></table></figure><pre><code>[3, [55, 44], (1, 2, 3)]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">l1[<span class="number">1</span>].append(<span class="number">60</span>)     <span class="comment"># 改变原容器中可变元素导致的副本变化</span></span><br><span class="line">l2</span><br></pre></td></tr></table></figure><pre><code>[3, [55, 44, 60], (1, 2, 3)]</code></pre><p>对列表和其他可变序列来说，还能使用简洁的l2 = l1[:]语句创建副本</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">l3 = [<span class="number">3</span>, [<span class="number">55</span>, <span class="number">44</span>], (<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)]</span><br><span class="line">l4 = l3[:]</span><br><span class="line">l4</span><br></pre></td></tr></table></figure><pre><code>[3, [55, 44], (1, 2, 3)]</code></pre><p>构造方法和 [:] 做的是浅复制（即复制了最外层容器，副本中的元素是源容器中元素的引用）。<br>如果所有元素都是不可变的，不会产生问题，还能节省内存；如果有可变元素，可能会导致问题。</p><p>ex6 浅复制的问题:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">l1 = [<span class="number">3</span>, [<span class="number">55</span>, <span class="number">44</span>], (<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)]</span><br><span class="line">l2 = list(l1)</span><br><span class="line">l1.append(<span class="number">100</span>)         <span class="comment"># l1追加100，对l2 无影响 </span></span><br><span class="line">l1[<span class="number">1</span>].remove(<span class="number">55</span>)       <span class="comment"># 内部列表 l1[1] 删除55， 对l2有影响，因为l2[1] 和 l1[1] 绑定同一个 列表</span></span><br><span class="line">print(<span class="string">'l1:'</span>, l1)</span><br><span class="line">print(<span class="string">'l2:'</span>, l2)</span><br></pre></td></tr></table></figure><pre><code>l1: [3, [44], (1, 2, 3), 100]l2: [3, [44], (1, 2, 3)]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">l2[<span class="number">1</span>] += [<span class="number">33</span>, <span class="number">22</span>]      <span class="comment"># l2[1]引用的list, +=运算符修改list,   修改对l1也有影响，因为l1[1] 是 l2[1] 的别名 </span></span><br><span class="line">l2[<span class="number">2</span>] += (<span class="number">33</span>, <span class="number">22</span>)      <span class="comment"># l2[2]引用的元组，+=运算符创建新元组，重新绑定给变量l2[2], 因此，l1 ,l2最后位置上的元组不是同一个对象。</span></span><br><span class="line">print(<span class="string">'l1:'</span>, l1)</span><br><span class="line">print(<span class="string">'l2:'</span>, l2)</span><br></pre></td></tr></table></figure><pre><code>l1: [3, [44, 33, 22], (1, 2, 3), 100]l2: [3, [44, 33, 22], (1, 2, 3, 33, 22)]</code></pre><p>因此，浅复制容易操作，但对于包含可变元素的对象，改变源对象或副本可能会产生不良结果。</p><h4 id="深复制和浅复制"><a href="#深复制和浅复制" class="headerlink" title="深复制和浅复制"></a>深复制和浅复制</h4><p>深复制：副本不共享内部对象的引用</p><p>copy模块提供的 deepcopy 和 copy 函数能为任意对象做深复制和浅复制。</p><p>ex7 copy() 和 deepcopy() 的影响:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 校车乘客中途上下车</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">bus</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, passengers=None)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> passengers <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            self.passengers = []</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.passengers = list(passengers)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pick</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.passengers.append(name)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">drop</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.passengers.remove(name)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line">bus1 = bus([<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'C'</span>, <span class="string">'D'</span>])</span><br><span class="line">bus2 = copy.copy(bus1)        <span class="comment"># 浅复制</span></span><br><span class="line">bus3 = copy.deepcopy(bus1)    <span class="comment"># 深复制</span></span><br><span class="line">id(bus1), id(bus2), id(bus3)   <span class="comment"># 创建三个不同的实例</span></span><br></pre></td></tr></table></figure><pre><code>(2464686488488, 2464686489216, 2464686487872)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bus1.drop(<span class="string">'A'</span>)</span><br><span class="line">bus2.passengers        <span class="comment"># bus1,bus2 共享同一个列表对象，因为 bus2 是 bus1 的浅复制副本</span></span><br></pre></td></tr></table></figure><pre><code>[&#39;B&#39;, &#39;C&#39;, &#39;D&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bus3.passengers        <span class="comment"># bus3 是 bus1 的深复制副本， 它的passengers属性指代另一个列表</span></span><br></pre></td></tr></table></figure><pre><code>[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">id(bus1.passengers), id(bus2.passengers), id(bus3.passengers)</span><br></pre></td></tr></table></figure><pre><code>(2464687364872, 2464687364872, 2464685576712)</code></pre><p>Note： 一般来说，深复制并不简单。若对象有循环引用，算法会进入无限循环。 deepcopy会记住已经复制的对象， 因此能优雅的处理循环引用。</p><p>ex8 循环引用：b 引用 a， 然后追加到 a 中；deepcopy 会复制 a </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="number">10</span>, <span class="number">20</span>]</span><br><span class="line">b = [a, <span class="number">30</span>]</span><br><span class="line">a.append(b)</span><br><span class="line">a</span><br></pre></td></tr></table></figure><pre><code>[10, 20, [[...], 30]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line">c = deepcopy(a)</span><br><span class="line">c</span><br></pre></td></tr></table></figure><pre><code>[10, 20, [[...], 30]]</code></pre><p>此外，深复制有时可能太深了。例如，对象可能会引用不该复制的外部资源或单例值。我们可以实现特殊方法__copy__() 和 __deepcopy__() ,控制 copy 和 deepcopy 的行为，详情参见 <a href="https://docs.python.org/3/library/copy.html" target="_blank" rel="noopener">copy模块文档</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;变量是标注，不是盒子&quot;&gt;&lt;a href=&quot;#变量是标注，不是盒子&quot; class=&quot;headerlink&quot; title=&quot;变量是标注，不是盒子&quot;&gt;&lt;/a&gt;变量是标注，不是盒子&lt;/h3&gt;&lt;p&gt;ex1 变量a,b引用同一个列表，而非副本:&lt;/p&gt;
&lt;figure cla
      
    
    </summary>
    
      <category term="python" scheme="http://yoururl.com/categories/python/"/>
    
    
      <category term="python" scheme="http://yoururl.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>JSMA</title>
    <link href="http://yoururl.com/2018/03/12/JSMA/"/>
    <id>http://yoururl.com/2018/03/12/JSMA/</id>
    <published>2018-03-11T16:24:04.000Z</published>
    <updated>2018-03-12T12:35:04.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>作者：Andy_z<br>翻译文献：<a href="https://arxiv.org/abs/1511.07528" target="_blank" rel="noopener">The Limitations of Deep Learning in Adversarial Settings</a></p></blockquote><h1 id="1-emsp-研究一个简单的神经网络"><a href="#1-emsp-研究一个简单的神经网络" class="headerlink" title="1.&emsp;研究一个简单的神经网络"></a>1.&emsp;研究一个简单的神经网络</h1><h1 id="2-emsp-推广到前馈深度神经网络"><a href="#2-emsp-推广到前馈深度神经网络" class="headerlink" title="2.&emsp;推广到前馈深度神经网络"></a>2.&emsp;推广到前馈深度神经网络</h1><div class="table-container"><table><thead><tr><th>符号</th><th>注释</th></tr></thead><tbody><tr><td>$X$</td><td>良性样本</td></tr><tr><td>$X^*$</td><td>对抗样本</td></tr><tr><td>$Y^*$</td><td>目标输出</td></tr><tr><td>$F$</td><td>非循环前馈DNN</td></tr><tr><td>$γ$</td><td>最大失真参数  </td></tr><tr><td>$θ$</td><td>特征变化参数</td></tr></tbody></table></div><h2 id="2-1-emsp-算法1"><a href="#2-1-emsp-算法1" class="headerlink" title="2.1&emsp;算法1"></a>2.1&emsp;算法1</h2><p>&emsp;算法1显示了构建对抗样本的过程，经历三个基本过程</p><ul><li>计算正向导数 $∇F(X^*)$</li><li>基于导数构造显著图$S$</li><li>利用θ修改输入特征 $i_{max}$。重复该过程直到网络输出 $Y^*$ 或达到最大失真 $γ$</li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-12/13991477.jpg" alt=""></p><h3 id="2-1-1-emsp-深度神经网络的正向导数："><a href="#2-1-1-emsp-深度神经网络的正向导数：" class="headerlink" title="2.1.1&emsp;深度神经网络的正向导数："></a>2.1.1&emsp;深度神经网络的正向导数：</h3><p>&emsp;第一步是计算给定样本$X$ 的正向导数。如前所述，它由下式给出：</p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-12/58575062.jpg" alt=""></p><ul><li><p>对应于神经网络在训练过程中学习到的函数的雅可比矩阵。<br>正向导数计算梯度类似于反向传播计算梯度，但有两个重要的区别：<br>a. 直接取网络的导数，而不是取其代价函数，<br>b. 区分输入特征而不是网络参数。<br>不是向后传播梯度，而是向前传播它们，因为这样就可以找到导致网络输出发生重大变化的输入成分。</p></li><li><p>递归地区分每个隐藏层 $k∈2..n$</p></li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-12/68721235.jpg" alt=""><br>&emsp;&emsp;&emsp;其中$H<em>k$是隐藏层$k$的输出矢量，$f</em>{k,j}$ 是输出神经元$j$在$k$层的激活函数。</p><ul><li>应用链式规则，我们可以写出一系列关于 $k∈2..n$ 的公式</li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-12/51759725.jpg" alt=""></p><p>&emsp;&emsp;&emsp;因此可以表示 $\frac{\partial^{}{H_n}}{\partial {x_i}^{}}$  ,</p><ul><li>输出神经元$j$  表达式计算：<script type="math/tex; mode=display">F_j(X) = f_{n+1,j}(W_{n+1,j}\cdot H_n+b_{n+1,j})</script></li></ul><p>&emsp;&emsp;&emsp;再次应用链规则来获得：</p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-12/98084428.jpg" alt=""></p><h3 id="2-1-2-emsp-对抗显著图"><a href="#2-1-2-emsp-对抗显著图" class="headerlink" title="2.1.2&emsp;对抗显著图"></a>2.1.2&emsp;对抗显著图</h3><p>&emsp;构建对抗显著图。这些图表明攻击应该干扰哪些输入特征，以便最有效地实现网络输出的所需变化，并且是使攻击者能够产生大范围的对抗样本的多功能工具。</p><ul><li><p>用作分类器的网络，其输出是概率最大的类别，其中最终的预测类别值对应于具有最高概率的分量：</p><script type="math/tex; mode=display">label(X)=arg\,\min_jF_j(X)</script></li><li><p>显著图是基于正向导数的，因为这给攻击者神经网络错误分类给定样本的信息。<br>更确切地说，攻击者想要误分类样本$X$，分配 目标类别 $t≠label(X)$ 。 为此，必须增加由 $F$ 给出的目标类 $t$ 的概率 $F_t(X)$ ，而所有其他类 $j ≠ t$ 的概率 $F_j(X)$ 减小，直到</p><script type="math/tex; mode=display">t=arg\,\min_jF_j(X)</script><p>&emsp;&emsp;&emsp; 攻击者可以通过使用以下显著图 $S(X,t)$  来增加输入特征实现这一点：</p></li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-12/32845154.jpg" alt=""></p><ul><li>其中 $i$ 是输入特征。 第一行指定的条件会拒绝具有负目标导数或其他类的总体正导数的输入分量。<br>$\frac{\partial^{}{F<em>t(X)}}{\partial {X_i}^{}}$  应该为正，以便当特征 $X_i$ 增加时 $F_t(X)$ 增加。同时，${\sum</em>{j≠t}}\frac{\partial^{}{F_j(X)}}{\partial {X_i}^{}}$ 需要为负才能减少或保持不变。</li><li>第二行的结果允许我们把所有其他的正向导数分量一起考虑，这样可以很容易地比较 $S(X,t)[i]$ 的所有输入特征。</li><li><strong>$S(X,t)[i]$ 的高值对应于将增加目标类或者显着减少其他类或者两者皆有的输入特征。</strong> 通过增加这些特征，攻击最终将样本误分类到目标类别中。</li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-12/33588992.jpg" alt=""></p><pre><code>LeNet架构的784维输入的显着图。 784输入尺寸reshape为对应于28x28图像像素。大的绝对值对应于受干扰时对输出有显着影响的特征。</code></pre><ul><li>引入一个额外的图，它与方程式(8)中给出的相对应，通过寻找攻击者应该减少的特征来实现误分类。唯一的区别在于对正向导数值的约束以及第二行绝对值的位置：</li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-12/86366637.jpg" alt=""></p><h3 id="2-1-3-emsp-修改样本："><a href="#2-1-3-emsp-修改样本：" class="headerlink" title="2.1.3&emsp;修改样本："></a>2.1.3&emsp;修改样本：</h3><p>&emsp;一旦输入特征已经被对抗性显著图识别，就需要被扰乱以实现攻击者的目标。 这是算法1每次迭代的最后一步，所选特征被扰动的数量（算法1中的$θ$）也是问题特定的。 我们在之后讨论如何在计算机视觉应用中设置这个参数。 最后，通过参数 $γ$来指定最大迭代次数，这相当于样本中允许的最大失真。 它限制了改变的特征的数量以制造对抗样本，并且可以取任何小于特征数量的正整数值。找到正确的 $γ$ 值需要考虑人类对对抗样本的感知失真的影响,太多的失真可能会导致对抗样本容易被人类识别。</p><h1 id="3-emsp-方法应用"><a href="#3-emsp-方法应用" class="headerlink" title="3.&emsp;方法应用"></a>3.&emsp;方法应用</h1><p>&emsp;我们使用三种工具正式描述了一类由前馈DNN误分类的制作对抗样本的算法：正向导数，对抗显著图和制作算法。 我们现在将这些工具应用于用于计算机视觉分类任务的DNN：手写数字识别。 实验显示，我们的算法成功地将来自任何源类的对抗样本制作成任何给定目标类别，对于这个应用来说，这意味着任何数字可以被扰乱，使得它被误分类为任何其他数字。</p><h2 id="3-1-emsp-算法二"><a href="#3-1-emsp-算法二" class="headerlink" title="3.1&emsp;算法二"></a>3.1&emsp;算法二</h2><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-12/3583770.jpg" alt=""></p><p>&emsp;给定网络$F$，算法2通过扰动由saliency_map选择的 <strong>两个输入特征（即，像素强度）$p_1$ 和 $p_2$ 来迭代地修改样本</strong> 。 使用DNN的正向导数 $∇F(X^*)$ 在算法的每次迭代之间构建和更新显著图。 当满足以下条件之一时，该算法停止：</p><p>&emsp;&emsp;      （1）对抗样本被DNN分类为目标类别$t$<br>&emsp;&emsp;      （2）已达到最大迭代次数max_iter，<br>&emsp;&emsp;      （3）特征搜索域 $Γ$  是空的</p><p>&emsp;制作算法由三个参数进行微调：</p><ul><li><p>最大失真$γ$：这个定义了什么时候该算法应该停止修改样本以达到对抗目标类别。 以百分比表示的最大失真对应于制作对抗样本时要修改的像素的最大数量，并因此如下设置最大迭代次数 $max_iter=\frac{784.γ}{2.100}$ （每次迭代修改2个像素）：</p></li><li><p>显著图：子程序saliency_map生成一个图，定义哪个输入要素将在迭代过程中被修改。 用于生成显著图的策略随着所考虑的DNN所处理的数据的性质以及对抗目标而变化。 我们在后面的算法3中提供了一个子例程。</p></li><li><p><strong>每次迭代的特征变化$θ$</strong>：一旦使用显著图选择了输入特征，它们必须被修改。 引入这些特征的变化 $θ$ 是攻击者必须设置的另一个参数，与它使用的显著图一致。</p></li></ul><h2 id="3-2-emsp-策略一：通过增加像素强度来制作"><a href="#3-2-emsp-策略一：通过增加像素强度来制作" class="headerlink" title="3.2&emsp;策略一：通过增加像素强度来制作"></a>3.2&emsp;策略一：通过增加像素强度来制作</h2><p>&emsp;制作对抗样本的第一个策略是基于增加一些像素的强度。 为了达到这个目的，我们从MNIST测试集中选取了10个手写数字样本，每个数字类别从0到9。  所有像素强度以θ= +1增加。</p><ul><li>对抗显著图用来制作算法，选择可以增加的像素对，这是在等式(8)的一般分类情况下引入的图应用。该图旨在利用下面的heuristic算法去寻找像素对 $(p_1，p_2)$ :</li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-12/76963465.jpg" alt=""></p><p>&emsp;&emsp;&emsp;这种启发式搜索能够增加目标类输出的像素对，同时减少所有其他类输出的总和。</p><ul><li><p><strong>显著图考虑像素对而不考虑单个像素，因为一次选择一个像素太严格，并且很少像素满足公式8中描述的启发式搜索标准。</strong> 搜索像素对更可能匹配条件，因为 其中一个像素可以补偿另一个像素的微小缺陷。 我们来考虑一个简单的例子：$p_1$的目标导数为5，其他类的导数总和等于0.1，而 $p_2$ 作为目标导数等于-0.5，其他类导数的总和等于-6。 单独地，这些像素与公式(8)中所述的显著图的标准不匹配，但是组合起来，该对确实与公式(10)中定义的显着性标准匹配。</p></li><li><p>算法3给出了相应的子程序saliency_map的伪代码。</p></li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-12/78631019.jpg" alt=""></p><p>&emsp;该算法能够为所有90个源 - 目标类对创建成功的对抗样本。</p><ul><li>下图显示了获得的90个对抗样品以及用于制造它们的10个原始样品。</li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-12/22786902.jpg" alt=""></p><pre><code>原始样本在对角线上找到。 行i和列j上的样本，当i ≠ j时，是从最初被归类为源类别i的图像制作的样本，将被错误分类为目标类别j。</code></pre><ul><li>在空输入（所以像素设置为0强度）上运行制作算法，并针对从0到9的每个类别制作一个对抗样本。下所示的不同样本展示了对抗显著图如何识别与一个类中分类有关的输入特征：</li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-12/10161483.jpg" alt=""></p><pre><code>有趣的是，对于类别0，2，3和5可以清楚地识别目标数字。</code></pre><h2 id="3-3-emsp-策略二：通过降低像素强度来制作"><a href="#3-3-emsp-策略二：通过降低像素强度来制作" class="headerlink" title="3.3&emsp;策略二：通过降低像素强度来制作"></a>3.3&emsp;策略二：通过降低像素强度来制作</h2><p>&emsp;第二种对抗策略通过 $θ=-1$ 来减小像素强度。 与公式(10)中所写的公式相同，但约束条件不同：乘法运算的左操作数现在被约束为负，右操作数为正。 在本文前面的章节中也会介绍这种启发式算法，它可以搜索使目标类输出增加，同时减少所有其他类输出总和的像素对。</p><ul><li>该算法能够为所有源 - 目标类对创建成功的对抗样本。 下图显示了获得的90个对抗样品以及用于制造它们的10个原始样品。 要观察的是，通过降低像素强度引入的失真似乎很难被人眼检测到。</li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-12/83317984.jpg" alt=""></p><h1 id="4-emsp-评估"><a href="#4-emsp-评估" class="headerlink" title="4.&emsp;评估"></a>4.&emsp;评估</h1><h2 id="4-1-emsp-生成大量对抗样本"><a href="#4-1-emsp-生成大量对抗样本" class="headerlink" title="4.1&emsp;生成大量对抗样本"></a>4.1&emsp;生成大量对抗样本</h2><p>&emsp;设计一组实验来评估MNIST数据集中的所有合法样本是否可以被攻击者利用来产生对抗样本。</p><h3 id="4-1-1-emsp-实验设计"><a href="#4-1-1-emsp-实验设计" class="headerlink" title="4.1.1&emsp;实验设计"></a>4.1.1&emsp;实验设计</h3><ul><li><p>样本集：<br>我们在三组10,000个样本上运行我们的制作算法，每个样本提取自三个MNIST训练，验证和测试集中的一个。对于这些样本中的每一个，我们制作了9个对立样本，每个样本都归类于与原始类别不同的9个目标类别之一。因此，我们为每组生成了9万个样本，总共有27万个对抗样本。</p></li><li><p>参数设置：<br>我们将最大失真设为 $γ= 14.5％$ ，像素强度增加 $θ= + 1$。</p></li><li><p>评价指标：<br>a. 成功率$τ$被定义为由DNN成功分类为对抗目标类别的对抗样本的百分比。<br>b. 失真被定义为在合法样本中修改以获得对抗样本的像素的百分比。换句话说，就是为了获得对抗样本而修改的输入特征的百分比。</p></li></ul><h3 id="4-1-2-emsp-实验结果与讨论"><a href="#4-1-2-emsp-实验结果与讨论" class="headerlink" title="4.1.2&emsp;实验结果与讨论"></a>4.1.2&emsp;实验结果与讨论</h3><p>&emsp;我们计算两个平均失真值：一个考虑所有样本，另一个考虑成功的样本:</p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-12/61993056.jpg" alt=""></p><ul><li><p>平均成功率为$97.10％$，所有对抗样本的平均失真率为$4.44％$，成功对抗样本的平均失真率为 $4.02％$ 。<br>这意味着为了制作成功的对抗样本而修改的像素的平均数量是784个像素中的32个。<br>第一个失真数字较高，因为它包含了不成功的样本。</p></li><li><p>我们还研究了使用降低显著图制作9,000个对抗样本。 我们发现成功率 $τ= 64.7％$ 较低，平均失真 $ε= 3.62％$ 略低。<br>同样，减小像素强度在产生期望的对抗行为方面不如递增像素强度成功。 直觉上，这可以理解，因为消除像素减少了信息熵，从而使DNN难以提取分类样本所需的信息。 强度变化的绝对值越大，DNN越可靠地错误分类。</p></li></ul><h2 id="4-2-emsp-量化硬度和建立防御机制"><a href="#4-2-emsp-量化硬度和建立防御机制" class="headerlink" title="4.2&emsp;量化硬度和建立防御机制"></a>4.2&emsp;量化硬度和建立防御机制</h2><p>&emsp;在前面的实验中，270,000个对抗样本中约有2.9％没有成功制作。这表明有些样本比其他样本更难开发。<br>&emsp;此外，所报告的失真数据在所有对抗样本上取平均值，但不是所有样本都需要相同的失真才能被错误分类。<br>因此，我们现在研究不同样品的硬度以量化这些现象。 我们的目标是确定哪些源 - 目标类对最容易被利用，以及不同的源 - 目标类对之间的相似性。 类对是一对源类和目标类。 这个硬度指标使我们能够为建立防御机制奠定基础。</p><h3 id="4-2-1-emsp-类对研究"><a href="#4-2-1-emsp-类对研究" class="headerlink" title="4.2.1&emsp;类对研究"></a>4.2.1&emsp;类对研究</h3><ul><li>使用前面实验中制作的9万个对抗样本，从10,000个样本 的MNIST测试集。</li><li>在下图中，我们绘制成功率矩阵，表示哪对最成功。 <strong>较深的阴影对应于较高的成功率</strong> 。这些行对应于每个源类的成功率，而列对应于每个目标类的成功率。</li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-12/87138047.jpg" alt="">  </p><pre><code>如果按行读取矩阵，可以感觉到类0，2和8很难制作，而类1，7和9很容易制作。 类似地，按照列的方式读取矩阵，可以看出，类1和类7很难制作，而类0,8和9容易制作。</code></pre><ul><li>下图，报告了源 - 目标类对的 <strong>成功样本的平均失真ε</strong></li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-12/1594025.jpg" alt=""></p><ul><li>有趣的是，<strong>需要较低失真的类对应于前一个矩阵中成功率较高的类</strong> 。 例如，对应于等级1的列与最高失真相关联，并且是前一个矩阵中成功率最低的列。 实际上，<strong>类对的平均失真越高，该类对中的样本越有可能达到最大失真，从而产生不成功的对抗样本</strong> 。</li></ul><h3 id="4-2-2-emsp-硬度测量"><a href="#4-2-2-emsp-硬度测量" class="headerlink" title="4.2.2&emsp;硬度测量"></a>4.2.2&emsp;硬度测量</h3><p>&emsp;分析结果表明一些源 - 目标类对不如其他类容易制作对抗样本。 这与防御者有关，他们正在寻找哪一类DNN最容易遭受对抗攻击。我们将这一指标称为<strong>目标类别相对于给定源类别的硬度</strong>。 它将类对 $(s，t)$ 的平均失真相对于其成功率进行标准化：</p><script type="math/tex; mode=display">H(s,t)=\int_τ {ε(s, t, τ )} \,{\rm d}τ</script><p>&emsp;其中 $ε(s，t，τ)$ 是相应成功率 $τ$ 的一组样本的平均失真。<br>&emsp;最大失真的集合给出了一系列 $k∈1..K$  的对 $(εk，τk)$。因此，用于计算源 - 目标类对的硬度的实际公式可以从梯形规则导出：</p><script type="math/tex; mode=display">H(s,t)≈\sum_{k=1}^{K-1}\;(τ_{k+1}-τ_k)\,\frac{ε(s, t, τ_{k+1}) + ε(s, t, τ_k)}{2}</script><ul><li><p>我们使用算法中的一组 $K = 9$ 的最大失真值<br>$Υ∈{0.3,1.3,2.6,5.1,7.7,10.2,12.8,25.5,38.3}％$ 计算所有类别的硬度值。 对于每个最大失真值$Y$，平均失真$ε$和成功率$τ$在9,000个对抗样本上被平均。</p></li><li><p>下图显示了所有类对 $(s, t) ∈ {0..9}^<br>2$ 的硬度值 $H(s,t)$。<br>源 - 目标类对的硬度矩阵。较深阴影对应难以实现错误分类的样本。</p></li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-12/37082866.jpg" alt=""></p><pre><code>观察到矩阵的形状与上图中绘制的平均失真矩阵类似。但是，硬度测量更精确，因为它使用一系列最大失真。</code></pre><h3 id="4-2-3-emsp-对抗距离"><a href="#4-2-3-emsp-对抗距离" class="headerlink" title="4.2.3&emsp;对抗距离"></a>4.2.3&emsp;对抗距离</h3><p>&emsp;样本$X$到类别$t$的对抗距离，并将其写为$A(X，t)$。 它估计样本 $X$ 和目标分类之间的距离。 我们将距离定义为：</p><script type="math/tex; mode=display">A(X,t)=1-\frac{1}{M}\,\sum_{i∈0..M}{1_{S(X,t)[i]>0}}</script><p>&emsp;其中 $1_E$ 是事件 $E$ 的指示函数（即当且仅当 $E$ 为真时为1）。 简而言之，$A(X,t)$ 是在算法2的第一次迭代中计算的 $X$ 的对抗显著图中的非零元素的归一化数目。对抗距离越接近 1，样本 $X$ 在目标分类 $t$ 中将更难以错误分类。</p><ul><li>图15：使用1000个样本计算的,每个源 - 目标类对的 平均对抗距离。</li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-12/60081174.jpg" alt=""></p><p>&emsp;上图证实了这个公式是凭经验确定的。它说明了每个源 - 目标类对的平均对抗距离的值，使得可以很容易地将平均值与硬度矩阵进行比较。 为了计算它，我们稍微改变公式，以对特征对进行求和，反映我们在验证过程中所做的观察。</p><ul><li>这种类间距离的概念直观地定义了网络F与对抗性扰动的鲁棒性的度量。 建议如下定义：<script type="math/tex; mode=display">R(F)=\min_{(X,t)}\,A(X,t)</script></li></ul><h2 id="4-3-emsp-研究人类对对抗样本的感知"><a href="#4-3-emsp-研究人类对对抗样本的感知" class="headerlink" title="4.3&emsp;研究人类对对抗样本的感知"></a>4.3&emsp;研究人类对对抗样本的感知</h2><p>&emsp;对抗样本不仅要被深度神经网络误分类为目标类别，而且还要在视觉上被人类分类为源类别。</p><ul><li><p>第一个实验旨在确定输入数据的基线感知率。<br>从原始MNIST数据集中的222个未改变的样本中随机挑选了3个呈现给74个参与者。 参与者将97.4％的样本确定为数字，正确分类95.3％的数字样本。</p></li><li><p>第二组实验试图评估失真量（$ε$）如何影响人的感知。 在这里，184名参与者被呈现总共1707个不同程度的失真（强度增加$θ= + 1$）样本。 实验显示，在低于阈值（ $ε= 14.29％$ 变形）的情况下，参与者能够将样本确定为数字（95％），并且正确地将它们分类（90％），准确度略微低于未改变的样本。 在高于阈值的失真率下，分类率急剧下降（71％）。</p></li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-12/29250443.jpg" alt=""></p><ul><li>最后一组实验评估了强度变化（$θ$）对感知的影响，如图17所示.203名参与者准确地确定了5,355个样本数字（96％）并正确分类（95％）。 在绝对强度较高（$θ= -1$ 和 $θ= +1$ ）时，特定的数字分类略有下降（90.5％和90％），但是数字的识别基本没有变化。</li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-12/64566307.jpg" alt=""></p><pre><code>改变特征失真强度提供了更好的结果：在-0.7≤θ≤+ 0.7时，人类以基本上与原始样本数据相同的速率对样本数据进行分类。</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;作者：Andy_z&lt;br&gt;翻译文献：&lt;a href=&quot;https://arxiv.org/abs/1511.07528&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;The Limitations of Deep Learning
      
    
    </summary>
    
      <category term="对抗攻击" scheme="http://yoururl.com/categories/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/"/>
    
    
      <category term="Deep learning" scheme="http://yoururl.com/tags/Deep-learning/"/>
    
      <category term="Adversarial attack" scheme="http://yoururl.com/tags/Adversarial-attack/"/>
    
      <category term="Translation" scheme="http://yoururl.com/tags/Translation/"/>
    
  </entry>
  
  <entry>
    <title>test</title>
    <link href="http://yoururl.com/2018/03/08/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB%E7%BB%BC%E8%BF%B01%EF%BC%9A%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E4%BA%A7%E7%94%9F%E4%B8%8EFGSM%E5%8E%9F%E7%90%86/"/>
    <id>http://yoururl.com/2018/03/08/对抗攻击综述1：对抗样本产生与FGSM原理/</id>
    <published>2018-03-08T10:38:04.000Z</published>
    <updated>2018-03-12T10:53:56.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="对抗攻击综述-1-：对抗样本产生与FGSM原理"><a href="#对抗攻击综述-1-：对抗样本产生与FGSM原理" class="headerlink" title="对抗攻击综述(1)：对抗样本产生与FGSM原理"></a>对抗攻击综述(1)：对抗样本产生与FGSM原理</h1><blockquote><p>作者：Andy_z<br>阅读文献：<a href="https://arxiv.org/abs/1412.6572" target="_blank" rel="noopener">EXPLAINING AND HARNESSING ADVERSARIAL EXAMPLES</a></p></blockquote><h2 id="1-emsp-对抗样本的线性解释"><a href="#1-emsp-对抗样本的线性解释" class="headerlink" title="1 &emsp;对抗样本的线性解释"></a>1 &emsp;对抗样本的线性解释</h2><p>&emsp;<strong>在许多问题中，单个输入特征的精度是有限的。</strong></p><ul><li>例如，数字图像每个像素通常只使用8位，因此它们会丢弃低于动态范围1/255的所有信息。  </li><li>如果扰动 $η$ 的每个元素小于特征的精度，则分类器对输入$x$和对抗输入 $x ̃=x+η$ 产生相同结果。<br>存在足够小的 $ε$，只要 $‖η‖_∞&lt;ε$，分类器就会分配给$x$和$x ̃$相同的类。  </li></ul><p>&emsp;考虑一个权值向量 $w$ 和一个对抗样本 $x ̃$ 的点积：  </p><script type="math/tex; mode=display">w^Tx ̃=w^Tx+w^Tη</script><ul><li><p>对抗扰动导致激活增长 $w^Tη$ 。令 $η=sign(w)$ ，我们可以最大化这个增量。 如果 $n$ 维权重向量 $w$ 的元素的平均值是 $m$ ，则激活将增加 $εmn$ 。  </p><blockquote><font color="#0099ff" size="2" face="黑体">[^_^]: 令扰动 $η$ 和权值向量 $w$ 各元素的符号相同，内积    $w^Tη$ 可最大化</font>  </blockquote></li><li><p>由于 $‖η‖_∞$ 不随维数变化而变化，但扰动 $η$ 引起的激活变化 $εmn$ 可随 $n$ 增加而线性增加。因此对于高维问题，对输入进行许多无限小的变化， 输出会产生一次大的变化。  </p></li></ul><p>&emsp;这个解释表明，<strong>如果一个简单的线性模型的输入具有足够的维度，它可能会有对抗样本。</strong> 基于线性的假设更简单，也可以解释为什么softmax回归容易受到对抗样本的影响。</p><picture><blockquote><p><a href="http://blog.csdn.net/Suan2014/article/details/77162042" target="_blank" rel="noopener">激活函数</a>:Sigmoid,Tanh,ReLu,softplus,softmax</p></blockquote><h2 id="2-emsp-非线性模型的线性扰动"><a href="#2-emsp-非线性模型的线性扰动" class="headerlink" title="2 &emsp;非线性模型的线性扰动"></a>2 &emsp;非线性模型的线性扰动</h2><p>&emsp;对抗样本的线性视图提出了一种快速生成对抗样本的方法。<br>&emsp;更复杂的非线性模型如sigmoid网络经过仔细调整，将其大部分时间花费在非饱和，更线性的机制中，因而也会受到对抗扰动。</p><ul><li>快速梯度符号法（FGSM）：<picture></picture></li></ul><div class="table-container"><table><thead><tr><th>符号</th><th>说明</th></tr></thead><tbody><tr><td>$θ$</td><td>模型参数</td></tr><tr><td>$x$</td><td>模型输入</td></tr><tr><td>$y$</td><td>关于x的目标</td></tr><tr><td>$J(θ,x,y)$</td><td>损失函数  </td></tr></tbody></table></div><p>&emsp;将损失函数线性化为  $θ$ 的当前值，得到最优的最大范数约束扰动</p><script type="math/tex; mode=display">η=εsign(∇_xJ(θ,x,y))</script><p>&emsp;称之为产生对抗样本的“快速梯度符号法”。 请注意，可以使用反向传播有效地计算所需的梯度。  </p><ul><li>FGSM在各种模型上的效果 :  </li></ul><div class="table-container"><table><thead><tr><th>$ε$</th><th>0.25</th><th>0.25</th><th>0.1</th></tr></thead><tbody><tr><td>测试集</td><td>MNIST</td><td>MNIST</td><td>CIFAR-10预</td></tr><tr><td>分类器</td><td>softmax</td><td>maxout</td><td>maxout</td></tr><tr><td>错误率</td><td>99.9％</td><td>89.4％</td><td>87.15％</td></tr><tr><td>平均置信度</td><td>79.3％</td><td>97.6％</td><td>96.6％</td></tr></tbody></table></div><blockquote><p><a href="https://github.com/lisa-lab/pylearn2/tree/master/pylearn2/scripts/papers/maxout" target="_blank" rel="noopener">预处理代码</a>: 其产生大约0.5的标准偏差。</p></blockquote><p>&emsp;其他生成对抗样本的简单方法也是可能的。 例如，我们还发现<strong>在梯度方向上以小角度旋转</strong> $x$ 也能可靠地产生对抗样本。</p><ul><li>在ImageNet上应用GoogLeNet的快速对抗样本生成演示：  </li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-10/67792085.jpg-Watermark" alt=""><br>对抗样本：</p><script type="math/tex; mode=display">x ̃=x+εsign(∇_xJ(θ,x,y))</script><picture><p>&emsp;通过添加一个不可察的小矢量，其元素等于损失函数梯度的元素的符号，可以改变GoogLeNet的图像分类。这里，$ε$ 对应于GoogLeNet转换为实数后8位图像编码的最小位数的大小， 因等于0.007。  </p><h2 id="3-emsp-反对权值衰减的线性模型对抗训练"><a href="#3-emsp-反对权值衰减的线性模型对抗训练" class="headerlink" title="3.&emsp;反对权值衰减的线性模型对抗训练"></a>3.&emsp;反对权值衰减的线性模型对抗训练</h2><p>&emsp;可以考虑的最简单的模型是逻辑回归。 在这种情况下，快速梯度符号方法是准确的。 通过案例来了解如何在简单的设置中生成对抗样本。  </p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-10/83037047.jpg-Watermark" alt=""></p><p>&emsp;图2：应用于逻辑回归的FGSM<br>&emsp;a）在MNIST上训练的逻辑回归模型的权重。<br>&emsp;b）在MNIST上训练的逻辑回归模型的权重的符号。 这是最佳的扰动。 尽管该模型的容量较低并且很适合，但这种扰动不容易被人察觉。<br>&emsp;c）MNIST数据集中的 3和 7 样本。 在这些例子中，逻辑回归模型在3与7的区分任务上有1.6％的错误率。<br>&emsp;d）Logistic回归模型的FGSM对抗样本，$ε=0.25$ 。 在这些样本中，逻辑回归模型的误差率为99％。</p><ul><li>如果训练一个简单的模型来识别标签 $y∈{-1,1}$  ，其中  <script type="math/tex; mode=display">P(y=1)=σ(w^Tx+b)</script>&emsp; $σ(z)$ 是逻辑sigmoid函数，使用梯度下降法训练，<script type="math/tex; mode=display">E_{x,y∽p_{data}}ζ(-y(w^Tx+b))</script>&emsp;其中 $ζ(z)=log(1+exp(z))$ 是softplus方程。根据梯度符号扰动，可以推导出一个简单的分析形式，用于训练 $x$ 的最坏情况对抗扰动，而不是 $x$ 本身。 请注意，梯度的符号只是 $-sign(x)$ ，而 $w^Tsign(w)=‖w‖_1$ 。 逻辑回归的对抗版本因此最小化为：  <script type="math/tex; mode=display">E_{x,y∽p_{data}}ζ(y(ε‖w‖_1-w^Tx-b))</script>&emsp;这与 $L^1$ <a href="http://blog.csdn.net/jinping_shi/article/details/52433975" target="_blank" rel="noopener">正则化</a>有些相似。 但是，有一些重要的区别。</li></ul><blockquote><font color="#0099ff" size="2" face="黑体"> [正则化]:采用正则化方法会自动削弱不重要的特征变量，自动从许多的特征变量中”提取“重要的特征变量，减小特征变量的数量级。这个方法非常有效，当我们有很多特征变量时，其中每一个变量都能对预测产生一点影响。</font></blockquote><ul><li>最重要的是，在训练期间将 $L^1$ 惩罚从模型的激活中减去，而不是增加到训练损失。 这意味着如果模型学习 $ζ$ 饱和充分置信，惩罚最终会开始消失。 这并不一定会发生 - 在欠拟合下，对抗训练只会使得更加欠拟合。 因此，我们可以将 $L^1$ <a href="https://www.cnblogs.com/lindaxin/p/7998334.html" target="_blank" rel="noopener">权值衰减</a>视为比对抗训练更坏的情况，因为它在好的边界不能解除激活。</li></ul><blockquote><font color="#0099ff" size="2" face="黑体"> [权值衰减]：在每次迭代过程中以某个小因子降低每个权值，这等效于修改E的定义，加入一个与网络权值的总量相应的惩罚项。此方法的动机是保持权值较小，避免weight decay,从而使学习过程向着复杂决策面的反方向偏。</font>  </blockquote><ul><li>如果我们将逻辑回归移出多分类softmax回归， $L^1$ 权重衰减变得更加严重，因为它将每个softmax的输出视为独立扰动，事实上，通常不可能找到与所有类的权重向量相关联的 $η$ 。在具有多个隐藏单元的深度网络的情况下，权重衰减高估了扰动可实现的损害。由于 $L^1$ 权重衰减高估了攻击可以造成的伤害量，因此有必要使用比与我们的特征精度相关联的 $ε$ 更小的 $L^1$ 权重衰减系数。</li><li>当在MNIST上训练maxout网络时，我们使用对抗训练获得了良好的结果 。当 权重衰减应用于第一层时，我们发现 $ε=0.0025$的系数太大，也会导致模型在训练集上超过5％的误差。较小的重量衰减系数可以实现成功训练，但没有获得正则化的效果。</li></ul><blockquote><p><a href="http://blog.csdn.net/hjimce/article/details/50414467" target="_blank" rel="noopener">maxout</a></p></blockquote><h2 id="4-emsp-深度网络的对抗训练"><a href="#4-emsp-深度网络的对抗训练" class="headerlink" title="4&emsp;深度网络的对抗训练"></a>4&emsp;深度网络的对抗训练</h2><p>&emsp;与浅层线性模型不同，深层网络至少能够体现抵抗对抗扰动的功能。<a href="https://www.jianshu.com/p/52e773d47338" target="_blank" rel="noopener">泛逼近理论</a>表示，只要隐藏层允许有足够的单元，具有至少一个隐藏层的神经网络可以表示任意精度的任何函数。 浅层线性模型不能在训练点附近变得恒定，同时也对不同的训练点产生不同的输出。</p><ul><li>作者发现基于FGSM的对抗目标函数训练是一种有效的正则化方法：<script type="math/tex; mode=display">J ̃(θ,x,y)=αJ(θ,x,y)+(1-α)J(θ,x+εsign(∇_xJ(θ,x,y)))</script>&emsp;在所有的实验中，使用 $α=0.5$。 用这种方法来训练一个<strong>被<a href="http://blog.csdn.net/hjimce/article/details/50413257" target="_blank" rel="noopener">dropout</a>规范化的maxout网络</strong>：</li></ul><div class="table-container"><table><thead><tr><th>模型是否经过对抗训练</th><th>未经过</th><th>经过</th></tr></thead><tbody><tr><td>错误率</td><td>0.94％</td><td>0.84％  </td></tr></tbody></table></div><p>&emsp;观察到在训练集上的对抗样本中没有达到零错误率。作者通过进行两项更改来解决这个问题。首先，使模型更大，每层使用1600个单元，而不是原来的maxout网络使用的240个单元，使用<a href="https://deeplearning4j.org/cn/earlystopping" target="_blank" rel="noopener">early stopping</a>，并且当验证集错误率经过100个周期后未减少时终止学习。实验发现：  </p><ul><li>如果没有对抗训练，会导致模型轻微过拟合，并在测试集中获得1.14％的错误率  </li><li>通过对抗训练，验证集错误率随着时间的推移而趋于平稳，并且进展缓慢。<br>虽然验证集错误非常平坦，但对抗验证集错误不是。  </li></ul><p>&emsp;因此，我们对对抗验证集误差使用了early stopping。用这个标准选择训练的周期数量，对所有60,000个样本进行再训练。对于随机数发生器使用不同的<a href="http://blog.csdn.net/linzch3/article/details/58220569" target="_blank" rel="noopener">seed</a>进行五次不同的训练，用于选择训练样本的mini_batches，初始化模型权重以及生成五个实验的dropout，  </p><blockquote><font color="#0099ff" size="2" face="黑体">seed() 用于指定随机数生成时所用算法开始的整数值，如果使用相同的seed()值，则每次生成的随即数都相同，如果不设置这个值，则系统根据时间来自己选择这个值，此时每次生成的随机数因时间差异而不同。</font>  </blockquote><div class="table-container"><table><thead><tr><th>实验对比</th><th>1-4</th><th>5</th><th>MNIST排列不变版本</th><th>微调DBM</th></tr></thead><tbody><tr><td>误差率</td><td>0.77％</td><td>0.83％</td><td>0.782％</td><td>0.79％   </td></tr></tbody></table></div><ul><li>对抗训练过的模型表现出更强的鲁棒性。  </li></ul><div class="table-container"><table><thead><tr><th>对抗样本生成来源</th><th>原始模型</th><th>原始模型</th><th>dropour规范化新模型</th></tr></thead><tbody><tr><td>识别模型</td><td>原始模型</td><td>对抗训练模型</td><td>原始模型</td></tr><tr><td>错误率</td><td>89.4%</td><td>19.6％</td><td>40.9%  </td></tr></tbody></table></div><ul><li>学习模型的权重发生了显着变化，对抗训练模型的权重明显更加局部化和可解释</li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-10/65793832.jpg-Watermark" alt=""></p><p>图3：在MNIST上训练的maxout网络的权重可视化。 每行显示单个maxout单元的过滤器。 左）原始模型。 右）对抗训练过的模型。</p><ul><li>事实上，在许多情况下，噪声会导致较低的目标函数值。 可以将对抗训练视为在噪声输入集合中进行硬性样本挖掘，以便通过仅考虑强烈抵制分类的那些噪点来更有效地进行训练。</li></ul><p>&emsp;作为控制实验，作者训练了一个带有噪声的maxout网络，每个像素被随机添加噪声 $±ε$，或者将 $U∈(-ε,ε)$ 中的噪声添加到每个像素。<br>&emsp;在FGSM对抗样本中的分类情况：</p><div class="table-container"><table><thead><tr><th>噪声类型</th><th>1</th><th>2</th></tr></thead><tbody><tr><td>错误率</td><td>86.2%</td><td>90.4%</td></tr><tr><td>置信度</td><td>97.3%</td><td>97.8%  </td></tr></tbody></table></div><h2 id="5-emsp-不同种类的模型容量"><a href="#5-emsp-不同种类的模型容量" class="headerlink" title="5&emsp;不同种类的模型容量"></a>5&emsp;不同种类的模型容量</h2><p>&emsp;对抗样本的存在似乎与直觉相反的一个原因是，我们大多数人对高维空间的直觉很差。 我们生活在三个维度中，所以我们不习惯在数百个维度中添加小的扰动来产生巨大的效果。 还有另一种方式，我们的直觉不能很好的为我们服务。 许多人认为低容量的模型无法做出许多不同的置信预测。这是不正确的。</p><ul><li><p>符合直觉的低容量模型，例如浅层RBF网络：</p><script type="math/tex; mode=display">p(y=1|x)=exp({(x-μ)^T}β(x-μ))</script><p>只能有把握地预测在 $μ$ 附近存在正类。 在其他地方，它们默认预测类别不存在，或者具有低置信度的预测。  </p></li><li><p>RBF网络自然不受对抗样本的影响，因为当它们被愚弄时，置信度很低。 使用FGSM生成的对抗样本，$ε=0.25$ ，没有隐藏层的浅RBF网络在MNIST上获得55.4％的错误率。 然而，它对错误样本的置信度只有1.2％。 它对干净测试样本的平均置信度是60.6％。 我们不能指望一个容量如此低的模型在空间的所有点上都能得到正确的答案，但它确实可以通过在它无法识别的点上大大减少置信度，从而做出相对正确的回应。</p></li><li><p>但是，RBF单元对于任何重要的转换都不是不变的，所以它们不能一概而论。 我们可以将线性单元和RBF单元视为准确-召回权衡曲线上的不同点。 线性单位通过响应某个方向上的每个输入来实现高召回率，但由于在不熟悉的情况下响应过强可能会导致精度低。 RBF单元通过仅响应空间中的特定点来实现高精度，但是这样做会牺牲召回率。  </p></li></ul><h2 id="6-emsp-对抗样本的泛化能力"><a href="#6-emsp-对抗样本的泛化能力" class="headerlink" title="6&emsp;对抗样本的泛化能力"></a>6&emsp;对抗样本的泛化能力</h2><p>&emsp;对抗样本的一个有趣方面是，<strong>为其中一个模型生成的样本经常能被其他模型错误分类，即使它们具有不同的架构或在不相交的训练集上进行训练。 而且，当这些不同的模型将一个对抗样本错误分类时，他们经常会归为同一类。</strong> 基于极端非线性和过度拟合的解释不能轻易解释这种行为 - 为什么多余的容量过剩的极端非线性模型始终以相同的方式标记分布外的点？ 这种行为尤其令人惊讶，从这样的假设来看，对抗样本就像实数空间中的有理数分布，因为在这种观点中，对抗样本很常见，但只发生在非常精确的位置。</p><ul><li><p>在线性观点下，对抗样本出现在宽泛的子空间中。 方向 $η$ 只需要具有损失函数梯度的正点积， $ε$ 只需要足够大。 图4显示了这种现象。 通过追踪出不同的值 $ε$  ，我们发现对抗样本出现在由FGSM方法定义的1-D子空间的连续区域中，而不是离散的。 这就解释了为什么对抗样本非常丰富，为什么一个分类器错误分类的样本具有相当高的可能性被另一个分类器错误分类。</p><picture></picture></li><li><p>为了解释为什么多个分类器将对抗样本分类为同一个类，我们假设用当前方法训练的神经网络都类似于在相同训练集上学习的线性分类器。 这个参考分类器在训练集的不同子集上训练时能够学习大致相同的分类权重，这仅仅是因为机器学习算法能够泛化。 基础分类权重的稳定性反过来又会导致对抗样本的稳定性。</p></li></ul><p>&emsp;为了检验这个假设，我们在深度maxout网络上生成了对抗样本，并使用浅softmax网络和浅RBF网络对这些样本进行了分类。在由maxout网络误分类的样本中，</p><div class="table-container"><table><thead><tr><th>分类模型</th><th>softmax网络</th><th>浅层RBF网络</th></tr></thead><tbody><tr><td>预测</td><td>54.6%</td><td>16.0%</td></tr><tr><td>回归预测</td><td>84.6%</td><td>54.3%</td></tr></tbody></table></div><p>&emsp;这些数字很大程度上是由不同模型的差错率驱动的。如果我们不把注意力放在两种模型比较出错的情况下，softmax回归预测84.6％的时间是maxout类别，而RBF网络只能预测maxout类别的时间为54.3％。为了比较，RBF网络可以预测softmax回归的时间为53.6％，所以它对自己的行为确实具有强大的线性分量。我们的假设并不能解释所有maxou网络的错误或者所有模型中泛化的错误，但很明显，其中很大一部分与线性行为一致是跨模型泛化的主要原因。</p><h2 id="7-emsp-讨论总结"><a href="#7-emsp-讨论总结" class="headerlink" title="7&emsp;讨论总结"></a>7&emsp;讨论总结</h2><ul><li><p>对抗样本可以解释为高维点积的一个特性。 它们是模型过于线性而非非线性的结果。</p></li><li><p>横跨不同模型的对抗样本的泛化可以解释为对抗扰动与模型的权重向量高度一致，并且不同模型在被训练执行相同任务时学习相似函数。</p></li><li><p>扰动的方向，而不是空间中的特定点。 空间并不是充满了对抗样本，它们像实数中的有理数一样分布。</p></li><li>因为它是最重要的方向，所以对抗干扰会在不同的干净样本上泛化。</li><li>我们引入了一系列快速生成对抗样本的方法。</li><li>我们已经证明，对抗训练可以导致正则化; 甚至比dropout更加正则化。</li><li>我们的运行控制实验未能用更简单但效率更低的正则化器重现此效应，包括 $L^1$ 权重衰减和增加噪音。</li><li>易于优化的模型易于受到干扰。</li><li>线性模型缺乏抵抗对抗扰动的能力; 只有具有隐藏层的结构（泛逼近定理适用）应该被训练来抵抗对抗扰动。</li><li>RBF网络对对抗样本有抗性。</li><li>训练模型化输入分布的模型不能抵抗对抗样本。</li><li>集成方法不能抵抗对抗样本。</li></ul></picture></picture>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;对抗攻击综述-1-：对抗样本产生与FGSM原理&quot;&gt;&lt;a href=&quot;#对抗攻击综述-1-：对抗样本产生与FGSM原理&quot; class=&quot;headerlink&quot; title=&quot;对抗攻击综述(1)：对抗样本产生与FGSM原理&quot;&gt;&lt;/a&gt;对抗攻击综述(1)：对抗样本产生与
      
    
    </summary>
    
      <category term="对抗攻击" scheme="http://yoururl.com/categories/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/"/>
    
    
      <category term="Deep learning" scheme="http://yoururl.com/tags/Deep-learning/"/>
    
      <category term="Adversarial attack" scheme="http://yoururl.com/tags/Adversarial-attack/"/>
    
      <category term="Translation" scheme="http://yoururl.com/tags/Translation/"/>
    
  </entry>
  
  <entry>
    <title>FGSM</title>
    <link href="http://yoururl.com/2018/03/08/The-Adversarial-Attacks-on-Deep-Learning-A-Summary-1/"/>
    <id>http://yoururl.com/2018/03/08/The-Adversarial-Attacks-on-Deep-Learning-A-Summary-1/</id>
    <published>2018-03-08T10:38:04.000Z</published>
    <updated>2018-03-12T13:06:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="对抗攻击综述-1-：对抗样本产生与FGSM原理"><a href="#对抗攻击综述-1-：对抗样本产生与FGSM原理" class="headerlink" title="对抗攻击综述(1)：对抗样本产生与FGSM原理"></a>对抗攻击综述(1)：对抗样本产生与FGSM原理</h1><blockquote><p>作者：zjj<br>阅读文献：<a href="https://arxiv.org/abs/1412.6572" target="_blank" rel="noopener">EXPLAINING AND HARNESSING ADVERSARIAL EXAMPLES</a></p></blockquote><h2 id="1-emsp-对抗样本的线性解释"><a href="#1-emsp-对抗样本的线性解释" class="headerlink" title="1 &emsp;对抗样本的线性解释"></a>1 &emsp;对抗样本的线性解释</h2><p>&emsp;<strong>在许多问题中，单个输入特征的精度是有限的。</strong></p><ul><li>例如，数字图像每个像素通常只使用8位，因此它们会丢弃低于动态范围1/255的所有信息。  </li><li>如果扰动 $η$ 的每个元素小于特征的精度，则分类器对输入$x$和对抗输入 $x ̃=x+η$ 产生相同结果。<br>存在足够小的 $ε$，只要 $‖η‖_∞&lt;ε$，分类器就会分配给$x$和$x ̃$相同的类。  </li></ul><p>&emsp;考虑一个权值向量 $w$ 和一个对抗样本 $x ̃$ 的点积：  </p><script type="math/tex; mode=display">w^Tx ̃=w^Tx+w^Tη</script><ul><li><p>对抗扰动导致激活增长 $w^Tη$ 。令 $η=sign(w)$ ，我们可以最大化这个增量。 如果 $n$ 维权重向量 $w$ 的元素的平均值是 $m$ ，则激活将增加 $εmn$ 。  </p><blockquote><font color="#0099ff" size="2" face="黑体">[^_^]: 令扰动 $η$ 和权值向量 $w$ 各元素的符号相同，内积    $w^Tη$ 可最大化</font>  </blockquote></li><li><p>由于 $‖η‖_∞$ 不随维数变化而变化，但扰动 $η$ 引起的激活变化 $εmn$ 可随 $n$ 增加而线性增加。因此对于高维问题，对输入进行许多无限小的变化， 输出会产生一次大的变化。  </p></li></ul><p>&emsp;这个解释表明，<strong>如果一个简单的线性模型的输入具有足够的维度，它可能会有对抗样本。</strong> 基于线性的假设更简单，也可以解释为什么softmax回归容易受到对抗样本的影响。</p><picture><blockquote><p><a href="http://blog.csdn.net/Suan2014/article/details/77162042" target="_blank" rel="noopener">激活函数</a>:Sigmoid,Tanh,ReLu,softplus,softmax</p></blockquote><h2 id="2-emsp-非线性模型的线性扰动"><a href="#2-emsp-非线性模型的线性扰动" class="headerlink" title="2 &emsp;非线性模型的线性扰动"></a>2 &emsp;非线性模型的线性扰动</h2><p>&emsp;对抗样本的线性视图提出了一种快速生成对抗样本的方法。<br>&emsp;更复杂的非线性模型如sigmoid网络经过仔细调整，将其大部分时间花费在非饱和，更线性的机制中，因而也会受到对抗扰动。</p><ul><li>快速梯度符号法（FGSM）：<picture></picture></li></ul><div class="table-container"><table><thead><tr><th>符号</th><th>说明</th></tr></thead><tbody><tr><td>$θ$</td><td>模型参数</td></tr><tr><td>$x$</td><td>模型输入</td></tr><tr><td>$y$</td><td>关于x的目标</td></tr><tr><td>$J(θ,x,y)$</td><td>损失函数  </td></tr></tbody></table></div><p>&emsp;将损失函数线性化为  $θ$ 的当前值，得到最优的最大范数约束扰动</p><script type="math/tex; mode=display">η=εsign(∇_xJ(θ,x,y))</script><p>&emsp;称之为产生对抗样本的“快速梯度符号法”。 请注意，可以使用反向传播有效地计算所需的梯度。  </p><ul><li>FGSM在各种模型上的效果 :  </li></ul><div class="table-container"><table><thead><tr><th>$ε$</th><th>0.25</th><th>0.25</th><th>0.1</th></tr></thead><tbody><tr><td>测试集</td><td>MNIST</td><td>MNIST</td><td>CIFAR-10预</td></tr><tr><td>分类器</td><td>softmax</td><td>maxout</td><td>maxout</td></tr><tr><td>错误率</td><td>99.9％</td><td>89.4％</td><td>87.15％</td></tr><tr><td>平均置信度</td><td>79.3％</td><td>97.6％</td><td>96.6％</td></tr></tbody></table></div><blockquote><p><a href="https://github.com/lisa-lab/pylearn2/tree/master/pylearn2/scripts/papers/maxout" target="_blank" rel="noopener">预处理代码</a><br>其产生大约0.5的标准偏差。</p></blockquote><p>&emsp;其他生成对抗样本的简单方法也是可能的。 例如，我们还发现<strong>在梯度方向上以小角度旋转</strong> $x$ 也能可靠地产生对抗样本。</p><ul><li>在ImageNet上应用GoogLeNet的快速对抗样本生成演示：  </li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-10/67792085.jpg-Watermark" alt=""></p><p>&emsp;通过添加一个不可察的小矢量，其元素等于损失函数梯度的元素的符号，可以改变GoogLeNet的图像分类。这里，$ε$ 对应于GoogLeNet转换为实数后8位图像编码的最小位数的大小， 因等于0.007。  </p><p>&emsp;对抗样本生成过程：</p><script type="math/tex; mode=display">x ̃=x+εsign(∇_xJ(θ,x,y))</script><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-10/43011594.jpg-Watermark" alt=""></p><h2 id="3-emsp-反对权值衰减的线性模型对抗训练"><a href="#3-emsp-反对权值衰减的线性模型对抗训练" class="headerlink" title="3.&emsp;反对权值衰减的线性模型对抗训练"></a>3.&emsp;反对权值衰减的线性模型对抗训练</h2><p>&emsp;可以考虑的最简单的模型是逻辑回归。 在这种情况下，快速梯度符号方法是准确的。 通过案例来了解如何在简单的设置中生成对抗样本。  </p><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-10/83037047.jpg-Watermark" alt=""></p><p>&emsp;图2：应用于逻辑回归的FGSM<br>&emsp;a）在MNIST上训练的逻辑回归模型的权重。<br>&emsp;b）在MNIST上训练的逻辑回归模型的权重的符号。 这是最佳的扰动。 尽管该模型的容量较低并且很适合，但这种扰动不容易被人察觉。<br>&emsp;c）MNIST数据集中的 3和 7 样本。 在这些例子中，逻辑回归模型在3与7的区分任务上有1.6％的错误率。<br>&emsp;d）Logistic回归模型的FGSM对抗样本，$ε=0.25$ 。 在这些样本中，逻辑回归模型的误差率为99％。</p><ul><li>如果训练一个简单的模型来识别标签 $y∈{-1,1}$  ，其中  <script type="math/tex; mode=display">P(y=1)=σ(w^Tx+b)</script>&emsp; $σ(z)$ 是逻辑sigmoid函数，使用梯度下降法训练，<script type="math/tex; mode=display">E_{x,y∽p_{data}}ζ(-y(w^Tx+b))</script>&emsp;其中 $ζ(z)=log(1+exp(z))$ 是softplus方程。根据梯度符号扰动，可以推导出一个简单的分析形式，用于训练 $x$ 的最坏情况对抗扰动，而不是 $x$ 本身。 请注意，梯度的符号只是 $-sign(x)$ ，而 $w^Tsign(w)=‖w‖_1$ 。 逻辑回归的对抗版本因此最小化为：  <script type="math/tex; mode=display">E_{x,y∽p_{data}}ζ(y(ε‖w‖_1-w^Tx-b))</script>&emsp;这与 $L^1$ <a href="http://blog.csdn.net/jinping_shi/article/details/52433975" target="_blank" rel="noopener">正则化</a>有些相似。 但是，有一些重要的区别。</li></ul><blockquote><font color="#0099ff" size="2" face="黑体"> [正则化]:采用正则化方法会自动削弱不重要的特征变量，自动从许多的特征变量中”提取“重要的特征变量，减小特征变量的数量级。这个方法非常有效，当我们有很多特征变量时，其中每一个变量都能对预测产生一点影响。</font></blockquote><ul><li>最重要的是，在训练期间将 $L^1$ 惩罚从模型的激活中减去，而不是增加到训练损失。 这意味着如果模型学习 $ζ$ 饱和充分置信，惩罚最终会开始消失。 这并不一定会发生 - 在欠拟合下，对抗训练只会使得更加欠拟合。 因此，我们可以将 $L^1$ <a href="https://www.cnblogs.com/lindaxin/p/7998334.html" target="_blank" rel="noopener">权值衰减</a>视为比对抗训练更坏的情况，因为它在好的边界不能解除激活。</li></ul><blockquote><font color="#0099ff" size="2" face="黑体"> [权值衰减]：在每次迭代过程中以某个小因子降低每个权值，这等效于修改E的定义，加入一个与网络权值的总量相应的惩罚项。此方法的动机是保持权值较小，避免weight decay,从而使学习过程向着复杂决策面的反方向偏。</font>  </blockquote><ul><li>如果我们将逻辑回归移出多分类softmax回归， $L^1$ 权重衰减变得更加严重，因为它将每个softmax的输出视为独立扰动，事实上，通常不可能找到与所有类的权重向量相关联的 $η$ 。在具有多个隐藏单元的深度网络的情况下，权重衰减高估了扰动可实现的损害。由于 $L^1$ 权重衰减高估了攻击可以造成的伤害量，因此有必要使用比与我们的特征精度相关联的 $ε$ 更小的 $L^1$ 权重衰减系数。</li><li>当在MNIST上训练maxout网络时，我们使用对抗训练获得了良好的结果 。当 权重衰减应用于第一层时，我们发现 $ε=0.0025$的系数太大，也会导致模型在训练集上超过5％的误差。较小的重量衰减系数可以实现成功训练，但没有获得正则化的效果。</li></ul><blockquote><p><a href="http://blog.csdn.net/hjimce/article/details/50414467" target="_blank" rel="noopener">maxout</a></p></blockquote><h2 id="4-emsp-深度网络的对抗训练"><a href="#4-emsp-深度网络的对抗训练" class="headerlink" title="4&emsp;深度网络的对抗训练"></a>4&emsp;深度网络的对抗训练</h2><p>&emsp;与浅层线性模型不同，深层网络至少能够体现抵抗对抗扰动的功能。<a href="https://www.jianshu.com/p/52e773d47338" target="_blank" rel="noopener">泛逼近理论</a>表示，只要隐藏层允许有足够的单元，具有至少一个隐藏层的神经网络可以表示任意精度的任何函数。 浅层线性模型不能在训练点附近变得恒定，同时也对不同的训练点产生不同的输出。</p><ul><li>作者发现基于FGSM的对抗目标函数训练是一种有效的正则化方法：<script type="math/tex; mode=display">J ̃(θ,x,y)=αJ(θ,x,y)+(1-α)J(θ,x+εsign(∇_xJ(θ,x,y)))</script>&emsp;在所有的实验中，使用 $α=0.5$。 用这种方法来训练一个<strong>被<a href="http://blog.csdn.net/hjimce/article/details/50413257" target="_blank" rel="noopener">dropout</a>规范化的maxout网络</strong>：</li></ul><div class="table-container"><table><thead><tr><th>模型是否经过对抗训练</th><th>未经过</th><th>经过</th></tr></thead><tbody><tr><td>错误率</td><td>0.94％</td><td>0.84％  </td></tr></tbody></table></div><p>&emsp;观察到在训练集上的对抗样本中没有达到零错误率。作者通过进行两项更改来解决这个问题。首先，使模型更大，每层使用1600个单元，而不是原来的maxout网络使用的240个单元，使用<a href="https://deeplearning4j.org/cn/earlystopping" target="_blank" rel="noopener">early stopping</a>，并且当验证集错误率经过100个周期后未减少时终止学习。实验发现：  </p><ul><li>如果没有对抗训练，会导致模型轻微过拟合，并在测试集中获得1.14％的错误率  </li><li>通过对抗训练，验证集错误率随着时间的推移而趋于平稳，并且进展缓慢。<br>虽然验证集错误非常平坦，但对抗验证集错误不是。  </li></ul><p>&emsp;因此，我们对对抗验证集误差使用了early stopping。用这个标准选择训练的周期数量，对所有60,000个样本进行再训练。对于随机数发生器使用不同的<a href="http://blog.csdn.net/linzch3/article/details/58220569" target="_blank" rel="noopener">seed</a>进行五次不同的训练，用于选择训练样本的mini_batches，初始化模型权重以及生成五个实验的dropout，  </p><blockquote><font color="#0099ff" size="2" face="黑体">seed() 用于指定随机数生成时所用算法开始的整数值，如果使用相同的seed()值，则每次生成的随即数都相同，如果不设置这个值，则系统根据时间来自己选择这个值，此时每次生成的随机数因时间差异而不同。</font>  </blockquote><div class="table-container"><table><thead><tr><th>实验对比</th><th>1-4</th><th>5</th><th>MNIST排列不变版本</th><th>微调DBM</th></tr></thead><tbody><tr><td>误差率</td><td>0.77％</td><td>0.83％</td><td>0.782％</td><td>0.79％   </td></tr></tbody></table></div><ul><li>对抗训练过的模型表现出更强的鲁棒性。  </li></ul><div class="table-container"><table><thead><tr><th>对抗样本生成来源</th><th>原始模型</th><th>原始模型</th><th>dropour规范化新模型</th></tr></thead><tbody><tr><td>识别模型</td><td>原始模型</td><td>对抗训练模型</td><td>原始模型</td></tr><tr><td>错误率</td><td>89.4%</td><td>19.6％</td><td>40.9%  </td></tr></tbody></table></div><ul><li>学习模型的权重发生了显着变化，对抗训练模型的权重明显更加局部化和可解释</li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-10/65793832.jpg-Watermark" alt=""></p><p>图3：在MNIST上训练的maxout网络的权重可视化。 每行显示单个maxout单元的过滤器。 左）原始模型。 右）对抗训练过的模型。</p><ul><li>事实上，在许多情况下，噪声会导致较低的目标函数值。 可以将对抗训练视为在噪声输入集合中进行硬性样本挖掘，以便通过仅考虑强烈抵制分类的那些噪点来更有效地进行训练。</li></ul><p>&emsp;作为控制实验，作者训练了一个带有噪声的maxout网络，每个像素被随机添加噪声 $±ε$，或者将 $U∈(-ε,ε)$ 中的噪声添加到每个像素。<br>&emsp;在FGSM对抗样本中的分类情况：</p><div class="table-container"><table><thead><tr><th>噪声类型</th><th>1</th><th>2</th></tr></thead><tbody><tr><td>错误率</td><td>86.2%</td><td>90.4%</td></tr><tr><td>置信度</td><td>97.3%</td><td>97.8%  </td></tr></tbody></table></div><h2 id="5-emsp-不同种类的模型容量"><a href="#5-emsp-不同种类的模型容量" class="headerlink" title="5&emsp;不同种类的模型容量"></a>5&emsp;不同种类的模型容量</h2><p>&emsp;对抗样本的存在似乎与直觉相反的一个原因是，我们大多数人对高维空间的直觉很差。 我们生活在三个维度中，所以我们不习惯在数百个维度中添加小的扰动来产生巨大的效果。 还有另一种方式，我们的直觉不能很好的为我们服务。 许多人认为低容量的模型无法做出许多不同的置信预测。这是不正确的。</p><ul><li><p>符合直觉的低容量模型，例如浅层RBF网络：</p><script type="math/tex; mode=display">p(y=1|x)=exp({(x-μ)^T}β(x-μ))</script><p>只能有把握地预测在 $μ$ 附近存在正类。 在其他地方，它们默认预测类别不存在，或者具有低置信度的预测。  </p></li><li><p>RBF网络自然不受对抗样本的影响，因为当它们被愚弄时，置信度很低。 使用FGSM生成的对抗样本，$ε=0.25$ ，没有隐藏层的浅RBF网络在MNIST上获得55.4％的错误率。 然而，它对错误样本的置信度只有1.2％。 它对干净测试样本的平均置信度是60.6％。 我们不能指望一个容量如此低的模型在空间的所有点上都能得到正确的答案，但它确实可以通过在它无法识别的点上大大减少置信度，从而做出相对正确的回应。</p></li><li><p>但是，RBF单元对于任何重要的转换都不是不变的，所以它们不能一概而论。 我们可以将线性单元和RBF单元视为准确-召回权衡曲线上的不同点。 线性单位通过响应某个方向上的每个输入来实现高召回率，但由于在不熟悉的情况下响应过强可能会导致精度低。 RBF单元通过仅响应空间中的特定点来实现高精度，但是这样做会牺牲召回率。  </p></li></ul><h2 id="6-emsp-对抗样本的泛化能力"><a href="#6-emsp-对抗样本的泛化能力" class="headerlink" title="6&emsp;对抗样本的泛化能力"></a>6&emsp;对抗样本的泛化能力</h2><p>&emsp;对抗样本的一个有趣方面是，<strong>为其中一个模型生成的样本经常能被其他模型错误分类，即使它们具有不同的架构或在不相交的训练集上进行训练。 而且，当这些不同的模型将一个对抗样本错误分类时，他们经常会归为同一类。</strong> 基于极端非线性和过度拟合的解释不能轻易解释这种行为 - 为什么多余的容量过剩的极端非线性模型始终以相同的方式标记分布外的点？ 这种行为尤其令人惊讶，从这样的假设来看，对抗样本就像实数空间中的有理数分布，因为在这种观点中，对抗样本很常见，但只发生在非常精确的位置。</p><ul><li><p>在线性观点下，对抗样本出现在宽泛的子空间中。 方向 $η$ 只需要具有损失函数梯度的正点积， $ε$ 只需要足够大。 图4显示了这种现象。 通过追踪出不同的值 $ε$  ，我们发现对抗样本出现在由FGSM方法定义的1-D子空间的连续区域中，而不是离散的。 这就解释了为什么对抗样本非常丰富，为什么一个分类器错误分类的样本具有相当高的可能性被另一个分类器错误分类。</p><picture></picture></li><li><p>为了解释为什么多个分类器将对抗样本分类为同一个类，我们假设用当前方法训练的神经网络都类似于在相同训练集上学习的线性分类器。 这个参考分类器在训练集的不同子集上训练时能够学习大致相同的分类权重，这仅仅是因为机器学习算法能够泛化。 基础分类权重的稳定性反过来又会导致对抗样本的稳定性。</p></li></ul><p>&emsp;为了检验这个假设，我们在深度maxout网络上生成了对抗样本，并使用浅softmax网络和浅RBF网络对这些样本进行了分类。在由maxout网络误分类的样本中，</p><div class="table-container"><table><thead><tr><th>分类模型</th><th>softmax网络</th><th>浅层RBF网络</th></tr></thead><tbody><tr><td>预测</td><td>54.6%</td><td>16.0%</td></tr><tr><td>回归预测</td><td>84.6%</td><td>54.3%</td></tr></tbody></table></div><p>&emsp;这些数字很大程度上是由不同模型的差错率驱动的。如果我们不把注意力放在两种模型比较出错的情况下，softmax回归预测84.6％的时间是maxout类别，而RBF网络只能预测maxout类别的时间为54.3％。为了比较，RBF网络可以预测softmax回归的时间为53.6％，所以它对自己的行为确实具有强大的线性分量。我们的假设并不能解释所有maxou网络的错误或者所有模型中泛化的错误，但很明显，其中很大一部分与线性行为一致是跨模型泛化的主要原因。</p><h2 id="7-emsp-讨论总结"><a href="#7-emsp-讨论总结" class="headerlink" title="7&emsp;讨论总结"></a>7&emsp;讨论总结</h2><ul><li><p>对抗样本可以解释为高维点积的一个特性。 它们是模型过于线性而非非线性的结果。</p></li><li><p>横跨不同模型的对抗样本的泛化可以解释为对抗扰动与模型的权重向量高度一致，并且不同模型在被训练执行相同任务时学习相似函数。</p></li><li><p>扰动的方向，而不是空间中的特定点。 空间并不是充满了对抗样本，它们像实数中的有理数一样分布。</p></li><li>因为它是最重要的方向，所以对抗干扰会在不同的干净样本上泛化。</li><li>我们引入了一系列快速生成对抗样本的方法。</li><li>我们已经证明，对抗训练可以导致正则化; 甚至比dropout更加正则化。</li><li>我们的运行控制实验未能用更简单但效率更低的正则化器重现此效应，包括 $L^1$ 权重衰减和增加噪音。</li><li>易于优化的模型易于受到干扰。</li><li>线性模型缺乏抵抗对抗扰动的能力; 只有具有隐藏层的结构（泛逼近定理适用）应该被训练来抵抗对抗扰动。</li><li>RBF网络对对抗样本有抗性。</li><li>训练模型化输入分布的模型不能抵抗对抗样本。</li><li>集成方法不能抵抗对抗样本。</li></ul></picture>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;对抗攻击综述-1-：对抗样本产生与FGSM原理&quot;&gt;&lt;a href=&quot;#对抗攻击综述-1-：对抗样本产生与FGSM原理&quot; class=&quot;headerlink&quot; title=&quot;对抗攻击综述(1)：对抗样本产生与FGSM原理&quot;&gt;&lt;/a&gt;对抗攻击综述(1)：对抗样本产生与
      
    
    </summary>
    
      <category term="对抗攻击" scheme="http://yoururl.com/categories/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/"/>
    
    
      <category term="Deep learning" scheme="http://yoururl.com/tags/Deep-learning/"/>
    
      <category term="Adversarial attack" scheme="http://yoururl.com/tags/Adversarial-attack/"/>
    
      <category term="Translation" scheme="http://yoururl.com/tags/Translation/"/>
    
  </entry>
  
  <entry>
    <title>The Adversarial Attacks methods</title>
    <link href="http://yoururl.com/2018/03/08/Adversarial%20attack%20methods/"/>
    <id>http://yoururl.com/2018/03/08/Adversarial attack methods/</id>
    <published>2018-03-08T10:38:04.000Z</published>
    <updated>2018-03-12T12:35:27.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>作者：Andy_z<br>翻译文献：<a href="https://arxiv.org/abs/1801.00553" target="_blank" rel="noopener">Threat of Adversarial Attacks on Deep Learning<br>in Computer Vision: A Survey</a></p></blockquote><h1 id="对抗攻击策略总结"><a href="#对抗攻击策略总结" class="headerlink" title="对抗攻击策略总结"></a>对抗攻击策略总结</h1><h2 id="1-emsp-常用术语介绍"><a href="#1-emsp-常用术语介绍" class="headerlink" title="1.&emsp;常用术语介绍"></a>1.&emsp;常用术语介绍</h2><ul><li>Adversarial example/image(对抗样本)：由干净样本添加了对抗扰动得到的新样本，用于欺骗机器学习模型。</li><li>Adversarial perturbation(对抗扰动)：使干净样本转化为对抗样本的噪声。</li><li>Adversarial training(对抗训练)：使用混合的对抗样本和干净样本去训练模型。</li><li>Adversary (攻击者)：制造对抗样本的人，有时候也指代对抗样本本身。</li><li>Black-box attacks(黑盒攻击)：攻击者在不清楚（或了解很少）模型的参数和结构的情况下，生成对抗样本攻击模型。</li><li>Detector(检测器)：用于检测一幅图像是否是对抗样本的装置。</li><li>Fooling ratio/rate：(欺骗率)：样本被扰动后，一个训练过的模型改变预测标签的比例。</li><li>One-shot/one-step methods(单步法)：使用单步计算去生成对抗扰动，相对于迭代法，后者计算量大。</li><li>Quasi-imperceptible(难以察觉)：轻微扰动图像，在人类视觉下无法察觉。</li><li>Rectifier(整流器，校正器)：整流器修改对抗样本，以恢复目标模型的预测，对应于干净版本的预测。</li><li>Targeted attacks(目标攻击)：欺骗机器学习模型，使之将对抗图片识别为指定标签。相对于non-targeted attacks(无目标攻击)。</li><li>non-targeted attacks(无目标攻击)：欺骗机器学习模型，使之将对抗图片识别为错误的任意标签。</li><li>Threat model(威胁模型)：指由方法考虑的潜在攻击的类型，例如， 黑盒攻击。</li><li>Transferability(转移性)：对抗样本对于生成模型之外的其他模型依然有效。</li><li>Universal perturbation(通用扰动)：添加到任何图像中，都能够以高概率愚弄的给定模型。 请注意，普遍性是指扰动的”图像的不可知”性，与’具有良好的可转移性’相反。</li><li>White-box attacks(白盒攻击):攻击者完全掌握了目标模型的参数，架构，训练方法，有时候包括训练数据。</li></ul><h1 id="2-emsp-攻击方法分类"><a href="#2-emsp-攻击方法分类" class="headerlink" title="2.&emsp;攻击方法分类"></a>2.&emsp;攻击方法分类</h1><p>&emsp;从不同角度分类现有的攻击策略：</p><h2 id="2-1-emsp-Black-White-box"><a href="#2-1-emsp-Black-White-box" class="headerlink" title="2.1&emsp;Black/White box"></a>2.1&emsp;Black/White box</h2><h2 id="2-2-emsp-Targeted-Non-targeted"><a href="#2-2-emsp-Targeted-Non-targeted" class="headerlink" title="2.2&emsp;Targeted/Non-targeted"></a>2.2&emsp;Targeted/Non-targeted</h2><h2 id="2-3-emsp-Gradient-Optimization-others"><a href="#2-3-emsp-Gradient-Optimization-others" class="headerlink" title="2.3&emsp;Gradient/Optimization/others"></a>2.3&emsp;Gradient/Optimization/others</h2><h2 id="2-4-emsp-Specific-Universal"><a href="#2-4-emsp-Specific-Universal" class="headerlink" title="2.4&emsp;Specific/Universal"></a>2.4&emsp;Specific/Universal</h2><h2 id="2-4-emsp-One-shot-Iterative"><a href="#2-4-emsp-One-shot-Iterative" class="headerlink" title="2.4&emsp;One-shot/Iterative"></a>2.4&emsp;One-shot/Iterative</h2><p>&emsp;<span id="Summary-">各方法属性总结：</span></p><div class="table-container"><table><thead><tr><th>Method</th><th><font size="2">Black/ White box</font></th><th><font size="2">Targeted/ Non-targeted</font></th><th><font size="2">Gradient/ Optimiza tion/others</font></th><th><font size="2">Specific/ Universal</font></th><th><font size="2">perturbation norm</font></th><th>learn</th><th>strength</th></tr></thead><tbody><tr><td><a href="#L-BFGS">L-BFGS</a></td><td>White-box</td><td>Targeted</td><td>-</td><td>Specific</td><td>$L_∞$</td><td>One-shot</td><td>3*</td></tr><tr><td><a href="#FGSM">FGSM</a></td><td>White-box</td><td>Targeted</td><td>Gradient</td><td>Specific</td><td>$L_∞$</td><td>One-shot</td><td>3*</td></tr><tr><td><a href="#BIM&amp;ILCM">BIM&amp;ILCM</a></td><td>White-box</td><td>Non-</td><td>Gradient</td><td>Specific</td><td>$L_∞$</td><td>Iterative</td><td>4*</td></tr><tr><td><a href="#JSMA">JSMA</a></td><td>White-box</td><td>Targeted</td><td>Gradient</td><td>Specific</td><td>$L_0$</td><td>Iterative</td><td>3*</td></tr><tr><td><a href="#One-Pixel">One-Pixel</a></td><td>Black-box</td><td>Non-</td><td>-</td><td>Specific</td><td>$L_0$</td><td>Iterative</td><td>2*</td></tr><tr><td><a href="#C.W-attacks">C&amp;W attacks</a></td><td>White-box</td><td>Targeted</td><td>-</td><td>Specific</td><td>$L<em>0,L_2,L</em>∞$</td><td>Iterative</td><td>5*</td></tr><tr><td><a href="#DeepFool">DeepFool</a></td><td>White-box</td><td>Non-</td><td>-</td><td>Specific</td><td>$L<em>2,L</em>∞$</td><td>Iterative</td><td>4*</td></tr><tr><td><a href="#Uni-pert">Uni.perturbation</a></td><td>White-box</td><td>Non-</td><td>-</td><td>Universal</td><td>$L<em>2,L</em>∞$</td><td>Iterative</td><td>5*</td></tr><tr><td><a href="#UPSET">UPSET</a></td><td>black-box</td><td>Targeted</td><td>-</td><td>Universal</td><td>$L_∞$</td><td>Iterative</td><td>4*</td></tr><tr><td><a href="#ANGRI">ANGRI</a></td><td>Black-box</td><td>Targeted</td><td>-</td><td>Specific</td><td>$L_∞$</td><td>Iterative</td><td>4*</td></tr><tr><td><a href="#Houdini">Houdini</a></td><td>Black-box</td><td>Targeted</td><td>-</td><td>Specific</td><td>$L<em>2,L</em>∞$</td><td>Iterative</td><td>4*</td></tr><tr><td><a href="#ATNs">ATNs</a></td><td>White-box</td><td>Targeted</td><td>-</td><td>Specific</td><td>$L_∞$</td><td>Iterative</td><td>4*</td></tr></tbody></table></div><h1 id="3-emsp-L-BFGS"><a href="#3-emsp-L-BFGS" class="headerlink" title="3.&emsp;L-BFGS"></a>3.&emsp;<span id="L-BFGS">L-BFGS</span></h1><p>通过对图像添加人眼不可察的微小扰动来误导神经网络做出错误分类。他们试图求解让神经网络做出错误分类的最小扰动方程，限于问题的高复杂度，他们简化了过程转而寻找最小的代价函数添加项，来误导神经网络，从而将问题转化为一个凸优化过程。  </p><p><a href="#Summary-">Back</a></p><h1 id="4-emsp-FGSM"><a href="#4-emsp-FGSM" class="headerlink" title="4.&emsp;FGSM"></a>4.&emsp;<span id="FGSM">FGSM</span></h1><h2 id="4-1-emsp-快速梯度符号法（FGSM）："><a href="#4-1-emsp-快速梯度符号法（FGSM）：" class="headerlink" title="4.1&emsp;快速梯度符号法（FGSM）："></a>4.1&emsp;快速梯度符号法（FGSM）：</h2><picture><div class="table-container"><table><thead><tr><th>符号</th><th>说明</th></tr></thead><tbody><tr><td>$θ$</td><td>模型参数</td></tr><tr><td>$x$</td><td>模型输入</td></tr><tr><td>$y$</td><td>关于x的目标</td></tr><tr><td>$J(θ,x,y)$</td><td>损失函数  </td></tr></tbody></table></div><p>&emsp;将损失函数线性化为  $θ$ 的当前值，得到最优的<strong>最大范数</strong>约束扰动</p><script type="math/tex; mode=display">η=εsign(∇_xJ(θ,x,y))</script><p>&emsp;称之为产生对抗样本的“快速梯度符号法”。 请注意，可以使用反向传播有效地计算所需的梯度。  </p><ul><li>FGSM在各种模型上的效果 :  </li></ul><div class="table-container"><table><thead><tr><th>$ε$</th><th>0.25</th><th>0.25</th><th>0.1</th></tr></thead><tbody><tr><td>测试集</td><td>MNIST</td><td>MNIST</td><td>CIFAR-10预</td></tr><tr><td>分类器</td><td>softmax</td><td>maxout</td><td>maxout</td></tr><tr><td>错误率</td><td>99.9％</td><td>89.4％</td><td>87.15％</td></tr><tr><td>平均置信度</td><td>79.3％</td><td>97.6％</td><td>96.6％</td></tr></tbody></table></div><blockquote><p><a href="https://github.com/lisa-lab/pylearn2/tree/master/pylearn2/scripts/papers/maxout" target="_blank" rel="noopener">预处理代码</a><br>其产生大约0.5的标准偏差。</p></blockquote><p>&emsp;其他生成对抗样本的简单方法也是可能的。 例如，我们还发现<a href="https://jjzhou012.github.io/2018/03/11/adversaria-%E6%AD%A3%E7%A1%AE%E5%88%86%E7%B1%BB-%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC-%E9%B2%81%E6%A3%92%E6%80%A7/" target="_blank" rel="noopener"><strong>在梯度方向上以小角度旋转</strong></a> $x$ 也能可靠地产生对抗样本。</p><ul><li>在ImageNet上应用GoogLeNet的快速对抗样本生成演示：  </li></ul><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-10/67792085.jpg-Watermark" alt=""></p><p>&emsp;通过添加一个不可察的小矢量，其元素等于损失函数梯度的元素的符号，可以改变GoogLeNet的图像分类。这里，$ε$ 对应于GoogLeNet转换为实数后8位图像编码的最小位数的大小， 因等于0.007。  </p><p>&emsp;对抗样本生成过程：</p><script type="math/tex; mode=display">x ̃=x+εsign(∇_xJ(θ,x,y))</script><p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-10/43011594.jpg-Watermark" alt=""></p><h2 id="4-2-emsp-FGSM的one-step-target-class变体"><a href="#4-2-emsp-FGSM的one-step-target-class变体" class="headerlink" title="4.2&emsp;FGSM的one-step target class变体"></a>4.2&emsp;FGSM的one-step target class变体</h2><div class="table-container"><table><thead><tr><th>符号</th><th>说明</th></tr></thead><tbody><tr><td>$X$</td><td>干净样本</td></tr><tr><td>$X^{adv}$</td><td>对抗图像</td></tr><tr><td>Misclassified adversarial image</td><td>误分类的对抗图像</td></tr><tr><td>$ε$</td><td>对抗扰动大小</td></tr><tr><td>$J(X,y_{true})$</td><td>用于训练模型的损失函数</td></tr></tbody></table></div><ul><li>最大化某个特定目标类 $y<em>{target}$ 的概率 $p(y</em>{target}|X)$，该目标类不可能是给定图像的真实类。 对于具有交叉熵损失的神经网络，一步目标类方法的公式：</li></ul><script type="math/tex; mode=display">X^{adv}=X - εsign(∇_XJ(X,y_{target}))</script><ul><li><p>对于目标类，我们可以选择被网络</p><script type="math/tex; mode=display">y_{LL} = arg \min_y\{p(y|X)\}</script><p>&emsp;&emsp;&emsp;预测的最小概率的类</p></li><li><p>对于这里给定图像 $X$ 和 $y$ 的神经网络的交叉熵代价函数 $J(X,y)$ 。 故意忽略代价函数中的网络权重（和其他参数）$θ$,<br>假设它们是固定的。对于softmax输出层的神经网络，则有 整数类标签的交叉熵代价函数等于给定图像的真实类的负对数概率：</p><script type="math/tex; mode=display">J(X,y)= - \log\;p（y | X）</script></li></ul><p><a href="#Summary-">Back</a></p><h1 id="5-emsp-BIM-ILCM"><a href="#5-emsp-BIM-ILCM" class="headerlink" title="5.&emsp;BIM&ILCM"></a>5.&emsp;<span id="BIM&amp;ILCM">BIM&ILCM</span></h1><h2 id="5-1-emsp-Basic-iterative-method-BIM"><a href="#5-1-emsp-Basic-iterative-method-BIM" class="headerlink" title="5.1&emsp;Basic iterative method(BIM):"></a>5.1&emsp;Basic iterative method(BIM):</h2><ul><li>$Clip_{X,ε}{X’}$ 基于像素剪切$X’$, 结果在原图像$X$的$ε$的最大范数邻域内，剪切方程：</li></ul><script type="math/tex; mode=display">Clip_{X,ε}\{X'\}(x,y,z) = \min\{255,X(x,y,z)+ε,\max\{0,X(x,y,z)-ε,X'(x,y,z)\}\}</script><p>&emsp;&emsp;&emsp;$X(x,y,z)$ 的值为图像$X$在坐标 $(x,y)$ 处 $z$ 通道的值。</p><ul><li>对于 单步类的方法，将它扩展为很多小步，在每个步骤之后剪切中间结果的像素值以确保它们处于<br>原始图像的一个 $ε$ 邻域内：<script type="math/tex; mode=display">\sideset{}{^{adv}_0}X = X,  \sideset{}{^{adv}_{N+1}}X=Clip_{X,ε}\{\sideset{}{^{adv}_{N}}X+αsign(ᐁ_XJ(\sideset{}{^{adv}_{N}}X,y_{true}))\}</script></li><li>在作者的实验中，使用了 $α=1$，即在每一步中只将每个像素的值改为1。 选择迭代次数为 $\min(ε+ 4,1.25ε)$。 这种迭代量是通过启发式选择的; 对抗样本足以达到$ε$的最大范数球但有足够的限制，以保持实验的计算成本可控。</li></ul><h2 id="5-2-emsp-ITERATIVE-LEAST-LIKELY-CLASS-METHOD-ILCM"><a href="#5-2-emsp-ITERATIVE-LEAST-LIKELY-CLASS-METHOD-ILCM" class="headerlink" title="5.2&emsp;ITERATIVE LEAST-LIKELY CLASS METHOD(ILCM)"></a>5.2&emsp;ITERATIVE LEAST-LIKELY CLASS METHOD(ILCM)</h2><p>&emsp;前面描述的两种方法都只是试图增加正确类的成本，而没有指定模型应该选择哪些不正确的类。 这样的方法足以应用于诸如MNIST和CIFAR-10数据集，其中类别数量很少，并且所有类别彼此差异很大。 在ImageNet上，类别数量多得多，类别之间的差异程度也不同，这些方法可能导致无趣的错误分类，例如将一种雪橇犬误认为另一种雪橇犬。 为了创造更多有趣的错误，引入了迭代最不可能的类方法。</p><ul><li>这种迭代方法试图制作一个对抗图像，将其分类为特定的期望目标类别。 对于期望的类别，根据图像$X$上训练网络的预测选择最不可能的类：<script type="math/tex; mode=display">y_{LL} = arg \min_y\{p(y|X)\}</script></li></ul><p>&emsp;对于训练很好的分类器，最不可能的分类通常与真实分类非常不相似，因此这种攻击方法会导致更多有趣的错误，例如将狗误认为是飞机。</p><ul><li>生成一张被分类为 $y<em>{LL}$ 的对抗图像，在 $sign{∇_X {\log}\;p(y</em>{LL}|X)}$ 方向上进行迭代来最小化 ${\log}\;p(y<em>{LL}|X)$，交叉熵损失的神经网络最后的表达式为 $sign{-∇_X J(X,y</em>{LL})}$ ，过程为下：<script type="math/tex; mode=display">\sideset{}{^{adv}_0}X = X,  \sideset{}{^{adv}_{N+1}}X=Clip_{X,ε}\{\sideset{}{^{adv}_{N}}X-αsign(ᐁ_XJ(\sideset{}{^{adv}_{N}}X,y_{LL}))\}</script></li></ul><p><a href="#Summary-">Back</a></p><h1 id="6-emsp-JSMA"><a href="#6-emsp-JSMA" class="headerlink" title="6.&emsp;JSMA"></a>6.&emsp;<span id="JSMA">JSMA</span></h1><p>&emsp;Papernot 等人通过限制扰动的 $L_0$ 范数，创造了一种新的对抗攻击“JSMA”。从物理上来说，这意味着只需修改图像中的几个像素，而不是扰动整个图像就能欺骗分类器。他们的算法一次修改干净图像的一个像素，并监视改动所引起的分类变化。通过使用网络层输出的梯度来计算显着图执行监视。显著图数值越大，表示欺骗网络的可能性越高，越容易获得目标标签。一旦图被计算出来，算法选择最有效的像素进行修改来欺骗网络。重复该过程，直到对抗图像中允许的像素的最大数量被改变或者愚弄成功。</p><p><a href="https://jjzhou012.github.io/2018/03/12/JSMA/" target="_blank" rel="noopener">JSMA</a></p><p><a href="#Summary-">Back</a></p><h1 id="7-emsp-One-Pixel"><a href="#7-emsp-One-Pixel" class="headerlink" title="7.&emsp;One-Pixel"></a>7.&emsp;<span id="One-Pixel">One-Pixel</span></h1><p>&emsp;一种极端的攻击方法，仅仅改变图像的一个像素实现对抗攻击。该攻击基于差分进化算法，迭代的修改每个像素值，生成子图像，和母图像进行对比，保留攻击效果最佳的子图像最终实现攻击。它对多种类型的DNN模型有效，且需要极少的对抗信息。</p><p><a href="#Summary-">Back</a></p><h1 id="8-emsp-C-amp-W-attacks"><a href="#8-emsp-C-amp-W-attacks" class="headerlink" title="8.&emsp;C&amp;W attacks"></a>8.&emsp;<span id="C.W-attacks">C&amp;W attacks</span></h1><p>通过限制扰动的l<em>0，l_2和l</em>∞范数使它们难以被察觉，并且成功的突破了防御净化法。</p><p><a href="#Summary-">Back</a></p><h1 id="9-emsp-DeepFool"><a href="#9-emsp-DeepFool" class="headerlink" title="9.&emsp;DeepFool"></a>9.&emsp;<span id="DeepFool">DeepFool</span></h1><p>&emsp;<a href="https://github.com/lts4/deepfool" target="_blank" rel="noopener">github</a>  </p><p>通过迭代生成最小规范扰动，将位于分类边界的图像逐步推到边界外，直到产生错误分类。</p><p><a href="#Summary-">Back</a></p><h1 id="10-emsp-Uni-perturbation"><a href="#10-emsp-Uni-perturbation" class="headerlink" title="10.&emsp;Uni.perturbation"></a>10.&emsp;<span id="Uni-pert">Uni.perturbation</span></h1><p><a href="#Summary-">Back</a></p><h1 id="11-emsp-UPSET"><a href="#11-emsp-UPSET" class="headerlink" title="11.&emsp;UPSET"></a>11.&emsp;<span id="UPSET">UPSET</span></h1><p><a href="#Summary-">Back</a></p><h1 id="12-emsp-ANGRI"><a href="#12-emsp-ANGRI" class="headerlink" title="12.&emsp;ANGRI"></a>12.&emsp;<span id="ANGRI">ANGRI</span></h1><p><a href="#Summary-">Back</a></p><h1 id="13-emsp-Houdini"><a href="#13-emsp-Houdini" class="headerlink" title="13.&emsp;Houdini"></a>13.&emsp;<span id="Houdini">Houdini</span></h1><p>通过限制l<em>2和l</em>∞范数生成能适应任务损失的对抗样本来欺骗基于梯度的ML模型。该算法利用神经网络的可微损耗函数的梯度来计算扰动。</p><p><a href="#Summary-">Back</a></p><h1 id="14-emsp-ATNs"><a href="#14-emsp-ATNs" class="headerlink" title="14.&emsp;ATNs"></a>14.&emsp;<span id="ATNs">ATNs</span></h1><p><a href="#Summary-">Back</a></p></picture>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;作者：Andy_z&lt;br&gt;翻译文献：&lt;a href=&quot;https://arxiv.org/abs/1801.00553&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Threat of Adversarial Attacks on
      
    
    </summary>
    
      <category term="对抗攻击" scheme="http://yoururl.com/categories/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/"/>
    
    
      <category term="Deep learning" scheme="http://yoururl.com/tags/Deep-learning/"/>
    
      <category term="Summary" scheme="http://yoururl.com/tags/Summary/"/>
    
      <category term="Adversarial attack" scheme="http://yoururl.com/tags/Adversarial-attack/"/>
    
      <category term="Translation" scheme="http://yoururl.com/tags/Translation/"/>
    
  </entry>
  
  <entry>
    <title>使用inception-v3模型做图像识别</title>
    <link href="http://yoururl.com/2018/01/10/8.4%20%20%E4%BD%BF%E7%94%A8inception-v3%E5%81%9A%E5%90%84%E7%A7%8D%E5%9B%BE%E5%83%8F%E7%9A%84%E8%AF%86%E5%88%AB/"/>
    <id>http://yoururl.com/2018/01/10/8.4  使用inception-v3做各种图像的识别/</id>
    <published>2018-01-10T10:38:04.000Z</published>
    <updated>2018-03-18T16:23:35.000Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><p>建立 编号-分类 映射表（字典）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NodeLookup</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 存放分类标签的路径</span></span><br><span class="line">        label_lookup_path = <span class="string">'inception_model/imagenet_2012_challenge_label_map_proto.pbtxt'</span></span><br><span class="line">        <span class="comment"># 存放分类编号的路径</span></span><br><span class="line">        uid_lookup_path = <span class="string">'inception_model/imagenet_synset_to_human_label_map.txt'</span></span><br><span class="line">        self.node_lookup = self.load(label_lookup_path, uid_lookup_path)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load</span><span class="params">(self, label_lookup_path, uid_lookup_path)</span>:</span></span><br><span class="line">        <span class="comment"># 加载  分类序列n*********--分类标签（名称）  文件</span></span><br><span class="line">        proto_as_ascii_lines = tf.gfile.GFile(uid_lookup_path).readlines()</span><br><span class="line">        uid_to_human = &#123;&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 一行行读取数据</span></span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> proto_as_ascii_lines :</span><br><span class="line">            <span class="comment"># 去掉换行符</span></span><br><span class="line">            line = line.strip(<span class="string">'\n'</span>)</span><br><span class="line">            <span class="comment"># 按照'\t'分割</span></span><br><span class="line">            parsed_items = line.split(<span class="string">'\t'</span>)</span><br><span class="line">            <span class="comment"># 获取分类序列</span></span><br><span class="line">            uid = parsed_items[<span class="number">0</span>]</span><br><span class="line">            <span class="comment"># 获取分类标签</span></span><br><span class="line">            human_string = parsed_items[<span class="number">1</span>]</span><br><span class="line">            <span class="comment"># 保存编号序列n*******与分类名称映射关系， 字典</span></span><br><span class="line">            uid_to_human[uid] = human_string</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 加载分类序列n*******对应分类编号1-1000的文件</span></span><br><span class="line">        proto_as_ascii = tf.gfile.GFile(label_lookup_path).readlines()</span><br><span class="line">        node_id_to_uid = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> proto_as_ascii:</span><br><span class="line">            <span class="keyword">if</span> line.startswith(<span class="string">'  target_class:'</span>):</span><br><span class="line">                <span class="comment"># 获取分类编号1-1000</span></span><br><span class="line">                target_class = int(line.split(<span class="string">': '</span>)[<span class="number">1</span>])</span><br><span class="line">            <span class="keyword">if</span> line.startswith(<span class="string">'  target_class_string:'</span>):</span><br><span class="line">                <span class="comment"># 获取编号序列串n**********</span></span><br><span class="line">                target_class_string = line.split(<span class="string">': '</span>)[<span class="number">1</span>]</span><br><span class="line">                <span class="comment"># 保存分类编号1-1000与编号序列n*******映射关系</span></span><br><span class="line">                node_id_to_uid[target_class] = target_class_string[<span class="number">1</span>:<span class="number">-2</span>]  <span class="comment"># 去引号</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 建立分类编号1-1000对应分类名称的映射关系</span></span><br><span class="line">        node_id_to_name = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> key, val <span class="keyword">in</span> node_id_to_uid.items():</span><br><span class="line">            <span class="comment"># 获取分类名称</span></span><br><span class="line">            name = uid_to_human[val]</span><br><span class="line">            <span class="comment"># 建立分类编号1-1000到分类名称的映射关系</span></span><br><span class="line">            node_id_to_name[key] = name</span><br><span class="line">        <span class="keyword">return</span> node_id_to_name</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 传入分类编号1-1000返回分类名称</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">id_to_string</span><span class="params">(self, node_id)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> node_id <span class="keyword">not</span> <span class="keyword">in</span> self.node_lookup:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">''</span></span><br><span class="line">        <span class="keyword">return</span> self.node_lookup[node_id]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个图来存放google训练好的模型</span></span><br><span class="line"><span class="keyword">with</span> tf.gfile.FastGFile(<span class="string">'inception_model/classify_image_graph_def.pb'</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    graph_def = tf.GraphDef()</span><br><span class="line">    graph_def.ParseFromString(f.read())</span><br><span class="line">    tf.import_graph_def(graph_def, name=<span class="string">''</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    softmax_tensor = sess.graph.get_tensor_by_name(<span class="string">'softmax:0'</span>)</span><br><span class="line">    <span class="comment"># 遍历目录</span></span><br><span class="line">    <span class="keyword">for</span> root,dirs,files <span class="keyword">in</span> os.walk(<span class="string">'images/'</span>):</span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">            <span class="comment"># 载入图片</span></span><br><span class="line">            image_data = tf.gfile.FastGFile(os.path.join(root, file), <span class="string">'rb'</span>).read()</span><br><span class="line">            predictions = sess.run(softmax_tensor, &#123;<span class="string">'DecodeJpeg/contents:0'</span>: image_data&#125;) <span class="comment"># 图片为jpg格式</span></span><br><span class="line">            predictions = np.squeeze(predictions) <span class="comment"># 把结果转为1维数据</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 打印图片路径及名称</span></span><br><span class="line">            image_path = os.path.join(root, file)</span><br><span class="line">            print(image_path)</span><br><span class="line">            <span class="comment"># 显示图片</span></span><br><span class="line">            img = Image.open(image_path)</span><br><span class="line">            plt.imshow(img)</span><br><span class="line">            plt.axis(<span class="string">'off'</span>)</span><br><span class="line">            plt.show()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 排序</span></span><br><span class="line">            top_k = predictions.argsort()[<span class="number">-5</span>:][::<span class="number">-1</span>]</span><br><span class="line">            node_lookup = NodeLookup()</span><br><span class="line">            <span class="keyword">for</span> node_id <span class="keyword">in</span> top_k:</span><br><span class="line">                <span class="comment"># 获取分类名称</span></span><br><span class="line">                human_string = node_lookup.id_to_string(node_id)</span><br><span class="line">                <span class="comment"># 获取该分类置信度</span></span><br><span class="line">                score = predictions[node_id]</span><br><span class="line">                print(<span class="string">'%s (score = %.5f)'</span> % (human_string, score))</span><br><span class="line">            print()</span><br></pre></td></tr></table></figure><pre><code>images/airplane.jpg</code></pre><p><img src="output_4_1.png" alt="png"></p><pre><code>airliner (score = 0.26513)wing (score = 0.22947)warplane, military plane (score = 0.21153)space shuttle (score = 0.06658)projectile, missile (score = 0.01168)images/ball.jpg</code></pre><p><img src="output_4_3.png" alt="png"></p><pre><code>balloon (score = 0.94387)joystick (score = 0.00086)punching bag, punch bag, punching ball, punchball (score = 0.00070)red wolf, maned wolf, Canis rufus, Canis niger (score = 0.00050)parachute, chute (score = 0.00035)images/bird.jpg</code></pre><p><img src="output_4_5.png" alt="png"></p><pre><code>bald eagle, American eagle, Haliaeetus leucocephalus (score = 0.92000)kite (score = 0.00593)vulture (score = 0.00099)magpie (score = 0.00070)hen (score = 0.00064)images/bird1.jpg</code></pre><p><img src="output_4_7.png" alt="png"></p><pre><code>kite (score = 0.59593)vulture (score = 0.18804)bald eagle, American eagle, Haliaeetus leucocephalus (score = 0.03131)hornbill (score = 0.00592)black grouse (score = 0.00467)images/car.jpg</code></pre><p><img src="output_4_9.png" alt="png"></p><pre><code>sports car, sport car (score = 0.89957)racer, race car, racing car (score = 0.03727)convertible (score = 0.00740)grille, radiator grille (score = 0.00419)car wheel (score = 0.00284)images/hudie.jpg</code></pre><p><img src="output_4_11.png" alt="png"></p><pre><code>ringlet, ringlet butterfly (score = 0.31588)lycaenid, lycaenid butterfly (score = 0.31296)admiral (score = 0.27269)cabbage butterfly (score = 0.00675)monarch, monarch butterfly, milkweed butterfly, Danaus plexippus (score = 0.00424)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span clas
      
    
    </summary>
    
      <category term="图像识别" scheme="http://yoururl.com/categories/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/"/>
    
    
      <category term="Deep learning" scheme="http://yoururl.com/tags/Deep-learning/"/>
    
      <category term="Tensorflow" scheme="http://yoururl.com/tags/Tensorflow/"/>
    
      <category term="Neural Networks" scheme="http://yoururl.com/tags/Neural-Networks/"/>
    
      <category term="Image Recognition" scheme="http://yoururl.com/tags/Image-Recognition/"/>
    
  </entry>
  
  <entry>
    <title>下载Google图像识别模型inception-v3并查看结构</title>
    <link href="http://yoururl.com/2018/01/09/8.3+%E4%B8%8B%E8%BD%BDgoogle%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E7%BD%91%E7%BB%9Cinception-v3%E5%B9%B6%E6%9F%A5%E7%9C%8B%E7%BB%93%E6%9E%84/"/>
    <id>http://yoururl.com/2018/01/09/8.3+下载google图像识别网络inception-v3并查看结构/</id>
    <published>2018-01-09T10:38:04.000Z</published>
    <updated>2018-03-18T16:28:34.000Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> tarfile</span><br><span class="line"><span class="keyword">import</span> requests</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#inception模型下载地址</span></span><br><span class="line">inception_pretrain_model_url = <span class="string">'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型存放地址</span></span><br><span class="line">inception_pretrain_model_dir = <span class="string">"inception_model"</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(inception_pretrain_model_dir):</span><br><span class="line">    os.makedirs(inception_pretrain_model_dir)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取文件名，以及文件路径</span></span><br><span class="line">filename = inception_pretrain_model_url.split(<span class="string">'/'</span>)[<span class="number">-1</span>]   <span class="comment"># 获取名字inception-2015-12-05.tgz</span></span><br><span class="line">filepath = os.path.join(inception_pretrain_model_dir, filename) <span class="comment"># 拼接生成文件路径：inception_model/inception-2015-12-05.tgz</span></span><br></pre></td></tr></table></figure><p>如果是小文件的话，一次性下载就OK了，但是如果文件比较大的话，那么下载下来的文件先放在内存中，内存还是比较有压力的。所以为了防止内存不够用的现象出现，我们要想办法把下载的文件分块写到磁盘中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载模型</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(filepath):</span><br><span class="line">    print(<span class="string">"download:"</span>, filename)</span><br><span class="line">    r = requests.get(inception_pretrain_model_url, stream=<span class="keyword">True</span>) <span class="comment"># 可用于获取来自服务器的原始套接字响应</span></span><br><span class="line">    <span class="keyword">with</span> open(filepath, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> chunk <span class="keyword">in</span> r.iter_content(chunk_size=<span class="number">1024</span>):</span><br><span class="line">            <span class="keyword">if</span> chunk:</span><br><span class="line">                f.write(chunk)</span><br><span class="line">print(<span class="string">"finish:"</span>, filename)</span><br><span class="line"><span class="comment"># 解压文件</span></span><br><span class="line">tarfile.open(filepath, <span class="string">'r:gz'</span>).extractall(inception_pretrain_model_dir)</span><br></pre></td></tr></table></figure><pre><code>download: inception-2015-12-05.tgzfinish: inception-2015-12-05.tgz</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型结构存放文件</span></span><br><span class="line">log_dir = <span class="string">'inception_log'</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(log_dir):</span><br><span class="line">    os.makedirs(log_dir)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># classify_image_graph_def.pb为google训练好的模型</span></span><br><span class="line">inception_graph_def_file = os.path.join(inception_pretrain_model_dir, <span class="string">'classify_image_graph_def.pb'</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 创建一个图来存放google训练好的模型</span></span><br><span class="line">    <span class="keyword">with</span> tf.gfile.FastGFile(inception_graph_def_file, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        graph_def = tf.GraphDef()</span><br><span class="line">        graph_def.ParseFromString(f.read())</span><br><span class="line">        tf.import_graph_def(graph_def, name=<span class="string">''</span>)</span><br><span class="line">    <span class="comment"># 保存图的结构</span></span><br><span class="line">    writer = tf.summary.FileWriter(log_dir, sess.graph)</span><br><span class="line">    writer.close()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span clas
      
    
    </summary>
    
      <category term="图像识别" scheme="http://yoururl.com/categories/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/"/>
    
    
      <category term="Deep learning" scheme="http://yoururl.com/tags/Deep-learning/"/>
    
      <category term="Tensorflow" scheme="http://yoururl.com/tags/Tensorflow/"/>
    
      <category term="Neural Networks" scheme="http://yoururl.com/tags/Neural-Networks/"/>
    
      <category term="Image Recognition" scheme="http://yoururl.com/tags/Image-Recognition/"/>
    
  </entry>
  
  <entry>
    <title>递归神经网络RNN</title>
    <link href="http://yoururl.com/2018/01/07/7.+%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CRNN/"/>
    <id>http://yoururl.com/2018/01/07/7.+递归神经网络RNN/</id>
    <published>2018-01-07T10:38:04.000Z</published>
    <updated>2018-03-18T16:19:25.000Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib <span class="keyword">import</span> rnn</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 载入数据集</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data/"</span>, one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入图片28*28</span></span><br><span class="line">n_inputs = <span class="number">28</span>  <span class="comment"># 输入一行，一共有28个数据</span></span><br><span class="line">max_time = <span class="number">28</span>  <span class="comment"># 一共28行</span></span><br><span class="line">lstm_size = <span class="number">100</span>  <span class="comment"># 隐层单元</span></span><br><span class="line">n_classes = <span class="number">10</span>  <span class="comment"># 10个分类器</span></span><br><span class="line">batch_size = <span class="number">50</span> <span class="comment"># 每批次50个样本</span></span><br><span class="line">n_batch = mnist.train.num_examples // batch_size  <span class="comment"># 总批次</span></span><br></pre></td></tr></table></figure><pre><code>Extracting MNIST_data/train-images-idx3-ubyte.gzExtracting MNIST_data/train-labels-idx1-ubyte.gzExtracting MNIST_data/t10k-images-idx3-ubyte.gzExtracting MNIST_data/t10k-labels-idx1-ubyte.gz</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里None表示第一个维度可以是任意长度</span></span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">784</span>])</span><br><span class="line"><span class="comment"># 正确的标签</span></span><br><span class="line">y = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">10</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化权值</span></span><br><span class="line">weights = tf.Variable(tf.truncated_normal([lstm_size, n_classes], stddev=<span class="number">0.1</span>))</span><br><span class="line"><span class="comment"># 初始化偏置值</span></span><br><span class="line">biases = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=[n_classes]))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义RNN网络</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">RNN</span><span class="params">(X, weight, biases)</span>:</span></span><br><span class="line">    <span class="comment"># inputs = [batch_size, max_time, n_inputs]</span></span><br><span class="line">    inputs = tf.reshape(X, [<span class="number">-1</span>, max_time, n_inputs])</span><br><span class="line">    <span class="comment"># 定义LSTM基本CELL</span></span><br><span class="line">    <span class="comment"># lstm_cell = tf.contrib.rnn.core_rnn_cell.BasicLSTMCell(lstm_size)</span></span><br><span class="line">    lstm_cell = rnn.BasicLSTMCell(lstm_size) </span><br><span class="line">    <span class="comment"># final_state[state,batch_size,cell.state_size]</span></span><br><span class="line">    <span class="comment"># final_state[0] 是 cell_state</span></span><br><span class="line">    <span class="comment"># final_state[1] 是hidden_state</span></span><br><span class="line">    <span class="comment"># outputs: The RNN output 'Tensor'</span></span><br><span class="line">    <span class="comment">#    if time_major == False(default), this will be a "Tensor" shaped:</span></span><br><span class="line">    <span class="comment">#        [batch_size, max_time, cell.output_size]</span></span><br><span class="line">    <span class="comment">#    if time_major == True, this will be a "Tensor" shaped:</span></span><br><span class="line">    <span class="comment">#        [max_time, batch_size, cell.output_size]</span></span><br><span class="line">    outputs,final_state = tf.nn.dynamic_rnn(lstm_cell,inputs,dtype=tf.float32)</span><br><span class="line">    results = tf.nn.softmax(tf.matmul(final_state[<span class="number">1</span>],weights) + biases)</span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算RNN的返回结果</span></span><br><span class="line">prediction = RNN(x, weights, biases)</span><br><span class="line"><span class="comment"># 损失函数</span></span><br><span class="line">cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))</span><br><span class="line"><span class="comment"># 使用AdamOptimizer进行优化</span></span><br><span class="line">train_step = tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(cross_entropy)</span><br><span class="line"><span class="comment"># 结果存放在一个布尔型列表中</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y,<span class="number">1</span>), tf.argmax(prediction,<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 准确率</span></span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line"><span class="comment"># 初始化</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">6</span>):</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> range(n_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            sess.run(train_step, feed_dict=&#123;x:batch_xs, y:batch_ys&#125;)</span><br><span class="line">        </span><br><span class="line">        acc = sess.run(accuracy, feed_dict=&#123;x:mnist.test.images, y:mnist.test.labels&#125;)</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">"Iter "</span> + str(epoch) + <span class="string">", Testing Accuracy= "</span> + str(acc))</span><br></pre></td></tr></table></figure><pre><code>WARNING:tensorflow:From &lt;ipython-input-6-24c9d74123b9&gt;:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.Instructions for updating:Future major versions of TensorFlow will allow gradients to flowinto the labels input on backprop by default.See tf.nn.softmax_cross_entropy_with_logits_v2.Iter 0, Testing Accuracy= 0.8108Iter 1, Testing Accuracy= 0.8805Iter 2, Testing Accuracy= 0.9063Iter 3, Testing Accuracy= 0.9204Iter 4, Testing Accuracy= 0.9287Iter 5, Testing Accuracy= 0.9358</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span clas
      
    
    </summary>
    
      <category term="神经网络" scheme="http://yoururl.com/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Deep learning" scheme="http://yoururl.com/tags/Deep-learning/"/>
    
      <category term="Tensorflow" scheme="http://yoururl.com/tags/Tensorflow/"/>
    
      <category term="Neural Networks" scheme="http://yoururl.com/tags/Neural-Networks/"/>
    
  </entry>
  
  <entry>
    <title>卷积与命名空间</title>
    <link href="http://yoururl.com/2018/01/05/6-2.%E5%8D%B7%E7%A7%AF%E4%B8%8E%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4/"/>
    <id>http://yoururl.com/2018/01/05/6-2.卷积与命名空间/</id>
    <published>2018-01-04T16:00:00.000Z</published>
    <updated>2018-03-18T16:30:25.000Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br></pre></td><td class="code"><pre><span class="line">mnist = input_data.read_data_sets(<span class="string">'MNIST_data'</span>,one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#每个批次的大小</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line"><span class="comment">#计算一共有多少个批次</span></span><br><span class="line">n_batch = mnist.train.num_examples // batch_size</span><br><span class="line"></span><br><span class="line"><span class="comment">#参数概要</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">variable_summaries</span><span class="params">(var)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'summaries'</span>):</span><br><span class="line">        mean = tf.reduce_mean(var)</span><br><span class="line">        tf.summary.scalar(<span class="string">'mean'</span>, mean)<span class="comment">#平均值</span></span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'stddev'</span>):</span><br><span class="line">            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))</span><br><span class="line">        tf.summary.scalar(<span class="string">'stddev'</span>, stddev)<span class="comment">#标准差</span></span><br><span class="line">        tf.summary.scalar(<span class="string">'max'</span>, tf.reduce_max(var))<span class="comment">#最大值</span></span><br><span class="line">        tf.summary.scalar(<span class="string">'min'</span>, tf.reduce_min(var))<span class="comment">#最小值</span></span><br><span class="line">        tf.summary.histogram(<span class="string">'histogram'</span>, var)<span class="comment">#直方图</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化权值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape,name)</span>:</span></span><br><span class="line">    initial = tf.truncated_normal(shape,stddev=<span class="number">0.1</span>)<span class="comment">#生成一个截断的正态分布</span></span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial,name=name)</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化偏置</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape,name)</span>:</span></span><br><span class="line">    initial = tf.constant(<span class="number">0.1</span>,shape=shape)</span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial,name=name)</span><br><span class="line"></span><br><span class="line"><span class="comment">#卷积层</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x,W)</span>:</span></span><br><span class="line">    <span class="comment">#x input tensor of shape `[batch, in_height, in_width, in_channels]`</span></span><br><span class="line">    <span class="comment">#W filter / kernel tensor of shape [filter_height, filter_width, in_channels, out_channels]</span></span><br><span class="line">    <span class="comment">#`strides[0] = strides[3] = 1`. strides[1]代表x方向的步长，strides[2]代表y方向的步长</span></span><br><span class="line">    <span class="comment">#padding: A `string` from: `"SAME", "VALID"`</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.conv2d(x,W,strides=[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],padding=<span class="string">'SAME'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#池化层</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_2x2</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="comment">#ksize [1,x,y,1]</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.max_pool(x,ksize=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>],padding=<span class="string">'SAME'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#命名空间</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'input'</span>):</span><br><span class="line">    <span class="comment">#定义两个placeholder</span></span><br><span class="line">    x = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">784</span>],name=<span class="string">'x-input'</span>)</span><br><span class="line">    y = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">10</span>],name=<span class="string">'y-input'</span>)</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'x_image'</span>):</span><br><span class="line">        <span class="comment">#改变x的格式转为4D的向量[batch, in_height, in_width, in_channels]`</span></span><br><span class="line">        x_image = tf.reshape(x,[<span class="number">-1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>],name=<span class="string">'x_image'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'Conv1'</span>):</span><br><span class="line">    <span class="comment">#初始化第一个卷积层的权值和偏置</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'W_conv1'</span>):</span><br><span class="line">        W_conv1 = weight_variable([<span class="number">5</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">32</span>],name=<span class="string">'W_conv1'</span>)<span class="comment">#5*5的采样窗口，32个卷积核从1个平面抽取特征</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'b_conv1'</span>):  </span><br><span class="line">        b_conv1 = bias_variable([<span class="number">32</span>],name=<span class="string">'b_conv1'</span>)<span class="comment">#每一个卷积核一个偏置值</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#把x_image和权值向量进行卷积，再加上偏置值，然后应用于relu激活函数</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'conv2d_1'</span>):</span><br><span class="line">        conv2d_1 = conv2d(x_image,W_conv1) + b_conv1</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'relu'</span>):</span><br><span class="line">        h_conv1 = tf.nn.relu(conv2d_1)</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'h_pool1'</span>):</span><br><span class="line">        h_pool1 = max_pool_2x2(h_conv1)<span class="comment">#进行max-pooling</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'Conv2'</span>):</span><br><span class="line">    <span class="comment">#初始化第二个卷积层的权值和偏置</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'W_conv2'</span>):</span><br><span class="line">        W_conv2 = weight_variable([<span class="number">5</span>,<span class="number">5</span>,<span class="number">32</span>,<span class="number">64</span>],name=<span class="string">'W_conv2'</span>)<span class="comment">#5*5的采样窗口，64个卷积核从32个平面抽取特征</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'b_conv2'</span>):  </span><br><span class="line">        b_conv2 = bias_variable([<span class="number">64</span>],name=<span class="string">'b_conv2'</span>)<span class="comment">#每一个卷积核一个偏置值</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#把h_pool1和权值向量进行卷积，再加上偏置值，然后应用于relu激活函数</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'conv2d_2'</span>):</span><br><span class="line">        conv2d_2 = conv2d(h_pool1,W_conv2) + b_conv2</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'relu'</span>):</span><br><span class="line">        h_conv2 = tf.nn.relu(conv2d_2)</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'h_pool2'</span>):</span><br><span class="line">        h_pool2 = max_pool_2x2(h_conv2)<span class="comment">#进行max-pooling</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#28*28的图片第一次卷积后还是28*28，第一次池化后变为14*14</span></span><br><span class="line"><span class="comment">#第二次卷积后为14*14，第二次池化后变为了7*7</span></span><br><span class="line"><span class="comment">#进过上面操作后得到64张7*7的平面</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'fc1'</span>):</span><br><span class="line">    <span class="comment">#初始化第一个全连接层的权值</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'W_fc1'</span>):</span><br><span class="line">        W_fc1 = weight_variable([<span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>,<span class="number">1024</span>],name=<span class="string">'W_fc1'</span>)<span class="comment">#上一场有7*7*64个神经元，全连接层有1024个神经元</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'b_fc1'</span>):</span><br><span class="line">        b_fc1 = bias_variable([<span class="number">1024</span>],name=<span class="string">'b_fc1'</span>)<span class="comment">#1024个节点</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#把池化层2的输出扁平化为1维</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'h_pool2_flat'</span>):</span><br><span class="line">        h_pool2_flat = tf.reshape(h_pool2,[<span class="number">-1</span>,<span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>],name=<span class="string">'h_pool2_flat'</span>)</span><br><span class="line">    <span class="comment">#求第一个全连接层的输出</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'wx_plus_b1'</span>):</span><br><span class="line">        wx_plus_b1 = tf.matmul(h_pool2_flat,W_fc1) + b_fc1</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'relu'</span>):</span><br><span class="line">        h_fc1 = tf.nn.relu(wx_plus_b1)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#keep_prob用来表示神经元的输出概率</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'keep_prob'</span>):</span><br><span class="line">        keep_prob = tf.placeholder(tf.float32,name=<span class="string">'keep_prob'</span>)</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'h_fc1_drop'</span>):</span><br><span class="line">        h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob,name=<span class="string">'h_fc1_drop'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'fc2'</span>):</span><br><span class="line">    <span class="comment">#初始化第二个全连接层</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'W_fc2'</span>):</span><br><span class="line">        W_fc2 = weight_variable([<span class="number">1024</span>,<span class="number">10</span>],name=<span class="string">'W_fc2'</span>)</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'b_fc2'</span>):    </span><br><span class="line">        b_fc2 = bias_variable([<span class="number">10</span>],name=<span class="string">'b_fc2'</span>)</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'wx_plus_b2'</span>):</span><br><span class="line">        wx_plus_b2 = tf.matmul(h_fc1_drop,W_fc2) + b_fc2</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'softmax'</span>):</span><br><span class="line">        <span class="comment">#计算输出</span></span><br><span class="line">        prediction = tf.nn.softmax(wx_plus_b2)</span><br><span class="line"></span><br><span class="line"><span class="comment">#交叉熵代价函数</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'cross_entropy'</span>):</span><br><span class="line">    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction),name=<span class="string">'cross_entropy'</span>)</span><br><span class="line">    tf.summary.scalar(<span class="string">'cross_entropy'</span>,cross_entropy)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#使用AdamOptimizer进行优化</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'train'</span>):</span><br><span class="line">    train_step = tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line"><span class="comment">#求准确率</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'accuracy'</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'correct_prediction'</span>):</span><br><span class="line">        <span class="comment">#结果存放在一个布尔列表中</span></span><br><span class="line">        correct_prediction = tf.equal(tf.argmax(prediction,<span class="number">1</span>),tf.argmax(y,<span class="number">1</span>))<span class="comment">#argmax返回一维张量中最大的值所在的位置</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">'accuracy'</span>):</span><br><span class="line">        <span class="comment">#求准确率</span></span><br><span class="line">        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))</span><br><span class="line">        tf.summary.scalar(<span class="string">'accuracy'</span>,accuracy)</span><br><span class="line">        </span><br><span class="line"><span class="comment">#合并所有的summary</span></span><br><span class="line">merged = tf.summary.merge_all()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    train_writer = tf.summary.FileWriter(<span class="string">'logs/train'</span>,sess.graph)</span><br><span class="line">    test_writer = tf.summary.FileWriter(<span class="string">'logs/test'</span>,sess.graph)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1001</span>):</span><br><span class="line">        <span class="comment">#训练模型</span></span><br><span class="line">        batch_xs,batch_ys =  mnist.train.next_batch(batch_size)</span><br><span class="line">        sess.run(train_step,feed_dict=&#123;x:batch_xs,y:batch_ys,keep_prob:<span class="number">0.5</span>&#125;)</span><br><span class="line">        <span class="comment">#记录训练集计算的参数</span></span><br><span class="line">        summary = sess.run(merged,feed_dict=&#123;x:batch_xs,y:batch_ys,keep_prob:<span class="number">1.0</span>&#125;)</span><br><span class="line">        train_writer.add_summary(summary,i)</span><br><span class="line">        <span class="comment">#记录测试集计算的参数</span></span><br><span class="line">        batch_xs,batch_ys =  mnist.test.next_batch(batch_size)</span><br><span class="line">        summary = sess.run(merged,feed_dict=&#123;x:batch_xs,y:batch_ys,keep_prob:<span class="number">1.0</span>&#125;)</span><br><span class="line">        test_writer.add_summary(summary,i)</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">if</span> i%<span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            test_acc = sess.run(accuracy,feed_dict=&#123;x:mnist.test.images,y:mnist.test.labels,keep_prob:<span class="number">1.0</span>&#125;)</span><br><span class="line">            train_acc = sess.run(accuracy,feed_dict=&#123;x:mnist.train.images[:<span class="number">10000</span>],y:mnist.train.labels[:<span class="number">10000</span>],keep_prob:<span class="number">1.0</span>&#125;)</span><br><span class="line">            <span class="keyword">print</span> (<span class="string">"Iter "</span> + str(i) + <span class="string">", Testing Accuracy= "</span> + str(test_acc) + <span class="string">", Training Accuracy= "</span> + str(train_acc))</span><br></pre></td></tr></table></figure><pre><code>Extracting MNIST_data\train-images-idx3-ubyte.gzExtracting MNIST_data\train-labels-idx1-ubyte.gzExtracting MNIST_data\t10k-images-idx3-ubyte.gzExtracting MNIST_data\t10k-labels-idx1-ubyte.gzIter 0, Testing Accuracy= 0.1511, Training Accuracy= 0.158Iter 100, Testing Accuracy= 0.3234, Training Accuracy= 0.3288Iter 200, Testing Accuracy= 0.6009, Training Accuracy= 0.6175Iter 300, Testing Accuracy= 0.6676, Training Accuracy= 0.6708Iter 400, Testing Accuracy= 0.7332, Training Accuracy= 0.7367Iter 500, Testing Accuracy= 0.7568, Training Accuracy= 0.7615Iter 600, Testing Accuracy= 0.9263, Training Accuracy= 0.9242Iter 700, Testing Accuracy= 0.9477, Training Accuracy= 0.9438Iter 800, Testing Accuracy= 0.9544, Training Accuracy= 0.9512Iter 900, Testing Accuracy= 0.9565, Training Accuracy= 0.9532Iter 1000, Testing Accuracy= 0.9629, Training Accuracy= 0.9602</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td
      
    
    </summary>
    
      <category term="神经网络" scheme="http://yoururl.com/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Deep learning" scheme="http://yoururl.com/tags/Deep-learning/"/>
    
      <category term="Tensorflow" scheme="http://yoururl.com/tags/Tensorflow/"/>
    
      <category term="Neural Networks" scheme="http://yoururl.com/tags/Neural-Networks/"/>
    
  </entry>
  
</feed>

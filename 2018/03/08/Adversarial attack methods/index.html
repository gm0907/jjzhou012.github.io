<!DOCTYPE html>
<html lang=zh>
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="作者：Andy_z翻译文献：Threat of Adversarial Attacks on Deep Learningin Computer Vision: A Survey  对抗攻击策略总结##1.&amp;emsp;常用术语介绍  Adversarial example/image(对抗样本)：由干净样本添加了对抗扰动得到的新样本，用于欺骗机器学习模型。 Adversarial perturba">
<meta name="keywords" content="Deep learning,Summary,Adversarial attack,Translation">
<meta property="og:type" content="article">
<meta property="og:title" content="The Adversarial Attacks methods">
<meta property="og:url" content="http://yoururl.com/2018/03/08/Adversarial attack methods/index.html">
<meta property="og:site_name" content="Andy_z &#39;s Blog">
<meta property="og:description" content="作者：Andy_z翻译文献：Threat of Adversarial Attacks on Deep Learningin Computer Vision: A Survey  对抗攻击策略总结##1.&amp;emsp;常用术语介绍  Adversarial example/image(对抗样本)：由干净样本添加了对抗扰动得到的新样本，用于欺骗机器学习模型。 Adversarial perturba">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://p5bxip6n0.bkt.clouddn.com/18-3-10/67792085.jpg-Watermark">
<meta property="og:image" content="http://p5bxip6n0.bkt.clouddn.com/18-3-10/43011594.jpg-Watermark">
<meta property="og:updated_time" content="2018-03-12T12:35:27.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="The Adversarial Attacks methods">
<meta name="twitter:description" content="作者：Andy_z翻译文献：Threat of Adversarial Attacks on Deep Learningin Computer Vision: A Survey  对抗攻击策略总结##1.&amp;emsp;常用术语介绍  Adversarial example/image(对抗样本)：由干净样本添加了对抗扰动得到的新样本，用于欺骗机器学习模型。 Adversarial perturba">
<meta name="twitter:image" content="http://p5bxip6n0.bkt.clouddn.com/18-3-10/67792085.jpg-Watermark">
    
    
        
          
              <link rel="shortcut icon" href="/images/favicon.ico">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
          
        
    
    <!-- title -->
    <title>The Adversarial Attacks methods</title>
    <!-- styles -->
    <link rel="stylesheet" href="/css/style.css">
    <!-- persian styles -->
    
      <link rel="stylesheet" href="/css/rtl.css">
    
    <!-- rss --><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
    
</head>

<body class="max-width mx-auto px3 ltr">    
      <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">Inici</a></li>
         
          <li><a href="/about/">Qui som</a></li>
         
          <li><a href="/archives/">Articles</a></li>
         
          <li><a href="/projects_url">Projectes</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2018/03/12/JSMA/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" href="/2018/03/08/The-Adversarial-Attacks-on-Deep-Learning-A-Summary-1/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Post Anterior</span>
      <span id="i-next" class="info" style="display:none;">Post Següent</span>
      <span id="i-top" class="info" style="display:none;">Adalt</span>
      <span id="i-share" class="info" style="display:none;">Compartir Post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=http://yoururl.com/2018/03/08/Adversarial attack methods/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=http://yoururl.com/2018/03/08/Adversarial attack methods/&text=The Adversarial Attacks methods"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=http://yoururl.com/2018/03/08/Adversarial attack methods/&title=The Adversarial Attacks methods"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=http://yoururl.com/2018/03/08/Adversarial attack methods/&is_video=false&description=The Adversarial Attacks methods"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=The Adversarial Attacks methods&body=Check out this article: http://yoururl.com/2018/03/08/Adversarial attack methods/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=http://yoururl.com/2018/03/08/Adversarial attack methods/&title=The Adversarial Attacks methods"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=http://yoururl.com/2018/03/08/Adversarial attack methods/&title=The Adversarial Attacks methods"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=http://yoururl.com/2018/03/08/Adversarial attack methods/&title=The Adversarial Attacks methods"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=http://yoururl.com/2018/03/08/Adversarial attack methods/&title=The Adversarial Attacks methods"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=http://yoururl.com/2018/03/08/Adversarial attack methods/&name=The Adversarial Attacks methods&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#对抗攻击策略总结"><span class="toc-number">1.</span> <span class="toc-text">对抗攻击策略总结</span></a></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        The Adversarial Attacks methods
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">Andy_z 's Blog</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2018-03-08T10:38:04.000Z" itemprop="datePublished">2018-03-08</time>
        
      
    </div>


      
    <div class="article-category">
        <i class="fas fa-archive"></i>
        <a class="category-link" href="/categories/对抗攻击/">对抗攻击</a>
    </div>


      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/Adversarial-attack/">Adversarial attack</a>, <a class="tag-link" href="/tags/Deep-learning/">Deep learning</a>, <a class="tag-link" href="/tags/Summary/">Summary</a>, <a class="tag-link" href="/tags/Translation/">Translation</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <blockquote>
<p>作者：Andy_z<br>翻译文献：<a href="https://arxiv.org/abs/1801.00553" target="_blank" rel="noopener">Threat of Adversarial Attacks on Deep Learning<br>in Computer Vision: A Survey</a></p>
</blockquote>
<h1 id="对抗攻击策略总结"><a href="#对抗攻击策略总结" class="headerlink" title="对抗攻击策略总结"></a>对抗攻击策略总结</h1><p>##1.&emsp;常用术语介绍</p>
<ul>
<li>Adversarial example/image(对抗样本)：由干净样本添加了对抗扰动得到的新样本，用于欺骗机器学习模型。</li>
<li>Adversarial perturbation(对抗扰动)：使干净样本转化为对抗样本的噪声。</li>
<li>Adversarial training(对抗训练)：使用混合的对抗样本和干净样本去训练模型。</li>
<li>Adversary (攻击者)：制造对抗样本的人，有时候也指代对抗样本本身。</li>
<li>Black-box attacks(黑盒攻击)：攻击者在不清楚（或了解很少）模型的参数和结构的情况下，生成对抗样本攻击模型。</li>
<li>Detector(检测器)：用于检测一幅图像是否是对抗样本的装置。</li>
<li>Fooling ratio/rate：(欺骗率)：样本被扰动后，一个训练过的模型改变预测标签的比例。</li>
<li>One-shot/one-step methods(单步法)：使用单步计算去生成对抗扰动，相对于迭代法，后者计算量大。</li>
<li>Quasi-imperceptible(难以察觉)：轻微扰动图像，在人类视觉下无法察觉。</li>
<li>Rectifier(整流器，校正器)：整流器修改对抗样本，以恢复目标模型的预测，对应于干净版本的预测。</li>
<li>Targeted attacks(目标攻击)：欺骗机器学习模型，使之将对抗图片识别为指定标签。相对于non-targeted attacks(无目标攻击)。</li>
<li>non-targeted attacks(无目标攻击)：欺骗机器学习模型，使之将对抗图片识别为错误的任意标签。</li>
<li>Threat model(威胁模型)：指由方法考虑的潜在攻击的类型，例如， 黑盒攻击。</li>
<li>Transferability(转移性)：对抗样本对于生成模型之外的其他模型依然有效。</li>
<li>Universal perturbation(通用扰动)：添加到任何图像中，都能够以高概率愚弄的给定模型。 请注意，普遍性是指扰动的”图像的不可知”性，与’具有良好的可转移性’相反。</li>
<li>White-box attacks(白盒攻击):攻击者完全掌握了目标模型的参数，架构，训练方法，有时候包括训练数据。</li>
</ul>
<p>#2.&emsp;攻击方法分类<br>&emsp;从不同角度分类现有的攻击策略：</p>
<p>##2.1&emsp;Black/White box</p>
<p>##2.2&emsp;Targeted/Non-targeted</p>
<p>##2.3&emsp;Gradient/Optimization/others</p>
<p>##2.4&emsp;Specific/Universal</p>
<p>##2.4&emsp;One-shot/Iterative</p>
<p>&emsp;<span id="Summary-">各方法属性总结：</span></p>
<table>
<thead>
<tr>
<th>Method</th>
<th><font size="2">Black/ White box</font></th>
<th><font size="2">Targeted/ Non-targeted</font></th>
<th><font size="2">Gradient/ Optimiza tion/others</font></th>
<th><font size="2">Specific/ Universal</font></th>
<th><font size="2">perturbation norm</font></th>
<th>learn</th>
<th>strength</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#L-BFGS">L-BFGS</a></td>
<td>White-box</td>
<td>Targeted</td>
<td>-</td>
<td>Specific</td>
<td>$L_∞$</td>
<td>One-shot</td>
<td>3*</td>
</tr>
<tr>
<td><a href="#FGSM">FGSM</a></td>
<td>White-box</td>
<td>Targeted</td>
<td>Gradient</td>
<td>Specific</td>
<td>$L_∞$</td>
<td>One-shot</td>
<td>3*</td>
</tr>
<tr>
<td><a href="#BIM&amp;ILCM">BIM&amp;ILCM</a></td>
<td>White-box</td>
<td>Non-</td>
<td>Gradient</td>
<td>Specific</td>
<td>$L_∞$</td>
<td>Iterative</td>
<td>4*</td>
</tr>
<tr>
<td><a href="#JSMA">JSMA</a></td>
<td>White-box</td>
<td>Targeted</td>
<td>Gradient</td>
<td>Specific</td>
<td>$L_0$</td>
<td>Iterative</td>
<td>3*</td>
</tr>
<tr>
<td><a href="#One-Pixel">One-Pixel</a></td>
<td>Black-box</td>
<td>Non-</td>
<td>-</td>
<td>Specific</td>
<td>$L_0$</td>
<td>Iterative</td>
<td>2*</td>
</tr>
<tr>
<td><a href="#C.W-attacks">C&amp;W attacks</a></td>
<td>White-box</td>
<td>Targeted</td>
<td>-</td>
<td>Specific</td>
<td>$L_0,L_2,L_∞$</td>
<td>Iterative</td>
<td>5*</td>
</tr>
<tr>
<td><a href="#DeepFool">DeepFool</a></td>
<td>White-box</td>
<td>Non-</td>
<td>-</td>
<td>Specific</td>
<td>$L_2,L_∞$</td>
<td>Iterative</td>
<td>4*</td>
</tr>
<tr>
<td><a href="#Uni-pert">Uni.perturbation</a></td>
<td>White-box</td>
<td>Non-</td>
<td>-</td>
<td>Universal</td>
<td>$L_2,L_∞$</td>
<td>Iterative</td>
<td>5*</td>
</tr>
<tr>
<td><a href="#UPSET">UPSET</a></td>
<td>black-box</td>
<td>Targeted</td>
<td>-</td>
<td>Universal</td>
<td>$L_∞$</td>
<td>Iterative</td>
<td>4*</td>
</tr>
<tr>
<td><a href="#ANGRI">ANGRI</a></td>
<td>Black-box</td>
<td>Targeted</td>
<td>-</td>
<td>Specific</td>
<td>$L_∞$</td>
<td>Iterative</td>
<td>4*</td>
</tr>
<tr>
<td><a href="#Houdini">Houdini</a></td>
<td>Black-box</td>
<td>Targeted</td>
<td>-</td>
<td>Specific</td>
<td>$L_2,L_∞$</td>
<td>Iterative</td>
<td>4*</td>
</tr>
<tr>
<td><a href="#ATNs">ATNs</a></td>
<td>White-box</td>
<td>Targeted</td>
<td>-</td>
<td>Specific</td>
<td>$L_∞$</td>
<td>Iterative</td>
<td>4*</td>
</tr>
</tbody>
</table>
<p>#3.&emsp;<span id="L-BFGS">L-BFGS</span></p>
<p>通过对图像添加人眼不可察的微小扰动来误导神经网络做出错误分类。他们试图求解让神经网络做出错误分类的最小扰动方程，限于问题的高复杂度，他们简化了过程转而寻找最小的代价函数添加项，来误导神经网络，从而将问题转化为一个凸优化过程。  </p>
<p><a href="#Summary-">Back</a></p>
<p>#4.&emsp;<span id="FGSM">FGSM</span></p>
<p>##4.1&emsp;快速梯度符号法（FGSM）：</p>
<picture>

<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>$θ$</td>
<td>模型参数</td>
</tr>
<tr>
<td>$x$</td>
<td>模型输入</td>
</tr>
<tr>
<td>$y$</td>
<td>关于x的目标</td>
</tr>
<tr>
<td>$J(θ,x,y)$</td>
<td>损失函数  </td>
</tr>
</tbody>
</table>
<p>&emsp;将损失函数线性化为  $θ$ 的当前值，得到最优的<strong>最大范数</strong>约束扰动<br>$$<br>η=εsign(∇_xJ(θ,x,y))<br>$$<br>&emsp;称之为产生对抗样本的“快速梯度符号法”。 请注意，可以使用反向传播有效地计算所需的梯度。  </p>
<ul>
<li>FGSM在各种模型上的效果 :  </li>
</ul>
<table>
<thead>
<tr>
<th>$ε$</th>
<th>0.25</th>
<th>0.25</th>
<th>0.1</th>
</tr>
</thead>
<tbody>
<tr>
<td>测试集</td>
<td>MNIST</td>
<td>MNIST</td>
<td>CIFAR-10预</td>
</tr>
<tr>
<td>分类器</td>
<td>softmax</td>
<td>maxout</td>
<td>maxout</td>
</tr>
<tr>
<td>错误率</td>
<td>99.9％</td>
<td>89.4％</td>
<td>87.15％</td>
</tr>
<tr>
<td>平均置信度</td>
<td>79.3％</td>
<td>97.6％</td>
<td>96.6％</td>
</tr>
</tbody>
</table>
<blockquote>
<p><a href="https://github.com/lisa-lab/pylearn2/tree/master/pylearn2/scripts/papers/maxout" target="_blank" rel="noopener">预处理代码</a><br>其产生大约0.5的标准偏差。</p>
</blockquote>
<p>&emsp;其他生成对抗样本的简单方法也是可能的。 例如，我们还发现<a href="https://jjzhou012.github.io/2018/03/11/adversaria-%E6%AD%A3%E7%A1%AE%E5%88%86%E7%B1%BB-%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC-%E9%B2%81%E6%A3%92%E6%80%A7/" target="_blank" rel="noopener"><strong>在梯度方向上以小角度旋转</strong></a> $x$ 也能可靠地产生对抗样本。</p>
<ul>
<li>在ImageNet上应用GoogLeNet的快速对抗样本生成演示：  </li>
</ul>
<p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-10/67792085.jpg-Watermark" alt=""></p>
<p>&emsp;通过添加一个不可察的小矢量，其元素等于损失函数梯度的元素的符号，可以改变GoogLeNet的图像分类。这里，$ε$ 对应于GoogLeNet转换为实数后8位图像编码的最小位数的大小， 因等于0.007。  </p>
<p>&emsp;对抗样本生成过程：<br>$$<br>x ̃=x+εsign(∇_xJ(θ,x,y))<br>$$  </p>
<p><img src="http://p5bxip6n0.bkt.clouddn.com/18-3-10/43011594.jpg-Watermark" alt=""></p>
<p>##4.2&emsp;FGSM的one-step target class变体</p>
<table>
<thead>
<tr>
<th>符号</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>$X$</td>
<td>干净样本</td>
</tr>
<tr>
<td>$X^{adv}$</td>
<td>对抗图像</td>
</tr>
<tr>
<td>Misclassified adversarial image</td>
<td>误分类的对抗图像</td>
</tr>
<tr>
<td>$ε$</td>
<td>对抗扰动大小</td>
</tr>
<tr>
<td>$J(X,y_{true})$</td>
<td>用于训练模型的损失函数</td>
</tr>
</tbody>
</table>
<ul>
<li>最大化某个特定目标类 $y_{target}$ 的概率 $p(y_{target}|X)$，该目标类不可能是给定图像的真实类。 对于具有交叉熵损失的神经网络，一步目标类方法的公式：</li>
</ul>
<p>$$<br>X^{adv}=X - εsign(∇<em>XJ(X,y</em>{target}))<br>$$  </p>
<ul>
<li><p>对于目标类，我们可以选择被网络<br>$$<br>y_{LL} = arg \min_y{p(y|X)}<br>$$<br>&emsp;&emsp;&emsp;预测的最小概率的类</p>
</li>
<li><p>对于这里给定图像 $X$ 和 $y$ 的神经网络的交叉熵代价函数 $J(X,y)$ 。 故意忽略代价函数中的网络权重（和其他参数）$θ$,<br>假设它们是固定的。对于softmax输出层的神经网络，则有 整数类标签的交叉熵代价函数等于给定图像的真实类的负对数概率：<br>$$<br>J(X,y)= - \log\;p（y | X）<br>$$</p>
</li>
</ul>
<p><a href="#Summary-">Back</a></p>
<p>#5.&emsp;<span id="BIM&ILCM">BIM&amp;ILCM</span></p>
<p>##5.1&emsp;Basic iterative method(BIM):</p>
<ul>
<li>$Clip_{X,ε}{X’}$ 基于像素剪切$X’$, 结果在原图像$X$的$ε$的最大范数邻域内，剪切方程：</li>
</ul>
<p>$$<br>Clip_{X,ε}{X’}(x,y,z) = \min{255,X(x,y,z)+ε,\max{0,X(x,y,z)-ε,X’(x,y,z)}}<br>$$  </p>
<p>&emsp;&emsp;&emsp;$X(x,y,z)$ 的值为图像$X$在坐标 $(x,y)$ 处 $z$ 通道的值。</p>
<ul>
<li>对于 单步类的方法，将它扩展为很多小步，在每个步骤之后剪切中间结果的像素值以确保它们处于<br>原始图像的一个 $ε$ 邻域内：<br>$$<br>\sideset{}{^{adv}<em>0}X = X,  \sideset{}{^{adv}</em>{N+1}}X=Clip_{X,ε}{\sideset{}{^{adv}_{N}}X+αsign(ᐁ<em>XJ(\sideset{}{^{adv}</em>{N}}X,y_{true}))}<br>$$  </li>
<li>在作者的实验中，使用了 $α=1$，即在每一步中只将每个像素的值改为1。 选择迭代次数为 $\min(ε+ 4,1.25ε)$。 这种迭代量是通过启发式选择的; 对抗样本足以达到$ε$的最大范数球但有足够的限制，以保持实验的计算成本可控。</li>
</ul>
<p>##5.2&emsp;ITERATIVE LEAST-LIKELY CLASS METHOD(ILCM)<br>&emsp;前面描述的两种方法都只是试图增加正确类的成本，而没有指定模型应该选择哪些不正确的类。 这样的方法足以应用于诸如MNIST和CIFAR-10数据集，其中类别数量很少，并且所有类别彼此差异很大。 在ImageNet上，类别数量多得多，类别之间的差异程度也不同，这些方法可能导致无趣的错误分类，例如将一种雪橇犬误认为另一种雪橇犬。 为了创造更多有趣的错误，引入了迭代最不可能的类方法。</p>
<ul>
<li>这种迭代方法试图制作一个对抗图像，将其分类为特定的期望目标类别。 对于期望的类别，根据图像$X$上训练网络的预测选择最不可能的类：<br>$$<br>y_{LL} = arg \min_y{p(y|X)}<br>$$</li>
</ul>
<p>&emsp;对于训练很好的分类器，最不可能的分类通常与真实分类非常不相似，因此这种攻击方法会导致更多有趣的错误，例如将狗误认为是飞机。</p>
<ul>
<li>生成一张被分类为 $y_{LL}$ 的对抗图像，在 $sign{∇<em>X {\log}\;p(y</em>{LL}|X)}$ 方向上进行迭代来最小化 ${\log}\;p(y_{LL}|X)$，交叉熵损失的神经网络最后的表达式为 $sign{-∇<em>X J(X,y</em>{LL})}$ ，过程为下：<br>$$<br>\sideset{}{^{adv}<em>0}X = X,  \sideset{}{^{adv}</em>{N+1}}X=Clip_{X,ε}{\sideset{}{^{adv}_{N}}X-αsign(ᐁ<em>XJ(\sideset{}{^{adv}</em>{N}}X,y_{LL}))}<br>$$    </li>
</ul>
<p><a href="#Summary-">Back</a></p>
<p>#6.&emsp;<span id="JSMA">JSMA</span></p>
<p>&emsp;Papernot 等人通过限制扰动的 $L_0$ 范数，创造了一种新的对抗攻击“JSMA”。从物理上来说，这意味着只需修改图像中的几个像素，而不是扰动整个图像就能欺骗分类器。他们的算法一次修改干净图像的一个像素，并监视改动所引起的分类变化。通过使用网络层输出的梯度来计算显着图执行监视。显著图数值越大，表示欺骗网络的可能性越高，越容易获得目标标签。一旦图被计算出来，算法选择最有效的像素进行修改来欺骗网络。重复该过程，直到对抗图像中允许的像素的最大数量被改变或者愚弄成功。</p>
<p><a href="https://jjzhou012.github.io/2018/03/12/JSMA/" target="_blank" rel="noopener">JSMA</a></p>
<p><a href="#Summary-">Back</a></p>
<p>#7.&emsp;<span id="One-Pixel">One-Pixel</span></p>
<p>&emsp;一种极端的攻击方法，仅仅改变图像的一个像素实现对抗攻击。该攻击基于差分进化算法，迭代的修改每个像素值，生成子图像，和母图像进行对比，保留攻击效果最佳的子图像最终实现攻击。它对多种类型的DNN模型有效，且需要极少的对抗信息。</p>
<p><a href="#Summary-">Back</a></p>
<p>#8.&emsp;<span id="C.W-attacks">C&amp;W attacks</span></p>
<p>通过限制扰动的l_0，l_2和l_∞范数使它们难以被察觉，并且成功的突破了防御净化法。</p>
<p><a href="#Summary-">Back</a></p>
<p>#9.&emsp;<span id="DeepFool">DeepFool</span></p>
<p>&emsp;<a href="https://github.com/lts4/deepfool" target="_blank" rel="noopener">github</a>  </p>
<p>通过迭代生成最小规范扰动，将位于分类边界的图像逐步推到边界外，直到产生错误分类。</p>
<p><a href="#Summary-">Back</a></p>
<p>#10.&emsp;<span id="Uni-pert">Uni.perturbation</span><br><a href="#Summary-">Back</a></p>
<p>#11.&emsp;<span id="UPSET">UPSET</span><br><a href="#Summary-">Back</a></p>
<p>#12.&emsp;<span id="ANGRI">ANGRI</span><br><a href="#Summary-">Back</a></p>
<p>#13.&emsp;<span id="Houdini">Houdini</span></p>
<p>通过限制l_2和l_∞范数生成能适应任务损失的对抗样本来欺骗基于梯度的ML模型。该算法利用神经网络的可微损耗函数的梯度来计算扰动。</p>
<p><a href="#Summary-">Back</a></p>
<p>#14.&emsp;<span id="ATNs">ATNs</span><br><a href="#Summary-">Back</a></p>
</picture>
  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Inici</a></li>
         
          <li><a href="/about/">Qui som</a></li>
         
          <li><a href="/archives/">Articles</a></li>
         
          <li><a href="/projects_url">Projectes</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#对抗攻击策略总结"><span class="toc-number">1.</span> <span class="toc-text">对抗攻击策略总结</span></a></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=http://yoururl.com/2018/03/08/Adversarial attack methods/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=http://yoururl.com/2018/03/08/Adversarial attack methods/&text=The Adversarial Attacks methods"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=http://yoururl.com/2018/03/08/Adversarial attack methods/&title=The Adversarial Attacks methods"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=http://yoururl.com/2018/03/08/Adversarial attack methods/&is_video=false&description=The Adversarial Attacks methods"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=The Adversarial Attacks methods&body=Check out this article: http://yoururl.com/2018/03/08/Adversarial attack methods/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=http://yoururl.com/2018/03/08/Adversarial attack methods/&title=The Adversarial Attacks methods"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=http://yoururl.com/2018/03/08/Adversarial attack methods/&title=The Adversarial Attacks methods"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=http://yoururl.com/2018/03/08/Adversarial attack methods/&title=The Adversarial Attacks methods"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=http://yoururl.com/2018/03/08/Adversarial attack methods/&title=The Adversarial Attacks methods"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=http://yoururl.com/2018/03/08/Adversarial attack methods/&name=The Adversarial Attacks methods&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menú</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Compartir</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Cap amunt</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy; 2019 Andy_z
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">Inici</a></li>
         
          <li><a href="/about/">Qui som</a></li>
         
          <li><a href="/archives/">Articles</a></li>
         
          <li><a href="/projects_url">Projectes</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">

    <!-- jquery -->
<script src="/lib/jquery/jquery.min.js"></script>
<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>
<!-- clipboard -->

  <script src="/lib/clipboard/clipboard.min.js"></script>
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight .code pre").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      target: function(trigger) {
        return trigger.nextElementSibling;
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>

<script src="/js/main.js"></script>
<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

<!-- Disqus Comments -->


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>
